<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Python的内置函数]]></title>
    <url>%2F2019%2F03%2F17%2F145314-Python%E7%9A%84%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[内置函数整理https://docs.python.org/zh-cn/3.7/library/functions.html#func-set 梳理作用域相关 基于字典的形式获取局部变量和全局变量 locals() 获取全局变量的字典 globals() 获取执行本方法所在命名空间内的局部变量的字典 字符串类型代码的执行 http://www.cnblogs.com/Eva-J/articles/7266087.html 输入输出相关 input() 接收用户输入 print() 输出 数据类型相关 type(o) 返回变量o的数据类型 内存相关 id(o) o是参数，返回变量o的内存地址 hash(o) o是参数，返回一个可hash数据的哈希值，不可hash的数据被hash之后会报错 hash函数会根据一个内部的算法对当前可hash变量进行处理，返回一个int数字 每一次执行程序，内容相同的变量hash值在这一次执行过程中不会发生改变 1234567891011121314151617181920212223name = 'Tom'print(hash(name))print(hash(name))print(hash(name))print(hash(name))print(hash(name))print(hash(name))# 323377793497756635# 323377793497756635# 323377793497756635# 323377793497756635# 323377793497756635# 323377793497756635t = (1,2,3)l = [1,2,3]print(hash(t)) #可hashprint(hash(l)) #会报错'''结果：TypeError: unhashable type: 'list'''' 字典寻址方式：在查找时，首先对键进行hash运算，把求得的值当做“键-值对”的内存地址，在结构中按照此位置取“键-值对”进行比较，若键相等，则表示搜索成功。在存储“键-值对”的时候，依照相同的hash函数计算存储位置，并按此位置存放 文件操作相关 open() 打开一个文件，返回一个文件操作符(文件句柄) 迭代器/生成器相关 range() 只有 __iter_ 方法，没有__next__，因此 range()是可迭代的对象而不是生成器，range() 返回的一个可迭代对象 可以切片 next() 返回迭代器的下一个数据项 iter() 将可迭代对象生成一个迭代器 模块操作相关 __import__导入一个模块 12# 导入一个模块import time 不建议的导入方式： 12os = __import__('os')print(os.path.abspath('.')) 帮助方法 help() 在控制台执行help()进入帮助模式 可以随意输入变量或者变量的类型。输入q退出 或者直接执行help(o)，o是参数，查看和o有关的操作 dir() 默认查看全局空间内的属性，也接受一个参数，查看这个参数内的方法或变量 调用相关 callable(o)，o是参数，看这个变量是不是可调用，如果o是一个函数名，就会返回True 123def func():passprint(callable(func)) #参数是函数名，可调用，返回Trueprint(callable(123)) #参数是数字，不可调用，返回False 数字相关 数据类型相关： bool，int，float，complex 进制转换相关： bin，oct，hex 数学运算： abs，divmod，min，max，sum，round，pow 数据结构相关 序列 列表元组：list()、tuple() 字符串：str，format，bytes，bytearry，memoryview，ord，chr，ascii，repr 集合 字典和集合：dict，set，frozenset 数据集合：len，sorted，enumerate，all，any，zip，filter，map divmoddivmod(a, b) 把除数和余数运算结果结合起来，返回一个包含商和余数的元组 (a // b, a % b) ordord() 函数是 chr() 函数（对于8位的ASCII字符串）或 unichr() 函数（对于Unicode对象）的配对函数，它以一个字符（长度为1的字符串）作为参数，返回对应的 ASCII 数值，或者 Unicode 数值，如果所给的 Unicode 字符超出了你的 Python 定义范围，则会引发一个 TypeError 的异常 123456&gt;&gt;&gt;ord('a')97&gt;&gt;&gt; ord('b')98&gt;&gt;&gt; ord('c')99 chrchr(i) 用一个范围在 range（256）内的（就是0～255）整数作参数，返回一个对应的字符，i 可以是10进制也可以是16进制的形式的数字 1234&gt;&gt;&gt;print chr(0x30), chr(0x31), chr(0x61) # 十六进制0 1 a&gt;&gt;&gt; print chr(48), chr(49), chr(97) # 十进制0 1 a repr将对象转化为供解释器读取的形式 1234567s = 'RUNOOB'&gt;&gt;&gt; repr(s)"'RUNOOB'"&gt;&gt;&gt; dict = &#123;'runoob': 'runoob.com', 'google': 'google.com'&#125;;&gt;&gt;&gt; repr(dict)"&#123;'google': 'google.com', 'runoob': 'runoob.com'&#125;"&gt;&gt;&gt; %r 和 %s %r用rper()方法处理对象 %s用str()方法处理对象 例： 123text = "I am %d years old." % 22 print("I said: %s." % text )print("I said: %r." % text ) 返回结果： 12I said: I am 22 years old.. I said: 'I am 22 years old..' # %r 给字符串加了单引号 enumerate将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标，一般用在 for 循环当中 1enumerate(sequence, [start=0]) 参数： sequence 一个序列、迭代器或其他支持迭代对象 start 下标起始位置 返回值：返回 enumerate(枚举) 对象 123456789101112&gt;&gt;&gt; seasons = ['Spring', 'Summer', 'Fall', 'Winter']&gt;&gt;&gt; list(enumerate(seasons))[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]&gt;&gt;&gt; list(enumerate(seasons, start=1)) # 小标从 1 开始[(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')]&gt;&gt;&gt; seq = ['one', 'two', 'three']&gt;&gt;&gt; for i, element in enumerate(seq,1):... print i, element... 1 one2 two3 three evaleval (expression, globals=None, locals=None) ，将字符串 str 当成有效的表达式来求值并返回计算结果 example: 123456a=1g=&#123;'a':20&#125;eval("a+1",g)# 21print(eval(1+3*2))# 7 123message = "&#123;'testhost': &#123;'status': 'disabled', 'ip': '192.168.1.1'&#125;&#125;" print(eval(message))# 将字符串类型解析成字典 安全性是eval最大的缺点，假设用户恶意输入，比如： 1__import__('os').system('dir') 那么 eval() 之后，会发现当前文件夹文件都会展示到用户面前，如何避免这种情况？ 自行写检查函数； 使用 ast.literal_eval：DOCUMENT 其它：Restricted “safe” eval(Python recipe) exec执行储存在字符串或文件中的 Python 语句，相比于 eval()，exec() 可以执行更复杂的 Python 代码，但是 exec() 没有返回值 zip 将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表 若各个迭代器的元素个数不一致，则返回列表长度与最短的对象相同，利用 * 操作符可以将元组解压为列表 123456789&gt;&gt;&gt; a = [1,2,3]&gt;&gt;&gt; b = [4,5,6]&gt;&gt;&gt; c = [4,5,6,7,8]&gt;&gt;&gt; zipped = zip(a,b) # 打包为元组的列表[(1, 4), (2, 5), (3, 6)]&gt;&gt;&gt; zip(a,c) # 元素个数与最短的列表一致[(1, 4), (2, 5), (3, 6)]&gt;&gt;&gt; zip(*zipped) # 与 zip 相反，*zipped 可理解为解压，返回二维矩阵式[(1, 2, 3), (4, 5, 6)]]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的生成器和迭代器]]></title>
    <url>%2F2019%2F03%2F16%2F081510-Python%E7%9A%84%E7%94%9F%E6%88%90%E5%99%A8%E5%92%8C%E8%BF%AD%E4%BB%A3%E5%99%A8%2F</url>
    <content type="text"><![CDATA[部分内容转自： http://python.jobbole.com/87805/ https://nvie.com/posts/iterators-vs-generators/ 概要在了解 Python 的数据结构时，容器(container)、可迭代对象(iterable)、迭代器(iterator)、生成器(generator)、列表/集合/字典推导式(list,set,dict comprehension)众多概念参杂在一起，难免让初学者一头雾水，我将用一篇文章试图将这些概念以及它们之间的关系捋清楚 容器(container)容器是一种把多个元素组织在一起的数据结构，容器中的元素可以逐个地迭代获取，可以用 in , not in 关键字判断元素是否包含在容器中。通常这类数据结构把所有的元素存储在内存中（也有一些特列并不是所有的元素都放在内存）在 Python 中，常见的容器对象有： list, deque, …. set, frozensets, …. dict, defaultdict, OrderedDict, Counter, …. tuple, namedtuple, … str 容器比较容易理解，因为你就可以把它看作是一个盒子、一栋房子、一个柜子，里面可以塞任何东西。从技术角度来说，当它可以用来询问某个元素是否包含在其中时，那么这个对象就可以认为是一个容器 可迭代对象(iterable)刚才说过，很多容器都是 Iterable 对象，此外还有更多的对象同样也是 Iterable 对象，比如处于打开状态的 files，sockets 等等。但凡是可以返回一个 迭代器 的对象都可称之为 Iterable 对象，可以使用 isinstance() 判断一个对象是否是 Iterable 对象： 1234567891011&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; isinstance([], Iterable)True&gt;&gt;&gt; isinstance(&#123;&#125;, Iterable)True&gt;&gt;&gt; isinstance('abc', Iterable)True&gt;&gt;&gt; isinstance((x for x in range(10)), Iterable)True&gt;&gt;&gt; isinstance(100, Iterable)False Iterable 对象和容器一样是一种通俗的叫法，并不是指某种具体的数据类型，list，dict，set 都是 Iterable 对象示例： 12345678910111213&gt;&gt;&gt; x = [1, 2, 3]&gt;&gt;&gt; y = iter(x)&gt;&gt;&gt; z = iter(x)&gt;&gt;&gt; next(y)1&gt;&gt;&gt; next(y)2&gt;&gt;&gt; next(z)1&gt;&gt;&gt; type(x)&lt;class 'list'&gt;&gt;&gt;&gt; type(y)&lt;class 'list_iterator'&gt; 上例中 y 和 z 是两个独立的迭代器 ( iterator)，迭代器内部持有一个状态，该状态用于记录当前迭代所在的位置，以方便下次迭代的时候获取正确的元素。迭代器有一种具体的迭代器类型，比如 list_iterator，set_iterator。 可迭代对象都有 x.__iter__ 和 iter(x) 方法，这两个方法本质一样，都会返回一个迭代器。能直接作用于 for 循环的对象统称为可迭代对象，要想可迭代，内部必须有一个 __iter__ 方法。 for循环的本质例子： 123x = [1, 2, 3]for elem in x: # 定时垃圾回收机制：没有引用指向这个对象，则被回收 ... 实际上 for 循环本质上做了三件事： 调用 iter() 方法将可迭代的对象转为迭代器，即： iter(x) 不断地调用 next() 方法，返回迭代器中下一个元素的值 处理 StopIteration 异常 如图： 因此上述例子完全等价于： 1234567891011# 首先获得迭代器对象:x = [1, 2, 3]it = iter(x)# 循环:while True: try: # 获得下一个值: elem = next(it) except StopIteration: # 遇到 StopIteration 就退出循环 break 迭代器(iterator)迭代器(iterator)是一个带状态的对象，同时满足下列两个条件的对象都是迭代器： 有 __iter__() 方法：等同于 iter() ，返回迭代器自身 有 __next()__ 方法：等同于 next() ，返回容器中的下一个值，如果容器中没有更多元素了，则抛出 StopIteration 异常 12345678910111213L = [1,2,3,4]print(L.__iter__())print(iter(L))# &lt;list_iterator object at 0x009DC490&gt;# &lt;list_iterator object at 0x009DC490&gt;# 虽然二者一样，但不建议使用内置方法 __iter__ 而是使用 iter()X = iter(L) # 将可迭代对象变成迭代器print(X.__iter__())print(inter(X))# &lt;list_iterator object at 0x009DC490&gt;# &lt;list_iterator object at 0x009DC490&gt;# 如果对象本身就是迭代器对象，则返回迭代器自身 在迭代器中每次调用 next() 方法的时候做两件事： 为下一次调用 next() 方法修改状态 为当前这次调用生成返回结果 迭代器就像一个懒加载的工厂，等到有人需要的时候才给它生成值返回，没调用的时候就处于休眠状态等待下一次调用 我们都知道 range() 可以被 for 循环，也就是说它是一个可迭代对象，那么 range() 是不是一个迭代器呢？ 12print('__iter__' in dir(range(12)))print('__next__' in dir(range(12))) 还可以使用 isinstance() 判断一个对象是否是 Iterator 对象 1234from collections import Iteratorprint(isinstance(range(100), Iterator)) 生成器(generator)通过列表生成式，可以直接创建一个列表。但是受到内存限制，列表容量肯定是有限的。而且创建一个包含100万个元素的列表，不仅占用很大的存储空间，如果我们仅仅需要访问前面几个元素，那后面绝大多数元素占用的空间都白白浪费了。 所以，如果列表元素可以按照某种算法推算出来，那我们是否可以在循环的过程中不断推算出后续的元素呢？这样就不必创建完整的list，从而节省大量的空间。在 Python 中这种一边循环一边计算的机制，称为生成器（generator） 生成器表达式(generator expression)创建生成器的第一种方法很简单，只要把一个列表生成式的 [] 改成 ()，就创建了一个 generator，生成器表达式是列表生成式的生成器版本，看起来像列表生成式，但是它返回的是一个生成器对象而不是列表对象： 123456&gt;&gt;&gt; L = [x * x for x in range(5)]&gt;&gt;&gt; L[0, 1, 4, 9, 16]&gt;&gt;&gt; g = (x * x for x in range(5))&gt;&gt;&gt; g&lt;generator object &lt;genexpr&gt; at 0x012967E0&gt; 创建 L 和 g 的区别仅在于最外层的 [] 和 ()，L 是一个 list 对象，而 g 是一个 generator 对象，我们可以直接打印出 list 的每一个元素，但我们怎么打印出 generator 的每一个元素呢？ 上述例子中，列表生成式相当于做好的 5 盘菜，什么时候想吃就什么时候吃，数据都都在内存空间，什么时候想调用就调用，但是比较占空间；而生成器相当于一位厨师，现在什么菜都没有，当你想吃第一道菜的时候就可以叫厨师做出来，以此类推。如果不吃，数据永远不会生成，不占内存空间，但是算法决定了必须从第一盘菜开始吃，只有在前 9 盘菜吃完才能吃最后一盘，所以如果要打印出 generator 的每一个元素，可以通过 next() 函数获得generator 的下一个返回值： 12345678910111213141516&gt;&gt;&gt; next(g)0&gt;&gt;&gt; next(g)1&gt;&gt;&gt; next(g)4&gt;&gt;&gt; next(g)9&gt;&gt;&gt; next(g)16&gt;&gt;&gt; next(g)Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration# next(s) 等价于 s.__next__(),但不建议使用 __next__() 方法# 在 Python2 中是 s.next() generator 保存的是算法，每次调用 next(g)，就计算出 g 的下一个元素的值，直到计算到最后一个元素，没有更多的元素时抛出 StopIteration 的错误。当然，上面这种不断调用 next(g) 实在是太变态了，正确的方法是使用 for 循环，因为 generator 也是可迭代对象： 123456789&gt;&gt;&gt; g = (x * x for x in range(5))&gt;&gt;&gt; for i in g:... print(i)...014916 所以我们创建了一个 generator 后基本上永远不会调用 next()，而是通过 for 循环来迭代它，并且不需要关心 StopIteration 的错误 generator 非常强大。如果推算的算法比较复杂，用生成器表达式的 for 循环无法实现的时候，还可以用函数来实现。 比如，著名的斐波拉契数列（Fibonacci），除第一个和第二个数外，任意一个数都可由前两个数相加得到： 11, 1, 2, 3, 5, 8, 13, 21, 34, ... 斐波那契数列用列表生成式写不出来，但是用函数把它打印出来却很容易： 12345678910111213141516#!/usr/bin/env python3# -*- coding: utf-8 -*-# 1, 1, 2, 3, 5, 8, 13, 21, 34, ...def fib(max): n, prev, curr = 0, 0, 1 while n &lt; max: print(curr) prev, curr = curr, curr + prev n += 1 return 'Done'print(fib(5)) 注意，赋值语句： 1prev, curr = curr, curr + prev 相当于： 123t = (curr, curr + prev) # t 是一个tupleprev = t[0]curr = t[1] 但不必显式写出临时变量 t 就可以完成赋值 yield关键字生成器其实是一种特殊的迭代器，不过这种迭代器更加优雅。它不需要再像上面一样写 iter() 和 next() 方法了，只需要一个 yiled 关键字。 生成器一定是迭代器（反之不成立），因此任何生成器也是以一种懒加载的模式生成值。 仔细观察，可以看出，fib 函数实际上是定义了斐波拉契数列的推算规则，可以从第一个元素开始，推算出后续任意的元素，这种逻辑其实非常类似 generator。 也就是说，上面的函数和 generator 仅一步之遥。要把 fib 函数变成 generator，只需要把 print(curr) 改为 yield curr 就可以了： 12345678910111213#!/usr/bin/env python3# -*- coding: utf-8 -*-# 1, 1, 2, 3, 5, 8, 13, 21, 34, ...def fib(max): n, prev, curr = 0, 0, 1 while n &lt; max: yield curr prev, curr = curr, curr + prev n += 1 return 'Done' 这就是定义 generator 的另一种方法。如果一个函数定义中包含 yield 关键字，那么这个函数就不再是一个普通函数，而是一个 generator： 1234567f = fib(5)print(f)# &lt;generator object fib at 0x00C4F7B0&gt;# 当执行 f=fib(5) 返回的是一个生成器对象# 此时函数体中的代码并不会执行，只有显示或隐示地调用next的时候才会真正执行里面的代码print(list(f))# [1, 1, 2, 3, 5] generator 和函数的执行流程不一样。函数是顺序执行，遇到 return 语句或者最后一行函数语句就返回。而变成 generator 的函数，在每次调用 next() 的时候执行，遇到 yield 语句返回，再次执行时从上次返回的 yield 语句处继续执行。 举个简单的例子，定义一个 generator，依次返回数字 1，3，5： 12345678&gt;&gt;&gt; def odd():... print(&apos;Step 1&apos;)... yield 1... print(&apos;Step 2&apos;)... yield 3... print(&apos;Step 3&apos;)... yield 5... 调用该 generator 时，首先要生成一个 generator 对象，然后用 next() 函数不断获得下一个返回值： 123456789101112131415&gt;&gt;&gt; o = odd()&gt;&gt;&gt; next(o)Step 11&gt;&gt;&gt; next(o)Step 23&gt;&gt;&gt; next(o)Step 35&gt;&gt;&gt; next(o)Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt;StopIteration&gt;&gt;&gt; 可以看到，odd 不是普通函数，而是 generator，在执行过程中遇到 yield 就中断，下次又继续执行。执行 3 次 yield 后，已经没有 yield 可以执行了，所以，第 4 次调用 next(o) 就报错 回到 fib 的例子，我们在循环过程中不断调用 yield，就会不断中断。当然要给循环设置一个条件来退出循环，不然就会产生一个无限数列出来。 同样的，把函数改成 generator 后，我们基本上从来不会用 next()来获取下一个返回值，而是直接使用 for 循环来迭代： 12for n in fib(5): print(n) return生成器函数跟普通函数只有一点不一样，就是把 return 换成 yield，其中 yield 是一个语法糖，内部实现了迭代器协议，同时保持状态可以挂起。 在一个生成器中，如果没有 return，则默认执行到函数完毕；如果在执行过程中 return，则直接抛出 StopIteration 终止迭代 12345678910111213141516171819def f(): yield 5 print("ooo") return yield 6 print("ppp")f=f()# print(f.__next__())# print(f.__next__())for i in f: print(i)'''return 即迭代结束for 不报错的原因是内部处理了迭代结束的这种情况''' 需要注意的是 123456f=f()print(f.__next__())print(f.__next__())# 上下两种方式不同，下面的是创建了两个生成器print(f().__next__())print(f().__next__()) 生成器在 Python 中是一个非常强大的编程结构，可以用更少地使用中间变量写流式代码，此外，相比其它容器对象它更能节省内存和CPU，当然它可以用更少的代码来实现相似的功能。现在就可以动手重构你的代码了，但凡看到类似： 12345def something(): result = [] for ... in ...: result.append(x) return result 都可以用生成器函数来替换： 123def iter_something(): for ... in ...: yield x 如果直接对文件对象调用 read() 和 readlines() 方法，会导致不可预测的内存占用。好的方法是利用固定长度的缓冲区来不断读取文件内容。通过 yield，我们不再需要编写读文件的迭代类就可以轻松实现文件读取： 123456789def read_file(fpath): BLOCK_SIZE = 1024 with open(fpath, 'rb') as f: while True: block = f.read(BLOCK_SIZE) if block: yield block else: return 更加便利的方法是使用 for 循环直接对文件对象进行迭代： 1234with open('test.log','r',encoding='utf-8') as f: for i in f: # f 是个迭代器对象 # for i in f.readlines(): # readline方法中，每个元素都是一行内容，如果文件有2G则全部加载到内存 print(i) 练习 使用文件读取，找出文件中最长的行 1max(len(x.strip()) for x in open('/hello/abc','r')) 生成器有个 send() 方法，用于传入值给生成器 1234567891011def f(): print("ok") s=yield 7 print(s) yield 8f=f()print(f.send(None)) # 等同于print(next(f))print(next(f))# 执行流程:打印ok,yield7,当再next进来时:将None赋值给s,然后返回8,可以通过断点来观察 生成器面试题试题1 1234567891011121314151617def add(n, i): return n + idef test(): for i in range(4): yield ig = test()for n in [1, 10]: g = (add(n, i) for i in g)print(list(g))# 结果# 20 21 22 23 解析 1234567891011121314151617181920# 上述代码中g = test()for n in [1, 10]: g = (add(n, i) for i in g)# 可以写成g = test() # 第一个g，生成器对象n = 1g = (add(n, i) for i in g) # 第二个 g，生成器表达式n = 10g = (add(n, i) for i in g) # 第三个 g，生成器表达式# 再推算g = test()n = 1g = (add(n, i) for i in test())n = 10g = (add(n, i) for i in (add(n, i) for i in test())) # 第三个g，生成器表达式# 此时的n为10即可算出结果 总结 容器是一系列元素的集合，str、list、set、dict、file、sockets 对象都可以看作是容器，容器都可以被迭代（用在 for，while 等语句中），因此他们被称为可迭代对象。 可迭代对象实现了 iter() 方法，该方法返回一个迭代器对象。 迭代器持有一个内部状态的字段，用于记录下次迭代返回值，它实现了 __next__ 和 __iter__ 方法，迭代器不会一次性把所有元素加载到内存，而是需要的时候才生成返回结果。 生成器是一种特殊的迭代器，它的返回值不是通过 return 而是用 yield 参考链接： https://docs.python.org/zh-cn/3/library/stdtypes.html#iterator-types]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的匿名函数和递归函数]]></title>
    <url>%2F2019%2F03%2F15%2F204714-Python%E7%9A%84%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%E5%92%8C%E9%80%92%E5%BD%92%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[匿名函数 lambda匿名函数的命名规则，用 lamdba 关键字标识，冒号 : 左侧表示函数接收的参数（a,b） , 冒号 : 右侧表示函数的返回值（a+b）。 因为 lamdba 在创建时不需要命名，不需要显式地指定函数 ，所以叫匿名函数 普通函数与匿名函数的对比： 123456789101112# 普通函数def add(a,b): return a + bprint add(2,3) # 匿名函数add = lambda a,b : a + bprint add(2,3) #========输出===========55 从上面看不出来本质的区别，匿名函数主要是和其它函数搭配使用，如下： 12345678910res = map(lambda x:x**2, [1,5,7,4,8])for i in res: print(i)#========输出===========125491664 匿名函数有个限制，就是只能有一个表达式，不用写return，返回值就是该表达式的结果。 用匿名函数有个好处，因为函数没有名字，不必担心函数名冲突。此外，匿名函数也是一个函数对象，也可以把匿名函数赋值给一个变量，再利用变量来调用该函数： 123456&gt;&gt;&gt; lbd = lambda x : x * x&gt;&gt;&gt; lbd&lt;function &lt;lambda&gt; at 0x0117D618&gt;&gt;&gt;&gt; lbd(3)9&gt;&gt;&gt; 同样，也可以把匿名函数作为返回值返回，比如： 12def build(x, y): return lambda: x * x + y * y 递归函数在函数内部，可以调用其他函数。如果一个函数在内部调用自身本身，这个函数就是递归函数。 例如在计算阶乘 n! = 1 x 2 x 3 x ... x n ，用函数 fact(n) 表示 ，则 fact(n) = n! = 1 x 2 x 3 x ... x (n-1) x n = (n-1)! x n = fact(n-1) x n ，所以 fact(n) 可以表示为 n x fact(n-1)，只有 n=1 时需要特殊处理 ： 12345678910111213#!/usr/bin/env python3# -*- coding: utf-8 -*-# 1 x 2 x 3 x 4 x ... x ndef fact(n): if n == 1: return n else: return fact(n - 1) * nprint(fact(5)) 计算 fact(5) 过程如下： 12345678910===&gt; fact(5)===&gt; 5 * fact(4)===&gt; 5 * (4 * fact(3))===&gt; 5 * (4 * (3 * fact(2)))===&gt; 5 * (4 * (3 * (2 * fact(1))))===&gt; 5 * (4 * (3 * (2 * 1)))===&gt; 5 * (4 * (3 * 2))===&gt; 5 * (4 * 6)===&gt; 5 * 24===&gt; 120 使用循环的方式处理： 1234567891011121314#!/usr/bin/env python3# -*- coding: utf-8 -*-# 1 x 2 x 3 x 4 x ... x ndef fact(n): x = 1 for i in range(1, n + 1): x *= i return xprint(fact(5)) 递归函数的优点 定义简单，逻辑清晰。理论上所有的递归函数都可以写成循环的方式，但循环的逻辑不如递归清晰 递归函数的特性 必须要有一个特定的结束条件 每次进入更深一层递归时，问题规模相比上次递归都应有所减少 递归函数在很多情况下效率会很低，并且递归层次过多会导致栈溢出，堆栈扫盲 练习斐波那契数列(Fibonacci sequence )： 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, ........ 定义一个函数，接收一个参数 n 从第 3 项开始，每一项都等于前两项之和 调用函数时返回第 n 项 的结果，例如 n = 8 时，对应的项是 21 循环法： 12345678# -*- coding: utf-8 -*-def fibo(n): pre = 1 # 前一个数 lst = 1 # 后一个数 for i in range(2,n-1): # 第一个值是固定的，循环到 n-1 即可得到 n 对应的值 pre,lst = lst, pre + lst return pre + lstprint(fibo(8)) 递归法： 123456# -*- coding: utf-8 -*-def fibo(n): if n == 1 or n == 2: return 1 return fibo(n-1) + fibo(n-2)print(fibo(8))]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的闭包和装饰器]]></title>
    <url>%2F2019%2F03%2F15%2F175527-Python%E4%B8%AD%E7%9A%84%E9%97%AD%E5%8C%85%E5%92%8C%E8%A3%85%E9%A5%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[基本要点函数即对象 函数名的本质就是一个变量，保存了函数所在的内存地址 12345678910def dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: return [line.strip().split()[1] for line in fr if line.startswith('nameserver')]print(dns_resolver) # 不调用函数，直接打印函数名# 输出结果：# &lt;function dns_resolver at 0x7f23b8cbfe18&gt; 函数对象可以被赋值给变量 123456789101112131415161718def dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: return [line.strip().split()[1] for line in fr if line.startswith('nameserver')]resolver = dns_resolverprint(resolver())# 函数对象有一个 __name__ 属性，可以拿到函数的名字print(resolver.__name__)print(dns_resolver.__name__)# 输出结果：# ['192.168.127.2', '8.8.8.8', '9.9.9.9', '114.114.114.114', '1.1.1.1', '180.96.96.96']# dns_resolver# dns_resolver 函数名可以作为另外一个函数的参数 1234567891011def dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: print([line.strip().split()[1] for line in fr if line.startswith('nameserver')])def runfunc(func): func()runfunc(dns_resolver) 函数名可以作为另外一个函数的返回值 1234567891011def resolver(): def dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: return [line.strip().split()[1] for line in fr if line.startswith('nameserver')] return dns_resolverb = resolver() # 实质上就是 b = dns_resolverprint(b()) 函数名可以作为容器类型(例如列表、元组，字典)的元素 123456789101112131415161718def dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: return [line.strip().split()[1] for line in fr if line.startswith('nameserver')]resolver = dns_resolverals = [resolver, dns_resolver]print(als)for x in als: print(x()) # 输出结果：# [&lt;function dns_resolver at 0x7f29ad3b2e18&gt;, &lt;function dns_resolver at 0x7f29ad3b2e18&gt;]# ['192.168.127.2', '8.8.8.8', '9.9.9.9', '114.114.114.114', '1.1.1.1', '180.96.96.96']# ['192.168.127.2', '8.8.8.8', '9.9.9.9', '114.114.114.114', '1.1.1.1', '180.96.96.96'] 函数嵌套函数都有各自的作用域： 123456789def foo(): print('foo') def bar(): # 作用域为局部 print('bar') # bar()bar() # 全局作用域中没有函数 bar 的定义，因此报错 Python 允许创建嵌套函数，通过在函数内部 def 的关键字再声明一个函数即为嵌套： 123456789101112# 想执行inner函数,两种方法def outer(): x = 1 def inner(): print(x) return innerin_func = outer() # outer() 调用后返回 inner，即 in_func = innerin_func() # 在全局作用域直接调用 inner() 则会报错 闭包认识闭包 在一些语言中，在函数中可以（嵌套）定义另一个函数时，如果内部的函数引用了外部的函数的变量，则可能产生闭包。运行时，一旦外部的函数被执行，一个闭包就形成了，闭包中包含了内部函数的代码，以及所需外部函数中的变量的引用。闭包可以用来在一个函数与一组“私有”变量之间创建关联关系。在给定函数被多次调用的过程中，这些私有变量能够保持其持久性。 —— 维基百科 闭包(closure)是函数式编程的重要的语法结构，在 Python 的嵌套函数中，如果内部函数中对在外部作用域（但不是在全局作用域）的变量进行了引用，并且这个内部函数名被当成对象返回，这就形成了一个闭包(closure) 什么意思呢？我们来看一个例子 123456789def echo_info(name): # name 是外层函数的变量 def echo(): print(name) # 夹带了外部变量 return echo # 返回的是函数名（函数内存地址），并且是夹带着外部变量的函数printer = echo_info('Tom') # 可以理解为 printer = echoprinter() 在上述的例子中 echo 就是内部函数，并且在 echo 中引用了外部作用域的变量 name (夹藏了私货），而变量 name 是在外部作用域 echo_info 里面的，并且不是全局的作用域，函数名 echo 又作为了外层函数的返回值，此时内部函数 echo 就形成了一个闭包 。 闭包 = 函数块 + 定义函数时的环境，echo 就是函数块， name 就是环境，当然这个环境可以有很多，不止一个简单的name 闭包的用途闭包的最大用处有两个： 内部函数可以引用外部作用域的变量（上面已经提到） 让外部作用域的变量的值始终保持在内存中 闭包存在有什么意义呢？为什么需要闭包？我们来看爬取网页源码的例子： 普通方式爬取 123456789101112from urllib.request import urlopendef geturl(): url = 'https://movie.douban.com' res = urlopen(url).read() print(res)geturl()geturl()geturl() 闭包的方式爬取 123456789101112131415161718from urllib.request import urlopendef geturl(): url = 'https://movie.douban.com' def inner_geturl(): res = urlopen(url).read() print(res) return inner_geturlmy_geturl = geturl()my_geturl()my_geturl()my_geturl() 假设我们要对函数调用100次，第二种要比第一种更节省资源。因为第一种每调用一次函数，就会在内存中创建一次对象引用 url = &#39;https://movie.douban.com&#39;，调用100次就创建了一百次对象引用。而第二种是个闭包函数，对象引用 url = &#39;https://movie.douban.com&#39; 会一直在内存中存在，而不会被创建一百次。这是为什么呢？ 原因在于 geturl 是 inner_geturl 的父函数，而 inner_geturl 被赋给了一个父级函数的变量 url，这导致 inner_geturl 始终在内存中，而 inner_geturl 的存在依赖于 geturl，因此 geturl 也始终在内存中，不会在调用结束后被垃圾回收机制回收 如何判断是不是闭包闭包函数相对与普通函数会多出一个 __closure__ 的属性，里面定义了一个元组用于存放所有的 cell 对象，每个 cell 对象一一保存了这个闭包中所有的外部变量。使用它就可以判断函数是否形成了闭包： 123456789101112131415def mkinfo(name, age, sex='F'): def make(): print('Name : %s' % name) print('Age : %s' % age) print('Sex : %s' % sex) return makeecho = mkinfo('Tom', 10)print(echo.__closure__)print(echo.__closure__[0].cell_contents)print(echo.__closure__[1].cell_contents)print(echo.__closure__[2].cell_contents) 输出结果如下： 1234(&lt;cell at 0x7f099fdf67c8: int object at 0x7f099fcc5680&gt;, &lt;cell at 0x7f099fdf67f8: str object at 0x7f099fdbc180&gt;, &lt;cell at 0x7f099fdf6828: str object at 0x7f099fdddce0&gt;)10TomF 装饰器装饰器前戏假设有如下函数，被其他各种程序调用 123456789101112def dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: print([line.strip().split()[1] for line in fr if line.startswith('nameserver')])def os_release(fpath='/etc/redhat-release'): with open(fpath, 'rt', encoding='utf-8') as fr: return fr.readline() # 此处省略 N 多函数.... 现在公司要进行绩效考核，考核标准为 Python 代码中每个函数所执行的时间。 如果在每个函数中加入时间统计的功能，会造成大量雷同的代码。为了解决这个问题，我们想到可以重新定义一个函数用来专门计算时间： 12345678910111213141516171819202122232425262728#!/usr/bin/env python3# -*- coding: utf-8 -*-import timedef dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: print([line.strip().split()[1] for line in fr if line.startswith('nameserver')])def os_release(fpath='/etc/redhat-release'): with open(fpath, 'rt', encoding='utf-8') as fr: return fr.readline()# 此处省略 N 多函数....def spent_time(func): start_time = time.time() func() stop_time = time.time() print('Spent %s in %s' % (stop_time - start_time, func.__name__))spent_time(dns_resolver)spent_time(os_release) 但是这样的话，基础平台的函数修改了名字，容易被业务线的人投诉的，因为我们每次都要将一个函数作为参数传递给 spent_time 函数。而且这种方式已经破坏了原有的代码逻辑结构，之前执行业务逻辑时，执行运行 dns_resolver() 、 os_release()，但是现在不得不改成 spent_time(dns_resolver)、spent_time(os_release) ，这在生产环境是很不切合实际的，使用了装饰器就可以很好地解决这个问题。 开放封闭原则软件开发中的”开放-封闭”原则 : 封闭：已实现需求的功能代码块不应该再被修改 开放：对现有功能的扩展开放 装饰器装饰器(Decorator)本质上是一个返回函数对象的高阶函数，该函数用不需要修改源函数代码（函数体、调用方式、返回值）的前提下为其增加额外的功能，装饰器的返回值也是一个函数对象。 概括的讲，装饰器的作用就是为已经存在的对象添加额外的功能 。装饰器常用于有切面需求的场景，比如插入日志、性能测试、事务处理、缓存、权限校验等应用场景 假设我们已经在源代码的基础上单独添加了计算时间的函数 1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/env python3# -*- coding: utf-8 -*-import timedef spent_time(funcname): def inner(*args, **kwargs): begin = time.time() retval = funcname(*args, **kwargs) end = time.time() print("You have spent %s in %s" % (end - begin, funcname.__name__)) return retval return innerdef dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: print([line.strip().split()[1] for line in fr if line.startswith('nameserver')])def os_release(fpath='/etc/redhat-release'): with open(fpath, 'rt', encoding='utf-8') as fr: return fr.readline()dns_resolver = spent_time(dns_resolver)# spent_time() 调用后返回了 inner，即 dns_resolver = innerdns_resolver()# 相当于 inner()os_release = spent_time(os_release)# spent_time()调用后返回了 inner，即 os_release = innerprint(os_release('/etc/centos-release'))# 相当于 print(inner('/etc/centos-release')) 上面的代码中，函数 spent_time 就是一个装饰器， funcname 就是被装饰的对象。看起来像 dns_resolver 、os_release 被上下时间函数装饰了，并且没有改变原函数的调用方式，但是每次调用时都必须进行一次赋值操作。为了避免这种重复性赋值操作，Python 使用了 @ 语法糖： 1234567891011121314151617181920212223242526272829303132333435#!/usr/bin/env python3# -*- coding: utf-8 -*-import timedef spent_time(funcname): def inner(*args, **kwargs): begin = time.time() retval = funcname(*args, **kwargs) end = time.time() print("You have spent %s in %s" % (end - begin, funcname.__name__)) return retval return inner@spent_time # 相当于 dns_resolver = spent_time(dns_resolver) =&gt; dns_resolver = innerdef dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: print([line.strip().split()[1] for line in fr if line.startswith('nameserver')])@spent_time # 相当于 os_release = spent_time(os_release) =&gt; os_release = innerdef os_release(fpath='/etc/redhat-release'): with open(fpath, 'rt', encoding='utf-8') as fr: return fr.readline()dns_resolver()# 相当于 inner()print(os_release('/etc/centos-release'))# 相当于 print(inner('/etc/centos-release')) 如上所示，装饰器直接省去赋值操作，这样就提高了程序的可重复利用性，并增加了程序的可读性 并且 dns_resolver = spent_time(dns_resolver) 实际上是把 inner 的对象引用给了 dns_resolver ，而 inner 中的变量 funcname 之所以可以用，是因为 inner 是一个闭包函数，他引用了外部作用域 spent_time 接收到的 funcname 带参数的装饰器上面我们已经用装饰器解决了调用方式和重复赋值的问题。现在问题又来了，这个月考核完了，函数代码不需要统计花费时间了，下个月又要再次进行一次考核。最笨的办法就是，如果不考核了我们把装饰器的使用给注释掉，如果开始考核再把注释取消。如果有一千个函数的话呢，每次都要操作一千次么？虽然编辑器都有批量查找替换的功能，但实际上也是操作了一千次。那么，有没有更简单的办法呢？ 我们可以使用一个全局变量作为 flag，再配合使用可以传入参数的装饰器即可： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/env python3# -*- coding: utf-8 -*-import timeflag = Truedef show_time(flag=False): # 默认值参数，默认为False def spent_time(funcname): def inner(*args, **kwargs): if flag: begin = time.time() retval = funcname(*args, **kwargs) end = time.time() print("You have spent %s in %s" % ( end - begin, funcname.__name__)) else: retval = funcname(*args, **kwargs) return retval return inner return spent_time@show_time(flag)# 1. 函数调用：show_time(flag), 返回 spent_time# 2. 可以理解为 @spent_time, 也就是 dns_resolver = spent_time(resolver), 并且可以调用 show_time 的参数flag# 3. dns_resolver = innerdef dns_resolver(fpath='/etc/resolv.conf'): with open(fpath, 'rt', encoding='utf-8') as fr: print([line.strip().split()[1] for line in fr if line.startswith('nameserver')])@show_time(flag)def os_release(fpath='/etc/redhat-release'): with open(fpath, 'rt', encoding='utf-8') as fr: return fr.readline()dns_resolver()# 相当于 inner()print(os_release('/etc/centos-release'))# 相当于 print(inner('/etc/centos-release')) 上面的代码开发完之后，如果想用装饰器就将全局变量 flag 的值改为 True，不想用就改为 False。 对象属性复制函数对象有 __name__ 等属性，看似上面的代码吧所有问题都已经解决掉了，但是如果我们打印经过 decorator 装饰之后的原函数，它们的 __name__ 已经发生了变化： 12print("function dns_resolver's name :", dns_resolver.__name__)print("function os_release's name :", os_release.__name__) 结果如下： 12function dns_resolver&apos;s name : innerfunction os_release&apos;s name : inner 本来 dns_resolver 在没有被装饰的时候，dns_resolver.__name__ 就是 dns_resolver，而装饰后却变成了 inner&#39; ，因为返回的那个 inner() 函数名字就是 inner，所以需要把原始函数的 __name__ 等属性复制到 inner() 函数中，否则有些依赖函数签名的代码执行就会出错 不需要编写 inner.__name__ = func.__name__ 这样的代码，Python 内置的 functools.wraps 就是干这个事的，所以一个完整的 decorator 的写法如下： 1234567891011121314151617181920#!/usr/bin/env python3# -*- coding: utf-8 -*-import timefrom functools import wrapsdef spent_time(funcname): @wraps(funcname) # 这里就是专门进行属性复制的 def inner(*args, **kwargs): begin = time.time() retval = funcname(*args, **kwargs) end = time.time() print("You have spent %s in %s" % (end - begin, funcname.__name__)) return retval return inner# 下面代码省略 如果是带参数的 decorator，应该这样写： 1234567891011121314151617181920212223242526272829#!/usr/bin/env python3# -*- coding: utf-8 -*-import timefrom functools import wrapsflag = Truedef show_time(flag=False): # 默认值参数，默认为False def spent_time(funcname): @wraps(funcname) def inner(*args, **kwargs): if flag: begin = time.time() retval = funcname(*args, **kwargs) end = time.time() print("You have spent %s in %s" % ( end - begin, funcname.__name__)) else: retval = funcname(*args, **kwargs) return retval return inner return spent_time# 下面代码省略 其中 from functools import wraps 是导入 functools 模块的 wraps 功能，现在只需记住在定义 inner() 的前面加上 @wraps(funcname) 即可 由此一来，属性也完成了复制： 12function dns_resolver's name : dns_resolverfunction os_release's name : os_release 多层装饰器多层装饰器有点类似于俄罗斯套娃，来看下面代码 1234567891011121314151617def makebold(fn): def wrapper(): return "&lt;b&gt;" + fn() + "&lt;/b&gt;" return wrapper def makeitalic(fn): def wrapper(): return "&lt;i&gt;" + fn() + "&lt;/i&gt;" return wrapper @makebold@makeitalicdef hello(): return "hello alvin" hello() 多层装饰器在执行时，最先执行的时离原函数最近的一层装饰器，依次往外执行，下面用一张图理解一下上述代码中装饰器的执行过程]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的高阶函数]]></title>
    <url>%2F2019%2F03%2F14%2F2019-03-14-163816-Python%E7%9A%84%E9%AB%98%E9%98%B6%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数式编程函数是 Python 内建支持的一种封装，我们通过把大段代码拆成函数，通过一层一层的函数调用，就可以把复杂任务分解成简单的任务，这种分解可以称之为面向过程的程序设计。函数就是面向过程的程序设计的基本单元。 函数式编程中的函数这个术语不是指计算机中的函数，而是指数学中的函数，即自变量的映射。也就是说一个函数的值仅决定于函数参数的值，不依赖其他状态。比如 y=x*x 函数计算 x 的平方根，只要 x 的平方，不论什么时候调用，调用几次，值都是不变的 Python 对函数式编程提供部分支持。由于 Python 允许使用变量，因此 Python 不是纯函数式编程语言。 举例来说，现在有这样一个数学表达式： 1(1 + 2) * 3 - 4 传统的过程式编程，可能这样写： 123var a = 1 + 2;var b = a * 3;var c = b - 4; 函数式编程要求使用函数，我们可以把运算过程定义为不同的函数，然后写成下面这样： 1var result = subtract(multiply(add(1,2), 3), 4); 这段代码再演进以下，可以变成这样 1add(1,2).multiply(3).subtract(4) 这基本就是自然语言的表达了。再看下面的代码，大家应该一眼就能明白它的意思吧： 1merge([1,2],[3,4]).sort().search("2") 因此，函数式编程的代码更容易理解 要想学好函数式编程，建议使用 Erlang ，Haskell 而不是 Python 高阶函数Python 中变量可以指向函数，函数名实际上也是变量 以 Python 内置的求绝对值的函数 abs() 为例： 1234&gt;&gt;&gt; abs(-10)10&gt;&gt;&gt; abs&lt;built-in function abs&gt; 由此可见 abs(-10) 是函数调用，而 abs 是函数名称。可以理解为 abs 等同于变量名，并且函数名（变量名）相当于是一个标签，贴在了内存中函数体（变量的值）上 如果要获得函数调用结果，可以把结果赋值给变量： 123&gt;&gt;&gt; x = abs(-10)&gt;&gt;&gt; x10 函数名称也可以赋值给变量，实际上相当于重新建立了一个对象引用，并且指向了函数名所指向的对象上，也就是函数体： 123456789&gt;&gt;&gt; id(abs)10652528&gt;&gt;&gt; f = abs&gt;&gt;&gt; id(f)10652528&gt;&gt;&gt; f(-10)10&gt;&gt;&gt; f&lt;built-in function abs&gt; 高阶函数：既然变量可以指向函数，函数的参数能接收变量，那么一个函数就可以接收另一个函数的函数名作为参数，这种函数就称之为高阶函数 ，至少满足下列条件之一： 接受一个或多个函数名作为输入 输出（返回）一个函数对象 编写高阶函数，就是让函数的参数能够接收别的函数 以简单的加法器示例： 123456# -*- coding:utf-8 -*-def add(x,y,f): return f(x) + f(y)sum = add(3,-6,abs)print(sum) 返回函数对象的示例： 123456789101112# -*- coding:utf-8 -*-def foo(): x=3 def bar(): return x return barx = fooprint(x())x = foo()print(x())# &lt;function foo.&lt;locals&gt;.bar at 0x00947E40&gt;# 3 Python内置的高阶函数filter1filter(function, sequence) 对 sequence 中的 item 依次执行 function(item)，将执行结果为 True 的 item 做成一个 filter object 的迭代器返回。可以看作是过滤函数，其功能类似于带循环且带条件的列表生成式 123456789lst = ['a','b','c','d','e']def func(x): if x != 'a': return x # 这两行可以简写成 return x != 'a'retval = filter(func,lst)print(retval) # &lt;filter object at 0x00F866F0&gt; 一个 filter object 迭代器对象print(list(retval)) 把一个序列中的空（空或空白）字符串删掉，可以这么写： 12345def not_empty(s): return s and len(strip()) &gt; 0list(filter(not_empty, ['A', '', 'B', None, 'C', ' ']))# 结果: ['A', 'B', 'C'] 如果只删除空字符串而保留空白字符串： 1234retval = list(filter(None, ['A', '', 'B', None, 'C', ' ']))print(retval)# None代表不输入函数，也就是 # [x for x in ['A', '', 'B', None, 'C', ' '] if x ] map1map(function, sequence) 对 sequence 中的 item 依次执行 function(item)，将执行结果组成一个 map object 的迭代器返回，其功能近似于不带条件，只有循环的列表生成式 12345678lst = ['a','b','c','d','e']def func(x): return '&lt;-' + x + '-&gt;'retval = map(func,lst)print(retval) # &lt;map object at 0x00D76770&gt; 一个 map object 迭代器对象print(list(retval)) # ['&lt;-a-&gt;', '&lt;-b-&gt;', '&lt;-c-&gt;', '&lt;-d-&gt;', '&lt;-e-&gt;'] map 也支持多个 sequence，这就要求 function 也支持相应数量的参数输入： 1234ef add(x,y): return x+yprint (list(map(add, range(10), range(10))))#[0, 2, 4, 6, 8, 10, 12, 14, 16, 18] 我们不但可以使用 map 函数计算简单的算术运算，还可以计算任意复杂的函数，比如把一个list所有数字转为字符串： 12&gt;&gt;&gt; list(map(str, [1, 2, 3, 4, 5, 6, 7, 8, 9]))['1', '2', '3', '4', '5', '6', '7', '8', '9'] sorted1sorted(iterable, /, *, key=None, reverse=False) 返回一个列表对象 列表对象的 sort 方法是在源数据的基础上进行的排序，因此源列表发生了变化 sorted() 方法重新生成了一个新对象，不改变原数据 使用sorted时内存会有两份数据容易造成内存空间占用过高 对list进行排序： 12&gt;&gt;&gt; sorted([36, 5, -12, 9, -21])[-21, -12, 5, 9, 36] 它可以接收一个key函数来实现自定义的排序，例如按绝对值大小排序： 12&gt;&gt;&gt; sorted([36, 5, -12, 9, -21], key=abs)[5, 9, -12, -21, 36] key指定的函数将作用于list的每一个元素上，并根据key函数返回的结果进行排序。对比原始的list和经过key=abs处理过的list： 123list = [36, 5, -12, 9, -21]keys = [36, 5, 12, 9, 21] 然后sorted()函数按照keys进行排序，并按照对应关系返回list相应的元素： 123keys排序结果 =&gt; [5, 9, 12, 21, 36] | | | | |最终结果 =&gt; [5, 9, -12, -21, 36] 我们再看一个字符串排序的例子： 12&gt;&gt;&gt; sorted([&apos;bob&apos;, &apos;about&apos;, &apos;Zoo&apos;, &apos;Credit&apos;])[&apos;Credit&apos;, &apos;Zoo&apos;, &apos;about&apos;, &apos;bob&apos;] 默认情况下，对字符串排序，是按照ASCII的大小比较的，由于&#39;Z&#39; &lt; &#39;a&#39;，结果，大写字母Z会排在小写字母a的前面。 现在，我们提出排序应该忽略大小写，按照字母序排序。要实现这个算法，不必对现有代码大加改动，只要我们能用一个key函数把字符串映射为忽略大小写排序即可。忽略大小写来比较两个字符串，实际上就是先把字符串都变成大写（或者都变成小写），再比较。 这样，我们给sorted传入key函数，即可实现忽略大小写的排序： 12&gt;&gt;&gt; sorted([&apos;bob&apos;, &apos;about&apos;, &apos;Zoo&apos;, &apos;Credit&apos;], key=str.lower)[&apos;about&apos;, &apos;bob&apos;, &apos;Credit&apos;, &apos;Zoo&apos;] 要进行反向排序，不必改动key函数，可以传入第三个参数reverse=True： 12&gt;&gt;&gt; sorted([&apos;bob&apos;, &apos;about&apos;, &apos;Zoo&apos;, &apos;Credit&apos;], key=str.lower, reverse=True)[&apos;Zoo&apos;, &apos;Credit&apos;, &apos;bob&apos;, &apos;about&apos;] 从上述例子可以看出，高阶函数的抽象能力是非常强大的，而且，核心代码可以保持得非常简洁。 reduce1reduce(function, sequence, starting_value) 高阶函数之一，对 sequence 中的 item 顺序迭代调用 function ，如果有 starting_value，还可以作为初始值调用 对一个序列求和，就可以用 reduce 实现 ，当然求和运算可以直接用 Python内建函数sum()，没必要动用reduce 12345678910from functools import reducedef add(x,y): return x+yprint (reduce(add, range(1, 101)))# 5050 （注：1+2+...+99+100） print (reduce(add, range(1, 101), 20))# 5070 （注：20+1+2+...+99+100） 但是如果要把序列 [1, 3, 5, 7, 9] 变换成整数 13579，reduce就可以派上用场： 123456&gt;&gt;&gt; from functools import reduce&gt;&gt;&gt; def fn(x, y):... return x * 10 + y...&gt;&gt;&gt; reduce(fn, [1, 3, 5, 7, 9])13579 假设Python中没有int() 函数，我们完全可以使用 map 和 lambda 实现这一功能： 12345678910111213from functools import reduceseq = ['1','3','5','7','9']DIGITS = &#123;'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7, '8': 8, '9': 9&#125;def char2num(x): return DIGITS[x]def str2int(s): return reduce(lambda x,y:x*10+y,map(char2num,s))print(str2int(seq))]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的函数]]></title>
    <url>%2F2019%2F03%2F13%2F110851-Python%E7%9A%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数及特性 定义：函数是指将一组语句的集合通过一个名字(函数名)封装起来，要想执行这个函数，只需调用其函数名即可 特性： 减少重复代码，提高应用的模块性和代码的重复利用率，用来实现单一，或相关联功能 可扩展性：方便修改，更容易扩展代码的功能 保持代码的一致性，修改函数功能之后所有调用函数的地方都会随之修改 函数的定义和调用 格式：Python 定义函数使用 def 关键字，一般格式如下： 1234567def 函数名（参数列表）: 函数体def hello(): print('hello') hello()#调用 函数名的命名规则，与变量名类似： 函数名区分大小写 函数名只能是 字母、数字 或 下划线 的任意组合，不能使用任何的标点符号 函数名不能以数字开头 函数名不能与 Python 的关键字同名 函数的参数任何传入参数和自变量必须放在圆括号中间。圆括号之间可以用于定义参数 形参和实参 形参：形式参数，不是实际存在，是虚拟变量。在定义函数和函数体的时候使用形参，目的是在函数调用时接收实参（实参个数，类型应与实参一一对应） 实参：实际参数，调用函数时传给函数的参数，可以是常量，变量，表达式，函数，传给形参 区别：形参是虚拟的，不占用内存空间，形参变量只有在被调用时才分配内存单元，实参是一个变量，占用内存空间，数据传送单向，实参传给形参，不能形参传给实参 12345import timetimes=time.strftime('%Y-%m-%d')def f(time): print('Now time is : %s'%times)f(times) 传入函数的参数位置参数位置参数也叫必备参数，必须要传，并且在传参时必须以正确的顺序传入函数，调用时的数量必须和函数声明时的一样 12345def f(name,age): print('I am %s,I am %d years old.'%(name,age)) f('Tom',18)f('Jerry',16) 关键字参数关键字参数和函数调用关系紧密，函数调用使用关键字参数来确定传入的参数值。 使用关键字参数允许函数调用时参数的顺序与声明时不一致，因为 Python 解释器能够用参数名匹配参数值 12345def f(name,age): print('I am %s,I am %d years old.'%(name,age)) # f(16,'Tom') #报错f(age=16,name='Tom') 定义函数时的参数默认参数默认参数也叫缺省参数，同时也是关键字参数，调用函数时缺省参数的值如果没有传入，则被认为是默认值。默认参数常用于多数情况下对象的值是固定的情况，例如一个班级的每个学生的班号都是固定的 1234567def echo_info(name,age,sex='male'): print('Name:%s' %name) print('Age:%d' %age) print('Sex:%s' %sex) echo_info('Tom',18)echo_info('Jerry',40,'female') 默认参数的陷阱： 在定义函数时，如果默认参数的值是可变数据类型，那么每一次调用函数的时候如果不传入值，就会公用这个数据类型的资源，即每次都操作的是同一个对象。例如： 12345678def test(names=[]): names.append('Tom') print(names) test()test()test()test() 输出结果： 1234['Tom']['Tom', 'Tom']['Tom', 'Tom', 'Tom']['Tom', 'Tom', 'Tom', 'Tom'] 再比如： 12345678def atest(k, data=&#123;&#125;): data[k] = 'v' print(data)atest(1)atest(2)atest(3) 输出结果 123&#123;1: 'v'&#125;&#123;1: 'v', 2: 'v'&#125;&#123;1: 'v', 2: 'v', 3: 'v'&#125; 不定长参数你可能需要一个函数能处理比当初声明时更多的参数。这些参数叫做不定长参数，也叫动态参数。动态参数和位置参数、关键字参数不同，声明时不会命名 例如下面的加法器，能且只能接收三个参数，并求出和 12345def add(x, y, z): print(x + y + z)add(1, 2, 3) 加了星号 * 的变量名会以元组的形式存放所有 未命名 的变量参数 123456789def add(*args): print(args) the_sum = 0 for i in args: the_sum += i print(the_sum)add(1, 2, 3, 4, 6, 9, 10) 下面的打印基本信息的函数，最多只能接收三个参数，如果再想添加其他参数就需要重新定义函数的参数 1234567def echo_info(name, age, sex='male'): print('Name : %s' % name) print('Age : %d' % age) print('Sex : %s' % sex)echo_info('Tom', 18) 而加了 ** 的变量名会以字典的形式存放 有命名 的变量参数 12345678def echo_info(*args, **kwargs): print(args) print(kwargs) for i in kwargs: print('%s : %s' % (i, kwargs[i]))echo_info('Tom', 18, 'male', Job='IT', Height='188') 参数的位置关系 定义函数时 *args 放左边，**kwargs 放右边，下面是错误的写法 1def print_info(name, **kwargs, *args): # 报错 按照规范，定义函数时默认参数应该放在位置参数之后 12345def test(name, age, *args, sex='fmale', **kwargs):def test(*args, sex='fmale'):# 不规范的写法：# def test(name, age, sex='fmale', *args, **kwargs):# def test(sex='fmale', *args): 调用函数进行传参时，关键字参数应该放在位置(必备)参数之后 123echo_info('Tom', 18, hobby='girl', nationality='Chinese', ability='Python')# echo_info(hobby='girl', 'alex', 18, nationality='Chinese', ability='Python') #报错# echo_info('Jerry', hobby='girl', 18, nationality='Chinese', ability='Python') #报错 其他传参方式函数在接收动态参数时，会把接收的参数聚合成一个元组 123456def func(*args): print(args)func(1, 2, 3)func(['a', 'b', 'c']) 输出结果： 12(1, 2, 3)(['a', 'b', 'c'],) 而在函数中使用 *args 的方式调用参数时，会把聚合的元组打散 123456def func(*args): print(*args)func(1, 2, 3)func(['a', 'b', 'c']) 输出结果： 123456def func(*args): print(*args)func(1, 2, 3)func(['a', 'b', 'c']) 这种方式其实又还原成了最原始传入参数的方式，这种情况最常用的情形是在装饰器内： 123456789101112131415def wrapper(funcname): def inner(*args, **kwargs): # 函数接收参数，聚合成一个元组 retval = funcname(*args, **kwargs) # 调用参数，打散元组，还原初始传入形式 print('Something') return retval return inner@wrapperdef func(s): print(s)func([1, 2, 3]) 如果传给函数的参数是个列表或元组，还可以使用 * 将其打散之后传入 12345678910def func(*args): print(args)func([1, 2, 3])func(*[1, 2, 3])# 将列表打散， 等同于# *[1, 2, 3] &lt; == &gt; 1, 2, 3func(1, 2, 3) 输出结果： 123([1, 2, 3],)(1, 2, 3)(1, 2, 3) 如果函数接收的是 **kwargs ，那么单纯地传入字典会被识别为位置参数，必须打散才能被接收 1234567def func(**kargs): print(kargs)# func(&#123;'Name': 'Jerry'&#125;) # 错误传参func(**&#123;'name': 'Tom'&#125;) 输出结果： 1&#123;'name': 'Tom'&#125; 函数的返回值要想获取函数的执行结果，就可以用 return 语句把结果返回 注意: 函数在执行过程中只要遇到 return 语句，就会停止执行并返回结果，也可以理解为 return 语句代表着函数的结束 如果未在函数中指定 return，那这个函数的返回值为 None return 可以接收多个对象，此时 python 会将多个对象封装成一个元组，并将这个元组对象返回 12345678910111213#!/usr/bin/env python3# -*- coding:utf-8 -*-def get_os_release(fpath='/etc/redhat-release'): with open(fpath, 'rt', encoding='utf-8') as fr: return fr.readline().strip()x = get_os_release()y = get_os_release('/etc/issue')print(x)print(y) 函数的注释定义了函数后，应该对整个函数作注释而不是逐行注释。以下是建议的注释方式： 1234567def func(name,sex): ''' 函数的作用 参数1：数据类型，用途 参数2：数据类型，用途 ''' pass 命名空间从 python 解释器开始执行代码之后，就在内存中开辟了一个空间，每当遇到一个变量的时候，就把变量名和值之间的对应关系记录下来 但是当遇到函数定义的时候解释器只是象征性的将函数名读入内存，表示知道这个函数的存在了，至于函数内部的变量和逻辑解释器根本不关心 等执行到函数调用的时候，python解释器会再开辟一块内存来存储这个函数里的内容，这个时候才关注函数里面有哪些变量，而函数中的变量会存储在新开辟出来的内存中。函数中的变量只能在函数的内部使用，并且会随着函数执行完毕，这块内存中的所有内容也会被清空 命名空间：存放名字与值的绑定关系的空间，分为三种： 代码在运行一开始创建的存储“变量名与值的关系”的空间叫做全局命名空间 在函数的运行中开辟的临时的空间叫做局部命名空间 内置命名空间中存放了python解释器为我们提供的名字：input,print,str,list,tuple… 三种命名空间之间的加载顺序： 内置命名空间(程序运行前加载) -&gt; 全局命名空间(程序运行中：从上到下加载) -&gt; 局部命名空间(程序运行中：调用时才加载) 取值顺序： 在局部调用：局部命名空间 -&gt; 全局命名空间 -&gt; 内置命名空间 在全局调用：全局命名空间 -&gt; 内置命名空间 作用域作用域就是作用范围，按照生效范围可以分为两类： 全局作用域：包含内置命名空间、全局命名空间，在整个文件的任意位置都能被引用、全局有效 局部作用域：局部命名空间，只能在局部范围内生效 使用 globals 和 locals 方法则会以字典类型返回当前位置的全局变量和局部变量： 全局调用 12print(globals())print(locals()) 局部调用 1234567def func(): a = 12 b = 20 print(locals()) print(globals())func() 作用域介绍python中的作用域分4种情况： L：local，局部作用域，即函数中定义的变量； E：enclosing，嵌套的父级函数的局部作用域，即包含此函数的上级函数的局部作用域，但不是全局的； G：global，全局变量，就是模块级别定义的变量； B：built-in，系统固定模块里面的变量，比如 int, bytearray 等。 搜索变量的优先级顺序依次是：局部作用域 &gt; 外层作用域 &gt; 当前模块中的全局 &gt; python内置作用域，也就是LEGB 12345678910111213141516171819x = int(2.9) # int built-ing_count = 0 # globaldef outer(): o_count = 1 # enclosing def inner(): i_count = 2 # local print(o_count) # print(i_count) 找不到 inner()outer()# print(o_count) #找不到 并且，local 和 enclosing 是相对的，enclosing 变量相对上层来说也是 local 作用域产生在 Python 中只有模块（module），类（class）以及函数（def、lambda）才会引入新的作用域，其它的代码块（如 if、try、for 等）是不会引入新的作用域的，如下代码中 if 并没有引入一个新的作用域，x 仍处在当前作用域中，后面代码可以使用 123if 2&gt;1: x = 1print(x) # 1 但是函数 def、class、lambda 会引入新的作用域 123def test(): x = 2print(x) # NameError: name 'x' is not defined 变量的修改123456x=6def f2(): print(x) x=5f2()# local variable 'x' referenced before assignment. 上述代码出现错误的原因在于 print(x) 时，解释器会先在局部作用区域找到变量 x 。这是因为在进行函数调用（ f2() ）之前，其前面的代码包括函数都会先加载到内存，因此执行到 print(x) 会先在局部区域找到 x=5 ，但 x 的使用出现在 x 的声明前了，所以报错 123456#x=6def f2(): print(x) #x=5f2()# name 'x' is not defined 上述代码出现错误的原因在于 print(x) 时，解释器会在局部作用域找，找不到 变量 x 的声明，然后去全局作用域找也找不到，最后在 Python 的内置区域找也找不到，因此会报变量未声明的错误 1234x=6def f2(): x+=1 #local variable 'x' referenced before assignment.f2() x += 1 即 x = x + 1 是先加再赋值，解释器会在局部作用域找，会找到 x += 1 (函数已经加载到内存)，但 x 的加法运算出现在赋值前了，所以报错 关键字 global当内部作用域想修改外部作用域的变量时，就要用到 global 和 nonlocal 关键字了，当修改的变量是在全局作用域（global 作用域）上的，就要使用 global 先声明一下。例如： 123456789count = 10def outer(): global count print(count) count = 100 print(count)outer()#10#100 关键字 nonlocal关键字 global 声明的变量必须在全局作用域上，不能应用在嵌套作用域上，当要修改嵌套作用域（enclosing作用域，外层非全局作用域）中的变量怎么办呢，这时就需要 nonlocal 关键字了： 1234567891011def outer(): count = 10 def inner(): nonlocal count count = 20 print(count) inner() print(count)outer()#20#20 小结 对于一个变量，内部作用域先声明就会覆盖外部变量，不在内部声明而直接使用，就会使用外部作用域的变量 内部作用域要修改外部作用域变量的值时，全局变量要使用 global 关键字，嵌套作用域变量要使用 nonlocal 关键字。nonlocal 是 python3 新增的关键字，有了这个关键字就能完美的实现闭包了。]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python对文件的操作]]></title>
    <url>%2F2019%2F03%2F11%2F124110-Python%E5%AF%B9%E6%96%87%E4%BB%B6%E7%9A%84%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Python的文件操作什么是IO在计算机中 I/O 是指 Input/Output，即 Stream (流)的输入和输出，输入和输出是相对于内存来说的。程序运行时数据都驻留在在内存当中，由 CPU 这个超快的计算机核心来执行，涉及到数据交换的地方，通常是磁盘、网络操作就需要 IO 接口。 在 IO 编程中可以把流想象成一个水管，数据就是水管里的水，但是只能单向流动。Input Stream（输入流）是指数据从外（磁盘、网络）流进内存，Output Stream 是数据从内存流出到外面（磁盘、网络）。 由于 CPU 和内存的速度远远高于外设的速度，所以在 IO 编程中，就存在速度严重不匹配的问题。举个例子来说，比如要把 100M 的数据写入磁盘，CPU 输出 100M 的数据只需要 0.01 秒，可是磁盘要接收这 100M 数据可能需要 10 秒，怎么办呢？有两种办法： 第一种是 CPU 处于等待状态，也就是程序暂停执行后续代码，等到 100M 的数据在 10 秒后写入磁盘，再接着往下执行，这种模式称为同步IO； 第二种是 CPU 不等待，只是告诉磁盘，“您老慢慢写，不着急，我接着干别的事去了”，于是后续代码可以立刻接着执行，这种模式称为异步IO； 同步和异步的区别就在于是否等待 IO 执行的结果，举个去肯德基吃汉堡的例子： 同步IO：你说“来个汉堡”，服务员告诉你，对不起，汉堡要现做，需要等5分钟，于是你站在收银台前面等了5分钟，拿到汉堡再去逛商场，这是同步IO。 异步IO：你说“来个汉堡”，服务员告诉你，汉堡需要等5分钟，你可以先去逛商场，等做好了，我们再通知你，这样你可以立刻去干别的事情（逛商场） 很明显，使用异步IO来编写程序性能会远远高于同步IO，但是异步IO的缺点是编程模型复杂。想想看，你得知道什么时候通知你“汉堡做好了”，而通知你的方法也各不相同。如果是服务员跑过来找到你，这是回调模式，如果服务员发短信通知你，你就得不停地检查手机，这是轮询模式。总之，异步IO的复杂度远远高于同步IO。 操作IO的能力都是由操作系统提供的，每一种编程语言都会把操作系统提供的低级C接口封装起来方便使用，Python也不例外 以上内容转自 [廖雪峰的官方网站] 文件读写读写文件是最常见的IO操作，Python 内置了读写文件的函数，用法和C是兼容的。 在磁盘上读写文件的功能都是由操作系统提供的，现代操作系统不允许普通的程序直接操作磁盘，所以读写文件就是请求操作系统打开一个文件对象（通常称为文件描述符），然后通过操作系统提供的接口从这个文件对象中读取数据（读文件），或者把数据写入这个文件对象（写文件）。 在 Python 中对文件操作的步骤： 打开文件，得到文件对象（文件描述符）赋值给一个变量 通过文件描述符对文件进行操作 关闭文件 文件打开模式1234567891011121314151617181920212223242526272829303132'r' open for reading (default)# 以只读模式打开文件（默认模式），并将文件指针指向文件头；如果文件不存在会报错'w' open for writing, truncating the file first# 以只写模式打开文件，并将文件指针指向文件头；如果文件存在则将其内容清空，如果文件不存在则创建'x' create a new file and open it for writing# 以只写模式新建文件，并将文件指针指向文件头；如果文件存在则抛出 FileExistsError'a' open for writing, appending to the end of the file if it exists# 以追加可写模式打开文件，并将文件指针指向文件尾部；如果文件不存在则创建'b' binary mode# 二进制模式，需要与上面几种模式搭配使用，如ab，wb, ab, ab+'t' text mode (default)# 普通文本模式（默认模式）'+' open a disk file for updating (reading and writing)# 在原有操作基础上补充其他操作功能'r+'# 在 r 的基础上增加了可写功能# 覆盖当前文件指针所在位置的字符，如原来文件内容是"Hello，World"，打开文件后写入"hi"则文件内容会变成"hillo, World"'w+'# 在w的基础上增加了可读功能# 'w+'与 r+ 的不同是，w+在打开文件时就会先将文件内容清空，和 w 基本相同'a+'# 在 a 的基础上增加了可读功能# a+ 与 r+ 的不同是， a+ 不管指针在哪只能写到文件末尾(读指针和写指针不相同) 读取文件例如现有文件 ‘poem’ 内容如下： 12345关关雎鸠，在河之洲。窈窕淑女，君子好逑。参差荇菜，左右流之。窈窕淑女，寤寐求之。求之不得，寤寐思服。悠哉悠哉，辗转反侧。参差荇菜，左右采之。窈窕淑女，琴瑟友之。参差荇菜，左右芼之。窈窕淑女，钟鼓乐之。 使用内置 open() 函数，传入文件名和标示符，指定文件编码并且以 read 模式打开文件： 12f = open('poem', 'rt', encoding='utf-8')# 如果文件不存在，open() 函数会抛出一个 IOError 的异常，并且给出错误码和详细的信息告诉你文件不存在 调用 read() 方法一次读取文件全部内容到内存，用一个 str 对象表示，并使用 print() 将内容输出到屏幕 1print(f.read()) 文件使用完毕后必须关闭，因为文件对象会占用操作系统的资源，并且操作系统同一时间能打开的文件数量也是有限的： 1f.close() 注意: 打开文件时 open() 函数是通过操作系统打开的文件，如果不指定文件编码方式则默认使用操作系统自身文件编码方式打开，并且在内存中是Unicode形式。在windows系统中，’poem’ 文件是 utf-8 保存的，而Windows的默认编码是 gbk 编码，所以直接打开会乱码，需要 f=open(&#39;poem&#39;,encoding=&#39;utf8&#39;)，’poem’ 文件如果是 gbk 保存的则直接打开即可 由于文件读写时都有可能产生 IOError ，一旦出错，后面的 f.close() 就不会调用。所以为了保证无论是否出错都能正确地关闭文件，我们可以使用 try ... finally 来实现： 123456try: # 执行代码，可能抛出异常 f = open('poem', 'r') print(f.read())finally: # 不管有无异常都执行 if f: f.close() 但是每次都这么写实在太繁琐，所以 Python 引入了 with 语句来自动帮我们调用 close() 方法： 12with open('poem', 'r') as f: print(f.read()) 这和前面的 try ... finally 是一样的，但是代码更加简洁并且不必调用 f.close() 方法 ，而且无论在这段代码的任何地方，如果发生异常，此时文件仍会被关闭。 读取文件常用方法 方法 描述 read() 一次读取文件所有内容，返回一个 str read(size) 每次最多读取指定长度的内容，返回一个str；Python3中 size 指定的是字符(非字节)长度 readlines() 一次读取文件所有内容，按行返回一个list readline() 每次只读取一行内容 seek(n) 将文件指针移动到指定字节的位置 tell() 获取当前文件指针所在字节位置 我们已经知道，对文件的读取操作需要将文件中的数据加载到内存 ，调用 read() 会一次性读取文件的全部内容，如果文件有10G，内存就爆了，所以为了保险起见，可以反复调用 read(size) 方法，每次最多读取 size 个字符的内容。另外调用 readline() 可以每次读取一行内容，调用 readlines() 一次读取所有内容并按行返回 list。因此要根据需要决定怎么调用。 如果文件很小，read() 一次性读取最方便；如果不能确定文件大小，反复调用 read(size) 比较保险；如果是配置文件，调用 readlines() 最方便： 1234with open('/etc/resolv.conf', 'rt', encoding='utf-8') as fr: for line in fr.readlines(): # 一次读取所有内容并返回列表(list) if line.startswith('nameserver'): print(line.strip()) 如果文件比较大，则可以使用迭代器的方法，它在你每次你需要下一个值的时候给你返回，没调用的时候就处于休眠状态等待下一次调用 1234with open('/etc/resolv.conf', 'rt', encoding='utf-8') as fr: for line in fr: # for 内部将文件对象 fr 做成一个迭代器，用一行取一行 if line.startswith('nameserver'): print(line.strip()) 需要注意的是，在 Python3 中使用 read() 时传入的参数是字符个数而不是字节，而 tell() 返回的是字节的位置，在 utf-8 中一个中文字符占三个字节： 1234with open('poem','r',encoding='utf-8') as f: print(f.tell()) print(f.read(5)) print(f.tell()) 返回结果： 1230关关雎鸠，15 写入文件写文件和读文件都需要调用 open() ，当以 &#39;w&#39; 模式写入文件时，如果文件已存在，会直接覆盖（相当于删掉后新写入一个文件）。以 &#39;a&#39; 模式写入文件时，会以追加（append）模式追加到文件末尾 123f = open('test.txt', 'w')f.write('Hello world')f.close() 可以反复调用 write() 来写入文件，但是务必要调用 f.close() 来关闭文件。当我们写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存缓存起来，空闲的时候再慢慢写入。只有调用 close() 方法时，操作系统才保证把没有写入的数据全部写入磁盘。忘记调用 close() 的后果是数据可能只写了一部分到磁盘，剩下的丢失了。所以还是用 with 语句来得保险： 12with open('test.txt','w') as f: f.write('Hello World') 其他方法 flush()：刷新缓冲区数据，立刻将缓冲区的数据写入硬盘中的文件 1234567import sys,timefor i in range(30): sys.stdout.write('*') # stdout 标准输出，也是一个文件 sys.stdout.flush() # 实时将内存中的数据写入标准输出文件 # 如果不写此行则数据会保留着内存缓冲区，直到sleep完成并一次性显示所有符号 time.sleep(0.1) 内置的 print() 也有 flush 参数 1234import sys,timefor i in range(30): print('*',end='',flush=True) time.sleep(0.1) truncate() ：裁切数据 如果不加任何参数，则裁切(删除)掉开头到结尾的内容 如果指定一个数字N，则将第N个字符后的内容全部截掉，保留前N个字符 123with open('poem2','a',encoding='utf-8') as f:# 文件打开模式应该是 append 而不是 write ，因为 write 会先清除所有内容 f.truncate(5) isatty()：判断文件是否是终端文件 next() ：返回文件下一行，这个方法也是 file 对象实例可以被当做迭代器使用的原因 fileno() ：返回一个整型的文件描述符，可以用于一些底层 IO 操作上（如 os 模块的 read 方法） 操作练习读取文件 ‘poem’ ，显示到屏幕同时为第四行添加注释 # 琴瑟友之：弹琴鼓瑟来亲近她 ，如果涉及到字符串拼接尽量使用 join() 方法代替 + 菜鸟版：一次性读入所有内容到内存然后循环打印，使用变量定位行号 12345678f = open('poem', mode='r', encoding='utf8')line_number = 0for i in f.readlines(): line_number += 1 if line_number == 4: i = ''.join([i.strip(), '# 琴瑟友之：弹琴鼓瑟来亲近她']) print(i.strip())f.close() 菜鸟加强版：读入所有内容赋值给变量后立即关闭文件，对变量的元素循环和修改，使用索引定位 1234567f = open('poem',mode='r',encoding='utf8')data = f.readlines()f.close()data[3] = ''.join([data[3].strip(),'# 琴瑟友之：弹琴鼓瑟来亲近她'])for line in data: print(line.strip()) 中级版：一次性读入所有内容，使用enumerate() 和 try ... finally 123456789try: f = open('poem', 'r', encoding='utf-8') for line_number, line in enumerate(f.readlines(), 1): if line_number == 4: line = ''.join([line.strip(), '# 琴瑟友之：弹琴鼓瑟来亲近她']) print(line.strip())finally: if f: f.close() 最佳实践： 前三种方法中 read() 、readlines() 在文件比较大时都会消耗大量内存空间，容易造成内存溢出 结合 with 语句并使用迭代器用一行取一行，变量定位行号 1234567line_number = 0with open('poem','r',encoding='utf-8') as f: for line in f: line_number += 1 if line_number == 4: line = ''.join([line.strip(), '# 琴瑟友之：弹琴鼓瑟来亲近她']) print(line.strip()) 在 Python 中由于内存的机制无法像 word 那样实时修改并保存文件，因此只能先读取源文件数据到内存空间中进行修改，然后写入到另一个文件，再把新文件替换掉源文件。 例如，要在文件 ‘poem’ 的第四行之后添加注释 # 琴瑟友之：弹琴鼓瑟来亲近她 12345678910111213# -*- coding:utf-8 -*-f_read = open('poem','r',encoding='utf-8')f_write = open('poem.bak','w',encoding='utf-8')line_number = 0for line in f_read: line_number += 1 if line_number == 4: line = line.replace('\n','# 琴瑟友之：弹琴鼓瑟来亲近她\n') f_write.write(line)f_read.close()f_write.close() 使用 with 语句，可以同时管理多个文件对象 12345678# -*- coding:utf-8 -*-line_number = 0with open('poem','r',encoding='utf-8') as fr , open('poem.bak','w',encoding='utf-8') as fw: for line in fr: line_number += 1 if line_number == 4: line = line.replace('\n','# 琴瑟友之：弹琴鼓瑟来亲近她\n') fw.write(line)]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[画图理解Python的深浅拷贝]]></title>
    <url>%2F2019%2F03%2F10%2F084210-%E7%94%BB%E5%9B%BE%E7%90%86%E8%A7%A3Python%E7%9A%84%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D%2F</url>
    <content type="text"><![CDATA[在平常运维工作中，难免会有一些修改服务配置文件的操作，为了安全和可以回滚起见，我们习惯性的会将源配置文件做一个拷贝，这样以来即便配置文件参数被修改错了也没事，可以快速从备份的副本还原回来。 同样，在 Python 中如果涉及到数据传递，在传递过程中就有可能会发生数据被修改的问题，为了防止数据被修改，就需要生成一个副本，这就产生了拷贝 基本概念对象在 Python 中，一切皆对象。任何数据类型、函数、模块在 Python 中都被当做对象处理。 所有的 Python 对象都有三个属性：身份、类型、值 1234567&gt;&gt;&gt; name = 'Tom' # 建立一个对象引用&gt;&gt;&gt; id(name) # ID其实是内存地址，即身份的唯一标识19018976&gt;&gt;&gt; type(name) # 对象的类型，决定对象可以引用什么样的值&lt;class 'str'&gt;&gt;&gt;&gt; name # 对象引用的值，即实际表示的数据'Tom' 可变与不可变对象可变对象：对象的值可变，身份是不变的，例如列表、字典、集合，这些都是容器类型的数据，容器的内存地址是不变的，发生变化的是容器内部的数据 不可变对象： 对象的值和身份都是不变的，新创建的对象被原来的变量名引用，旧的对象就会被丢弃，最后交给垃圾回收机制处理掉，例如数字、字符串、元组 变量赋值或许在很多人的直观印象中，变量是一个容器，给变量赋值，就像是往一个存储的容器中填入一个数据，再次赋值就是把容器中的数据换掉，在 Python 中，这种理解是不准确的！ 更恰当的比喻是，我们可以把变量当做是一个标签：给变量赋值就是把标签贴在一个物体上；再次赋值就是把标签取下来贴在另一个物体上。 对象引用在 Python 程序中，每个对象都会在内存中申请开辟一块空间来保存该对象，该对象在内存中所在位置的地址被称为引用。在开发程序时，所定义的变量名实际就是对象的地址引用。 引用实际就是内存中的一个数字地址编号（内存地址），在使用对象时，只要知道这个对象的内存地址，就可以操作这个对象，但是因为内存地址不方便在开发时使用和记忆，所以使用变量名的形式来代替对象的内存地址。 在 Python 中，变量就是地址的一种表示形式，并不开辟开辟存储空间。 就像在访问网站时我们输入的是域名，而不是IP，但实际都是通过 IP 地址来进行网络通信的，而 IP 地址不方便记忆，所以使用域名来代替 IP 地址，在使用域名访问网站时，域名被 DNS 服务器解析成 IP 地址来使用。 在创建一个数据项时，将其赋值给一个变量，或者将其插入到一个组合中时，实际上是使得某个变量对内存中存放数据的对象进行引用，使用 del 时，实际上是删除了相应的对象引用 不可变对象的引用赋值123456789101112&gt;&gt;&gt; a = 1&gt;&gt;&gt; id(a)497079344&gt;&gt;&gt; b = a&gt;&gt;&gt; id(b)497079344&gt;&gt;&gt; a = 'xyz'&gt;&gt;&gt; id(a)19019808&gt;&gt;&gt; id(b)497079344&gt;&gt;&gt; a = 1 相当于把标签 a 贴在了 1 上，他的身份（内存地址）是 497079344 使用 b = a 的方式，实际上就相当于把标签 b 也贴在了标签 a 贴的那个物体上，也就是 a 和 b 都指向了同一块内存地址，可以简单的认为给对象的引用做了一个别名 当重新为 a 进行赋值时（a=&#39;xyz&#39;），实际上是在内存中新开辟了一段空间存放字符串对象 &#39;xyz&#39; 并把 a 的指向改为 &#39;xyz&#39;，而 b 则还是原来的对象引用 可变对象的引用赋值可变对象保存的其实是对象引用（内存地址），而不是真正的对象数据。当对可变对象进行赋值时，只是将可变对象中保存的引用指向了新的对象 123456789101112131415&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = a&gt;&gt;&gt; id(a)19007448&gt;&gt;&gt; id(b)19007448&gt;&gt;&gt; a[0] = 'hello'&gt;&gt;&gt; a['hello', 2, 3]&gt;&gt;&gt; b['hello', 2, 3]&gt;&gt;&gt; id(a)19007448&gt;&gt;&gt; id(b)19007448 上例中变量 a 并不是引用了实际数据 1, 2, 3 的内存地址，而是单纯的列表的内存地址，引用实际数据的是这个列表对象而不是变量 a 当改变列表中的数据时，改变的不是列表的内存地址，而改变的是列表中对实际数据的引用 浅拷贝不可变对象的拷贝123456789101112&gt;&gt;&gt; import copy&gt;&gt;&gt; a = 1&gt;&gt;&gt; b = copy.copy(a)&gt;&gt;&gt; id(a)505009200&gt;&gt;&gt; id(b)505009200&gt;&gt;&gt; a1&gt;&gt;&gt; b1&gt;&gt;&gt; 不可变对象的拷贝就是对象赋值，实际上是让多个对象同时指向一个引用 （内存地址） 可变对象的拷贝12345678910111213141516&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [1, 2, 3]&gt;&gt;&gt; b = copy.copy(a)&gt;&gt;&gt; id(a)11778728&gt;&gt;&gt; id(b)11778968&gt;&gt;&gt; a[0] = 'hello'&gt;&gt;&gt; id(a)11778728&gt;&gt;&gt; id(b)11778968&gt;&gt;&gt; a['hello', 2, 3]&gt;&gt;&gt; b[1, 2, 3] 可变对象的拷贝，会在内存中开辟一个新的空间来保存拷贝的数据。当再改变之前的对象时，对拷贝之后的对象没有任何影响 可变对象与不可变对象的组合123456789101112131415161718192021222324&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [1, 2, 3, ['Tom', 'Jerry']]&gt;&gt;&gt; b = copy.copy(a)&gt;&gt;&gt; id(a)11779648&gt;&gt;&gt; id(b)11778728&gt;&gt;&gt; id(a[3])11779728&gt;&gt;&gt; id(b[3])11779728&gt;&gt;&gt; a[3][0] = 'Dog'&gt;&gt;&gt; id(a)11779648&gt;&gt;&gt; id(b)11778728&gt;&gt;&gt; id(a[3])11779728&gt;&gt;&gt; id(b[3])11779728&gt;&gt;&gt; a[1, 2, 3, ['Dog', 'Jerry']]&gt;&gt;&gt; b[1, 2, 3, ['Dog', 'Jerry']] 复杂对象在拷贝时并没有解决数据在传递之后数据改变的问题。 这是因为 copy() 函数在拷贝对象时，只是将指定对象中的所有引用拷贝了一份，如果这些引用当中包含了一个可变对象的话，那么数据还是会被改变。 这种拷贝方式，称为浅拷贝。 浅拷贝只拷贝顶层数据，不拷贝子层数据 再比如 123456&gt;&gt;&gt; d1=dict.fromkeys(['host1','host2','host3'],['test1','test2'])&gt;&gt;&gt; d1&#123;'host1': ['test1', 'test2'], 'host2': ['test1', 'test2'], 'host3': ['test1', 'test2']&#125;&gt;&gt;&gt; d1['host2'][1]='test3'&gt;&gt;&gt; d1&#123;'host1': ['test1', 'test3'], 'host2': ['test1', 'test3'], 'host3': ['test1', 'test3']&#125; 深拷贝12345678910111213141516171819202122232425&gt;&gt;&gt; import copy&gt;&gt;&gt; a = [1, 2, 3, ['Tom', 'Jerry']]&gt;&gt;&gt; b = copy.deepcopy(a)&gt;&gt;&gt; id(a)11778968&gt;&gt;&gt; id(b)11779528&gt;&gt;&gt; id(a[3])11779648&gt;&gt;&gt; id(b[3])11779688&gt;&gt;&gt; a[3][0] = 'Dog'&gt;&gt;&gt; id(a)11778968&gt;&gt;&gt; id(b)11779528&gt;&gt;&gt; id(a[3])11779648&gt;&gt;&gt; id(b[3])11779688&gt;&gt;&gt; a[1, 2, 3, ['Dog', 'Jerry']]&gt;&gt;&gt; b[1, 2, 3, ['Tom', 'Jerry']]&gt;&gt;&gt; 深拷贝会逐层进行拷贝，直到拷贝的所有引用都是不可变引用为止 总结 在 Python 中，默认的拷贝方式是浅拷贝。从时间上看，浅拷贝花费时间更少；从使用空间上看，浅拷贝花费内存更少；从执行效率上看，浅拷贝只拷贝顶层数据，一般情况下比深拷贝效率高 不可变对象在赋值时会开辟新空间 深、浅拷贝对不可变对象拷贝时，不开辟新空间，相当于赋值操作 浅拷贝在拷贝时，只拷贝第一层中的引用，如果元素是可变对象，并且被修改，那么拷贝的对象也会发生变化 大多数情况下，编写程序时，都是使用浅拷贝，除非有特定的需求 小插曲下面这段代码是之前在和别人学习交流时遇到的，和深浅拷贝应该没有什么关联，但是觉着放到这篇文章比较合适。 1234567#!/usr/bin/env python3# -*- coding: utf-8 -*-ls = [1, 2, 3, 4, 5]for ls[-2] in ls: print(ls[-2]) 乍一看，你能猜到执行的结果么？ 1234512335 这个是因为什么呢？画个图来理解一下： 那么到底是不是这样呢？我们打印每个元素的内存地址来验证一下： 12345678910111213#!/usr/bin/env python3# -*- coding: utf-8 -*-ls = [1, 2, 3, 4, 5]for i in ls: print(id(i))for ls[-2] in ls: print("\033[0;33m ls[-2] is \033[0m", ls[-2], end=' ; ') print("\033[0;32m ls is \033[0m", ls, end=' ; ') print("\033[0;31m id ls[-2] is \033[0m", id(ls[-2])) 执行结果： 12345678910139930381165920139930381165952139930381165984139930381166016139930381166048 ls[-2] is 1 ; ls is [1, 2, 3, 1, 5] ; id ls[-2] is 139930381165920 ls[-2] is 2 ; ls is [1, 2, 3, 2, 5] ; id ls[-2] is 139930381165952 ls[-2] is 3 ; ls is [1, 2, 3, 3, 5] ; id ls[-2] is 139930381165984 ls[-2] is 3 ; ls is [1, 2, 3, 3, 5] ; id ls[-2] is 139930381165984 ls[-2] is 5 ; ls is [1, 2, 3, 5, 5] ; id ls[-2] is 139930381166048]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的组合数据类型-集合]]></title>
    <url>%2F2019%2F03%2F09%2F082110-Python%E7%9A%84%E7%BB%84%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[集合Python提供了两种内置的集合类型：可变的 set 类型，固定的 frozenset 类型 可变集合(set)：可添加和删除元素，非可哈希的，不能用作字典的键，也不能做其他集合的元素 不可变集合(frozenset)：与上面恰恰相反 只有可哈希运算的对象可以添加到集合中，所有内置固定数据类型（比如 float、frozenset、int、str、tuple )都是可哈希运算的，都可以添加到集合中。内置的可变数据类型（比如 dict、list、set )都不是可哈希运算的，因为其哈希值会随着包含项数的变化而变化，因此这些数据类型不能添加到集合中 集合的作用集合是一个无序的，不重复的数据组合，它的主要作用如下： 去重，把一个列表变成集合，就自动去重了 1234567li=[1,2,'a','b']s =set(li)print(s) # &#123;1, 2, 'a', 'b'&#125; li2=[1,2,1,'a','a']s=set(li2)print(s) #&#123;1, 2, 'a'&#125; 进行快速的成员关系测试，测试两组数据之前的交集、差集、并集等关系 集合对象是一组无序排列的可哈希的值：集合成员可以做字典的键 集合的相关操作创建由于集合没有自己的语法格式，只能通过集合的方法 set() 和 frozenset() 创建 123456789&gt;&gt;&gt; s1 = set('Tom')&gt;&gt;&gt; s2= frozenset('Jerry')&gt;&gt;&gt;&gt;&gt;&gt; print(s1,type(s1))&#123;'m', 'o', 'T'&#125; &lt;class 'set'&gt;&gt;&gt;&gt; &gt;&gt;&gt; print(s2,type(s2))frozenset(&#123;'J', 'r', 'y', 'e'&#125;) &lt;class 'frozenset'&gt;&gt;&gt;&gt; 访问由于集合本身是无序的，所以不能为集合创建索引或切片操作，只能循环遍历或使用 in、not in 来访问或判断集合元素 123456789&gt;&gt;&gt; s1 = set(['Tom','Jerry'])&gt;&gt;&gt; print('Tom' in s1)True&gt;&gt;&gt; for i in s1:... print(i)...TomJerry&gt;&gt;&gt; 更新可使用以下内建方法来更新： 12345s.add()# 将传入的参数当成一个整体放进集合s.update()# 将传入的参数拆散放进集合s.remove() 需要注意的是只有可变集合才能更新： 1234567891011&gt;&gt;&gt; s1 = set('Tom and Jerry')&gt;&gt;&gt; s1.add(' Dog ')&gt;&gt;&gt; print(s1)&#123;'a', 'd', 'm', 'r', 'o', 'J', ' Dog ', 'y', ' ', 'T', 'e', 'n'&#125; &gt;&gt;&gt; s1.remove(' Dog ')&gt;&gt;&gt; s1.remove('r')&gt;&gt;&gt; print(s1)&#123;'a', 'd', 'm', 'o', 'J', 'y', ' ', 'T', 'e', 'n'&#125;&gt;&gt;&gt; s1.update('Pig')&gt;&gt;&gt; print(s1)&#123;'a', 'd', 'm', 'o', 'J', 'g', 'y', ' ', 'T', 'i', 'e', 'n', 'P'&#125; del：删除集合本身 集合类型操作符 in ,not in 集合等价与不等价(==, !=) 子集、超集 12345678&gt;&gt;&gt; s1 = set('Tom and Jerry')&gt;&gt;&gt; s2 = set('Jerry and Tom')&gt;&gt;&gt; print('T' in s1)True&gt;&gt;&gt; print(s1 &lt; s2)False&gt;&gt;&gt; print(s1 == s2)True 联合(|)：与集合的 or 等价的，联合符号的等价方法是 union() 1234567&gt;&gt;&gt; s1=set('Tom')&gt;&gt;&gt; s2=set('Jerry')&gt;&gt;&gt; s3=s1|s2&gt;&gt;&gt; print(s3)&#123;'r', 'm', 'y', 'o', 'T', 'J', 'e'&#125;&gt;&gt;&gt; print(s1.union(s2))&#123;'r', 'm', 'y', 'o', 'T', 'J', 'e'&#125; 交集(&amp;)：与集合的 and 等价，交集符号的等价方法是 intersection() 12345678&gt;&gt;&gt; s1=set('abc')&gt;&gt;&gt; s2=set('cde')&gt;&gt;&gt; s3=s1&amp;s2&gt;&gt;&gt; s3&#123;'c'&#125;&gt;&gt;&gt; print(s1.intersection(s2))&#123;'c'&#125;&gt;&gt;&gt; 差集(-)：等价方法是 difference() 12345678&gt;&gt;&gt; s1=set('abc')&gt;&gt;&gt; s2=set('cde')&gt;&gt;&gt; s3=s1-s2&gt;&gt;&gt; s3&#123;'a', 'b'&#125;&gt;&gt;&gt; print(s1.difference(s2))&#123;'a', 'b'&#125;&gt;&gt;&gt; 对称差集(^)：对称差分是集合的 XOR (‘异或’)，取得的元素属于 s1，s2 但不同时属于 s1和 s2 ，其等价方法 symmetric_difference() 12345678&gt;&gt;&gt; s1=set('abc')&gt;&gt;&gt; s2=set('cde')&gt;&gt;&gt; s3=s1^s2&gt;&gt;&gt; s3&#123;'a', 'd', 'b', 'e'&#125;&gt;&gt;&gt; print(s1.symmetric_difference(s2))&#123;'a', 'd', 'b', 'e'&#125;&gt;&gt;&gt; 应用 最简单的去重方式 1234&gt;&gt;&gt; x = [1,2,3,4,1,2,3,4]&gt;&gt;&gt; print(list(set(x)))[1, 2, 3, 4]&gt;&gt;&gt;]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的字典练习-三级菜单]]></title>
    <url>%2F2019%2F03%2F08%2F164610-Python%E7%9A%84%E5%AD%97%E5%85%B8%E7%BB%83%E4%B9%A0-%E4%B8%89%E7%BA%A7%E8%8F%9C%E5%8D%95%2F</url>
    <content type="text"><![CDATA[需求说明 打印省、市、县三级菜单 可返回上一级 可随时退出程序 参考的字典样例： 1234567891011121314151617181920province_city = &#123; '河北': &#123; '石家庄': ['长安区', '桥东区', '桥西区', '新华区', '井陉矿区', '裕华区', '井陉县', '正定县', '栾城县', '其他'], '唐山': ['路南区', '路北区', '古冶区', '开平区', '丰南区', '丰润区', '滦县', '滦南县', '乐亭县', '迁西县', '其他'], '秦皇岛': ['海港区', '山海关区', '北戴河区', '青龙满族自治县', '昌黎县', '抚宁县', '卢龙县', '其他'], '衡水': ['桃城区', '枣强县', '武邑县', '武强县', '饶阳县', '安平县', '故城县', '景县', '阜城县', '冀州市', '其他'] &#125;, '山西': &#123; '太原': ['小店区', '迎泽区', '杏花岭区', '尖草坪区', '万柏林区', '晋源区', '清徐县', '阳曲县', '娄烦县', '古交市', '其他'], '大同': ['城区', '矿区', '南郊区', '新荣区', '阳高县', '天镇县', '广灵县', '灵丘县', '浑源县', '左云县', '大同县', '其他'], '吕梁': ['离石区', '文水县', '交城县', '兴县', '临县', '柳林县', '石楼县', '岚县', '方山县', '交口县', '汾阳市', '其他'] &#125;, '内蒙古': &#123; '呼和浩特': ['新城区', '回民区', '玉泉区', '玉泉区', '赛罕区', '土默特左旗', '托克托县', '和林格尔县', '清水河县', '其他'], '包头': ['东河区', '昆都仑区', '青山区', '石拐区', '白云矿区', '九原区', '土默特右旗', '固阳县', '达尔罕茂明安联合旗', '其他'], '阿拉善': ['阿拉善左旗', '阿拉善右旗', '额济纳旗', '其他'] &#125;&#125; &#125;&#125; 示范代码123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env python3# -*- coding: utf-8 -*-province_city = &#123; '河北': &#123; '石家庄': ['长安区', '桥东区', '桥西区', '新华区', '井陉矿区', '裕华区', '井陉县', '正定县', '栾城县', '其他'], '唐山': ['路南区', '路北区', '古冶区', '开平区', '丰南区', '丰润区', '滦县', '滦南县', '乐亭县', '迁西县', '其他'], '秦皇岛': ['海港区', '山海关区', '北戴河区', '青龙满族自治县', '昌黎县', '抚宁县', '卢龙县', '其他'], '衡水': ['桃城区', '枣强县', '武邑县', '武强县', '饶阳县', '安平县', '故城县', '景县', '阜城县', '冀州市', '其他'] &#125;, '山西': &#123; '太原': ['小店区', '迎泽区', '杏花岭区', '尖草坪区', '万柏林区', '晋源区', '清徐县', '阳曲县', '娄烦县', '古交市', '其他'], '大同': ['城区', '矿区', '南郊区', '新荣区', '阳高县', '天镇县', '广灵县', '灵丘县', '浑源县', '左云县', '大同县', '其他'], '吕梁': ['离石区', '文水县', '交城县', '兴县', '临县', '柳林县', '石楼县', '岚县', '方山县', '交口县', '汾阳市', '其他'] &#125;, '内蒙古': &#123; '呼和浩特': ['新城区', '回民区', '玉泉区', '玉泉区', '赛罕区', '土默特左旗', '托克托县', '和林格尔县', '清水河县', '其他'], '包头': ['东河区', '昆都仑区', '青山区', '石拐区', '白云矿区', '九原区', '土默特右旗', '固阳县', '达尔罕茂明安联合旗', '其他'], '阿拉善': ['阿拉善左旗', '阿拉善右旗', '额济纳旗', '其他'] &#125;&#125;current_layer = province_city # 当前层就是初始层，用来实现动态循环parent_list = [] # 保存所有父级元素，最后一个元素永远都是父亲级while True: for key in current_layer: # 遍历当前层的所有元素并打印之 print(key) user_choice = input('输入名称进行选择,返回上一级请按b,退出请按q &gt;&gt; ') # 引导用户进行选择 if user_choice in current_layer: if type(current_layer) is list: # 根据最后一层是列表对象的特点判断 print('\033[0;31m已经是最后一层了\033[0m') else: parent_list.append(current_layer) # 即将进入下一层，当前层作为父级元素追加到列表 current_layer = current_layer[user_choice] # 当前层赋值为当前层的下一层数据 elif user_choice == 'b': if parent_list: # 如果父级元素为空则不做任何操作 current_layer = parent_list.pop() # 删除并返回列表的最后一个元素，及父层元素 elif user_choice == 'q': exit('退出') else: print('输入的内容 \033[0;31m%s\033[0m 不正确' % user_choice)]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的组合数据类型-字典]]></title>
    <url>%2F2019%2F03%2F08%2F123810-Python%E7%9A%84%E7%BB%84%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[字典字典 ( dictionary ) 采用 0 个或多个键值对（key-value）的形式存储数据。Python 对 key 进行哈希函数运算，根据计算的结果决定 value 的存储地址，所以是无序组合数据类型，且 key 必须是可哈希的。可哈希的 key 必须是不可变类型，如：数字、字符串、元组。 字典是除列表以外 Python 之中最灵活的内置数据结构类型。列表是有序的对象结合，字典是无序的对象集合。两者之间的区别在于：字典当中的元素是通过键来存取的，而不是通过偏移存取 字典是可变的，因此可以对其进行数据项的添加或移除操作。由于字典是无序的，因此索引位置对其而言是无意义的，也不能进行分片或按步距分片 字典的两大特点：无序，键唯一 字典的创建dict 数据类型可以作为函数调用：dict()——不带参数将返回一个空字典，带一个映射类型参数将返回以该参数为基础的字典。比如该参数本身为字典，则返回该参数的浅拷贝。使用序列型参数也是可以的，前提是序列中的每个数据项本身是一个包含两个对象的序列，其中第一个用作键，第二个用作值。 字典也可以使用花括号 {} 创建——空的 {} 会创建空字典，非空的 {} 必须包含一个或多个逗号分隔的项，其中每一项都包含一个键、一个字面意义的冒号以及一个值： 12345678dic1 = &#123; 'name' : 'Tom', 'age' : '18', 'sex' : 'male', 'hobby': 'Jerry'&#125;dic1=&#123;'name':'Tom','age':18,'sex':'male','hobby':'Jerry'&#125; 字典的操作字典支持内置的 len() 函数，也可以使用 in 与 not in 对其键进行快速的成员关系测试 方法 语法 表述 d.clear() 将字典d清空 d.copy() 返回字典d的浅拷贝 d.fromkeys(s,v) 返回一个字典，该字典的键为序列s的项，值为None或v(r如果给定了参数v) d.get(k) 返回字典d中键k对应的值，如果k不在d中就返回None d.get(k,v) 返回字典d中键k对应的值，如果k不在d中就返回预设值v d.items() 返回字典d中所有 键-值 对的视图 d.keys() 返回字典d中所有的键的视图 d.values() 返回字典d中所有值的视图 d.pop(k) 移除键为k的项并返回键k对应的值，如果k不在d中就产生KeyError异常 d.pop(k,v) 移除键为k的项并返回键k对应的值，如果k不在d中就返回预设值v d.popitem() 随机移除并返回字典d中的任意一个 键-值 对，如果d为空就产生KeyError异常 d.setdefault(k,v) 与d.get()类似，不同之处在于，如果键k不在d中就插入一个键为k的新值，其值为None或预设值v（如果给定了参数v） d.update(a) 如果a中的键-值 对不存在d中就添加到d，如果a中的键在d中，就将a中的键对应的值替换掉d中键对应的值。a可以是字典，也可以是关键字参数 示例 增加元素，字典的键是独一无二的，因此如果向字典中添加一个键-值项，并且该键与字典中现存的某个键相同，那么实际的效果是使用新值替换该键的现值 1234567891011dic1=&#123;&#125;dic1['name'] = 'Tom'dic1['age'] = 18print(dic1) #&#123;'name': 'Tom', 'age': 18&#125; a=dic1.setdefault('name','Jerry') b=dic1.setdefault('age',22)# 如果 key 存在则不做更改，返回对应字典中相应的 key 对应的 value# 如果 key 不存在则在字典中增加新的 key-value 对，并返回相应的 valueprint(a,b)print(dic1) 查找元素 123456789101112131415dic1=&#123;'name':'Tom','age':18,'sex':'male','hobby':'Jerry'&#125;print(dic1['name'])print(dic3.get('age',False))print(dic3.get('son','little jerry'))print(dic3.get('ages',False))# 指定的键对应的值不存在，则使用指定的默认值，否则返回实际的值print(list(dic1.keys()))# 查看 key 的列表print(list(dic1.values()))# 查看 value 的列表print(list(dic1.items()))# 查看所有的 key-value 对 修改 12345678dic1=&#123;'name':'Tom','age':18,'sex':'male','hobby':'Jerry'&#125;dic1['name'] = 'Jerry'print(dic1)dic2=&#123;'sex':'male','hobby':'girl','age':36&#125;dic1.update(dic2)# 如果两个字典中存在相同的 key ，则在使用 update 时将会更新相应的 key 对应的 value ，否则将 key-value 对加入字典print(dic1) 删除 12345678910111213dic1=&#123;'name':'Tom','age':18,'sex':'male','hobby':'Jerry'&#125;# 删除指定的 key-value 对del dic1['name']dic1.pop('age') # 删除并返回该 key-value 的值dic1.pooitem() # 随机删除某组 key-value 对，并以元组方式返回值# 清空整个字典dic1.clear()# 删除整个字典del dic1 其他操作 dict.fromkeys 12345d1=dict.fromkeys(['host1','host2','host3'],'Mac')print(d1) # &#123;'host1': 'Mac', 'host2': 'Mac', 'host3': 'Mac'&#125;d1['host2'] = 'abc'print(d1) 字典的嵌套 1234567province_city = &#123; '河北': &#123; '石家庄': ['长安区', '桥东区', '桥西区', '新华区', '井陉矿区', '裕华区', '井陉县', '正定县', '栾城县', '行唐县', '灵寿县', '高邑县', '深泽县', '赞皇县', '无极县', '平山县', '元氏县', '赵县', '辛集市', '藁城市', '晋州市', '新乐市', '鹿泉市', '其他'], '唐山': ['路南区', '路北区', '古冶区', '开平区', '丰南区', '丰润区', '滦县', '滦南县', '乐亭县', '迁西县', '玉田县', '唐海县', '遵化市', '迁安市', ' 曹妃甸区', '其他'], '秦皇岛': ['海港区', '山海关区', '北戴河区', '青龙满族自治县', '昌黎县', '抚宁县', '卢龙县', '其他'] &#125;&#125; sorted(dict) : 返回一个有序的包含字典所有 key 的列表 12345dic=&#123;5:'555',2:'666',4:'444'&#125;print(sorted(dic))# [2, 4, 5]print(sorted(dic.values))print(sorted(dic.items)) 字典的遍历 12345678910dic5=&#123;'name': 'tom', 'age': 18&#125; for key in dic5: print(key,dic5[key]) # itmes 指的是键值对，存在一个转换过程，因此如果数据量大的情况下，效率比第一种方式低for items in dic5.items(): print(items)for keys,values in dic5.items(): print(keys,values) 使用上述的例子，存储一个班学生的信息： 1234dic=&#123;'zhangsan':&#123;'age':23,'sex':'male'&#125;, '李四':&#123;'age':33,'sex':'male'&#125;, 'wangwu':&#123;'age':27,'sex':'women'&#125; &#125;]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的组合数据类型-元组]]></title>
    <url>%2F2019%2F03%2F07%2F085510-Python%E7%9A%84%E7%BB%84%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-%E5%85%83%E7%BB%84%2F</url>
    <content type="text"><![CDATA[元组元组是有序序列，其中包含0个或多个对象引用。元组被称为只读列表，即数据可以被查询但不能被修改，所以列表的切片操作同样适用于元组。如果需要修改有序序列应该使用列表而非元组。如果有一个元组需要对其进行修改，则可以使用 list() 转换函数将其转换为列表之后在产生的列表之上进行适当修改。 tuple 数据类型可以作为函数进行调用，tuple()——不带参数将返回一个空元组，带一个 tuple 类参数将返回该参数的浅拷贝，对其他任意参数将尝试把给定的对象转换为 tuple 类型。该函数最多只能接受一个参数。虽然 tuple 的元素不可改变，但它可以包含可变的对象，比如 list 列表 如何创建元组元组写在小括号()，元素之间用逗号隔开。元组也可以使用 tuple() 函数创建，空元组是使用空的圆括号 () 创建的，包含一个或多个项的元组则可以使用逗号分隔进行创建。有时元组必须包含在圆括号中，以避免发生歧义。如果需要将元组 1,2,3 传递给一个函数，就应该写成 function((1,2,3)) 的形式 构造包含 0 个或 1 个元素的元组比较特殊，所以有一些额外的语法规则： 12tup1 = () # 空元组tup2 = (20,) # 一个元素，需要在元素后添加逗号 元组的作用 对于一些数据我们不想被修改，可以使用元组； 元组可以在映射（和集合的成员）中当作键使用——而列表则不行；元组作为很多内建函数和方法的返回值存在 元组的方法元组只提供了两种方法：t.count(x) ,返回对象 x 在元组中出现的次数；t.index(x) ,返回对象在元组 t 中出现的最左边位置——元组中不包含 x 时则产生ValueError异常。 元组操作符元组可以使用操作符 + (连接)、* (复制) 与 [] (分片)，也可以使用 in 与 not in 来测试成员关系。虽然元组是固定对象，但 += 与 *= 这两个增强的赋值运算符也可以使用——实际上是 Python 创建了新元组用于存放结果，并将左边的对象引用设置为指向新元组。元组可以使用标准的比较操作符（&lt;、&lt;=、==、!=、&gt;=、&gt;)进行比较，这种比较实际是逐项进行的（对嵌套项，比如元组内的元组，递归进行处理)。示例: 12345&gt;&gt;&gt; hair = "black", "brown", "blonde", "red"&gt;&gt;&gt; hair[2]'blonde'&gt;&gt;&gt; hair[-3:] # same as: hair[l:]('brown', 'blonde', 'red') 12&gt;&gt;&gt; hair[:2], "gray", hair[2:](('black', 'brown'), 'gray', ('blonde', 'red')) 这里本来是想创建一个新的五元组，但结果是一个三元组，其中包含两个二元组，之所以会这样是因为在3个项（一个元组，一个字符串，一个元组)之间使用了逗号操作符。要得到一个单独的元组，并包含所需项必须对其进行连接： 12&gt;&gt;&gt; hair[:2] + ("gray",) + hair[2:]('black', 'brown', 'gray', 'blonde', 'red') 要构成一个一元组逗号是必需的，但在这一情况下，将逗号放置在其中，就会产生一个 TypeError (因为 Python 会认为我们试图将字符串与元组进行连接)，因此必须同时使用逗号与圆括号]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的列表生成式]]></title>
    <url>%2F2019%2F03%2F06%2F191925-Python%E7%9A%84%E5%88%97%E8%A1%A8%E7%94%9F%E6%88%90%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在 Python 中小列表通常可以使用列表字面值直接创建，但长一些的列表通常则需要使用程序进行创建。对一系列整数我们可以使用 list(range(n)) 创建，或者如果只需要一个整数迭代子则使用 range() 就足以完成任务，但对更复杂一些的列表，使用 for...in 循环创建是一种更常见的做法。比如生成 Linux 系统 DNS 地址的列表，可以使用如下语句： 1234567891011#!/usr/bin/env python3# -*- coding:utf-8 -*-def get_dns_ip(): '''获取系统默认的 DNS 地址''' dns_list = [] with open('/etc/resolv.conf', 'r', encoding='utf-8') as f: for line in f: if line.startswith('nameserver '): dns_list.append(line.strip().split()[1]) return dns_list 再比如生成给定时间范围内的闰年列表，可以使用如下的语句： 123456789#!/usr/bin/env python3# -*- coding:utf-8 -*-leaps = []for year in range(1900, 1940): if (year % 4 == 0 and year % 100 != 0) or (year % 400 == 0): leaps.append(year)print(leaps) 在为内置的 range() 函数指定两个整数参数 n 与 m 时，该函数返回的迭代子 iterator 将生成整数n,n+l,...,m-1 列表生成式也是一个循环，该循环有一个可选的、包含在 [] 中的条件，作用是为列表生成数据项，并且可以使用条件过滤掉不需要的数据项。列表生成式最简单的形式如下： 1[item for item in iterable] 上面的语句将返回一个列表，其中包含 iterable 中的每个数据项，在语义上与 list(iterable) 是一致的。示例： 123&gt;&gt;&gt; alist=[x for x in range(0,11)]&gt;&gt;&gt; alist[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10] 有两个特点使得列表生成式具有更强大的功能，一个是可以使用表达式，另一个是可以附加条件——由此带来如下两种实现列表生成式的常见语法格式： 12345678[expression for item in iterable][expression for item in iterable if condition]# 第二种语法格式实际上等价于：temp = []for item in iterable: if condition: temp.append(expression) 通常在上面的语法中，expression 要么是数据项本身，要么与数据项相关。当然列表生成式不需要 for x in 循环中使用的 temp 变量 现在我们可以使用列表生成式编写代码，以便生成列表 leaps 。分三个阶段开发这段代码 首先生成一个列表，其中包含给定时间范围内的所有年份 123leaps = [y for y in range(1900, 1940)]# 或者leaps = list(range(1900，1940)) 接下来，为该语句添加一个简单的条件，以便每隔4年获取一次 1leaps = [y for y in range(900, 1940) if y % 4 == 0] 最后，给出完整的代码： 1leaps = [y for y in range(900, 1940) if (y % 4 == 0 and y % 100 != 0) or (y % 400 == 0)] 使用生成式的获取系统 DNS 地址的函数代码： 12345def get_dns_ip(): '''获取系统默认的 DNS 地址''' with open('/etc/resolv.conf', 'r', encoding='utf-8') as f: dns_list = [line.split()[1] for line in f if line.startswith('nameserver')] return dns_list 由于列表生成式会生成列表，也就是 iterable ，同时用于列表生成式的语法需要使用 iterable，因此对列表生成式进行嵌套也是可以的。这与嵌套的 for...in 循环是等价的。比如，对给定的性别、尺寸、颜色集需要生成所有可能的服装标号，但排除肥胖女士的标号，因为时装工业会忽视这一类女性。使用嵌套的 for...in 循环可以完成这一任务: 1234567codes = []for sex in "MF": # Male, Female for size in "SMLX": # Small, Medium, Large, extra large if sex == "F" and size == "X": continue for color in "BGW": # Black, Gray, White codes.append(sex + size + color) 使用列表生成式，只需要两行代码就可以实现相同的功能： 12codes = [sex + size + color for sex in "MF" for size in "SMLX" for color in "BGW" if not (size == "F" and size == "X")] 这里列表中的每个数据项都是使用表达式 sex + size + color 生成的。并且跳过无效的 sex/size 组合是在最内部的循环中实现的，而嵌套的 for...in 循环版本中，跳过无效的组合是在中间循环中实现的。任何列表生成式都可以使用一个或多个 for...in 循环重写 如果生成的列表非常大，那么根据需要去生成每个数据项会比一次生成整个列表更高效。这可以通过使用生成器实现，而不使用列表生成式]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的列表练习-购物车]]></title>
    <url>%2F2019%2F03%2F06%2F162310-Python%E7%9A%84%E5%88%97%E8%A1%A8%E7%BB%83%E4%B9%A0-%E8%B4%AD%E7%89%A9%E8%BD%A6%2F</url>
    <content type="text"><![CDATA[需求说明 启动程序后让用户输入工资，如果输错工资的次数超过三次则退出 1234请输入您的工资：fda您的输入有误，请重新输入：fdas您的输入有误，请重新输入：fsd错误输入超过三次，程序自动退出 输入正确后打印商品清单，允许用户根据商品编号购买商品，参考格式如下 1234567请输入您的工资：1234351 Iphone 5800 2 Mac pro 12000 3 Watch 500 4 Python book 81 5 Bike 800 如需购买请输入商品编号[退出:q] : 用户选择商品后，检测余额是否足够，够就直接扣款，不够就提醒 可随时退出，退出时打印已购买商品和余额 商品清单使用列表进行存储，例如 1234567product_list = [ ["Iphone", 5800], ["Mac pro", 12000], ["Watch", 500], ["Python book", 81], ["Bike", 800]] 示范代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/env python3# -*- coding: utf-8 -*-product_list = [ ["Iphone", 5800], ["Mac pro", 12000], ["Watch", 500], ["Python book", 81], ["Bike", 800]]shopping_list = []counter = 1salary = input('请输入您的工资：')while not salary.isdigit(): if counter == 3: exit('输入错误次数过多，程序自动退出') salary = input("您的输入有误，请重输入：") counter += 1else: salary = int(salary) while True: # 打印商品内容 print('商品列表'.center(30, '-')) for idx, itm in enumerate(product_list, 1): print('%-3s%-15s%-8s' % (idx, itm[0], itm[1])) # 引导用户选择商品 your_choice = input('如需购买请输入商品编号[退出请输入q]:') # 验证输入是否合法 if your_choice.isdigit(): your_choice = int(your_choice) if 0 &lt; your_choice &lt;= len(product_list): # 根据 user_choice 将用户选择的商品取出来 buy_itm = product_list[your_choice - 1] # 如果余额充足，则使用本金减去该商品价格，并将该商品加入购物车 if salary &gt;= buy_itm[1]: salary -= buy_itm[1] shopping_list.append(buy_itm) print('商品 %s 已加入购物车,余额为 \033[0;32m%s\033[0m' % ( buy_itm[0], salary)) else: print('您的余额不足，当前余额为 \033[0;31m%s\033[0m' % salary) else: print('输入的编号 %s 不存在' % your_choice) elif your_choice == 'q': print('购物清单'.center(30, '-')) for x, y in enumerate(shopping_list, start=1): print('%-3s%-15s%-8s' % (x, y[0], y[1])) print('您的余额为 \033[032m%s\033[0m' % salary) exit() else: print('\033[0;31m输入的编号 %s 错误\033[0m' % your_choice)]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的组合数据类型-列表]]></title>
    <url>%2F2019%2F03%2F06%2F084510-Python%E7%9A%84%E7%BB%84%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-%E5%88%97%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[列表列表是有序的序列而且是可变对象，它包含了0个或多个对象引用。因为可变，我们可以对列表中的元素进行删除或替换操作，还可以插入、替换或删除列表中的分片。 list 数据类型可以作为函数进行调用， list() ——不指定参数将返回一个空列表；带一个 list 类型的参数将返回该参数的浅拷贝：对任意其他参数 list() 将尝试把给定的对象转换为 list 类型。该函数只能接受一个参数。列表也可以不使用 list() 函数创建，空列表可以使用空的方括号 [] 来创建，包含一个或多个元素的列表则可以使用逗号分隔并且被包含在 [] 中来创建。另一种创建列表的方法是使用列表生成式 列表中所有元素实际上都是对象引用，因此列表也可以存放任意数据类型的元素，包括组合数据类型，比如列表与元组。列表可以使用标准的比较操作符 ( &lt; 、&lt;= 、 == 、 != 、 &gt;= 、 &gt; ) 进行比较，这种比较实际是逐项进行的（对嵌套元素，比如列表内的元组或列表，则递归进行处理) 列表操作符 表达式 结果 描述 [1, 2, 3] + [4, 5, 6] [1, 2, 3, 4, 5, 6] 两个列表进行组合 [‘Hi!’] * 4 [‘Hi!’, ‘Hi!’, ‘Hi!’, ‘Hi!’] 元素复制 3 in [1, 2, 3] True 成员比较 for x in [1, 2, 3]: print x, 1 2 3 迭代 列表分片1L = ['spam', 'Spam', 'SPAM!'] 表达式 结果 描述 L[2] ‘SPAM!’ 读取列表中第三个元素 L[-2] ‘Spam’ 读取列表中倒数第二个元素 L[1:] [‘Spam’, ‘SPAM!’] 从第二个元素开始截取列表 L[2] ‘SPAM!’ 读取列表中第三个元素 L[::-1] [‘SPAM!’, ‘Spam’, ‘spam’] 将列表倒序 示例 12345a = ['zhangsan', 'lisi', 'wangwu', 'tom', 'jerry']print(a[1:]) # 从左向右取到最后print(a[1:-1]) # 从左向右取到倒数第二个值print(a[1:-1:1]) # 从左向右取到倒数第二个值，步进长度为1去取print(a[1::2]) # 从左向右取到最后，步进长度为2 常用函数 len(L) 取得列表的长度 max(L) 返回列表元素中的最大值，列表里面是嵌套的对象构成元素时，按照嵌套对象的元素里面的第一个元素的排列顺序，输出最大值（如果第一个元素相同，则比较第二个元素，输出最大值），按照 ASCII 码进行排序 min(L) 返回列表元素中的最小值 list(X) 将对象 X 转为列表 列表常用的方法 方法 描述 L.append(x) 将元素 x 追加到列表 L 的尾部 L.count(x) 返回元素 x 在列表 L 中出现的次数 L.extend(m) 或 L+=m 将 iterable 对象m的元素和 L 进行连接 L.index(x, start, end) 返回数据项x在列表 L 中（或L的start,end分片中）最左边出现的索引位置，否则会产生—个ValueError异常 L.insert(i, x) 在索引位置 i 处将元素 x 插入列表 L L.pop() 返回并移除列表 L 最右边的元素 L.pop(i) 返回并移除L中索引位置 i 处的元素 L.remove(x) 从list L中移除最左边出现的元素 x，如果找不到 x 就产生ValueError异常 L.reverse() 对列表 L 进行反转 L.sort(…) 对列表 L 进行排序，与内置的 sorted() 函数一样，这一方法可以接受可选的 key 与 reverse 参数 拆分操作符进行赋值数据类型都可以使用序列拆分操作符 * 进行拆分。 在进行赋值操时，= 左边如果有两个或多个变量时对其中的一个使用 * 进行引导，元素将赋值给对应的未使用 * 引导的变量，而所有剩下的元素将赋值给带星号的变量： 12345&gt;&gt;&gt; first, *rest = [9, 2, -4, 8, 7]&gt;&gt;&gt; first9&gt;&gt;&gt; rest[2, -4, 8, 7] 1234567&gt;&gt;&gt; first, *mid, last = "Charles Philip Arthur George Windsor".split()&gt;&gt;&gt; first'Charles'&gt;&gt;&gt; mid['Philip', 'Arthur', 'George']&gt;&gt;&gt; last'Windsor' 12345&gt;&gt;&gt; *directories, executable = "/usr/local/bin/gvim".split("/")&gt;&gt;&gt; directories['', 'usr', 'local', 'bin']&gt;&gt;&gt; executable'gvim' del语句虽然从名称上看，del 语句代表的是删除，但是实际上 del 语句的作用并不一定是删除数据。 应用于某些对象引用（引用的是非组合类型的数据项）时，del语句的作用是取消该对象引用到数据项的绑定，并删除对象引用，例如： 12345678&gt;&gt;&gt; x = 8143 # object ref.'x' created; int of value 8143 created&gt;&gt;&gt; x8143&gt;&gt;&gt; del x&gt;&gt;&gt; xTraceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;NameError: name 'x' is not defined 对象引用被删除后，如果该对象引用所引用的数据项没有被其他对象引用进行引用，那么该数据项将进入垃圾收集流程。在垃圾收集是否自动进行不能确定时，如果需要进行清理，就必须自己手动进行处理。对垃圾收集的不确定性，Python 提供了两种方案，一种是使用 try ... finally 语句块，确保垃圾收集得以进行；另一种是使用 with 语句]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的字符串练习-获取tag间的内容]]></title>
    <url>%2F2019%2F03%2F05%2F213839-Python%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%BB%83%E4%B9%A0-%E8%8E%B7%E5%8F%96tag%E9%97%B4%E7%9A%84%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[需求说明 已知变量和值如下 1aline = '&lt;title&gt;Python的字符串练习-获取tag间的内容&lt;/title&gt;' 取出 &lt;title&gt; 和 &lt;/title&gt; 之间的内容 示例代码12345678910111213141516171819#!/usr/bin/env python3# -*- coding: utf-8 -*-aline = '&lt;title&gt;Python的字符串练习-获取tag间的内容&lt;/title&gt;'def content_in_tag(s, tag): if tag in s: tag_open = '&lt;' + tag + '&gt;' tag_close = '&lt;/' + tag + '&gt;' index_tag_open = s.index(tag_open) index_tag_close = s.index(tag_close) index_content = index_tag_open + len(tag_open) print(s[index_content:index_tag_close]) else: print('%s not in %s' % (tag, s))content_in_tag(aline, 'title')]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中字符串的format方法]]></title>
    <url>%2F2019%2F03%2F05%2F204910-Python%E4%B8%AD%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84format%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[字符串的格式化字符串的 s.format() 方法会返回一个新字符串，在新字符串中原字符串的替换字段被适当格式化后的参数所替代 12&gt;&gt;&gt; "The novel '&#123;0&#125;' was published in &#123;1&#125;".format("Hard Times", 1854)"The novel 'Hard Times' was published in 1854" 每个替换字段都是由包含在花括号中的字段名标识的 如果字段名是简单的整数，就将被作为传递给 s.format() 方法的一个参数的索引位置。因此在这种情况下，名为 0 的字段被第一个参数所替代，名为 1 的字段则被第二个参数所替代。如果需要在格式化字符串中包含花括号，就需要将其复写，下面给出一个实例： 12&gt;&gt;&gt; "&#123;&#123;&#123;0&#125;&#125;&#125; &#123;1&#125;;-&#125;&#125;".format("I'm in braces", "I'm not")"&#123;I'm in braces&#125; I'm not;-&#125;" 如果我们试图连接字符串与数字将产生 TypeError 异常，但使用 str.format() 方法可以很容易地做到这一点： 12&gt;&gt;&gt; "&#123;0&#125;&#123;1&#125;".format("The amount due is $",200)'The amount due is $200' 字段名可以是一个与某个 s.format() 方法参数对应的整数，也可以是方法的某个关键字参数的名称 使用关键字参数 12345&gt;&gt;&gt; string="My name is &#123;who&#125; , I am is &#123;age&#125; years old "&gt;&gt;&gt; print(string.format(who="Linux",age=18))My name is Linux , I am is 18 years old&gt;&gt;&gt; print(string.format_map(&#123;"who":"Litingjie","age":"18"&#125;))My name is Litingjie , I am is 18 years old 使用位置参数和关键字参数 123&gt;&gt;&gt; string="My name is &#123;who&#125; , I am is &#123;0&#125; years old "&gt;&gt;&gt; print(string.format(18,who="Linux"))My name is Linux , I am is 18 years old 注意：在参数列表中，关键字参数总是在位置参数之后 字段名可以引用组合数据类型——比如列表。在这样的情况下，我们可以包含一个索引（不是一个分片）来标识特定的数据项 123&gt;&gt;&gt; stock = ["paper", "envelopes", "notepads", "pens", "paper clips"]&gt;&gt;&gt; "We have &#123;0[1]&#125; and &#123;0[2]&#125; in stock".format(stock)'We have envelopes and notepads in stock' 0 引用的是位置参数，因此 {0[1]}是列表 stock 参数的第二个数据项，{0[2]} 是 列表 stock 参数的第三个数据项。字典对象也可以用于 s.format() 方法： 12&gt;&gt;&gt; "The &#123;0[animal]&#125; weighs &#123;0[weight]&#125;kg".format(d)'The elephantn weighs 12000kg']]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的组合数据类型-字符串]]></title>
    <url>%2F2019%2F03%2F05%2F201910-Python%E7%9A%84%E7%BB%84%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[字符串Python 字符串不可以被更改，它们是不可变的 。因此，赋值给字符串索引的位置会导致错误。字符串是使用固定不变的 str 数据类型表示的，其中存放 Unicode 字符序列。 str 数据类型可以作为函数进行调用，用于创建字符串对象： 参数为空时返回一个空字符串 参数为非字符串类型时返回该参数的字符串形式 参数为字符串时返回该字符串的拷贝 str() 函数也可以用作一个转换函数，此时要求第一个参数为字符串或可以转换为字符串的其他数据类型，其后跟随至多两个可选的字符串参数，其中一个用于指定要使用的编码格式，另一个用于指定如何处理编码错误。 引号的使用字符串是使用引号创建的，可以使用单引号也可以使用双引号，但是字符串两端必须相同。此外还可以使用三引号包含的字符串——这是 Python 对起始端与终端都使用3个引号包含的字符串的叫法，例如： 123text = """A triple quoted string like this can include 'quotes' and "quotes" without formality. We can also escape newlines \ so this particular string is actually only two lines long.""" 如果需要在通常的、引号包含的字符串中使用引号，在要使用的引号与包含字符串的引号不同时，可以直接使用该引号，而不需要进行格式化处理操作，但是如果相同，就必须对其进行转义： 12a = "Single 'quotes' are fine; \"doubles\" must be escaped." b = 'Single \'quotes\' must be escaped; "doubles" are fine.' 换行Python 使用换行作为其语句终结符，但是如果在圆括号、方括号、花括号内或三引号包含的字符串内则是例外。在三引号包含的字符串中，可以直接使用换行而不需要进行格式化处理操作。通过使用 \n 转义，也可以在任何字符串中包含换行。 有些情况下——比如编写正则表达式时, 需要创建带有大量字面意义反斜杠的字符串。由于每个反斜杠都必须进行转义处理，从而造成了不便： 12import rephone1 = re.compile("^((?:[(]\\d+[)])?\\s*\\d+(?:-\\d+)?)$") 解决方法是使用原始的字符串，这种引号包含的或三引号包含的字符串的第一个引号由字面意义的 r 引导。在这种字符串内部，所有字符都按其字面意义理解，因此不再需要进行转义。下面给出了使用原始字符串的 phone 正则表达式： 1phone2 = re.compile(r"^((?:[()\d+[]])?\s*\d+(?:-\d+)?)$") 再比如： 12print('C:\some\name') # 这里的\n意味着换行print(r'C:\some\name') # 在引号前使用r来引导，则\n就按照字面意义理解 如果变量中有特殊字符串，但不希望被引用，则可以使用 repr() 方法使用字符串原意(方便机器阅读，而不是方便人阅读) 1234567&gt;&gt;&gt; line = 'Hello Tom ! \n Hi'&gt;&gt;&gt; print(line)Hello Tom ! Hi&gt;&gt;&gt; print(repr(line))'Hello Tom ! \n Hi'&gt;&gt;&gt; 连接 字符串可以由 + 操作符连接(粘到一起)，可以由 * 表示重复 123&gt;&gt;&gt; # 3 times 'un', followed by 'ium'&gt;&gt;&gt; 3 * 'un' + 'ium''unununium' 相邻的两个字符串文本自动连接在一起 1234&gt;&gt;&gt; 'Py' 'thon''Python'&gt;&gt;&gt; 'Py''thon''Python' 这种方法只用于两个字符串文本，不能用于字符串表达式 12345678910111213&gt;&gt;&gt; prefix = 'Py'&gt;&gt;&gt; prefix 'thon' # # can't concatenate a variable and a string literal File "&lt;stdin&gt;", line 1 prefix 'thon' ^SyntaxError: invalid syntax&gt;&gt;&gt; &gt;&gt;&gt; ('un' * 3) 'ium' File "&lt;stdin&gt;", line 1 ('un' * 3) 'ium' ^SyntaxError: invalid syntax&gt;&gt;&gt; 使用 + 将多个变量连成字符串，或将一个变量和一个字符串文本连接成字符串 12345&gt;&gt;&gt; prefix + 'thon''Python'&gt;&gt;&gt; prefix='Py';suffix='thon'&gt;&gt;&gt; prefix + suffix'Python' 使用 , 连接成元组 123456&gt;&gt;&gt; prefix='Py';suffix='thon'&gt;&gt;&gt; prefix , suffix('Py', 'thon')&gt;&gt;&gt; a= prefix , suffix&gt;&gt;&gt; a('Py', 'thon') 用 % 连接一个字符串和一组变量，字符串中的特殊标记会被自动用右边变量组中的变量替换，功能比较强大，借鉴了 C 语言中 printf 函数的功能： 1234&gt;&gt;&gt; a='Tom' &gt;&gt;&gt; b='Jerry'&gt;&gt;&gt; '%s %s %s' %(a,'and',b)'Tom and Jerry' 较长字符串的表示方法如果需要写一个长字符串，跨越了2行或更多行，则可以使用三种方法： 使用三引号，行尾换行符会被自动包含到字符串中，但是可以在行尾加上 \ 来避免这个行为。下面的示例： 可以使用反斜杠作为行结尾的连续字符串，它表示下一行在逻辑上是本行的后续内容 12345print("""\Usage: thingy [OPTIONS] -h Display this usage message -H hostname Hostname to connect to \""") 由 + 操作符连接 12345&gt;&gt;&gt; t = "This is not the best way to join two long strings " + \... "together since it relies on ugly newline escaping"&gt;&gt;&gt; t'This is not the best way to join two long strings together since it relies on ugly newline escaping'&gt;&gt;&gt; 使用圆括号构成一个单独的表达式，如果不使用圆括号，就只有第一个字符串对变量进行赋值，第二个字符串则会导致 IndentationError 异常。建议总是使用圆括号将跨越多行的任何语句进行封装而不使用转义的换行符。 12345&gt;&gt;&gt; s = ("This is the nice way to join two long strings "... "together; it relies on string literal concatenation.")&gt;&gt;&gt; s'This is the nice way to join two long strings together; it relies on string literal concatenation.'&gt;&gt;&gt; 操作符由于字符串是固定序列，所有可用于固定序列的功能都可用于字符串，包括使用 in 进行成员关系测试，使用 += 进行追加操作，使用 * 进行复制，使用 *= 进行增强的赋值复制等。 * 操作符提供了字符串复制功能 123456&gt;&gt;&gt; s='#'&gt;&gt;&gt; s*5'#####'&gt;&gt;&gt; s*=50&gt;&gt;&gt; s'##################################################' 在用于字符串时，如果成员关系操作符 in 左边的字符串是右边字符串的一部分或者相等，就返回 True 1234&gt;&gt;&gt; 'usr' in '/usr/local/bin'True&gt;&gt;&gt; 'usr' in '/usfr/local/bin'False 字符串支持通常的比较操作符 &lt; 、&lt;= 、= 、!= 、&gt; 与 &gt;= ，这些操作符在内存中逐个字节对字符串进行比较 作为一种策略（以便防止出错)，Python 并不进行推测字符串是哪个国家的语言字符。在字符串比较时，Python 使用的是字符串的内存字节的形式，此时的排序是基于 Unicode 编码格式的，比如对英语就是按 ASCII 顺序。对要比较的字符串进行小写或大写，会产生更贴近自然英语的排序。 字符串的切片与步距字符串也可以被截取(检索)。字符串的索引位置从0开始，直至字符串长度值减去1。索引用于获得单个字符，切片则可以获得一个子字符串 单个字符的提取 Python 没有单独的字符类型；一个字符就是一个简单的长度为1的字符串。 12345&gt;&gt;&gt; word = 'Python'&gt;&gt;&gt; word[0] # character in position 0'P'&gt;&gt;&gt; word[5] # character in position 5'n' 使用负索引位置也是可以的一一此时的计数方式是从最后一个字符到第一个字符。 123456&gt;&gt;&gt; word[-1] # last character'n'&gt;&gt;&gt; word[-2] # second-last character'o'&gt;&gt;&gt; word[-6]'P' 注意： -0 实际上就是 0，所以它不会导致从右边开始计算。-1 这个值总是代表字符串的最后一个字符。 存取超过范围的索引位置（或空字符串中的索引位置）会产生 IndexError 异常 分片操作分片操作符 [] 有3种语法格式： seq 可以是任意序列，比如列表、字符串或元组。start 、end 与 step 必须都是整数（或存放整数的变量)： seq [start] ,从序列中提取从start开始的数据项 12345&gt;&gt;&gt; s = "The waxwork man"&gt;&gt;&gt; s[0]'T'&gt;&gt;&gt; s[1]'h' seq[start:end]，一个冒号，从(包含) start 开始的数据项到(不包含) end 结束的数据项提取一个分片。如果使用这种语法格式就可以省略任意的整数索引值。 如果省略了起点索引值，就默认为0； 如果省略了终点索引值，就默认为 len(seq)，即要切片的字符串的长度； 如果省略了两个索引值，比如 s[:] 则与 s[0:len(s)] 是一样的，作用都是提取也就是复制整个序列 给定赋值操作 s = &quot;The waxwork man&quot;，图2-2展示了字符串s的一些实例分片 123456&gt;&gt;&gt; s = "The waxwork man"&gt;&gt;&gt; len(s)15&gt;&gt;&gt; s = s[:12] + "wo" + s[12:]&gt;&gt;&gt; s'The waxwork woman' 实际上由于文本 wo 在原始字符串中，因此我们也可以写成 s[:12] + s[7:9] + s[12:] 达到同样的效果。在涉及很多字符串时，使用 + 进行连接、使用 += 进行追加等操作并不是特别高效，如果需要连接大量的字符串，通常最好使用 str.join() 方法 seq[start:end:step]，两个冒号，与上面用法类似，区别在于不是提取每一个字符，每隔 step 个字符进行提取；也可以省略两个索引 如果省略了起点索引值，就默认为0 ——除非给定的是负的step值，此时起点索引值默认为-1 如果省略了终点索引值，那么默认为 len(seq)——除非给定的是负的step值， 此时终点索引值默认为字符串起点前面 不能忽略 step，并且 step 不能为0。如果不需要step，那么应该使用不包含 step 的第二种语法（一个冒号） 给定赋值操作 s = &quot;he ate camel food&quot; 下图2-3展示了字符串带步距的分片的两个实例 更常见的情况下，步距是与字符串之外的序列类型一起使用的，但是也存在用于字符串的情况： 12&gt;&gt;&gt; s, s[::-1]('The waxwork woman', 'namow krowxaw ehT') step 为 -1 意味着每个字符都将被提取，方向为从终点到起点，因此会产生反转的字符串。 注意： 包含起始的字符，不包含末尾的字符。这使得 s[:i] + s[i:] 永远等于 s： 12345&gt;&gt;&gt; word = 'Python'&gt;&gt;&gt; word[:2] + word[2:]'Python'&gt;&gt;&gt; word[:4] + word[4:]'Python' 常用方法大小写转换 s.title()：返回字符串s的副本并将每个单词的首字母变为大写，其他字母变为小写 123&gt;&gt;&gt; s='hello world'&gt;&gt;&gt; s.title()'Hello World' s.capitalize()：返回字符串s的副本并将首字母变为大写 123&gt;&gt;&gt; s='jerry'&gt;&gt;&gt; s.capitalize()'Jerry' s.lower()：将字符串转为小写 123&gt;&gt;&gt; s='Jerry'&gt;&gt;&gt; s.lower()'jerry' s.upper()：将字符串转为大写 123&gt;&gt;&gt; s='hwaddr=00:0c:29:85:60:ee'&gt;&gt;&gt; s.upper()'HWADDR=00:0C:29:85:60:EE' s.swapcase()：交换大小写，返回s的副本并将其中大写字符变为小写，小写字符变为大写 123&gt;&gt;&gt; s='hwaddr=00:0C:29:85:60:EE'&gt;&gt;&gt; s.swapcase()'HWADDR=00:0c:29:85:60:ee' 剔除字符串 s.strip(chars)：返回s的副本，并将两边(开头和结尾)的空白字符（或字符串为 chars 的字符）移除 s.lstrip(chars)：返回s的副本，并将左边(开头)的空白字符（或字符串为 chars 的字符）移除 s.rstrip(chars)：返回s的副本，并将右边(结尾)的空白字符（或字符串为 chars 的字符）移除 123456789101112131415161718192021222324252627282930313233&gt;&gt;&gt; s=" \n\nMy name is Linux. \n I'm 18 years old.\n\n "&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; print(s)My name is Linux. I'm 18 years old.&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; print(s.strip())My name is Linux. I'm 18 years old.&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; print(s.lstrip())My name is Linux. I'm 18 years old.&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; print(s.rstrip())My name is Linux. I'm 18 years old.&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; "&lt;[unbracketed]&gt;".strip("[]()&#123;&#125;&lt;&gt;")&gt;&gt;&gt; 'unbracketed' 填充字符串 s.center(width,char)：返回一个长度为 width 的字符串，并且s在这个字符串中处于 居中 位置，不足部分使用空格或可选的 char (长度为1的字符串)进行填充 s.ljust(width,char)： 返回一个长度为 width 的字符串，并且s在这个字符串中处于 左 对齐位置，不足部分使用空格或可选的 char (长度为1的字符串)进行填充 s.rjust(width,char)： 返回一个长度为 width 的字符串，并且s在这个字符串中处于右 对齐位置，不足部分使用空格或可选的 char (长度为1的字符串)进行填充 123456789&gt;&gt;&gt; s='Shopping list'&gt;&gt;&gt; s.center(50)' Shopping list '&gt;&gt;&gt; s.center(50,'=')'==================Shopping list==================='&gt;&gt;&gt; s.ljust(50,'=')'Shopping list====================================='&gt;&gt;&gt; s.rjust(50,'=')'=====================================Shopping list' s.zfill(w)：返回s的副本，如果 s 的长度比 w 短，就在开头使用 0 填充，使其长度为 w ，其中 w 必须为整数 123&gt;&gt;&gt; s='10'&gt;&gt;&gt; s.zfill(8)'00000010' 统计字符串次数 s.count(t,start,end)：返回字符串 s 中(或在 s 的 start:end 切片中)字符串 t 出现的次数 1234567&gt;&gt;&gt; s="You're so You're so... sexy sexy sexy I need your love"&gt;&gt;&gt; s.count('sexy')3&gt;&gt;&gt; s.count('so',0,15)1&gt;&gt;&gt; s.count('so',0,20)2 匹配开头和结尾 s.startswith(x,start,end)：如果 s (或 s 的 start:end 分片)以字符串 x (或以元组 x 中的任意字符串)开始，就返回 True ，否则返回 False s.endswith(x,start,end)：如果 s (或 s 的 start:end 分片)以字符串 x (或以元组 x 中的任意字符串)结尾，就返回 True ，否则返回 False 1234567&gt;&gt;&gt; s='jerry and tom'&gt;&gt;&gt; s.startswith('jerry')True&gt;&gt;&gt; s.endswith('jerry')False&gt;&gt;&gt; s.endswith('tom')True 分隔 s.split(t,n)：以 t 作为分隔符，分隔 n 次，并返回结果。如果 t 未指定则默认以空白符作为分隔，如果 n 未指定则尽可能多地分隔。使用 s.rsplit(t,n) 可以从右往左进行分割——只有在指定了 n 并且 n 小于可能分割的最大次数是才能起作用 12345678&gt;&gt;&gt; s='/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin'&gt;&gt;&gt; s.split(':',1)['/usr/local/sbin', '/usr/local/bin:/usr/sbin:/usr/bin:/root/bin']&gt;&gt;&gt; s.split(':',2)['/usr/local/sbin', '/usr/local/bin', '/usr/sbin:/usr/bin:/root/bin']&gt;&gt;&gt; s.rsplit('/',2)['/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:', 'root', 'bin']&gt;&gt;&gt; s.partition(t)：返回包含3个字符串的元组，字符串 s 中 从左往右 第一个 t 的左边的部分，t ， 从左往右 第一个 t 右边的部分。如果 t 不在 s 内则返回 s 与两个空字符串。 s.rpartition(t) ：返回包含3个字符串的元组，字符串 s 中 从右往左 第一个 t 的左边的部分，t ， 从右往左 第一个 t 右边的部分。如果 t 不在 s 内则返回 s 与两个空字符串。 123456789&gt;&gt;&gt; s='/usr/local/bin/firefox'&gt;&gt;&gt; s.partition('/')('', '/', 'usr/local/bin/firefox')&gt;&gt;&gt; s.rpartition('/')('/usr/local/bin', '/', 'firefox')&gt;&gt;&gt; s.partition('fdas')('/usr/local/bin/firefox', '', '')&gt;&gt;&gt; s.rpartition('fdas')('', '', '/usr/local/bin/firefox') 位置检索 s.index(t,start,end)：如果在 s (或 s 的 start:end 分片 )中 从左往右 能找到字符串 t ，则返回 最左边 的 t 的位置；如果没有找到则产生 ValueError 异常； s.rindex(t,start,end)：如果在 s (或 s 的 start:end 分片 )中 从右往左 能找到字符串 t ，则返回 最右边 的 t 的位置；如果没有找到则产生 ValueError 异常； s.find(t,start,end)：如果在 s (或 s 的 start:end 分片 )中 从左往右 能找到字符串 t ，则返回 最左边 的t的位置；如果没有找到则返回 -1； s.rfind(t,start,end)：如果在 s (或 s 的 start:end 分片 )中 从右往左 能找到字符串 t ，则返回 最右边 的 t 的位置；如果没有找到则返回 -1； 12345678910111213141516171819202122232425262728&gt;&gt;&gt; s='/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin'&gt;&gt;&gt; s.index('local')5&gt;&gt;&gt; s.rindex('local')21&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; s.index('localsf')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: substring not found&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; s.rindex('localsf')Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;ValueError: substring not found&gt;&gt;&gt; &gt;&gt;&gt; &gt;&gt;&gt; s.find('usr')1&gt;&gt;&gt; s.rfind('usr')42&gt;&gt;&gt; s.rfind('usrf')-1&gt;&gt;&gt; s.rfind('usrf')-1 替换 s.replace(t,u,n)：返回 s 的副本，其中每个(或最多 n 个，若指定了n)字符串 t 使用 u 进行替换 1234567&gt;&gt;&gt; s="You're so You're so... sex sex sex I need your love"&gt;&gt;&gt; s.replace('sex','sexy')"You're so You're so... sexy sexy sexy I need your love"&gt;&gt;&gt; s.replace('sex','sexy',0)"You're so You're so... sex sex sex I need your love"&gt;&gt;&gt; s.replace('sex','sexy',1)"You're so You're so... sexy sex sex I need your love" 可迭代数据类型转为字符串 x.join(seq)：以 x (可以为空)作为连接符，将可迭代对象 seq 中的每个元素连接起来 123456789&gt;&gt;&gt; s=['usr','local','bin']&gt;&gt;&gt; ''.join(s)'usrlocalbin'&gt;&gt;&gt; '/'.join(s)'usr/local/bin'&gt;&gt;&gt; '/'.join(s).replace('usr','/usr')'/usr/local/bin'&gt;&gt;&gt; print('+'.join(["1","2","3"]))1+2+3 x.join() 方法也可以与内置的 reversed() 函数一起使用，以实现对字符串的反转，例如&quot;&quot;.join(reversed(s))。当然通过步距也可以更精确地获取同样的结果，比如s[::-1] 12345&gt;&gt;&gt; s=['1', '2', '3', '4', '5']&gt;&gt;&gt; ''.join(s[::-1])'54321'&gt;&gt;&gt; ''.join(reversed(s))'54321' 其他 s.isidentifier()：如果 s 非空，并且是一个有效的标识符（变量名），则返回 True s.isalnum()：如果 s 非空，并且其中每一个字符都是字母或数字，则返回 True s.isdigit()：如果 s 非空，并且其中每一个字符都是一个 ASCII 数字，则返回 True 1234567891011121314151617181920&gt;&gt;&gt; s='/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin'&gt;&gt;&gt; s.isidentifier()False&gt;&gt;&gt; s='Name'&gt;&gt;&gt; s.isidentifier()True&gt;&gt;&gt; s='abc234,'&gt;&gt;&gt; s.isalnum()False&gt;&gt;&gt; s='abc23'&gt;&gt;&gt; s.isalnum()True&gt;&gt;&gt; s.isdigit()False&gt;&gt;&gt; s='023'&gt;&gt;&gt; s.isdigit()True&gt;&gt;&gt; s='abc23.12'&gt;&gt;&gt; s.isdigit()False 连接效率测试与总结实验比较 + 和 x.join(s) 的连接效率 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#!/usr/bin/env python# -*- coding: utf-8 -*-from time import timedef test1(): """ 使用 + 连接100个字符串 'python' """ time_begin=time() for i in range(100000): s='python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python'+'python' print(time()-time_begin)def test2(): """ 使用join连接100个字符串 'python' """ time_begin=time() for i in range(100000): s=''.join(['python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python','python']) print(time()-time_begin)def test3(): """ 使用 + 连接3个字符串 'python' """ time_begin=time() for i in range(100000): s='python'+'python'+'python' print(time()-time_begin)def test4(): """ 使用join连接3个字符串 'python' """ time_begin=time() for i in range(100000): s=''.join(['python','python','python']) print(time()-time_begin)test1()test2()print('-'*50)test3()test4() 运行结果 123456[user1@CentOS-7.3 tmp]$ ./test.py0.9836847782135010.21014761924743652--------------------------------------------------0.0030026435852050780.02301621437072754 总结 使用 + 连接效率低是在连续进行多个字符串连接的时候出现的，如果连接的个数较少，加号连接效率反而比 join 连接效率高 join 使用略复杂，但对多个字符进行连接时效率高，只会有一次内存的申请。而且如果是对 list 的字符进行连接的时候，这种方法必须是首选 使用 + 进行字符串连接，操作效率低下，因为 Python 中字符串是不可变的类型，使用 + 连接两个字符串时会生成一个新的字符串，生成新的字符串就需要重新申请内存，当连续相加的字符串很多时效率低下就很显然了]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的基本数据类型-整型和浮点型]]></title>
    <url>%2F2019%2F03%2F05%2F164610-Python%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-%E6%95%B4%E5%9E%8B%E5%92%8C%E6%B5%AE%E7%82%B9%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Python提供了两种内置的 Integral 类型，即 int 与 bool 。整数与布尔型值都是固定的，但由于Python提供了增强的赋值操作符，使得这一约束极少导致实际问题。在布尔表达式中， 0 与 False 表示 False ，其他任意整数与 true 都表示 true 。在数字表达式中，True表示1，False表示0。这意味着有些看起来很怪异的表达式也是有效的。 例如可以使用表达式 i += True 来对整型变量 i 进行递增操作，当然最自然的方法还是 i+=1 Integral (整型)整数整数的大小只受限于机器的内存大小，因此包含几百个数字的整数可以很容易地创建与操纵。默认情况下整数采用的是十进制，但在方便的时候也可以使用其他进制 12345678910&gt;&gt;&gt; 14600926 #decimal14600926&gt;&gt;&gt; 0b110111101100101011011110 #binary14600926&gt;&gt;&gt; 0o67545336 #octal14600926&gt;&gt;&gt; 0xDECADE #hexadecimal14600926&gt;&gt;&gt; 二进制数以0b引导，八进制数以0o引导，十六进制数则以0x引导，大写字母也可以使用。 语法 描述 x + y 将数x与数y相加 x - y 从x减去y x * y 将x与y相乘 x / y 用x除以y ,产生一个浮点值(若x或y是一个复数就产生一个复数) x // y 用x除以y ,舍弃小数部分,结果总为整数,参见round() x % y 用 x 除以 y ,取模(余数) x ** y 计算x的y次幂,参见pow() -x 对x取负数,若x为0不做任何操作,否则改变其符号 +x 不做任何操作,有时候用于澄清代码 abs(x) 返回x的绝对值 divmod() 以二元组的形式返回x除以y所得的商和余数(两个整数) pow(x,y) 计算x的y次幂,与操作符**相同 pow(x,y,z) (x**y)%z的另一种写法 round(x,n) 返回浮点数x四舍五入后的整数(或给定n将浮点数转换为小数点后有n位) 所有二元数学操作符(+、-、/、//、％与)都有相应的增强版赋值操作符(+=、 -=、/=、//=、％=与=) 对象的创建可以通过给变量赋字面意义上的值，比如 x=17，或者将相关的数据类型作为函数进行调用，比如x=int(17)。使用数据类型创建对象时，有3种用例： 第一种情况，不使用参数调用数据类型函数，这种情况下对象会被赋值为一个默认值，比如 x=int() 会创建一个值为0的整数。所有内置的数据类型都可以作为函数并不带任何参数进行调用。 第二种情况，使用一个参数调用数据类型函数。若给定的参数是同样的数据类型,就将创建一个新对象，新对象是原始对象的一个浅拷贝。如果给定的参数不是同样的数据类型，就会尝试进行转换。如果给定参数支持到给定数据类型的转换，但是转换失败，就会产生一个 ValueError 异常，否则返回给定类型的对象。如果给定参数不知道到给定数据类型的转换，就会产生一个TypeError 异常。内置的 float 与 str 类型都支持到整数的转换。 第三种情况，给定两个或多个参数但不是所有数据类型都支持，而对支持这一情况的数据类型，参数类型以及内涵都是变化的。对于 int 类型，允许给定两个参数，其中第一个参数是一个表示整数的字符串，第二个参数则是字符串表示的 base。 比如，int(&quot;A4&quot;,16) 会创建一个值为164的整数。 布尔型有两个内置的布尔型对象：True 与 False。布尔数据类型也可以当作函数进行调用——不指定参数时将返回False，给定的是布尔型参数时，会返回该参数的一个拷贝，给定的是其他类型的参数时，则会尝试将其转换为布尔数据类型。所有内置的数据类型与标准库提供的数据类型都可以转换为一个布尔型值，为自定义数据类型提供布尔型转换也很容易。下面给出了两个布尔型赋值操作以及两个布尔表达式： 123456&gt;&gt;&gt; t = True&gt;&gt;&gt; f = False&gt;&gt;&gt; t and fFalse&gt;&gt;&gt; t and TrueTrue 浮点型浮点数也就是小数，之所以称为浮点数，是因为按照科学记数法表示时，一个浮点数的小数点位置是可变的，比如，1.23x10^9和12.3x10^8是完全相等的。浮点数可以用数学写法，如1.23，3.14，-9.01，等等。但是对于很大或很小的浮点数，就必须用科学计数法表示，把10用e替代，1.23x10^9就是1.23e9，或者12.3e8，0.000012可以写成1.2e-5等等。 整数和浮点数在计算机内部存储的方式是不同的，整数运算永远是精确的（除法也是精确的），而浮点数运算则可能会有四舍五入的误差。 浮点数有完整的支持；整数和浮点数的混合计算中，整数会被转换为浮点数]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的流程控制]]></title>
    <url>%2F2019%2F03%2F05%2F120910-Python%E7%9A%84%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[说明.py 文件中的每条语句都是顺序执行的，从第一条语句开始逐行执行。实际上函数、方法调用或控制结构都可以使控制流转向，比如条件分支或循环语句。有意外产生时控制流也会被转向 布尔表达式实际上就是对某对象进行布尔运算，并可以产生一个布尔值结果( True 或 False )。在 Python 中，预定义为常量 False 的布尔表达式、特殊对象 None 、空序列或集合(比如空字符串、列表或元组)、值为 0 的数值型数据项等的布尔结果为 False， 其他的则为 True。创建自定义数据类型时，我们可以自己决定这些自定义数据类型在布尔上下文中的返回值 在 Python 中，一块代码，也就是说一条或多条语句组成的序列称为 suite 。由于 Python 中的某些语法要求存在一个 suite，Python 就提供了关键字 pass，pass 实际上是一条空语句，不进行任何操作，可以用在需要 suite (或者需要指明我们己经考虑了特殊情况）但又不需要进行处理的地方 选择语句 ifPython 常规的 if 语法如下 1234567if boolean_expression 1: suite1elif boolean一expression2: suite2elif boolean_expressionN: suiteNelse_suite 示例：实现一个猜年龄的游戏 1234567891011# -*- coding:utf-8 -*-my_age = 18input_age = int(input("请猜一猜我的年龄："))if input_age == my_age: print("猜对了！")elif input_age &lt; my_age: print("猜的太大了")else: print("猜的太小了") 循环语句 有限循环：有次数限制的循环 无限循环：没有次数限制的循环，即死循环 流程控制 continue：结束本次循环，继续进行下一次循环 break：跳出当前的循环 for 循环只能是有限循环，while 循环可以是有限循环也可以是无限循环 whilewhile 语句用于0次或多次执行某个 suite ，循环执行的次数取决于 while 循环中布尔表达式的状态 12while boolean_expression: suite 只有条件不成立时退出循环，如果条件为真则循环就没有停止的时候，成为一个死循环 12345while True: item = get_next_item() if not item: break process_item(item) while 循环具有非常典型的结构，只要还存在需要处理的数据项，就一直循环 ( get_next_item() 与 process_item() 都是在某处定义的自定义函数)。在上面的实例中， while 语句的 suite 中包含了一条 if 语句，该 if 语句本身又包含了自己的 suite，因此在这一实例中必须包含一条 break 语句 上面的猜年龄游戏，每执行一次用户就输入一次数字，程序就会判断一个结果，之后程序就结束了。然而这样并不好，程序应该是一直让用户输入数字，一直到用户输入的数字正确： 12345678910111213# -*- coding:utf-8 -*-my_age = 18input_age = int(input("请猜一猜我的年龄："))while input_age != my_age: if input_age &lt; my_age: print("猜的太小了") else: print("猜的太大了") input_age = int(input("请猜一猜我的年龄："))print("猜对了！") break结束当前的循环，不支持接收参数。在死循环中，也可以通过设置一定的条件来结束循环 例如：输出 1 到 10，但是当输出到 5 时不再执行循环 123456789# -*- coding:utf-8 -*-num = 1while num &lt;= 10: print("当前数字是", num) if num == 5: break num = num + 1 print("现在数字变成了：", num) continue结束本次循环，进行下一次循环 例如：输出1-100之间的所有奇数 12345678# -*- coding:utf-8 -*-num = 0while num &lt; 100: num = num + 1 if num % 2 == 0: continue print(num) while中的elsewhile循环中的 else 语句比较特殊，这里的 else 语句，只有在循环正常结束的时候才会执行，什么意思呢？意思就是说如果我们的 while 循环在执行过程中中断了，也就是说执行了break语句，这里的 else 语句就不会被执行 12345# while循环结构while 判断条件： 执行语句……else: 执行语句…… 示例 循环没有被中断 12345678num = 0while num &lt; 10: num = num + 1 if num % 2 == 0: continue print(num)else: print("else-----") 循环被中断 12345678num = 0while num &lt; 10: num = num + 1 if num % 2 == 0: break print(num)else: print("else-----") 序列 序列就是按照一定的顺序排列起来的一组元素，range() 语句用来生成一组数字 12345678&gt;&gt;&gt; range(10)[0, 1, 2, 3, 4, 5, 6, 7, 8, 9] # 就像队伍一样，还是有按照顺序来排列的，每个元素不是在其他元素之前就是在其之后&gt;&gt;&gt; range(1,10) # range()生成的数字默认从0开始，也可以是指定起始值。[1, 2, 3, 4, 5, 6, 7, 8, 9]&gt;&gt;&gt; range(1,10,2) # 还可以指定步长[1, 3, 5, 7, 9] rang() 的用法： 123456range(stop) #stop为结束位置，列出从0到stop之前的所有整数range(start, stop[, step]) #start表示起始数字,stop表示结束数字，stop表示每两个相邻数字之间的差，也叫步长 #列出从start开始，到stop之前所有的数字 forPython 的 for 循环语句重用了关键字 in ，与 while 循环类似，for 循环也支持 break 语句与 continue 语句，也包含可选的 else 分支 循环结构 12for var in sequence: statements(s) 示例 12for i in range(10): print(i) 九九乘法表 12345for row in range(1, 10): for col in range(1, 10): if col &lt;= row: print('%s x %s = %-2s' % (col, row, col * row), end=' ') print() 练习输入用户名和密码做认证，如果输错三次则退出，正确则输出欢迎登录 版本一 12345678910111213141516171819# -*- coding: utf-8 -*-username = 'root'password = '123456'true_or_false = False # 标志位for i in range(3): input_username = input("Username : ") input_password = input("Password : ") if input_username == username and input_password == password: print("Welcome %s login in " % username) true_or_false = True break else: print("Invalid username or password !")if not true_or_false: print("Too many failures ") 版本二 12345678910111213141516# -*- coding: utf-8 -*-username = 'root'password = '123456'for i in range(3): input_username = input("Username : ") input_password = input("Password : ") if input_username == username and input_password == password: print("Welcome %s login in " % username) true_or_false = True break # 跳出，中断。break for 过后就不会执行最后面的 else else: print("Invalid username or password !")else: # 只要上面的 for 循环正常执行完毕，中间没有被打断，就会执行 else print("Too many failures ") 版本三 1234567891011121314151617# -*- coding: utf-8 -*-username = 'root'password = '123456'counter = 0while counter &lt; 3: # 当条件成立（True），才会执行循环体中的代码 input_username = input("Username : ") input_password = input("Password : ") if input_username == username and input_password == password: print("Welcome %s login in " % username) break else: print("Invalid username or password !") counter += 1else: print("Too many failures ")]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中的input和print方法]]></title>
    <url>%2F2019%2F03%2F05%2F083910-Python%E4%B8%AD%E7%9A%84input%E5%92%8Cprint%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[input很多情况下运行的 Python 程序并没有和用户交互，程序运行后就等待结果的输出。而有些程序是需要用户输入才能继续向下执行。Python 中使用 input() 函数可以很便捷地获取用户的输入 12name = input("What's your name ? ")print("Your name is", name) 输出结果 12What&apos;s your name ? TomYour name is Tom 需要注意的是， input() 返回的数据类型都是字符串 print使用帮助print() 函数是 Python 的内置方法，用于将指定的值打印到屏幕输出，或文件流。它的参数如下： 123456789101112&gt;&gt;&gt; help(print)Help on built-in function print in module builtins:print(...) print(value, ..., sep=' ', end='\n', file=sys.stdout, flush=False) Prints the values to a stream, or to sys.stdout by default. Optional keyword arguments: file: a file-like object (stream); defaults to the current sys.stdout. sep: string inserted between values, default a space. end: string appended after the last value, default a newline. flush: whether to forcibly flush the stream. 参数说明 *values : 表示要打印的值，任何多个无名参数, 各个值之间用 , 隔开，打印出来的各个值之间默认是以空格隔开 1234&gt;&gt;&gt; name = 'Tom'&gt;&gt;&gt; age = '18'&gt;&gt;&gt; print(name, age)Tom 18 sep=&#39; &#39;： 表示当输入多个打印的值时，各个值之间分割方式， 默认是空格，也可以自定义，例如 1234&gt;&gt;&gt; name = 'Tom'&gt;&gt;&gt; age = '18'&gt;&gt;&gt; print(name, age, sep = '---' )Tom---18 end=&#39;\n&#39;: 控制 print() 中传入值输出完后的结束符号，默认是换行，也可以自定义，例如： 1234567&gt;&gt;&gt; name = 'Tom'&gt;&gt;&gt; age = '18'&gt;&gt;&gt; print(name);print(age)Tom18&gt;&gt;&gt; print(name, end=' is ');print(age, end=' years old ')Tom is 18 years old file=sys.stdout：在 Linux 中一切皆文件，包括屏幕终端输出，file 用来设置输出到哪里，默认是输出到屏幕(标准输出)，在 Python 中就是 sys.stdout 。我们可以设置 file=&#39;/tmp/test.txt&#39;，把内容存到该文件中 123f = open(r'/tmp/test.txt', 'w')print('Tom is 18 years old', file=f)f.close() flush=False：刷新内存中的缓冲区数据，是否立刻将缓冲区的数据写入硬盘中的文件，默认为 False 。默认情况下 print() 将内容输出到 sys.stdout ，即标准输出（屏幕）文件，比较下面两种的参数实现进度条的效果 默认情况，flush=False，当所有 sleep 完成之后才会写到屏幕输出文件 12345import timefor i in range(30): print('*', end='') time.sleep(0.1) 人为干预，flush=True，每次输出都会写到屏幕输出文件 12345import timefor i in range(30): print('*', end='', flush=True) time.sleep(0.1) 另一种实现效果 123456789import timefor i in range(0, 101, 2): time.sleep(0.3) char_num = i // 2 # 打印多少个'*' per_str = '\r%s%% : %s' % (i, '*' * char_num) print(per_str, end='', flush=True)print('')# \r 可以把光标移动到行首但不换行，覆盖之前行的内容 格式化输出Python 中的 print 继承了 C 中的 printf，例如 12&gt;&gt;&gt; print('%s x %s = %s' % (5, 6, 5 * 6))5 x 6 = 30 %：占位符，标记了转换说明符的开始 转换标志 - 表示左对齐 + 表示在转换值之前要加上正负号 （空白字符）表示正数之前保留空格 0 表示转换值若位数不够则用0填充 最小字段宽度：转换后的字符串至少应该具有该值指定的宽度。如果是 *，则宽度值会从元组中读出 . 后跟精度值： 如果转换的是实数，精度值就表示出现在小数点后的位数。 如果转换的是字符串，那么该数字就表示最大字段宽度。 如果是 *，那么精度将从元组中读出 字符串格式化转换类型 转换类型 含义 d,i 带符号的十进制整数 o 不带符号的八进制 u 不带符号的十进制 x 不带符号的十六进制(小写) X 不带符号的十六进制(大写) e 科学计数法表示的浮点数（小写） E 科学计数法表示的浮点数（大写） f,F 十进制浮点数 g 如果指数大于-4或者小于精度值则和e相同，其他情况和f相同 G 如果指数大于-4或者小于精度值则和E相同，其他情况和F相同 C 单字符（接受整数或者单字符字符串） r 字符串（使用repr转换任意python对象) s 字符串（使用str转换任意python对象） 示例 12345678910111213# 最小宽度为2，默认右对齐&gt;&gt;&gt; print('%2sx%2s=%2s' % (5, 6, 5 * 6)) 5x 6=30# 最小宽度为2，左对齐&gt;&gt;&gt; print('%-2sx%-2s=%-2s' % (5, 6, 5 * 6))5 x6 =30# 最小宽度为8,&gt;&gt;&gt; print('%8d' % 9) 9# 最小宽度为8，位数不够用0填充 &gt;&gt;&gt; print('%08d' % 9)00000009 颜色输出示例和说明 示例 123print('\033[0;31m Hello \033[0;39m')# print('\033[字背景颜色;文字颜色m 字符串\033[0m') print('\033[1;36;41m Something here \033[0m') 说明 \ 代表转义 033 代表键盘的Control键 1 字体行为(高亮，闪烁，下划线等)； 36 字体颜色 41 字体背景色 注： 字背景颜色和文字颜色之间是英文的分号’;’ 文字颜色后面有个m 字符串前后可以没有空格，如果有的话，输出也是同样有空格 文字和背景颜色搭配 字体颜色范围值 30~37 12345678"\033[30m 黑色字 \033[0m""\033[31m 红色字 \033[0m""\033[32m 绿色字 \033[0m""\033[33m 黄色字 \033[0m""\033[34m 蓝色字 \033[0m""\033[35m 紫色字 \033[0m""\033[36m 天蓝字 \033[0m""\033[37m 白色字 \033[0m" 字体背景颜色范围值 40~47 12345678"\033[40;37m 黑底白字 \033[0m" "\033[41;37m 红底白字 \033[0m" "\033[42;37m 绿底白字 \033[0m" "\033[43;37m 黄底白字 \033[0m" "\033[44;37m 蓝底白字 \033[0m" "\033[45;37m 紫底白字 \033[0m" "\033[46;37m 天蓝底白字 \033[0m" "\033[47;30m 白底黑字 \033[0m" 控制选项说明 1234567891011121314151617181920\033[0m # 关闭所有属性 \033[1m # 设置高亮度 \033[4m # 下划线 \033[5m # 闪烁 \033[7m # 反显 \033[8m # 消隐 \033[30m — \33[37m # 设置前景色 \033[40m — \33[47m # 设置背景色 \033[60A # 光标上移60行 \033[60B # 光标下移60行 \033[60C # 光标右移60行 \033[60G # 光标右移60行\033[60D # 光标左移60行 \033[y;xH # 设置光标位置 \033[2J # 清屏 \033[K # 清除从光标到行尾的内容 \033[s # 保存光标位置 \033[u # 恢复光标位置 \033[?25l # 隐藏光标 \033[?25h # 显示光标 额外说明 前景颜色各数字是对应背景颜色减去10 结束非常规字符序列的 m 要紧跟前面的数字，不能有空格 练习输入的内容如下 1234name = input(&quot;Input your name : &quot;)age = input(&quot;Input your age : &quot;)job = input(&quot;input your job : &quot;)salary = input(&quot;input your salary : &quot;) 输出格式： 123456---------- Info of Jerry ----------Name : JerryAge : 18Job : ITSalary : 1000------------ End ------------------- 示例代码： 1234567891011121314151617181920name = input("Input your name : ")age = input("Input your age : ")job = input("input your job : ")salary = input("input your salary : ")if salary.isdigit(): salary = int(salary)else: exit('Must input digit')msg = '''---------- Info of %s ----------Name : %sAge : %sJob : %sSalary : %s------------ End ---------------''' % (name, name, age, job, salary)print(msg)]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的运算符]]></title>
    <url>%2F2019%2F03%2F04%2F161610-Python%E7%9A%84%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[运算符和表达式表达式就是由操作数和运算符组成的一句代码或语句，表达式可以求值，可以放在 = 的右边，用来给变量赋值 举个例子：1+2*3 就是一个表达式，+ 和 * 称为操作符，也叫做运算符，1、2、3 叫做操作数。1+2*3 经过计算后得到的结果是 7 。我们可以将计算结果赋值给变量，result = 1+2*3 算术运算符Python 提供了完整的算术运算符集，包括用于基本四则数学运算的操作符 +、-、 *、/ 。在 操作数都是整数时，+、-、* 等操作符可以分别按正常的加法、减法、乘法进行运算，其中 - 既可以作为单值操作符（否定)，也可以作为二元操作符（减法)。 12345678910&gt;&gt;&gt; 5 + 611&gt;&gt;&gt; 3 - 7-4&gt;&gt;&gt; 4 * 832&gt;&gt;&gt; -4 - 5-9&gt;&gt;&gt; 2**38 在 Python 中，与一般程序语言不同的地方在于对除法的处理，除法操作符会产生一个浮点值，而不是一个整数值；很多其他程序设计语言都是产生一个整数值，并剥离掉小数部分。如果需要产生一个整数值结果，我们可以使用 int()进行转换（或使用剥离操作符//)。 12345678&gt;&gt;&gt; 12 / 34.0&gt;&gt;&gt; 5 / 22.5&gt;&gt;&gt; 5//22&gt;&gt;&gt; 5%21 可使用 () 来解决优先级的问题时 1234&gt;&gt;&gt; 1 + 2 * 37&gt;&gt;&gt; ( 1 + 2 ) * 39 赋值运算符除了基本的赋值运算符 = 之外，很多 Python 数据类型还可以使用一些增强的赋值运算符： 12345678&gt;&gt;&gt; num = 2 &gt;&gt;&gt; num += 1 # 等价于 num = num + 1&gt;&gt;&gt; num -= 1 # 等价于 num = num - 1&gt;&gt;&gt; num *= 1 # 等价于 num = num * 1&gt;&gt;&gt; num /= 1 # 等价于 num = num / 1&gt;&gt;&gt; num //= 1 # 等价于 num = num // 1&gt;&gt;&gt; num %= 1 # 等价于 num = num % 1&gt;&gt;&gt; num **= 2 # 等价于 num = num ** 2 比较运算符Python 提供了二进制比较操作符的标准集合，这些操作符对对象的值进行比较 运算符 描述 实例 == 等于：比较对象是否相等 (a == b) 返回 False != 不等于：比较两个对象是否不相等 (a != b) 返回 True &lt;&gt; 不等于：比较两个对象是否不相等 (a &lt;&gt; b) 返回 true 这个运算符类似 != &gt; 大于：返回x是否大于y (a &gt; b) 返回 False &lt; 小于：返回x是否小于y。所有比较运算符返回1表示真，返回0表示假。这分别与特殊的变量 True 和 False 等价。 (a &lt; b) 返回 True &gt;= 大于等于：返回x是否大于等于y (a &gt;= b) 返回 False &lt;= 小于等于：返回x是否小于等于y (a &lt;= b) 返回 True Python 比较操作符的一个特别好用的特性是可以进行结链比较，例如 123&gt;&gt;&gt; a = 9&gt;&gt;&gt; 0 &lt;= a &lt;= 10True Python 并不会猜测我们的真正意图，进行无意义的比较会导致异常，出现异常而又未得到处理时，Python 会输出该异常错误消息的回溯与追踪信息。正确的方法是进行明确的转换，使用可比较的类型。例如： 123456&gt;&gt;&gt; '3' &lt; 4Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;TypeError: '&lt;' not supported between instances of 'str' and 'int'&gt;&gt;&gt; int('3') &lt; 4True 身份运算符在 Python 中， 变量实际上都是对象引用，有时我们需要知道两个或更多的对象引用是否都指向相同的对象 is ：如果其左端对象引用与右端的对象引用指向的 是 同一个对象，则会返回 True，否则返回 False is not： 如果其左端对象引用与右端的对象引用指向的 不是 同一个对象，则会返回 True，否则返回 False 利用 id() 函数可以取得对象的内存地址 示例注意： 以下测试情况会在交互模式下出现，在脚本模式中 is 和 == 结果是一样的 12345678910111213141516&gt;&gt;&gt; a = 2.0&gt;&gt;&gt; b = 2.0&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; a == bTrue&gt;&gt;&gt; id(a)47800288&gt;&gt;&gt; id(b)47800224&gt;&gt;&gt; a = ["Retention", 3, None]&gt;&gt;&gt; b = ["Retention", 3, None]&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; a == bTrue Python 中会为每个出现的对象分配内存，哪怕他们的值完全相等，注意这里说的是 字面意义上的值相等，而不是说相同，相同指的是引用的对象是同一个 。上例中，a = 2.0，b = 2.0 这两个语句时会先后为 2.0 这个 float 类型对象分配内存，然后将 a 与 b 分别指向这两个对象。所以 a 与 b 指向的不是同一对象 但是为了提高内存利用效率，对于一些简单的对象，如一些数值较小的 int 对象，python 采取重用对象内存的办法，如 a = 2，b = 2 时，由于 2 作为简单的 int 类型且数值小，Python 不会两次为其分配内存而是只分配一次，然后将 a 与 b 同时指向已分配的对象： 123456&gt;&gt;&gt; a = 2&gt;&gt;&gt; b = 2&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; a == bTrue 如但果赋值的不是 2 而是大的数值，情况就跟前面的一样了： 123456&gt;&gt;&gt; a = 3333&gt;&gt;&gt; b = 3333&gt;&gt;&gt; a is bFalse&gt;&gt;&gt; a== bTrue 在交互模式下，如果变量写在同一行，将会指向同一个对象 123456789101112&gt;&gt;&gt; a=3333; b=3333; # 写在同一行&gt;&gt;&gt; a is bTrue&gt;&gt;&gt; a == bTrue&gt;&gt;&gt; c = 5555 # 写在不同一行&gt;&gt;&gt; d = 5555 # 写在不同一行&gt;&gt;&gt; c is dFalse&gt;&gt;&gt; c == dTrue 在 python 脚本中，不管是否是一行都指向同一个对象 12345678# -*- coding: utf-8 -*-a = 3333; b = 3333print(a is b) # truec = 5555d = 5555print(c is d) # true 总结： 对 int (整型)、str (字符串) 以及很多其他数据类型进行比较是没有意义的，因为几乎绝大多数情况下我们基本上是比较他们的值，而不是比较他们的引用的对象是不是同一个 身份比较的一个好处是速度非常快，这是因为 Python 并不必须对进行比较的对象本身进行检查，is 操作符只需要对对象所在的内存地址进行比较——同样的地址存储的是同样的对象 最常见的情况使用 is 将数据项与内置的空对象 None 进行比较，None 通常用作位置标记值，表示“未知”或“不存在” 1234&gt;&gt;&gt; a="Something"&gt;&gt;&gt; b=None&gt;&gt;&gt; a is not None,b is None(True, True) 成员运算符对序列或集合这一类数据类型，比如字符串、列表或元组我们可以使用操作符 in 来测试成员关系，用 not in 来测试非成员关系。例如： 12345&gt;&gt;&gt; p = (4, "frog", 9, -33, 9, 2)&gt;&gt;&gt; 2 in p True&gt;&gt;&gt; "dog" not in pTrue 对列表与元组，in 操作符使用线性搜索，对非常大的组合类型（包含数万个或更多的数据项)，速度可能会较慢；而对字典或集合，in 操作可以非常快 对字符串数据类型，使用成员运算符可以很方便地测试任意长度的子字符串 12345&gt;&gt;&gt; phrase = "Wild Swans by Jung Chang"&gt;&gt;&gt; "J" in phraseTrue&gt;&gt;&gt; "han" in phraseTrue 逻辑运算符Python 提供了 3 个逻辑运算符：and 、or 、 not 。其中 and 与 or 都使用 short-circuit 短路逻辑，并返回决定结果的操作数——而不是返回布尔值（除非实际上就是布尔操作数) 1234567&gt;&gt;&gt; five = 5; two = 2; zero = 0&gt;&gt;&gt; five and two2&gt;&gt;&gt; two and five5&gt;&gt;&gt; five and zero0 如果逻辑表达式本身（例如 if 语句）出现在布尔上下文中，那么结果也为布尔值。因此上面的内容使用了表达式后，返回的结果将变为 True True False 123456789&gt;&gt;&gt; nought = 0&gt;&gt;&gt; five or two5&gt;&gt;&gt; two or five2&gt;&gt;&gt; zero or five5&gt;&gt;&gt; zero or nought0 or 操作符是类似的，这里在布尔上下文中，上面的结果应该为 True True True 与 False 1234&gt;&gt;&gt; not(zero or nought)True&gt;&gt;&gt; not twoFalse not 单一操作符在布尔上下文中评估其参数，并总是返回布尔型结果]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的标识符与关键字]]></title>
    <url>%2F2019%2F03%2F04%2F081210-Python%E7%9A%84%E6%A0%87%E8%AF%86%E7%AC%A6%E4%B8%8E%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[标识符(变量)Variables are used to store information to be referenced and manipulated in a computer program. They also provide a way of labeling data with a descriptive name, so our programs can be understood more clearly by the reader and ourselves. It is helpful to think of variables as containers that hold information. Their sole purpose is to label and store data in memory. This data can then be used throughout your program. 变量就是用来存储一些信息，供程序以后调用或者操作修改。变量为标记数据提供了一种描述性的名字，以便我们的程序可以被程序的阅读者很清晰的理解。把变量作为一个存储信息的容器会更容易理解变量。它的主要是目的是笔记和存储在内存中的数据，这个数据就可以在你的整个程序中使用 或许在很多人的直观印象中，变量是一个容器；给变量赋值，就像是往一个存储的容器中填入一个数据；再次赋值就是把容器中的数据换掉，在 Python 中，这种理解是不准确的！ 变量更像是一个标签：给变量赋值，就是把标签贴在一个物体上；再次赋值就是把标签贴在另一个物体上。变量不存在实体，它仅仅是一个标签，一旦赋值就被设置到另一个物体上，不变的是那些物体，即对象。Python 中所有东西都是对象，包括字符串、列表、元组等，以及函数、类、模块都是对象 123# -*- coding: utf-8 -*-name = "Jerry" 以上代码声明了一个变量，变量名为 name，并使用赋值操作符 = 为变量 name 赋了一个值为 Jerry 变量的命名规则 变量名区分大小写 变量名只能是 字母、数字 或 下划线 的任意组合 变量名不能以数字开头 变量名不能与 Python 的关键字同名，以下是 Python 关键字的获取方法 1234&gt;&gt;&gt; import keyword&gt;&gt;&gt; keyword.kwlist['False', 'None', 'True', 'and', 'as', 'assert', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or', 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']&gt;&gt;&gt; 变量名名的开头和结尾都使用下划线的情况 _ 应该避免使用，这是因为 Python 定义了各种特殊方法与变量，使用的就是这样的名称。命名惯例： 以单一下划线开头变量名 _x 不会被 from module import * 语句导入 前后有下划线的变量名 __x__ 是系统定义变量名，对 python 解释器有特殊意义 以两个下划线开头但结尾没有下划线的变量名 __x 是类的本地变量 交互模式下，变量名 _ 用于保存最后表达式的结果 变量的赋值 使用等号 = 作为赋值操作符来给变量进行赋值 等号 = 左边是一个变量名，右边是存储在变量中的值 Python 是动态类型的语言，在 Python 中变量赋值不需要声明数据的类型 每个变量在内存中创建，都包括变量的标识，名称和数据 每个变量在使用前都必须先进行赋值，变量赋值以后该变量才会被创建 示例 12345678910#!/usr/bin/env python3# -*- coding:utf-8 -*-counter = 12345678 # 赋值整型变量miles = 12345678.0 # 浮点型name = "Litingjie" # 字符串 print(counter)print(miles)print(name) 多个变量赋值 Python 允许同时为多个变量赋值。例如 12a = b = c = 1# 创建一个整型对象，值为1，三个变量被分配到相同的内存空间上 Python 也可以为多个对象指定多个变量。例如 12a, b, c = 1, 2, "Jerry"# 两个整型对象 1 和 2 的分配给变量 a 和 b，字符串对象 "Jerry" 分配给变量 c]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pycharm中警告信息汇总.]]></title>
    <url>%2F2019%2F03%2F03%2F215521-Pycharm%E4%B8%AD%E8%AD%A6%E5%91%8A%E4%BF%A1%E6%81%AF%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[警告信息使用 Pycharm 写的代码尽可能要符合 PEP8 代码规范，养成一个良好的习惯，在编写过程中会报出很多警告，以下做了个汇总方便自己查阅 1Indent expected 期望有缩进，也就是说我们写的代码少了缩进，添加缩进即可 1Unexpected inden 不期望的缩进，这时修改成符合规范的缩进 1PEP 8: expected 2 blank lines，found 0 期望有两个空行，发现0个，添加两行空行即可 1PEP 8: expected 2 blank lines after class or function definition, found 期望在类或函数定义的后面有两个空行，发现1个，在函数下面补充上即可 1PEP 8: module level import not at top of file import不在文件的最上面，可能引用之前还有代码 ，把import引用放到文件的最上部即可 1function name should be lowercas 函数名应该改成小写 1PEP 8: indentation contains tab 缩进中出现了 tab 空格，改成用四个空格缩进 1PEP 8: missing whitespace around operato 操作符前后丢失了空格，例如 x=3，改成x = 3 1PEP 8: no newline at end of fil 文件末尾没有新起一行，在最后一行回车即可 1PEP 8: blank line at end of file 文件末尾多了一个空行，删掉即可 1Shadows name ‘fr’ from outer scope fr 在外部已经定义了，修改成其他的即可：fr- &gt; ofr 1PEP 8: block comment should start with ‘# ’ 以 # 开头的注释， # 后面要跟一个空格 1PEP 8: inline comment should start with ‘# 行内注释也应该以 # 后面要跟一个空格作为开始 1PEP 8: multiple statements on one line (colon) 多行语句写到一行了，应该分行写 1Symplify chained comparision 链比较还可以简化，例如 if x &gt;= 1 and x &lt;= 10 可以简化为 1 &lt;= x &lt;= 10]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python代码规范总结]]></title>
    <url>%2F2019%2F03%2F03%2F215059-Python%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[规范总结 每个缩进层级使用4个空格 使用UTF-8编码 使用行末反斜杠折叠长行，限制每行最大79字符 每行只写一条语句 导入包：每条 import 导入一个模块，导入放在代码顶端，导入顺序是先标准库，第三方库，本地库，每组导入之间放置1行空行，所有导入使用包的绝对路径。 类内方法空1行分隔，类外空2行分隔 顶层函数或类的定义之间空两行（特别容易漏，漏的话，是报E302 expected 2 blank lines, found 1） 运算符除 * 外，两边空1格分隔，函数参数=周围不用空格 ，小括号，大括号，中括号之间的逗号没有额外的空格 类命名采用骆驼命名法，RedhatRelease; 函数用小写字符 其他模块、函数、方法、变量均使用全小写加下划线 1个前导下划线表示半公开 2个前导下划线表示私有，与保留字区分使用单个后置下划线 开发时使用中文注释，发布时再写英文文档]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的注释方法]]></title>
    <url>%2F2019%2F03%2F03%2F203210-Python%E7%9A%84%E6%B3%A8%E9%87%8A%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[程序代码中的注释并不是必须要写的，但是添加注释可以更方便的理解该行代码的意义。在 Python 中注释方式有两种，即 单行注释 和 多行注释 单行注释单行注释以 # 开头，例如: 12# 使用 print() 打印字符print("Hello, World!") 多行注释多行注释用三个单引号 &#39;&#39;&#39; 或者三个双引号 &quot;&quot;&quot; 将注释括起来，也称之为 “三引号”。单引号或双引号本质上没有什么区别。例如 使用 &#39;&#39;&#39; 1234567891011121314151617#!/usr/bin/python3 '''Help on built-in function print in module builtins:print(...) print(value, ..., sep=' ', end='\n', file=sys.stdout, flush=False) Prints the values to a stream, or to sys.stdout by default. Optional keyword arguments: file: a file-like object (stream); defaults to the current sys.stdout. sep: string inserted between values, default a space. end: string appended after the last value, default a newline. flush: whether to forcibly flush the stream.'''print("Hello, World!") 使用 &quot;&quot;&quot; 12345678910111213141516171819#!/usr/bin/python3 """Welcome to Python 3.6's help utility!If this is your first time using Python, you should definitely check outthe tutorial on the Internet at http://docs.python.org/3.6/tutorial/.Enter the name of any module, keyword, or topic to get help on writingPython programs and using Python modules. To quit this help utility andreturn to the interpreter, just type "quit".To get a list of available modules, keywords, symbols, or topics, type"modules", "keywords", "symbols", or "topics". Each module also comeswith a one-line summary of what it does; to list the modules whose nameor summary contain a given string such as "spam", type "modules spam"."""print("Hello, World!") 三引号来做单行注释也是可行的 123456#!/usr/bin/python3 """ Welcome to Python 3.6's help utility! """''' Help on built-in function print in module builtins: '''print("Hello, World!")]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一个Python程序]]></title>
    <url>%2F2019%2F03%2F03%2F080810-%E7%AC%AC%E4%B8%80%E4%B8%AAPython%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[Python程序的文件结构Python的源程序文件通常以 .py 结尾，第一行为 shellbang，即执行脚本时通知文件内容要使用哪个解释器来解释，Python 当中一切皆对象。 Python程序可以分解成模块、语句、表达式和对象。程序由模块组成，模块包含语句，语句包含表达式，表达式建立并处理对象 查看python版本我们可以使用以下命令来查看我们使用的 Python 版本： 1python -V 以上命令执行结果如下： 1Python 3.6.4 也可以进入 Python 的交互式模式，查看版本： 1python 直接在命令行界面执行 Python 即可进入交互式 123Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)] on win32Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; 编写和执行第一个Python程序对于大多数程序语言，第一个入门编程代码便是 Hello World !，可以通过以下两种方式来实现 交互式解释器1python 直接在命令行界面执行 Python 即可进入交互式 12345Python 3.6.4 (v3.6.4:d48eceb, Dec 19 2017, 06:04:45) [MSC v.1900 32 bit (Intel)] on win32Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; print("Hello world!") Hello world!&gt;&gt;&gt; python程序文件交互模式下的程序执行完成后难以再次运行，将编写的程序保存至文件（.py结尾）则很方便地多次运行。Python 的此类包含了一系列预先写好的语句程序文件称作 “ 模块 ”。能够直接运行的模块文件通常称作脚本（即程序的顶层文件） 123#!/usr/bin/python3 print("Hello, World!"); 第1行为注释。在 Python 中，注释以 # 开始，作用范围为该行。第2行为空行，Python 会忽视空行，但空行通常有助于将大块代码分割，以便于阅读。第3行为 Python 代码，其中调用了 print() 函数 在UNIX上，当某程序在控制台中被引用时，该文件的头两个字节先被读入。如果这两个字节是ASCII字符 #! ， shell 就会认为该文件将要由解释器执行，并且该文件的首行指定了要使用哪个解释器。该行称为 shebang ( shell 执行)行，如果存在，就必须为可执行文件的首行。shebang 行通常呈现为如下两种形式之一： 1#!/usr/bin/python3 1#!/usr/bin/env python3 如果是第一种形式，就会使用指定的解释器。如果是第二种形式， 就会使用在 shell 当前环境中发现的第一个 python 解释器。第二种形式具有更强的适应性，因为这种情况考虑了 Python 解释器位于 /usr/bin 之外（比如，安装在 /usr/local/bin 或 $HOME 等目录之下）的可能性。 将以上代码保存在 hello.py 文件中并使用 python 命令执行该脚本文件。 1python3 hello.py 以上命令输出结果为： 1Hello, World! 关于实例中第一行代码 #!/usr/bin/python3 的理解，如果调用 python 脚本时分成两种情况： 使用 python script.py 时，#!/usr/bin/python 被忽略，等同于注释 使用:./script.py 时，#!/usr/bin/python 指定解释器的路径 这句话仅仅在 linux 或 unix 系统下有作用，在 windows 下无论在代码里加什么都无法直接运行一个文件名后缀为.py的脚本，因在windows下文件名对文件的打开方式起了决定性作用]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python的字符编码]]></title>
    <url>%2F2019%2F03%2F02%2F200410-Python%E7%9A%84%E5%AD%97%E7%AC%A6%E7%BC%96%E7%A0%81%2F</url>
    <content type="text"><![CDATA[二进制与数字通过烽火戏诸侯的历史典故，我们能知道在古代的曾经使用的通信方式是使用烽火台，如果出现战事有敌人来了则会点燃烽火用烟来传递信息。光信号的传递速度很快，所以古代的这种信息传递方式是非常高效的。 假设长城足够长的话，通过烽火依次传递消息，能很快的传递信息给盟友。点火代就表敌人来了，不点火则代表没有敌人。 但是这种信息传递方式有一个缺点，那就是无法精确的传递敌人的规模。假设敌人有十万大军，我们该怎样向盟军传递信息呢？显然，我们用一根烟代表一个敌人没有办法在短时间内表示十万。于是我们可以使用这种方法：点燃第一根则代表敌人规模是1-100，点燃第二根则代表敌人规模是101-1000，以此类推 1231-100 101-1000 1001-5000第一根 第二根 第三根# 如果我们需要精确的传递敌人的个数，这种方法就不可行了 烟只有两种状态，那么如何才能表示精确的数字呢？一根烟可以表示两个状态，两根烟便可以表示四个状态。那么我们就可以约定，第一根烟代表1，第二根代表2，第三根代表4….. 来了一个敌人 1234# 从左往右表示0 1 # 代表的敌人：0+1=1-----------------------------------0 1 # 第一根亮，第二根灭 来了两个敌人 1234# 从左往右表示2 0 # 代表的敌人：2+0=2-----------------------------------1 0 # 第一根灭，第二根亮 来了三个敌人 1234# 从左往右表示2 1 # 代表的敌人：2+1=3-----------------------------------1 1 # 第一根亮，第二根亮 来了四个敌人 1234# 从左往右表示4 0 0 # 代表的敌人：4+0=4-----------------------------------1 0 0 # 第三根亮，第二根第一根都灭 来了五个敌人 1234# 从左往右表示4 0 1 # 代表的敌人：4+1=5-----------------------------------1 0 1 # 第三根亮，第二根灭，第一根亮 借位 利用前三位我们可以表示的数字有1、2、3、4、5、6、7，最多能表示7 如果想要表示8，我们可以借一位，用这个位加上前面的三个位最大表示8 每一个位最大能表示的数都是前面的位所能表示的最大数的和加1，并且依次是2的0次幂、1次幂、….. 123456# 从左往右表示16 8 4 2 1 1 1 1 1 1-----------------------------------16 = 8 + 4 + 2 + 1 +18 = 4 + 2 + 1 +1 利用这种表示方法，我们就可以根据使用0和1的不同序列来表示不同的数字。 计算机必须在通电情况下工作，它在物理层面上只能表示两种状态：低电压和高电压，或者我们可以简单的理解为电路的通电和不通电。通电用1表示，不同电则用0表示。 在拆开的硬盘盘片上我们看不到所谓的 0 和 1 ，但是如果使用足够大的放大镜能看到磁盘的表面有着无数的凹凸不平的元件，凹下去的代表0，凸出的代表1，这就是计算机用来表现二进制的方式。计算机中的所有数据，不论是文字、图片、视频、还是音频文件，本质上最终都是按照类似 01010101 的二进制存储的。 ASCII码通过二进制的1和0的不同序列边可以表示我们平常说的十进制数字了，但是每个国家都有各自的语言，相比在计算机上去读很难读懂的不同序列的0101二进制，我们更愿意在计算机上使用人类自己的语言。 计算机诞生在美国，为了让计算机表示不同的英文字母、数字和特殊符号，美国人便在计算机上使用了字符编码。字符编码是如何让二进制来表示字母的呢？字符编码规定了哪些数字表示哪些字母，只要计算机用二进制能表示出这些数字，便可以通过编码来表示字母了。最早的编码便是ASCII码对照表，全称是American Standard Code for Information Interchange , 美国信息交换标准代码。 ASCII 码使用指定的 7 位或 8 位二进制数组合来表示128 或 256 种可能的字符，但是最早的时候只用了 7 位二进制，已经完全能够来表示所有的大写和小写字母，数字0 到9、标点符号， 以及在美式英语中使用的特殊控制字符。 后来为了将拉丁文也编码进了ASCII表，将最高位也占用了，这就是扩展ASCII码。 二进制 ASCII值 控制字符 二进制 ASCII值 控制字符 二进制 ASCII值 控制字符 二进制 ASCII值 控制字符 00000000 0 NUT 00100000 32 (space) 01000000 64 @ 01100000 96 、 00000001 1 SOH 00100001 33 ! 01000001 65 A 01100001 97 a 00000010 2 STX 00100010 34 “ 01000010 66 B 01100010 98 b 00000011 3 ETX 00100011 35 # 01000011 67 C 01100011 99 c 00000100 4 EOT 00100100 36 $ 01000100 68 D 01100100 100 d 00000101 5 ENQ 00100101 37 % 01000101 69 E 01100101 101 e 00000110 6 ACK 00100110 38 &amp; 01000110 70 F 01100110 102 f 00000111 7 BEL 00100111 39 , 01000111 71 G 01100111 103 g 00001000 8 BS 00101000 40 ( 01001000 72 H 01101000 104 h 00001001 9 HT 00101001 41 ) 01001001 73 I 01101001 105 i 00001010 10 LF 00101010 42 * 01001010 74 J 01101010 106 j 00001011 11 VT 00101011 43 + 01001011 75 K 01101011 107 k 00001100 12 FF 00101100 44 , 01001100 76 L 01101100 108 l 00001101 13 CR 00101101 45 - 01001101 77 M 01101101 109 m 00001110 14 SO 00101110 46 . 01001110 78 N 01101110 110 n 00001111 15 SI 00101111 47 / 01001111 79 O 01101111 111 o 00010000 16 DLE 00110000 48 0 01010000 80 P 01110000 112 p 00010001 17 DCI 00110001 49 1 01010001 81 Q 01110001 113 q 00010010 18 DC2 00110010 50 2 01010010 82 R 01110010 114 r 00010011 19 DC3 00110011 51 3 01010011 83 S 01110011 115 s 00010100 20 DC4 00110100 52 4 01010100 84 T 01110100 116 t 00010101 21 NAK 00110101 53 5 01010101 85 U 01110101 117 u 00010110 22 SYN 00110110 54 6 01010110 86 V 01110110 118 v 00010111 23 TB 00110111 55 7 01010111 87 W 01110111 119 w 00011000 24 CAN 00111000 56 8 01011000 88 X 01111000 120 x 00011001 25 EM 00111001 57 9 01011001 89 Y 01111001 121 y 00011010 26 SUB 00111010 58 : 01011010 90 Z 01111010 122 z 00011011 27 ESC 00111011 59 ; 01011011 91 [ 01111011 123 { 00011100 28 FS 00111100 60 &lt; 01011100 92 / 01111100 124 00011101 29 GS 00111101 61 = 01011101 93 ] 01111101 125 } 00011110 30 RS 00111110 62 &gt; 01011110 94 ^ 01111110 126 ` 00011111 31 US 00111111 63 ? 01011111 95 _ 01111111 127 DEL 字符编码的发展史计算机开始普遍在其他国家开始使用，但是ASCII只能表示英文，无法表示中文、日文、韩文等。一个字节是8个比特，这意味着1个比特并没有被使用，也就是从128到255的编码并没有被制定ASCII标准的人所规定。其它国家的人趁这个机会开始使用128到255范围内的编码来表达自己语言中的字符。例如，144在阿拉伯人的ASCII码中是گ，而在俄罗斯的ASCII码中是ђ。ASCII码的问题在于尽管所有人都在0-127号字符的使用上达成了一致，但对于128-255号字符却有很多很多不同的解释。你必须告诉计算机使用哪种风格的ASCII码才能正确显示128-255号的字符。 关于中文为了处理汉字，程序员设计了用于简体中文的GB2312和用于繁体中文的big5 GB2312(1980年)一共收录了7445个字符，包括6763个汉字和682个其它符号。 GB2312 支持的汉字太少。1995年的汉字扩展规范GBK1.0收录了21886个符号，它分为汉字区和图形符号区。汉字区包括21003个字符。2000年的 GB18030 是取代GBK1.0的正式国家标准。该标准收录了27484个汉字，同时还收录了藏文、蒙文、维吾尔文等主要的少数民族文字。现在的PC平台必须支持 GB18030，对嵌入式产品暂不作要求。所以手机、MP3一般只支持GB2312。 从ASCII、GB2312、GBK 到 GB18030，这些编码方法是向下兼容的，即同一个字符在这些方案中总是有相同的编码，后面的标准支持更多的字符。在这些编码中，英文和中文可以统一地处理。区分中文编码的方法是高字节的最高位不为0。按照程序员的称呼，GB2312、GBK到GB18030都属于双字节字符集 (DBCS)。 有的中文Windows的缺省内码还是GBK，可以通过GB18030升级包升级到GB18030。不过GB18030相对GBK增加的字符，普通人是很难用到的，通常我们还是用GBK指代中文Windows内码。 unicode全世界有上百种语言，日本把日文编到Shift_JIS里，韩国把韩文编到Euc-kr里，各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码。比如如果中国的软件出口到美国，在美国人的电脑上就会显示乱码，因为他们没有gbk编码。 因此，Unicode（统一码、万国码、单一码）应运而生。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。规定所有的字符和符号统一最少由 16 位(2Bytes)代表一个字符，2**16-1=65535，可代表6万多个字符，因而兼容万国语言。 utf-8但对于通篇都是英文的文本来说，本来用一个字节就可以表示的内容，用unicode这种编码方式无疑是多了一倍的存储空间。本着节约的精神，于是产生了UTF-8，对英文字符只用1Bytes表示，对中文字符用3Bytes。如果你要传输的文本包含大量英文字符，用UTF-8编码就能节省空间： 字符 ASCII Unicode UTF-8 A 01000001 00000000 01000001 01000001 中 无法表示 01001110 00101101 11100100 10111000 10101101 总结 为了处理英文字符，产生了ASCII码为了处理中文字符，产生了GB2312为了处理各国字符，产生了Unicode为了提高Unicode存储和传输性能，产生了UTF-8，它是Unicode的一种实现形式 unicode 所有字符都是2Bytes，兼容所有语言字符，优点是字符-&gt;数字的转换速度快，缺点是占用空间大 utf-8 精准，对不同的字符用不同的长度表示，优点是节省空间，缺点是：字符-&gt;数字的转换速度慢，因为每次都需要计算出字符需要多长的Bytes才能够准确表示 内存中使用的编码是unicode 用空间换时间（程序都需要加载到内存才能运行，因而内存应该是尽可能的保证快） 硬盘中或者网络传输用 utf-8 网络I/O延迟或磁盘I/O延迟要远大与utf-8的转换延迟，而且I/O应该是尽可能地节省带宽，保证数据传输的稳定性。 编码的使用计算机中所有程序的运行都是在内存中进行的。内存 ( Memory ) 也被称为内存储器，其作用是用于暂时存放CPU中的运算数据，以及与硬盘等外部存储器交换的数据。只要计算机在运行中，CPU就会把需要运算的数据调到内存中进行运算，当运算完成后CPU再将结果传送出来。 当我们在计算机上打开一个文本编辑器的时候，计算机实际上就是在内存中启动了一个相应的进程，所以我们所有编辑的内容也都在内存中存放，只有当我们点击保存的时候才会将数据写入硬盘，没有保存之前一旦断电，内存中未保存的数据就会丢失。 在计算机内存中，统一使用Unicode编码，当需要保存到硬盘或者需要传输的时候，就转换为UTF-8编码。需要注意的是 文件以什么编码保存的，就以什么编码方式打开 Python的编码存取过程1python test.py 上面是一个在命令行使用python解释器来执行写好的 python 程序，这个过程大致可以分成三个步骤： 启动解释器，进程运行在内存中 解释器将 test.py 从硬盘读入内存 解释器执行内存中的代码 python 中关于编码出现的问题: 如果不在 python 文件指定头信息 ＃-*-coding:utf-8-*- ，在 python2 中就默认使用 ascii 读取文件，python3 中默认使用 utf-8 读取文件。我们使用以下代码做个演示 12345import sysprint(sys.getdefaultencoding())s="你好"print(s) python2的运行结果 12 File "encode.py", line 4SyntaxError: Non-ASCII character '\xe4' in file encode.py on line 4, but no encoding declared; see http://www.python.org/peps/pep-0263.html for details python3的运行结果 12utf-8你好 在 python 文件中使用utf-8编码进行存取 123456#-*- coding: utf-8 -*-import sysprint(sys.getdefaultencoding())s="你好"print(s) python2的运行结果 12ascii你好 python3的运行结果 12utf-8你好 内存中的执行python 读取已经加载到内存的代码（unicode 编码的二进制），然后执行，执行过程中可能会开辟新的内存空间，比如 x=&quot;hello&quot; 内存的编码使用 unicode，不代表内存中全都是 unicode 编码的二进制，在程序执行之前，内存中确实都是 unicode 编码的二进制，比如从文件中读取了一行x=&quot;hello&quot;，其中的x，等号，引号，地位都一样，都是普通字符而已，都是以unicode编码的二进制形式存放与内存中的。但是程序在执行过程中，会申请内存（与程序代码所存在的内存是两个空间），可以存放任意编码格式的数据，比如x=&quot;hello&quot;，会被python解释器识别为字符串，会申请内存空间来存放hello，然后让x指向该内存地址，此时新申请的该内存地址保存也是unicode编码的hello，如果代码换成x=&quot;hello&quot;.encode(&#39;utf-8&#39;)，那么新申请的内存空间里存放的就是utf-8编码的字符串hello了. Python2与python3编码区别Python2在 python2 中有两种字符串类型 str 和 unicode str类型 当 python 解释器执行到产生字符串的代码时（例如 s = &#39;好&#39;），会申请新的内存地址，然后将 &#39;好&#39; 编码成文件开头指定的编码格式，这已经是encode(编码)之后的结果了，所以 s 只能 decode(解码)。再次 encode 就会报错。 123456#!/usr/bin/env python# -*- coding: utf-8 -*-s = "好"# print s.encode("utf-8") # 报错print s.decode("utf-8") # 结果：好 在 python2 中，str 就是编码后的结果 bytes，str=bytes，所以在 python2 中，unicode 字符编码的结果是 str/bytes 123456789#!/usr/bin/env python# -*- coding: utf-8 -*-s = '好' # 在执行时,'好'会被以conding:utf-8的形式保存到新的内存空间中print repr(s) #'\xe5\xa5\xbd' 三个Bytes,证明确实是utf-8print type(s) # &lt;type 'str'&gt;s.decode('utf-8')# s.encode('utf-8') # 报错，s为编码后的结果bytes，所以只能decode unicode类型 当 python 解释器执行到产生字符串的代码时（例如 s = u&#39;好&#39;），会申请新的内存地址，然后将 &#39;好&#39; 以 unicode 的格式存放到新的内存空间中，所以 s 只能 encode ，不能 decode. 1234567s = u'好'print repr(s) # u'\u597d'print type(s) # &lt;type 'unicode'&gt;# s.decode('utf-8') # 报错，s为unicode，所以只能encodes.encode('utf-8') Python3在 python3 中也有两种字符串类型 str 和 bytes python3中，str 类型在内存中默认以 unicode 编码保存到新的内存空间中 12345678# -*- coding: utf-8 -*-s = '好' # 当程序执行时，无需加 u，默认以 unicode 形式保存新的内存空间中# s可以直接 encode 成任意编码格式s.encode('utf-8')s.encode('gbk')print(type(s)) # &lt;class 'str'&gt; bytes类型 12345678910111213141516# -*- coding: utf-8 -*-s = '好' # 当程序执行时，无需加 u，默认以 unicode 形式保存新的内存空间中# s可以直接 encode 成任意编码格式s1 = s.encode('utf-8')s2 = s.encode('gbk')print(type(s)) # &lt;class 'str'&gt;print(s) # 好print(s1) # b'\xe6\x9e\x97' 在 python3 中，是什么就打印什么print(s2) # b'\xc1\xd6' 同上print(type(s)) # &lt;class 'str'&gt;print(type(s1)) # &lt;class 'bytes'&gt;print(type(s2)) # &lt;class 'bytes'&gt; 注意事项当数据要打印到终端时，要注意一些问题. 当程序执行时，比如: x = &#39;好&#39;;print(x) ，这一步是将 x 指向的那块新的内存空间（非代码所在的内存空间）中的内存，打印到终端，而终端仍然是运行于内存中的，所以这打印可以理解为从内存打印到内存，即内存-&gt;内存，unicode -&gt; unicode，对于 unicode 格式的数据来说，无论怎么打印都不会乱码。 python3 中的字符串与 python2 中的 u’字符串’，都是 unicode，所以无论如何打印都不会乱码。 在 windows 终端（终端编码为gbk，文件编码为 utf-8，乱码产生） 总结 在ASCII中一个中文字符占用几个字节？答：ASCII无法表示中文字符 Python2 的默认文件编码是 ascii Python3 的默认文件编码是 utf-8，所有字符串都是 unicode unicode 中一个中文占用两个字节空间，utf-8 中一个中文占用三个字节 参考链接：https://www.cnblogs.com/vipchenwei/p/6993788.htmlhttp://blog.csdn.net/apache0554/article/details/53889253]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python初识]]></title>
    <url>%2F2019%2F03%2F01%2F105110-Python%E5%88%9D%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Python介绍Python的创始人为吉多·范罗苏姆（Guido van Rossum）。1989年荷兰的圣诞节期间，吉多·范罗苏姆为了在阿姆斯特丹打发时间，决心开发一个新的脚本解释程序，作为ABC语言的一种继承。 最新的 TIOBE排行榜，Python 赶超 PHP 占据第三， Python 崇尚优美、清晰、简单，是一个优秀并广泛使用的语言。 Python的应用Python可以应用于众多领域，如：数据分析、组件集成、网络服务、图像处理、数值计算和科学计算等众多领域。目前业内几乎所有大中型互联网企业都在使用Python，如：Youtube、Dropbox、BT、Quora（中国知乎）、豆瓣、知乎、Google、Yahoo!、Facebook、NASA、百度、腾讯、汽车之家、美团等。 Python目前主要应用领域 云计算: 云计算最火的语言， 典型应用OpenStack WEB开发: 众多优秀的WEB框架，众多大型网站均为Python开发，Youtube，Dropbox，豆瓣， 典型WEB框架有Django 科学运算、人工智能: 典型库 NumPy，SciPy，Matplotlib，Enthought librarys，pandas 系统运维: 运维人员必备语言 金融：量化交易，金融分析，在金融工程领域，Python 不但在用，且用的最多，而且重要性逐年提高。原因：作为动态语言的 Python，语言结构清晰简单，库丰富，成熟稳定，科学计算和统计分析都很出色，生产效率远远高于c，c++，java，尤其擅长策略回测 图形GUI: PyQT, WxPython,TkInter Python在公司的应用 谷歌：Google App Engine 、code.google.com 、Google earth 、谷歌爬虫、Google广告等项目都在大量使用Python开发 CIA: 美国中情局网站就是用Python开发的 NASA: 美国航天局(NASA)大量使用Python进行数据分析和运算 YouTube:世界上最大的视频网站YouTube就是用Python开发的 Dropbox:美国最大的在线云存储网站，全部用Python实现，每天网站处理10亿个文件的上传和下载 Instagram:美国最大的图片分享社交网站，每天超过3千万张照片被分享，全部用python开发 Facebook:大量的基础库均通过Python实现的 Redhat: 世界上最流行的Linux发行版本中的yum包管理工具就是用python开发的 豆瓣: 公司几乎所有的业务均是通过Python开发的 知乎: 国内最大的问答社区，通过Python开发(国外Quora) 春雨医生：国内知名的在线医疗网站是用Python开发的 除上面之外，还有搜狐、金山、腾讯、盛大、网易、百度、阿里、淘宝 、土豆、新浪、果壳等公司都在使用Python完成各种各样的任务。 Python是什么样的语言？经过上节的阅读，了解编程语言及分类之后我们便知道，Python是一门动态解释性的强类型定义语言。 Python的优缺点 优点 简单易学、功能强大 python的定位时“优雅”、“明确”、“简单”，但是功能却很强大； 丰富的库、开发效率高 python有非常强大的第三方库，基本上你想通过计算机实现的任何功能，python官方库里都有相应的模块进行支持；在基础库的基础上进行开发，大大降低开发周期，提高了开发效率； 高级语言、抽象程度高 用Python编写程序的时候无需考虑过多底层细节，如如何管理程序使用的内存等； 面向过程、面向对象 Python及支持面向过程编程，也支持面向对象编程；在面向过程的语言中，程序是由过程或仅仅是可重用代码的函数构建起来的；而在面向对象的语言中，程序数据（属性）和功能（函数/方法）组合而成的对象构建起来的； 可移植性 由于它开源的本质、Python已经被移植在许多平台上（经过改动使它能够工作在不同平台上）；如果你小心的避免使用依赖于特定系统的特性，那么你的python程序无需修改就可以在几乎所有的系统平台上运行； 可扩展性 如果需要一段关键代码运行得更快或者希望某些算法不公开，可以将这部分程序用C/C++编写，然后再Python中调用。 缺点： 线程不能利用多CPU 这是Python被人诟病最多的一个缺点。Python的线程是操作系统的原生线程，在Linux上为pthread，在Windows上为Win thread，完全由操作系统调度线程执行。一个Python解释器进程内有一条主线程，以及多条用户程序的执行子线程。由于GIL（Global Interpreter Lock，全局解释器锁，它是计算机程序设计语言解释器用于同步线程的工具，使得任何时刻仅有一个线程在执行）的存在，使得即使在多核CPU平台上，还是会禁止多线程的并行执行。 代码不能加密 由于Python是一个解释型语言，其源代码都是以明文存在的。 执行速度慢 这里是指与C和C++相比，Python确实要慢很多，这是由语言特性确定的；另外Python比Java也会慢一点，JVM比PVM的实现更底层一些，因此JVM在将字节码翻译为机器码的速度也就更快一些。 多行语句与命令行输出问题 由于Python规定用缩进来表示代码结构，而不支持分号分割，因此在大多数情况下不能将多条程序语句写成一行；如果在shell下要使用多条python语句来完成一个功能时，必须将程序写入.py文件中。 任何一门语言都不是完美的，都有擅长和不擅长做的事情，所以不建议拿一个语言的劣势去跟另一个语言的优势来去比较，语言只是一个工具，是实现程序设计师思想的工具，就像我们之前中学学几何时，有的时候需要要圆规，有的时候需要用三角尺一样，拿相应的工具去做它最擅长的事才是正确的选择。 Python的运行过程Python 和 Java/C# 一样，也是一门基于虚拟机的语言，我们先从表面上简单地了解一下 Python 程序的运行过程。 当我们在命令行中输入 python hello.py 时，其实是激活了 Python 的 “解释器”，告诉 “解释器”：你要开始工作了。可是在“解释”之前，其实执行的第一项工作和 Java 一样，是编译。 所以我们应该这样来描述Python，Python是一门先编译后解释的语言。 PyCodeObject和pyc文件当 python 程序运行时，编译的结果则是保存在位于内存中的 PyCodeObject （Python编译器真正编译成的结果）中，当 Python 程序运行结束时，Python 解释器则将 PyCodeObject 写回到pyc文件中。 当 python 程序第二次运行时，首先程序会在硬盘中寻找 pyc 文件，如果找到则直接载入，否则就重复上图的过程。 所以我们应该这样来定位 PyCodeObject 和 pyc 文件，我们说 pyc 文件其实是 PyCodeObject 的一种持久化保存方式。 Python解释器的分类当我们编写 Python 代码时，我们得到的是一个包含Python代码的以 .py 为扩展名的文本文件。要运行代码，就需要 Python 解释器去执行 .py 文件。 由于整个 Python 语言从规范到解释器都是开源的，所以理论上，只要水平够高，任何人都可以编写 Python 解释器来执行 Python 代码（当然难度很大）。事实上，确实存在多种 Python 解释器。 CPython当我们从 Python官方网站 下载并安装好 Python 3.7 后，就直接获得了一个官方版本的解释器：CPython。这个解释器是用C语言开发的，所以叫 CPython。在命令行下运行 python 就是启动 CPython 解释器。CPython 是使用最广的 Python 解释器 IPythonIPython 是基于 CPython 之上的一个交互式解释器，也就是说 IPython 只是在交互方式上有所增强，但是执行 Python 代码的功能和 CPython 是完全一样的。好比很多国产浏览器虽然外观不同，但内核其实都是调用了IE。 CPython用 &gt;&gt;&gt; 作为提示符，而IPython用 In [``序号``]: 作为提示符。 PyPyPyPy 是另一个 Python 解释器，它的目标是执行速度。PyPy 采用 JIT技术 ，对 Python 代码进行动态编译（注意不是解释），所以可以显著提高Python代码的执行速度。 绝大部分 Python 代码都可以在 PyPy下 运行，但是 PyPy 和 CPython 有一些是不同的，这就导致相同的 Python 代码在两种解释器下执行可能会有不同的结果。如果你的代码要放到 PyPy 下执行，就需要了解 PyPy和CPython的不同点。 JythonJython 是运行在 Java 平台上的 Python 解释器，可以直接把 Python 代码编译成 Java 字节码执行。 IronPythonIronPython和 Jython 类似，只不过 IronPython 是运行在微软 .Net 平台上的 Python 解释器，可以直接把 Python 代码编译成 .Net 的字节码。 总结Python 的解释器很多，但使用最广泛的还是 CPython。如果要和 Java 或 .Net 平台交互，最好的办法不是用 Jython 或 IronPython ，而是通过网络调用来交互，确保各程序之间的独立性。]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程语言简介]]></title>
    <url>%2F2019%2F03%2F01%2F083210-%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[编程语言编程语言（programming language），是用来定义计算机程序的形式语言。它是一种被标准化的交流技巧，用来向计算机发出指令。一种计算机语言让程序员能够准确地定义计算机所需要使用的数据，并精确地定义在不同情况下所应当采取的行动 编程语言的分类编程语言主要从以下几个角度为进行分类 编译型和解释型 编译型，其实它和汇编语言是一样的：也是有一个负责翻译的程序来对我们的源代码进行转换，生成相对应的可执行代码。这个过程说得专业一点，就称为编译（Compile），而负责编译的程序自然就称为编译器（Compiler）。如果我们写的程序代码都包含在一个源文件中，那么通常编译之后就会直接生成一个可执行文件，我们就可以直接运行了。但对于一个比较复杂的项目，为了方便管理，我们通常把代码分散在各个源文件中，作为不同的模块来组织。这时编译各个文件时就会生成目标文件（Object file）而不是前面说的可执行文件。一般一个源文件的编译都会对应一个目标文件。这些目标文件里的内容基本上已经是可执行代码了，但由于只是整个项目的一部分，所以我们还不能直接运行。待所有的源文件的编译都大功告成，我们就可以最后把这些半成品的目标文件“打包”成一个可执行文件了，这个工作由另一个程序负责完成，由于此过程好像是把包含可执行代码的目标文件连接装配起来，所以又称为链接（Link），而负责链接的程序就叫链接程序（Linker）。链接程序除了链接目标文件外，可能还有各种资源，例如图标文件、声音文件等等，还要负责去除目标文件之间的冗余重复代码，等等。链接完成之后，一般就可以得到我们想要的可执行文件了。 解释型，从字面上看，“编译”和“解释”的确都有“翻译”的意思，它们的区别则在于翻译的时机安排不大一样。打个比方：假如你打算阅读一本外文书，而你不知道这门外语，那么你可以找一名翻译，给他足够的时间让他从头到尾把整本书翻译好，然后把书的母语版交给你阅读；或者你也立刻让这名翻译辅助你阅读，让他一句一句给你翻译，如果你想往回看某个章节，他也得重新给你翻译。 两种方式，前者就相当于我们刚才所说的编译型：一次把所有的代码转换成机器语言，然后写成可执行文件；而后者就相当于我们要说的解释型：在程序运行的前一刻，还只有源程序而没有可执行程序；而程序每执行到源程序的某一条指令，则会有一个称之为解释程序的外壳程序将源代码转换成二进制代码以供执行，总言之，就是不断地解释、执行、解释、执行……所以，解释型程序是离不开解释程序的。像早期的BASIC就是一门经典的解释型语言，要执行BASIC程序，就得进入BASIC环境，然后才能加载程序源文件、运行。解释型程序中，由于程序总是以源代码的形式出现，因此只要有相应的解释器，移植几乎不成问题。编译型程序虽然源代码也可以移植，但前提是必须针对不同的系统分别进行编译，对于复杂的工程来说，的确是一件不小的时间消耗，况且很可能一些细节的地方还是要修改源代码。而且，解释型程序省却了编译的步骤，修改调试也非常方便，编辑完毕之后即可立即运行，不必像编译型程序一样每次进行小小改动都要耐心等待漫长的Compiling…Linking…这样的编译链接过程。不过凡事有利有弊，由于解释型程序是将编译的过程放到执行过程中，这就决定了解释型程序注定要比编译型慢上一大截，像几百倍的速度差距也是不足为奇的。 编译型与解释型，两者各有利弊。前者由于程序执行速度快，同等条件下对系统要求较低，因此像开发操作系统、大型应用程序、数据库系统等时都采用它，像C/C++、Pascal/Object Pascal（Delphi）、VB等基本都可视为编译语言，而一些网页脚本、服务器脚本及辅助开发接口这样的对速度要求不高、对不同系统平台间的兼容性有一定要求的程序则通常使用解释性语言，如Java、JavaScript、VBScript、Perl、Python等等。 但既然编译型与解释型各有优缺点又相互对立，所以一批新兴的语言都有把两者折衷起来的趋势，例如 Java语言虽然比较接近解释型语言的特征，但在执行之前已经预先进行一次预编译，生成的代码是介于机器码和Java源代码之间的中介代码，运行的时候则由JVM（Java的虚拟机平台，可视为解释器）解释执行。它既保留了源代码的高抽象、可移植的特点，又已经完成了对源代码的大部分预编译工作，所以执行起来比“纯解释型”程序要快许多。 而像VB6（或者以前版本）、C#这样的语言，虽然表面上看生成的是.exe可执行程序文件，但VB6编译之后实际生成的也是一种中介码，只不过编译器在前面安插了一段自动调用某个外部解释器的代码（该解释程序独立于用户编写的程序，存放于系统的某个DLL文件中，所有以VB6编译生成的可执行程序都要用到它），以解释执行实际的程序体。 C#（以及其它.net的语言编译器）则是生成.net目标代码，实际执行时则由.net解释系统（就像JVM一样，也是一个虚拟机平台）进行执行。当然.net目标代码已经相当“低级”，比较接近机器语言了，所以仍将其视为编译语言，而且其可移植程度也没有Java号称的这么强大，Java号称是“一次编译，到处执行”，而.net则是“一次编码，到处编译”。当然这些都是题外话了。总之随着设计技术与硬件的不断发展，编译型与解释型两种方式的界限正在不断变得模糊。 编译型 解释型 混合型 C JavaScript Java C++ Python C# GO Ruby Swift PHP Object-C Perl Pascal Erlang 编译器和解释器的区别 编译器是把源程序的每一条语句都编译成机器语言，并保存成二进制文件，这样运行时计算机可以直接以机器语言来运行此程序，速度很快 解释器则是只在执行程序时，才一条一条的解释成机器语言给计算机来执行，所以运行速度是不如编译后的程序运行的快的，这是因为计算机不能直接认识并执行我们写的语句，它只能认识机器语言(二进制的形式) 编译型和解释型的优缺点 编译型 优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。 缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。 解释型 优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。 缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。 静态语言和动态语言通常我们所说的动态语言、静态语言是指动态类型语言和静态类型语言 动态类型语言：动态类型语言是指在运行期间才去做数据类型检查的语言，也就是说，在用动态类型的语言编程时，永远也不用给任何变量指定数据类型，该语言会在你第一次赋值给变量时，在内部将数据类型记录下来。Python和Ruby就是一种典型的动态类型语言，其他的各种脚本语言如VBScript也多少属于动态类型语言。 静态类型语言：静态类型语言与动态类型语言刚好相反，它的数据类型是在编译其间检查的，也就是说在写程序时要声明所有变量的数据类型，C/C++是静态类型语言的典型代表，其他的静态类型语言还有C#、JAVA等。 强类型定义语言和弱类型定义语言 强类型定义语言：强制数据类型定义的语言。也就是说一旦一个变量被指定了某个数据类型，如果不经过强制转换，那么它就永远是这个数据类型了。举个例子：如果你定义了一个整型变量a，那么程序根本不可能将a当作字符串类型处理。强类型定义语言是类型安全的语言。 弱类型定义语言：数据类型可以被忽略的语言。它与强类型定义语言相反，一个变量可以赋不同数据类型的值。 强类型定义语言在速度上可能略逊色于弱类型定义语言，但是强类型定义语言带来的严谨性能够有效的避免许多错误。另外，“这门语言是不是动态语言”与“这门语言是否类型安全”之间是完全没有联系的！例如：Python是动态语言，是强类型定义语言（类型安全的语言）; VBScript是动态语言，是弱类型定义语言（类型不安全的语言）; JAVA是静态语言，是强类型定义语言（类型安全的语言）。]]></content>
      <tags>
        <tag>Python3</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix3.4入门教程]]></title>
    <url>%2F2018%2F05%2F16%2F082210-Zabbix3.4%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Linux下常用的系统监控软件有 Nagios、Cacti、Zabbix、Monit 等，这些开源的软件可以帮助我们更好的管理机器，在第一时间内发现问题，并及时发送告警，通知系统维护人员 Zabbix简介Alexei Vladishev创建了Zabbix项目，当前处于活跃开发状态，Zabbix SIA提供支持 Zabbix是一个企业级的、开源的、分布式的监控套件 Zabbix可以监控网络和服务的监控状况。Zabbix 利用灵活的告警机制，允许用户对事件发送基于 Email 的告警，这样可以保证快速的对问题作出相应。Zabbix 可以利用存储数据提供杰出的报告及图形化方式，这一特性将帮助用户完成容量规划 Zabbix支持 polling 和 trapping 两种方式，所有的 Zabbix 报告都可以通过配置参数在 WEB 前端进行访问，Web 前端将帮助你在任何区域都能够迅速获得你的网络及服务状况，Zabbix 可以通过尽可能的配置来扮演监控你的 IT 基础框架的角色，而不管你是来自于小型组织还是大规模的公司 Zabbix是零成本的. 因为 Zabbix 编写和发布基于 GPL V2 协议，意味着源代码是免费发布的 Zabbix公司也提供商业化的技术支持. Zabbix的功能 应用监控：数据库/SSH/Apache/Nginx等应用程序的监控。 服务器监控：CPU，内存，SWAP，磁盘空间，网卡流量的监控等. 网络设备监控：支持Cisco, Juniper, 3Com等网络设备，网络设备通过SNMP（SNMP (v1,v2,v3) devices）协议进行监控。 自定义监控：对于Zabbix无法满足的监控，可以添加自定义监控。 Zabbix的特性 数据收集 可用性及性能检测 支持SNMP(trapping及polling)、IPMI、JMX监控 自定义检测 自定义间隔收集收据 server/proxy/agents吸能 灵活的阀值定义 允许灵活地自定义问题阀值，Zabbix中称为触发器(trigger), 存储在后端数据库中 高级告警配置 可以自定义告警升级(escalation)、接收者及告警方式 告警信息可以配置并允许使用宏(macro)变量 通过远程命令实行自动化动作(action) 实时绘图 通过内置的绘图方法实现监控数据实时绘图 扩展的图形化显示 允许自定义创建多监控项视图 网络拓扑(network maps) 自定义的面板(screen)和slide shows，并允许在dashboard页面显示 报告 高等级(商业)监控资源 历史数据存储 数据存储在数据库中 历史数据可配置 内置数据清理机制 配置简单 主机通过添加监控设备方式添加 一次配置，终生监控(译者注：除非调整或删除) 监控设备允许使用模板 支持多种语言，包括中文 模板使用 模板中可以添加组监控 模板允许继承 系统自带多种监控模版 网络自动发现 自动发现网络设备 agent自动注册 自动发现文件系统、网卡设备、SNMP OID等 快速的web接口 web前端采用php编写 访问无障碍 你想怎么做就能做么做 审计日志 Zabbix API Zabbix API提供程序级别的访问接口，第三方程序可以很快接入 权限系统 安全的权限认证 用户可以限制允许维护的列表 全特性、agent易扩展 在监控目标上部署 支持Linux及Windows 二进制守护进程 C开发，高性能，低内存消耗 易移植 具备应对复杂环境情况 通过Zabbix proxy可以非常容易的创建远程监控 支持分布式部署和WEB集中管理 Zabbix的优缺点 优点 安装配置简单，支持多种语言，包括中文。 系统自带多种监控模板，可以直接使用。 支持分布式部署和WEB集中管理（通过WEB页面设置或查看报警结果）。 自动化功能，自动发现，自动注册主机，自动添加模板，自动添加分组 支持自定义监控 触发器，报警条件有多重判断机制 支持多种监控方式，agent，snmp，ipmi，jmx 缺点 需要在被监控机器上面安装agent 配置信息都存储在数据库里面，数据库是整个监控平台的瓶颈 Zabbix的组件默认情况下，zabbix 包含5个程序：zabbix_agentd、zabbix_get、zabbix_sender、zabbix_server，zabbix_proxy、可选程序 zabbix_java_gateway （需要另外安装），以及 web 前端组件和数据存储系统 zabbix_agentd：被监控端守护进程，监控本地资源和应用，将收集数据（CPU负载、内存、硬盘使用情况等）汇报给Zabbix Server。zabbix_agentd 并不是必须的，因为zabbix系统支持众多的监控数据采集方法，通过被监控设备代理采集监控数据只是其中的一种方法。 zabbix_get：zabbix工具，单独使用的命令，通常在server或proxy端执行，用于获取被监控端数据，多用于排错 zabbix_sender：zabbix工具，单独使用的命令，发送数据给server或proxy端，通常用于耗时较长的check，并且与trapper配合使用。生产环境中，个别消耗时间较长的check经常导致zabbix超时，于是我们在脚本执行完后，使用sender主动提交数据。 zabbix_server：服务端守护进程，zabbix_agentd、zabbix_get、zabbix_sender、zabbix_proxy、zabbix_java_gateway的数据最终都提交到server 端。zabbix_server 负责所有监控设备和监控项目配置、数据的存储与报表的生成和展示、报警的发送等。（数据不都是主动提交给server，多数情况下都是server主动去获取数据） zabbix_proxy： zabbix代理守护进程，功能和 server 类似。唯一不同的是它只是一个中转站，需要把收集到的数据 提交/被提交 到 server 端。一般跨机房、地区的环境需要用到 proxy。可以减轻 Zabbix Server 的压力 zabbix_java_gateway：Java网关，zabbix2.0之后引入的一个功能。类似与agentd，但只用于Java方面。需要特别注意的是，它只能主动去获取数据，而不能被动获取数据。它的数据最终会提交给server或proxy。 Web前端组件：通过Web界面进行管理和维护操作 数据存储系统：所有被监控主机和被监控项目的配置信息以及系统所采集的所有监控数据都存储在数据库中 Zabbix环境需求软硬件需求 内存和磁盘 基本需求：128M内存、256M硬盘。硬盘需要考虑的问题：监控条目越多、历史记录保留时间越久数据库将会越大。100台server，做基本的CPU、内存、硬盘、网卡流量等监控，建议硬盘空间80GB CPU 由Zabbix数据库使用情况而定，如果监控条目越多，选择的CPU应该越好 其他硬件 如果有必要的话，可准备GSM短信猫 硬件配置样例 Name Platform CPU/Memory Database Monitored hosts Small CentOS Virtual Appliance MySQL InnoDB 100 Medium CentOS 2 CPU cores/2GB MySQL InnoDB 500 Large RedHat Enterprise Linux 4 CPU cores/8GB RAID10 MySQL InnoDB or PostgreSQL &gt;1000 Very large RedHat Enterprise Linux 8 CPU cores/16GB Fast RAID10 MySQL InnoDB or PostgreSQL &gt;10000 数据库硬盘容量计算 每秒处理的数据量 这里的每秒只是一个平均值，例如：3000个监控项，均为60秒刷新一次，那么平均每秒有50（3000/60）个数据要处理。也就是说每秒有50条数据要存储到MySQL（或其他数据库）中。 历史记录保存时间 一般情况下，zabbix监控项值都要存储到数据库中，并且保留一段时间。假如一个数据需要保存30天，而且每秒有50个值要保存，这30天要存储129 600 000（300 * 24小时 * 3600秒 * 50）个值 一条记录需要多少容量：容量由当前使用的数据库引擎和存储的数据类型（浮点型、整型、字符型等）共同决定。通常，一条记录需要占用大约50个字节，这个案例中129 600 000个记录大约需要（129 600 000 * 50）6.5GB的硬盘空间 趋势数据保存时间 什么是趋势数据？当查看一周或一月的图标，图表上看到的 MAX / MIN / AVG / COUNT / 都是取自趋势数据，趋势数据一小时获取一次。通常，一条趋势数据大约占用128字节，如果需要保存5年的趋势数据，3000个监控项每年需要2.4GB（3000 个 * 24小时 * 365天 * 128字节），5年共16.8GB。 事件记录保存时间 报警、警告、恢复等事件。一个事件大概占用130个字节，通常情况下不会有太多的事件，除非运维做的很糟糕，或者运维要求太严格，把阈值调的很低。如果每秒有一个事件发生，那么一年事件记录占用的数据空间为： （1天 * 365天 * 24小时 * 3600秒 * 130字节） 大约4.1G空间。 数据库空间计算公式 zabbix配置占用：固定大小，一般 &lt; 10MB 历史数据：天数 *（监控项总数 / 更新频率）* 24小时 * 3600秒 * 50字节 趋势数据：天数 *（监控项总数 / 3600）* 24 小时 * 3600秒 * 128 字节 事件数据：天数 * 事件个数（大概值）* 24 小时 * 3600 秒 * 130 字节 安装 Zabbix这里使用了编写好的 shell 脚本，基于 CentOS 7.x 版本的系统进行安装的，并且使用的是 rpm 包安装方式。另外安装服务器端的同时也应该安装客户端，因为服务器端到自己本身的监控也应该配置 需要说一下，MariaDB 数据库管理系统是 MySQL 的一个分支，主要由开源社区在维护，采用 GPL 授权许可。 开发这个分支的原因是：甲骨文公司收购了 MySQL 后，有 将MySQL 闭源的潜在风险，因此社区采用分支的方式来避开这个风险。MariaDB 的目的是完全兼容 MySQL，包括API和命令行，使之能轻松成为 MySQL 的代替品。 准备工作配置系统基础环境 12345678910111213# 关闭防火墙：systemctl stop firewalld# 禁止掉防火墙开机自启：systemctl disable firewalld# 关闭selinux：setenforce 0 # 临时关闭sed -ri 's/(^SELINUX=).*/\1disabled/' /etc/sysconfig/selinux /etc/selinux/config# 永久关闭 脚本安装服务器端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061#!/bin/bashif test -d /tmp/zabbix_IS_ok ;then echo '' echo 'Zabbix already configured , unable to run again' echo '' echo "You can access http://$(hostname -I | awk '&#123;print $1&#125;')/zabbix" exit 3else # Check network repo_URL="repo.zabbix.com" http_code=$(curl -s --connect-timeout 10 --max-time 20 -o /dev/null -w %&#123;http_code&#125; $&#123;repo_URL&#125;) if [[ $&#123;http_code&#125; -ne 200 ]];then echo "URL $&#123;repo_URL&#125; is unreachable , please check your network" exit 5 else mkdir -p /tmp/zabbix_IS_ok fifi# 在这里定义数据库的密码# --------------------------------------------------zabbix_DBPpassword='zabbix'# --------------------------------------------------# Install Repository with MySQL databaserpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm# Install Zabbix server, frontend, agent, getyum -y install zabbix-server-mysql zabbix-web-mysql zabbix-get# Install Mysql's branch mariadbyum -y install mariadb-serverfor cmd in start enable status;do systemctl $&#123;cmd&#125; mariadb.service; done# Create initial databasemysql -e 'create database zabbix character set utf8 collate utf8_bin;'mysql -e 'grant all privileges on zabbix.* to zabbix@localhost identified by ''"'"$&#123;zabbix_DBPpassword&#125;"'"'';'# Import initial schema and data. You will be prompted to enter your newly created password.zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p"$&#123;zabbix_DBPpassword&#125;" zabbix# Configure the database for Zabbix server.Edit file /etc/zabbix/zabbix_server.confsed -ri.origin "/^# *DBPassword=/aDBPassword=$&#123;zabbix_DBPpassword&#125;" /etc/zabbix/zabbix_server.conf# Configure PHP for Zabbix frontend. Edit file /etc/httpd/conf.d/zabbix.conf, uncomment and set the right timezone for you.sed -ri.origin '/# php_value date.timezone/a\\tphp_value date.timezone Asia/Shanghai' /etc/httpd/conf.d/zabbix.conf# Install fontsyum -y install wqy-microhei-fonts"cp" /usr/share/fonts/wqy-microhei/wqy-microhei.ttc /usr/share/fonts/dejavu/DejaVuSans.ttf# Start and enable servicesfor s in zabbix-server httpd ;do systemctl start $&#123;s&#125;.service systemctl enable $&#123;s&#125;.servicedone# Print messagesecho "You can access http://$(hostname -I | awk '&#123;print $1&#125;')/zabbix" 脚本安装客户端 要让 zabbix 查到主机名需要编辑 /etc/hosts 文件 12hostName=$(hostname);fgrep "$&#123;hostName&#125;" /etc/hosts || echo "客户端的IP地址 $&#123;hostName&#125;" &gt;&gt; /etc/hosts 仓库链接： http://repo.zabbix.com/zabbix/3.4/rhel/ 根据不通版本的系统修改脚本中yum源、服务配置 安装客户端 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bash# 在这里定义服务器端的 IP 地址# --------------------------------------------------Zabbix_Server_IP='192.168.127.157'# --------------------------------------------------if test -d /tmp/zabbix_agent_is_ok ;then echo '' echo 'Zabbix agent already configured , unable to run again' echo '' exit 3else # Check network repo_URL="repo.zabbix.com" http_code=$(curl -s --connect-timeout 10 --max-time 20 -o /dev/null -w %&#123;http_code&#125; $&#123;repo_URL&#125;) if [[ $&#123;http_code&#125; -ne 200 ]];then echo "URL $&#123;repo_URL&#125; is unreachable , please check your network" exit 5 else mkdir -p /tmp/zabbix_agent_is_ok fifi# Install Repositoryrpm -ivh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm# Install Zabbix agent, senderyum -y install zabbix-agent zabbix-sender# Configure the Server, ServerActive, Hostname for Zabbix agent. Edit file /etc/zabbix/zabbix_server.confsed -ri.origin -e "s#^(Server)=.*#\1=$&#123;Zabbix_Server_IP&#125;#" -e "s#^(ServerActive)=.*#\1=$&#123;Zabbix_Server_IP&#125;#" -e "/^Hostname=/s@^@# @" /etc/zabbix/zabbix_agentd.conf# Create UserParameterecho 'UserParameter=login.user,who | wc -l' &gt;&gt; /etc/zabbix/zabbix_agentd.d/userparameter_login.conf# Start servicesfor cmd in start enable status;do systemctl $&#123;cmd&#125; zabbix-agent.service; done 连通性检查服务器端安装了 zabbix-get 工具便可以进行到客户端的测试 1234[root@ZabbixServer ~]# zabbix_get --host 192.168.127.155 --port 10050 --key &quot;system.cpu.load[all,avg1]&quot; 0.000000[root@ZabbixServer ~]# zabbix_get --host 192.168.127.157 --port 10050 --key &quot;system.cpu.load[all,avg1]&quot;0.010000 注意事项注意 如果服务器端配置的 IP 地址有多个，需要配置源地址 SourceIP=。因为默认情况下服务器端会从默认出口的第一个 IP 地址作为源地址建立 session ，如果客户端配置的 Server= 是服务器端的其他 IP 就会出现连接被拒绝的情况。例如： 在服务器端配置有两个 IP 地址 192.168.127.156 和 192.168.127.157 ，默认情况下会监听所有的地址 在客户端配置的服务器端的 IP 为 Server=192.168.127.157 可能出现服务器端是以 192.168.127.156 作为源地址去客户端获取数据，而客户端允许的服务器为 192.168.127.157 。这种情况查看客户端的日志 /var/log/zabbix/zabbix_agentd.log 就会有如下记录： 12894:20180515:145944.712 failed to accept an incoming connection: connection from "192.168.127.156" rejected, allowed hosts: "192.168.127.157" 另外，在多 IP 环境中的服务器端进行到本机客户端测试的时候要注意指定的 IP 应该和 /etc/zabbix/zabbix_agentd.conf 中的 Server= 的地址相同，否则会提示配置错误： 12345[root@ZabbixServer ~]# zabbix_get --host 192.168.127.156 --port 10050 -k &quot;system.cpu.load[all,avg1]&quot; zabbix_get [22225]: Check access restrictions in Zabbix agent configuration[root@ZabbixServer ~]# zabbix_get --host 192.168.127.157 --port 10050 -k &quot;system.cpu.load[all,avg1]&quot; 0.000000 建议 为了避免这种情况的发生，我们应该在服务器端上配置 SourceIP= ，在客户端上配置 Server= ，并且配置相同的 IP 地址 其他 在客户端的配置中 Hostname= 并不是必须的，因此脚本配置过程中会将此行注释 服务器端存在的同时也可以作为Client 端，在使用 zabbix-get 的时候指定的 host Web端的操作安装web管理页面 访问 http://192.168.127.157/zabbix 接下来进行环境需求检查，正常情况下都是 OK 状态，否则查看具体的报错信息进行不同的解决 配置数据库，没有特殊需要则输入数据库密码即可 配置 zabbix 细节性的信息，Host 和 Port 保持默认不变即可，Name 进行自定义配置 查看摘要信息，没有异常情况则进行下一步 完成安装 进入登录页面， 默认账号 Admin ，密码 zabbix ，注意要区分大小写 中文环境、主题选择以及 web 前端页面报警：登录成功后，点击页面右上角的用户头像，进入用户配置 语言和主题选择：User 标签下的 Language 下拉菜单选择 Chinese (zh_CN) ，在 Theme 下拉菜单选择 Dark 前端页面启用声音报警：Messaging 标签下，勾选 Frontend messaging ，并将 Trigger severity 下不同严重级别都勾选上 最后点击 Update 即可 修改主机信息使用客户端安装脚本在服务器端安装之后，便可以将服务器端同时也作为客户端。 依次点击 配置 =&gt; 主机 =&gt; Zabbix server 配置服务端的信息 主机名称： 一般和服务器的主机名保持一致，这是 zabbix_server 程序用的，也可以根据实际情况自定义 可见名称： 显示在 web 网页上的名称，呈现给我们来看的 agent 代理程序的接口： IP地址:客户端的 IP 地址，对于服务端来说虽然客户端也是自己，但这里不建议不使用 127.0.0.1 而是使用物理网卡上的地址 DNS名称 :可以进行 DNS 解析的域名，如果环境允许的话推荐使用 DNS 作为接口。如果这里配置了 www.test.com ，那么当客户端因为迁移或其他原因，导致 IP 地址发生了变更，就不需要在 web 端修改主机的 IP 了 启用状态：用来配置该主机是否要进行监控 添加新的主机在要被监控的服务器上安装客户端之后，便可以在 web 页面添加并监控了 依次点击 配置 =&gt; 主机 =&gt; 创建主机 然后进行链接模板，自带模板 Template OS Linux 提供CPU、内存、磁盘、网卡等常规监控，只要新加主机关联此模板，就可自动添加这些监控项 添加成功后将会列出来 查看数据 依次点击 监测中 =&gt; 最新数据 使用过滤器过滤出相应的主机后则可以列出监控的条目，并且可以查看最新的数据 查看图形 依次点击 监测中 =&gt; 图形 ，选择相应的主机和图形即可展现出来 添自定义监控实际生产环境中，可能不是所有监控数据都能通过zabbix自带的内建 key 监控，有时候也需要自定义 key 来监控，我们先以监控系统登录用户数做个示范。 自定义参数 官方手册：https://www.zabbix.com/documentation/3.4/zh/manual/config/items/userparameters 语法格式 1UserParameter=&lt;key&gt;,&lt;shell command&gt; 示例 12UserParameter=login.user,who | wc -lUserParameter=login.user,/bin/bash /server/scripts/login.sh 创建自定义参数 1echo 'UserParameter=login.user,who | wc -l' &gt;&gt; /etc/zabbix/zabbix_agentd.d/userparameter_login.conf 创建参数后需要重启服务 1systemctl restart zabbix-agent 服务器端进行测试 12[root@ZabbixServer ~]# zabbix_get --host 192.168.127.155 --port 10050 --key login.user2 web端添加监控创建自定义模板 为了不改变系统原有的模板，可以创建自己定义的一个模板 依次点击 配置 =&gt; 模板 =&gt; 创建模板 点击添加之后，使用过滤器即可看到创建出来的模板 创建应用集 应用集可以看作是目录或文件夹，其作用是给监控项分类 依次点击 应用集 =&gt; 创建应用集 创建监控项 监控项指的是具体监控哪一项数据 依次点击 监控项 =&gt; 创建监控项 创建监控项的时候，要注意选择上应用集 创建触发器 触发器的作用是当监控项获取到的值达到一定条件时就触发相应的操作，比如邮件报警，或者远程执行命令 依次点击 触发器 =&gt; 创建触发器 创建图形 以图形的方式展示出来监控信息 依次点击 图形 =&gt; 创建图形 主机关联模板 一个主机可以关联多个模板 依次点击 配置 =&gt; 主机，点击要关联的主机名称并进入 模板 标签页面关联模板并更新 查看监控的图形 条件触发测试 开启多个终端来增加登录用户数，并查看图形的趋势变化以及仪表板上的问题显示 自定义脚本报警媒介 仅仅靠web端的页面展示或声音告警并不能很好的通知维护人员，因此需要报警平台或者第三方客户端来更方便更及时地通知别人，系统自带的媒介类型可能对于我们来说不太适用，因此可以进行自定义 使用自定义脚本媒介后 zabbix 将会传递信息给脚本，脚本接收参数后进行相应的处理 使用下面的方式可以看到自定义脚本的配置目录 12[root@ZabbixServer ~]# egrep -i ^alertscripts /etc/zabbix/zabbix_server.confAlertScriptsPath=/usr/lib/zabbix/alertscripts 使用Email传送门 = &gt; 官方参考链接 大致步骤： 在 zabbix 服务器端配置邮件发送脚本，修改zabbix服务端配置文件 在 zabbix 前端控制台进行相关设置 邮件和脚本配置 安装软件包 mailx，为了避免脚本发送出现乱码最好同时装上 dos2unix 1yum -y install mailx dos2unix 注册并设置邮箱，网易邮箱配置比较简单 服务器端 mail 配置 /etc/mail.rc 1234567891011121314# 指定的邮件发送人smtp-auth-user和smtp-auth-password分别进行用户名和密码的验证；set from=***********@163.com# 指定使用的邮件服务器set smtp=smtp.163.com# 认证发送人set smtp-auth-user=**********@163.com# 认证发送人密码或客户端授权密码set smtp-auth-password=**********# 认证方式set smtp-auth=login 邮件发送测试，并查看收件人是否成功收到邮件 1echo "Test mail" | mail -s "hello" 收件人@xxxx.com 编写 zabbix 发送邮件的脚本 /usr/local/etc/alertscripts/sendmail.sh 123456789#!/bin/bashexport LANG=en_US.UTF-8 to=$1subject=$2echo "$3" &gt; /tmp/zabbix_mailbodydos2unix /tmp/zabbix_mailbodymail -s "$subject" "$to" &lt; /tmp/zabbix_mailbody 修改脚本属主属组和权限 12chown -R zabbix.zabbix /usr/lib/zabbix/alertscripts/chmod +x /usr/lib/zabbix/alertscripts/sendmail.sh web端报警媒介配置 创建自定义邮件脚本媒介：依次打开 管理 =&gt; 报警媒介类型 =&gt; Email ，将其禁用然后 创建媒体类型 进行自定义，并且注意需要指定传递给邮件发送脚本的参数： 邮件接收方 {ALERT.SENDTO} 、邮件标题 {ALERT.SUBJECT} 、邮件内容 {ALERT.MESSAGE} 设置用户报警媒介：依次打开 管理 =&gt; 用户 =&gt; Admin ，然后打开 报警媒介 标签，添加脚本并配置收件人邮件地址、什么时候使用 配置相关的动作这个是针对触发器设定的，当监控项的数据达到一定的条件就会使触发器执行设定好的动作，一个动作可以针对多个触发器设定，当他们满则条件时都会执行相应的动作。因为我们用的是邮件报警，所以当发生故障，触发器被触发时 zabbix 给相关用户的邮箱发送邮件，当故障恢复后还会发送恢复邮件，这样就可以把机器及业务的运行状态及时的监控起来 创建动作 动作名称和条件：条件是针对动作何时执行，可以多个条件并存或者任意存在，还可以编写相关的逻辑进行判断 操作配置 恢复操作配置 触发测试：以登录用户为例，多个终端登录被监控机后测试触发器和动作，在仪表板将会显示对应的问题和动作状态。当故障恢复后会执行相应的恢复动作 使用Slack简介Slack 是一款 聊天群组 + 大规模工具集成 + 文件整合 + 统一搜索 的软件，整合了电子邮件、短信、Google Drives、Twitter、Trello、Asana、GitHub 等 65 种工具和服务，可以把各种碎片化的企业沟通和协作集中到一起 要注意的是，Slack 的通信已 被墙 导致在大陆无法正常使用，并且账号注册也有一定的限制，因此如果条件不允许请量力而行 slack配置 账号注册： https://slack.com 创建 workspace 完成一系列的内容填写之后，创建一个 channnel 用来给 zabbix 发送告警信息，还可以根据不同部门添加不同的 channnel 创建公共的 channel 配置 incoming webhook ：https://my.slack.com/services/new/incoming-webhook 拷贝 Webhook Url 出来，稍后我们需要将他粘贴到自定义脚本当中，附上一张可参考的 logo 客户端效果图 在 zabbix 服务器端配置脚本 /usr/local/etc/alertscripts/slack.sh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#!/bin/bash# Example# bash slack.sh '#zabbix-alert' PROBLEM 'Oh no! Something is wrong!'# Slack incoming web-hook URL and user name#url='CHANGEME' # example: https://hook.bearychat.com/XXX/zabbix/XXXXXXXXXXXXXXXXXXXXXXXurl=''# ---------------------------# 复制相应的webhook的URL# ---------------------------username='Zabbix'## Values received by this script:# To = $1 (Slack channel or user to send the message to, specified in the Zabbix web interface; "@username" or "#channel")# Subject = $2 (usually either PROBLEM or RECOVERY/OK)# Message = $3 (whatever message the Zabbix action sends, preferably something like "Zabbix server is unreachable for 5 minutes - Zabbix server (127.0.0.1)")# Get the Slack channel or user ($1) and Zabbix subject ($2 - hopefully either PROBLEM or RECOVERY/OK)to="$1"subject="$2"# Change message emoji depending on the subject - smile (RECOVERY/OK), frowning (PROBLEM), or ghost (for everything else)recoversub='^RECOVER(Y|ED)?$'if [[ "$subject" =~ $&#123;recoversub&#125; ]]; then emoji=':smile:'elif [ "$subject" == 'OK' ]; then emoji=':smile:'elif [ "$subject" == 'PROBLEM' ]; then emoji=':frowning:'else emoji=':ghost:'fi# The message that we want to send to Slack is the "subject" value ($2 / $subject - that we got earlier)# followed by the message that Zabbix actually sent us ($3)message="$&#123;subject&#125;: $3"# Build our JSON payload and send it as a POST request to the Slack incoming web-hook URLpayload="payload=&#123;\"channel\": \"$&#123;to//\"/\\\"&#125;\", \"username\": \"$&#123;username//\"/\\\"&#125;\", \"text\": \"$&#123;message//\"/\\\"&#125;\", \"icon_emoji\": \"$&#123;emoji&#125;\"&#125;"curl -m 5 --data-urlencode "$&#123;payload&#125;" $url -A 'zabbix-slack-alertscript / https://github.com/ericoc/zabbix-slack-alertscript'# --------------------------------------------------# 调试内容，可以方便地知道zabbix传入的参数，前两条需要root在命令行执行# --------------------------------------------------#touch /tmp/zabbix.log #chown zabbix:zabbix /tmp/zabbix.log #echo ''"$payload"'' &gt;| /tmp/zabbix.log #echo "$@" &gt;&gt; /tmp/zabbix.log 修改脚本属主属组和权限 1chmod +x /usr/lib/zabbix/alertscripts/slack.sh 命令行调试 1bash slack.sh '#zabbix-alert' PROBLEM 'Oh no! Something is wrong!' 效果图 参考文档： shell： zabbix-slack-alertscript python：zabbix-slack-alertscript web端报警媒介配置 创建自定义邮件脚本媒介：依次打开 管理 =&gt; 报警媒介类型 =&gt; 创建媒体类型 进行自定义，并且注意需要指定传递给 Slack 发送脚本的参数： 接收方 {ALERT.SENDTO} 、标题 {ALERT.SUBJECT} 、内容 {ALERT.MESSAGE} 设置用户报警媒介：依次打开 管理 =&gt; 用户 =&gt; Admin ，然后打开 报警媒介 标签，添加脚本并配置收件人的 channel 、什么时候使用 配置相关的动作 创建动作 操作配置 恢复操作配置 触发测试：以登录用户为例，测试效果 使用倍洽倍洽（BearyChat）与 Slack 类似，zabbix 结合 倍洽 进行自定义媒介的方式可参照 Slack 的配置 官网：https://bearychat.com/ 机器人配置教程：https://bearychat.com/integrations/zabbix 用到的脚本和 Slack 的类似，但是传入的参数需要删除 #，在 zabbix 的 web 端的收件人和 Slack 相同都需要加 #，例如 #zabbix-alert 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#!/bin/bash# Example# 需要注意的是这里传给脚本的第一个参数如果带 # 则无法发送成功# bash bearychat.sh 'zabbix-alert' PROBLEM 'Oh no! Something is wrong!'# BearyChat zabbix web-hook URL#url='CHANGEME' # example: https://hook.bearychat.com/XXX/zabbix/XXXXXXXXXXXXXXXXXXXXXXXurl=''# ---------------------------# 复制相应的webhook的URL# ---------------------------## Values received by this script:# To = $1 (Slack channel or user to send the message to, specified in the Zabbix web interface; "@username" or "#channel")# Subject = $2 (usually either PROBLEM or RECOVERY)# Message = $3 (whatever message the Zabbix action sends, preferably something like "Zabbix server is unreachable for 5 minutes - Zabbix server (127.0.0.1)")# Get the Slack channel or user ($1) and Zabbix subject ($2 - hopefully either PROBLEM or RECOVERY)#to="$&#123;1&#125;"# --------------------------------------------------# 将原始的修改为以下去除#的形式# --------------------------------------------------to=$(echo $&#123;1&#125; | sed -r 's@#@@')STATUS="$2"# Change message emoji depending on the subject - smile (RECOVERY), frowning (PROBLEM), or ghost (for everything else)recoversub='^RECOVER(Y|ED)?$'if [[ "$STATUS" =~ $&#123;recoversub&#125; ]]; then emoji=':smile:'elif [ "$STATUS" == 'PROBLEM' ]; then #emoji=':frowning:' emoji=':red_circle:'else #emoji=':ghost:' emoji=':large_blue_circle:'fi# The message that we want to send to Slack is the "subject" value ($2 / $subject - that we got earlier)# followed by the message that Zabbix actually sent us ($3)message="$&#123;STATUS&#125; \n$3"# Build our JSON payload and send it as a POST request to the BearyChat incoming web-hook URLpayload="payload=&#123;\"channel\": \"$&#123;to//\"/\\\"&#125;\", \"text\": \"$&#123;emoji&#125; $&#123;message//\"/\\\"&#125;\"&#125;"curl -m 5 --data-urlencode "$&#123;payload&#125;" $url -A 'zabbix-bearychat-alertscript / https://github.com/ericoc/zabbix-bearychat-alertscript'# --------------------------------------------------# 调试内容，可以方便地知道zabbix传入的参数，前两条需要root在命令行执行# --------------------------------------------------#touch /tmp/zabbix.log #chown zabbix:zabbix /tmp/zabbix.log #echo ''"$payload"'' &gt;| /tmp/zabbix.log #echo "$@" &gt;&gt;/tmp/zabbix.log 服务监控监控ssh服务假设生产线上的 Linux 主机的 ssh 服务端口有默认的 22 ，以及自定义的 9022 ，因此需要两个监控项 在自定义模板中创建应用集，也可以使用系统自带模板 Template App SSH Service 创建监控项 点击创建监控项，创建默认端口的监控项 再次创建监控项，创建 9022 端口的监控项 创建触发器 点击进入表达式构造器，添加 9022 端口ssh服务的表达式 条件表达式，只要有一个端口正常我们就认为服务运行正常，因此所有端口都没有运行就认为ssh服务故障 在被监控机做触发测试，可以将ssh服务端口换成其他的，并且只监听一个端口，注意不要被防火墙踢出 监控nginx状态发现网络发现概述 Zabbix提供了有效和非常灵活的网络自动发现功能，当网络发现正确设置后你可以： 加快Zabbix部署 简化管理 无需过多管理就能在快速变化的环境中使用Zabbix Zabbix网络发现基于以下信息： IP范围 可用的外部服务（FTP，SSH，WEB，POP3，IMAP，TCP等） 来自 zabbix agent 的信息（仅支持未加密模式） 来自 snmp agent 的信息 发现 Zabbix定期扫描网络发现规则中定义的IP范围，并为每个规则单独配置检查的频次。 请注意，一个发现规则始终由单一发现进程处理，IP范围主机不会被分拆到多个发现进程处理。 每个规则中都定义了一组需要检测的服务。 动作 zabbix 所有 动作 都是基于发现事件，例如: 发送通知 添加/删除主机 启用/禁用主机 添加主机到组 从组中删除主机 将主机链接到模板/从模板中取消链接 执行远程脚本命令 基于事件的网络发现动作, 可以根据设备类型、IP地址、状态、运行时间/停机时间等进行配置，查看动作操作和 条件页面。 配置网络发现规则参考链接：https://www.zabbix.com/documentation/3.4/zh/manual/discovery/network_discovery/rule 例如我们设置IP段为 124.160.121.64/27 和 115.231.107.98-115.231.107.126 的网络发现规则： 配置 =&gt; 自动发现 =&gt;创建发现规则（或在自动发现规则名称上编辑现有规则） =&gt; 编辑自动发现规则属性 设备唯一性准则： IP地址 - 使用 IP 地址作为设备唯一性标识，不处理多IP设备。如果具有相同IP的设备已经存在，则将认为已经发现，并且不会添加新的主机。 发现检查类型 - 使用 SNMP 或者 Zabbix agent 的 check 作为唯一标识。 选择事件源并创建动作 定义名称和触发条件 定义操作 查看已发现的设备 监测中 =&gt; 自动发现 自动注册概述 活动的Zabbix agent可以自动注册到服务器进行监控，这种方式无需在服务器上手动配置它们 当以前未知的active agent要求检查时，会发生自动注册。 该功能可能非常方便自动监控新的Cloud节点。一旦在Cloud Zabbix中有一个新节点，Zabbix将自动启动主机监控，并进行性能和可用性数据的收集。 Active agent自动注册还支持对被添加的主机进行被动检查的监控。当active agent要求检查时，提供它配置文件中定义的“ListenIP”或“ListenPort”配置参数，这些参数将发送到服务器。（如果指定了多个IP地址，则第一个将被发送到服务器。） 服务器在添加新的自动注册主机时，使用接收到的IP地址和端口配置agent。如果没有接收到IP地址值，则使用传入连接的IP地址。如果没有接收到端口值，则使用10050。 客户端指定服务器 在使用客户端安装脚本进行安装时已经包含了相关的配置，下面是详细的说明 在客户端的配置文件 /etc/zabbix/zabbix_agentd.conf 中指定服务器 1ServerActive=10.0.0.1 如果你没有在配置文件 /etc/zabbix/zabbix_agentd.conf 中特别定义了 Hostname，则服务器将使用 agent 的系统主机名命名主机。Linux 中的系统主机名可以通过运行 hostname 命令获得。修改配置后需要重启 agent active agent自动注册动作 当服务器从 agent 收到自动注册请求时，它会调用一个动作。事件源“自动注册”的操作必须配置为 agent 自动注册 在 Zabbix 页面，转到 配置 =&gt; 动作，选择 自动注册 为事件源，然后单击 创建操作 在动作选项卡，定义 Action 名称 在操作选项卡中，添加添加主机，添加到主机组（例如，发现的主机），链接到模板等 自动发现（LLD）概述 自动发现（low-level discovery）提供了一种在计算机上为不同实体自动创建监控项，触发器和图形的方法。例如， Zabbix 可以在你的机器上自动开始监控文件系统或网络接口，而无需为每个文件系统或网络接口手动创建监控项。此外，可以配置 Zabbix 根据定期执行发现后的得到实际结果，来移除不需要的监控项。 在Zabbix中，支持六种类型的发现项目 系统文件的发现； 网络接口的发现； CPU和CPU内核的发现 SNMP OID的发现 使用ODBC SQL查询的发现 Windows服务的发现 用户可以自己定义发现类型，只要它们遵循特定的JSON协议 发现过程的一般架构如下： 用户在“配置”→“模板”→“发现”列中创建一个发现规则。发现规则包括（1）发现必要实体（例如，文件系统或网络接口）的项目和（2）应该根据该项目的值创建的监控项，触发器和图形的原型 发现必要实体的项目就像其他地方所看到的常规项目：服务器向该项目的值询问 Zabbix agent（或者该项目的任何类型的设置），agent 以文本值进行响应。区别在于 agent 响应的值应该包含特定 JSON 格式的发现实体的列表。这种格式的自定义检查者发现的细节才是最重要的，因为返回值必须包含 宏&lt;=&gt;值 对，例如： 1项目 `net.if.discovery` 可能会返回两对键值：`&#123;#IFNAME&#125; &lt;=&gt; lo` 和 `&#123;#IFNAME&#125; &lt;=&gt; eth0` 这些宏用于名称，键值和其他原型字段中，然后用接收到的值为每个发现的实体创建实际的监控项，触发器，图形甚至主机 当服务器接收到发现项目的值时，它会查看宏→值对，每对都根据原型生成实际监控项，触发器和图形。在上面的“net.if.discovery”示例中，服务器将生成环路接口“lo”的一组监控项，触发器和图表，另一组用于界面“eth0”。 以下部分将详细说明上述过程，并作为一个指导上述类型的所有发现。最后一节描述了发现项目的JSON格式，并给出了文件系统发现实现的Perl脚本的示例。 配置示例 办公室的网关上需要针对大量 url 做监控，来保证基本网络的正常访问。要求 url 状态异常则报警 创建自定义脚本 12mkdir -pv /usr/lib/zabbix/scriptsvim /usr/lib/zabbix/scripts/web_site_code_status.sh 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/bin/bashUrlFile="/usr/lib/zabbix/scripts/url.txt"IFS=$'\n'web_site_discovery () &#123; lines_number=$(egrep -v "^(#|$)" $&#123;UrlFile&#125; | wc -l ) echo -e '&#123;' echo -e '\t"data":[' while read the_mark the_url the_proxyip the_other;do (( lines_number -= 1 )) if [ $&#123;lines_number&#125; -ne 0 ] ; then echo -e '\t\t&#123;"&#123;#SITENAME&#125;":"'"$&#123;the_mark&#125; $&#123;the_url&#125;"'","&#123;#PROXYIP&#125;":"'"$&#123;the_proxyip&#125;"'"&#125;,' else echo -e '\t\t&#123;"&#123;#SITENAME&#125;":"'"$&#123;the_mark&#125; $&#123;the_url&#125;"'","&#123;#PROXYIP&#125;":"'"$&#123;the_proxyip&#125;"'"&#125;' echo -e '\t]' echo -e '&#125;' fi done &lt; &lt;(egrep -v "^(#|$)" $&#123;UrlFile&#125;)&#125;web_site_code () &#123; if [ "$3" == "" ]; then /usr/local/bin/curl -s --connect-timeout 10 -m 20 -o /dev/null -w %&#123;http_code&#125; "$2" elif echo $3 |grep ':' &amp;&gt;/dev/null ; then /usr/local/bin/curl -s --connect-timeout 10 -m 20 -o /dev/null -w %&#123;http_code&#125; "$2" -x $3 else /usr/local/bin/curl -s --connect-timeout 10 -m 20 -o /dev/null -w %&#123;http_code&#125; "$2" -x $3:80 fi&#125;case "$1" in web_site_discovery) $1 ;; web_site_code) $1 $2 $3 $4 ;; *) echo "Usage : $0 &#123; web_site_discovery | web_site_code [URL]&#125;" ;;esac 1chmod +x /usr/lib/zabbix/scripts/web_site_code_status.sh 配置域名列表 1vim /usr/lib/zabbix/scripts/url.txt 1234腾讯 www.qq.com百度 www.baidu.com新浪 www.sina.com.cntest www.test.cn 配置客户端自定义参数 1vim /etc/zabbix/zabbix_agentd.d/web_site_discovery.conf 12UserParameter=web.site.discovery,/usr/lib/zabbix/scripts/web_site_code_status.sh web_site_discoveryUserParameter=web.site.code[*],/usr/lib/zabbix/scripts/web_site_code_status.sh web_site_code $1 $2 $3 重启客户端服务 1systemctl restart zabbix-agent 服务器端键值测试 123456789101112[root@ZabbixServer ~]# zabbix_get --host 124.160.121.82 --port 10050 -k web.site.discovery&#123; &quot;data&quot;:[ &#123;&quot;&#123;#SITENAME&#125;&quot;:&quot;腾讯 www.qq.com &quot;,&quot;&#123;#PROXYIP&#125;&quot;:&quot;&quot;&#125;, &#123;&quot;&#123;#SITENAME&#125;&quot;:&quot;百度 www.baidu.com &quot;,&quot;&#123;#PROXYIP&#125;&quot;:&quot;&quot;&#125;, &#123;&quot;&#123;#SITENAME&#125;&quot;:&quot;新浪 www.sina.com.cn &quot;,&quot;&#123;#PROXYIP&#125;&quot;:&quot;&quot;&#125;, &#123;&quot;&#123;#SITENAME&#125;&quot;:&quot;test www.test.cn &quot;,&quot;&#123;#PROXYIP&#125;&quot;:&quot;&quot;&#125; ]&#125;[root@ZabbixServer ~]# zabbix_get --host 124.160.121.82 --port 10050 -k web.site.code[&quot;腾讯 www.qq.com &quot;] 200 为了方便管理，专门针对这个功能创建一个自定义模板和应用集，下面是创建完成的应用集显示 创建自动发现规则 创建监控项原型 创建触发器原型 构造表达式 主机关联模板 很快就会发现监控项自动生成]]></content>
      <tags>
        <tag>monitor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haproxy的应用]]></title>
    <url>%2F2018%2F03%2F03%2F112119-Haproxy%E7%9A%84%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[多次代理 如上图所示，在 192.168.1.0/24 这个网段的客户端想要访问在 172.20.0.0/20 网段内的服务器，所有的通信又不想暴露在互联网上，因此可以在这两个网段内分别都放一台 Haproxy 服务器，并将两台 Haproxy 直连，10.94.0.73 到 10.94.0.72 互通，然后做两次代理即可。 Haproxy1 应该监听在 192.168.1.105 上以供 192.168.1.0/24 网段内的主机访问，然后指定源地址 10.94.0.73 将请求指向后端服务器 Haproxy2 的 10.94.0.72 。 Haproxy1 的配置 12345678910111213141516171819202122global daemon user nobody group nobody nbproc 1 maxconn 300000defaults maxconn 300000 timeout client 30s timeout server 30s timeout connect 8s mode tcp source 10.94.0.73 listen http bind 192.168.1.105:80 server http 10.94.0.72:80 listen mysql bind 192.168.1.105:3306 server mysql 10.94.0.72:3306 Haproxy2 应该监听在 10.94.0.72 以供 Haproxy1 的 10.94.0.73 来请求，然后指定源地址 172.20.0.254 将 Web 请求指向后端服务器 172.20.15.15:80，将 MySQL 请求指向后端服务器 172.20.11.154:3306。 Haproxy2 的配置 12345678910111213141516171819202122global daemon user nobody group nobody nbproc 1 maxconn 300000defaults maxconn 300000 timeout client 30s timeout server 30s timeout connect 8s mode tcp source 172.20.0.254 listen http bind 10.94.0.72:80 server http 172.20.15.15:80 listen mysql bind 10.94.0.72:3306 server mysql 172.20.11.154:3306 Web 负载均衡 如图所示，客户端访问 192.168.127.130 时，要把请求分发到 192.168.127.131:80、192.168.127.132:80 这两台服务器上。这是一个最简单的负载均衡结构图，实现起来比较简单。 1234567891011121314151617181920212223242526272829303132333435363738global chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4096 user nobody group nobody daemon # turn on stats unix socket stats socket /var/lib/haproxy/statsdefaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000frontend web_proxy bind 192.168.127.130:80 default_backend webserversbackend webservers balance roundrobin mode http server web1 192.168.127.131:80 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 server web2 192.168.127.132:80 maxconn 1024 weight 5 check inter 2000 rise 2 fall 3 配置说明 Global settings ：这是第一部分的配置，全局配置；对Haproxy进程自身属性的设定 proxys：对代理的设定，通常有4部分组成 defaults：提供默认配置 frontend：前端配置 backend：后端配置 listen：从某种意义上讲可以认为是将 frontend 和 backend 整合到一块的 ACL 匹配 如图所示，要求1、如果客户端的 IP 是 192.168.127.110，访问 192.168.127.130 时，要把请求分发到 Web Server3 上，即 192.168.127.133。 2、客户端访问 192.168.127.130 时，要把请求分发到 192.168.127.131，192.168.127.132，192.168.127.133 这三台服务器上。同时还要求客户端每一次访问，都跳转到不同的服务器上。 3、如果客户端访问的不是 192.168.127.130 而是 192.168.127.129 时，要把请求全部分发到 Web Server1 上，即 192.168.127.131。 1234567891011121314151617181920212223242526272829303132333435363738394041global log 127.0.0.1 local0 log 127.0.0.1 local1 notice maxconn 4096 uid 1005 gid 1005 daemondefaults log global mode http option httplog option dontlognull retries 3 option redispatch maxconn 2000 contimeout 5000 clitimeout 50000 srvtimeout 50000frontend WebLB bind *:80 acl from_110 src 192.168.127.110 acl to_129 hdr_beg(host) 192.168.127.129 acl to_130 hdr_beg(host) 192.168.127.130 use_backend from_to if from_110 to_130 use_backend 3round if to_130 default_backend backend_defaultbackend from_to balance source server web3 192.168.127.133:80 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 backend 3round balance roundrobin server web1 192.168.127.131:80 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 server web2 192.168.127.132:80 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 server web3 192.168.127.133:80 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 backend backend_default server web1 192.168.127.131:80 maxconn 1024 weight 3 check inter 2000 rise 2 fall 3 状态监控在其他的配置完成后，做一个全局配置区段，用来监控 Haproxy 服务器的状态。 12345678910listen Haproxy_Status # 关联前端和后端定义一个完整的代理 mode http # 设置代理协议 bind 0.0.0.0:1080 # 绑定相应的端口 stats enable # 开启 Haproxy 统计状态 stats refresh 10s # 统计页面自动刷新时间间隔 stats uri /status # 访问的url stats realm Haproxy\ Statistics # 统计页面认证时提示内容信息 stats auth admin:admin # 设置登录用户和密码 stats admin if TRUE # 如果认证通过，则就可以打开 status stats hide-version # 隐藏代理服务器版本 配置好之后，重启服务访问 http://192.168.127.130:1080/status 即可看到状态信息。 记录日志自己记录日志 1local2.* /var/log/haproxy.log 交给日志服务器记录日志 配置 /etc/haproxy/haproxy.cfg 1log 127.0.0.1 local2 开启 rsyslog 记录 haproxy 日志功能，编辑 /etc/rsyslog.conf 找到如下配置项并去掉配开头的的注释 123# Provides UDP syslog reception$ModLoad imudp$UDPServerRun 514 添加如下内容 12# Save haproxy log local2.* /var/log/haproxy.log 配置 /etc/sysconfig/rsyslog 12345# Options for rsyslogd# Syslogd options are deprecated since rsyslog v3.# If you want to use them, switch to compatibility mode 2 by "-c 2"# See rsyslogd(8) for more detailsSYSLOGD_OPTIONS="-r -m 0" 相关解释说明: -r: 打开接受外来日志消息的功能,其监控514 UDP端口; -x: 关闭自动解析对方日志服务器的FQDN信息,这能避免DNS不完整所带来的麻烦; -m: 修改syslog的内部mark消息写入间隔时间(0为关闭),例如240为每隔240分钟写入一次”–MARK–”信息; -h: 默认情况下,syslog不会发送从远端接受过来的消息到其他主机,而使用该选项,则把该开关打开,所有接受到的信息都可根据syslog.conf中定义的@主机转发过去. 重启服务查看日志 1systemctl restart rsyslog haproxy]]></content>
      <tags>
        <tag>Load Balance</tag>
        <tag>Haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haproxy配置文件参数说明]]></title>
    <url>%2F2018%2F03%2F02%2F152115-Haproxy%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[Haproxy 的配置处理 3 类来主要参数来源： 最优先处理的命令行参数； global 配置段，用于设定全局配置参数； proxy相关配置段，如defaults、listen、frontend和backend； 时间格式一些包含了值的参数表示时间，如超时时长。这些值一般以毫秒为单位，但也可以使用其它的时间单位后缀。 us: 微秒(microseconds)，即1/1000000秒； ms: 毫秒(milliseconds)，即1/1000秒； s: 秒(seconds)； m: 分钟(minutes)； h：小时(hours)； d: 天(days)； 下面的例子配置了一个监听在所有接口的 80 端口上 HTTP proxy 服务，它转发所有的请求至后端监听在 127.0.0.1:8000 上的 server 。 12345678910111213141516global daemon maxconn 25600 defaults mode http timeout connect 5000ms timeout client 50000ms timeout server 50000ms frontend http-in bind *:80 default_backend servers backend servers server server1 127.0.0.1:8080 maxconn 32 全局配置global配置中的参数为进程级别的参数，且通常与其运行的OS相关。 进程管理及安全相关的参数 chroot &lt;jail dir&gt;：修改haproxy的工作目录至指定的目录并在放弃权限之前执行chroot()操作，可以提升haproxy的安全级别，不过需要注意的是要确保指定的目录为空目录且任何用户均不能有写权限；一般情况下可以考虑不要，配置文件中注释掉或删掉即可； daemon：让haproxy以守护进程的方式工作于后台，其等同于“-D”选项的功能，当然，也可以在命令行中以“-db”选项将其禁用； gid &lt;number&gt;：以指定的GID运行haproxy，建议使用专用于运行haproxy的GID，以免因权限问题带来风险； group &lt;group name&gt;：同gid，不过指定的组名； log &lt;address&gt; &lt;facility&gt; [max level [min level]]：定义全局的syslog服务器，最多可以定义两个； log-send-hostname [&lt;string&gt;]：在syslog信息的首部添加当前主机名，可以为“string”指定的名称，也可以缺省使用当前主机名； nbproc &lt;number&gt;：指定启动的haproxy进程个数，只能用于守护进程模式的haproxy；默认只启动一个进程，鉴于调试困难等多方面的原因，一般只在单进程仅能打开少数文件描述符的场景中才使用多进程模式； pidfile：pid文件，也可以使用命令行中”-p”选项指定pid文件 uid：以指定的UID身份运行haproxy进程； ulimit-n：设定每进程所能够打开的最大文件描述符数目，默认情况下其会自动进行计算，因此不推荐修改此选项； user：同uid，但使用的是用户名； stats：是否开启Haproxy 状态信息页面 node：定义当前节点的名称，用于HA场景中多haproxy进程共享同一个IP地址时； description：当前实例的描述信息； 性能调整相关的参数 maxconn &lt;number&gt;：设定每个haproxy进程所接受的最大并发连接数，其等同于命令行选项“-n”；“ulimit -n”自动计算的结果正是参照此参数设定的； maxpipes &lt;number&gt;：haproxy使用pipe完成基于内核的tcp报文重组，此选项则用于设定每进程所允许使用的最大pipe个数；每个pipe会打开两个文件描述符，因此，“ulimit -n”自动计算时会根据需要调大此值；默认为maxconn/4，其通常会显得过大； noepoll：在Linux系统上禁用epoll机制； nokqueue：在BSE系统上禁用kqueue机制； nopoll：禁用poll机制； nosepoll：在Linux禁用启发式epoll机制； nosplice：禁止在Linux套接字上使用内核tcp重组，这会导致更多的recv/send系统调用；不过，在Linux 2.6.25-28系列的内核上，tcp重组功能有bug存在； spread-checks &lt;0..50, in percent&gt;：在haproxy后端有着众多服务器的场景中，在精确的时间间隔后统一对众服务器进行健康状况检查可能会带来意外问题；此选项用于将其检查的时间间隔长度上增加或减小一定的随机时长； tune.bufsize &lt;number&gt;：设定buffer的大小，同样的内存条件大小，较小的值可以让haproxy有能力接受更多的并发连接，较大的值可以让某些应用程序使用较大的cookie信息；默认为16384，其可以在编译时修改，不过强烈建议使用默认值； tune.chksize &lt;number&gt;：设定检查缓冲区的大小，单位为字节；更大的值有助于在较大的页面中完成基于字符串或模式的文本查找，但也会占用更多的系统资源；不建议修改； tune.maxaccept &lt;number&gt;：设定haproxy进程内核调度运行时一次性可以接受的连接的个数，较大的值可以带来较大的吞吐率，默认在单进程模式下为100，多进程模式下为8，设定为-1可以禁止此限制；一般不建议修改； tune.maxpollevents &lt;number&gt;：设定一次系统调用可以处理的事件最大数，默认值取决于OS；其值小于200时可节约带宽，但会略微增大网络延迟，而大于200时会降低延迟，但会稍稍增加网络带宽的占用量； tune.maxrewrite &lt;number&gt;：设定为首部重写或追加而预留的缓冲空间，建议使用1024左右的大小；在需要使用更大的空间时，haproxy会自动增加其值； Debug相关的参数 debug quiet 代理代理相关的配置可以如下配置段中。 defaults &lt;name&gt;“defaults”段用于为所有其它配置段提供默认参数，这配置默认配置参数可由下一个“defaults”所重新设定。 frontend &lt;name&gt;“frontend”段用于定义一系列监听的套接字，这些套接字可接受客户端请求并与之建立连接。 backend &lt;name&gt;“backend”段用于定义一系列“后端”服务器，代理将会将对应客户端的请求转发至这些服务器。 listen &lt;name&gt;“listen”段通过关联“前端”和“后端”定义了一个完整的代理，通常只对TCP流量有用。 所有代理的名称只能使用大写字母、小写字母、数字、-(中线)、_(下划线)、.(点号)和:(冒号)。此外，ACL名称会区分字母大小写。 配置文件中的关键字参考balance12balance &lt;algorithm&gt; [ &lt;arguments&gt; ]balance url_param &lt;param&gt; [check_post [&lt;max_wait&gt;]] 定义负载均衡算法，可用于“defaults”、“listen”和“backend”。&lt;algorithm&gt;用于在负载均衡场景中挑选一个server，其仅应用于持久信息不可用的条件下或需要将一个连接重新派发至另一个服务器时。支持的算法有： roundrobin 基于权重进行轮叫，在服务器的处理时间保持均匀分布时，这是最平衡、最公平的算法 此算法是动态的，这表示其权重可以在运行时进行调整，不过，在设计上，每个后端服务器仅能最多接受4128个连接； static-rr 基于权重进行轮叫，与roundrobin类似，但是为静态方法，在运行时调整其服务器权重不会生效；不过，其在后端服务器连接数上没有限制； leastconn 新的连接请求被派发至具有最少连接数目的后端服务器 在有着较长时间会话的场景中推荐使用此算法，如LDAP、SQL等，其并不太适用于较短会话的应用层协议，如HTTP； 此算法是动态的，可以在运行时调整其权重； source 将请求的源地址进行hash运算，并由后端服务器的权重总数相除后派发至某匹配的服务器； 这可以使得同一个客户端IP的请求始终被派发至某特定的服务器； 不过，当服务器权重总数发生变化时，如某服务器宕机或添加了新的服务器，许多客户端的请求可能会被派发至与此前请求不同的服务器； 常用于负载均衡无cookie功能的基于TCP的协议； 其默认为静态，不过也可以使用hash-type修改此特性； uri 对URI的左半部分(“问题”标记之前的部分)或整个URI进行hash运算，并由服务器的总权重相除后派发至某匹配的服务器； 这可以使得对同一个URI的请求总是被派发至某特定的服务器，除非服务器的权重总数发生了变化；此算法常用于代理缓存或反病毒代理以提高缓存的命中率； 需要注意的是，此算法仅应用于HTTP后端服务器场景； 其默认为静态算法，不过也可以使用hash-type修改此特性； url_param 通过 &lt;argument&gt; 为URL指定的参数在每个 HTTP GET 请求中将会被检索； 如果找到了指定的参数且其通过等于号“=”被赋予了一个值，那么此值将被执行hash运算并被服务器的总权重相除后派发至某匹配的服务器； 此算法可以通过追踪请求中的用户标识进而确保同一个用户ID的请求将被送往同一个特定的服务器，除非服务器的总权重发生了变化； 如果某请求中没有出现指定的参数或其没有有效值，则使用轮叫算法对相应请求进行调度； 此算法默认为静态的，不过其也可以使用hash-type修改此特性； hdr(&lt;name&gt;) 对于每个HTTP请求，通过 &lt;name&gt; 指定的HTTP首部将会被检索； 如果相应的首部没有出现或其没有有效值，则使用轮叫算法对相应请求进行调度； 其有一个可选选项 “use_domain_only”，可在指定检索类似Host类的首部时仅计算域名部分(比如通过www.magedu.com 来说，仅计算magedu字符串的hash值)以降低hash算法的运算量； 此算法默认为静态的，不过其也可以使用hash-type修改此特性； bind12bind [&lt;address&gt;]:&lt;port_range&gt; [, ...]bind [&lt;address&gt;]:&lt;port_range&gt; [, ...] interface &lt;interface&gt; 此指令仅能用于 frontend 和 listen 区段，用于定义一个或几个监听的套接字。 &lt;address&gt;：可选选项，其可以为主机名、IPv4地址、IPv6地址或；省略此选项、将其指定为或0.0.0.0时，将监听当前系统的所有IPv4地址； &lt;port_range&gt;：可以是一个特定的TCP端口，也可是一个端口范围(如5005-5010)，代理服务器将通过指定的端口来接收客户端请求；需要注意的是，每组监听的套接字&lt;address:port&gt;在同一个实例上只能使用一次，而且小于1024的端口需要有特定权限的用户才能使用，这可能需要通过uid参数来定义； &lt;interface&gt;：指定物理接口的名称，仅能在Linux系统上使用；其不能使用接口别名，而仅能使用物理接口名称，而且只有管理有权限指定绑定的物理接口； mode1mode &#123; tcp|http|health &#125; 设定实例的运行模式或协议。当实现内容交换时，前端和后端必须工作于同一种模式(一般说来都是HTTP模式)，否则将无法启动实例。 tcp：实例运行于纯TCP模式，在客户端和服务器端之间将建立一个全双工的连接，且不会对7层报文做任何类型的检查；此为默认模式，通常用于SSL、SSH、SMTP等应用； http：实例运行于HTTP模式，客户端请求在转发至后端服务器之前将被深度分析，所有不与RFC格式兼容的请求都会被拒绝； health：实例工作于health模式，其对入站请求仅响应“OK”信息并关闭连接，且不会记录任何日志信息；此模式将用于响应外部组件的健康状态检查请求；目前业讲，此模式已经废弃，因为tcp或http模式中的monitor关键字可完成类似功能； hash-type1hash-type &lt;method&gt; 定义用于将hash码映射至后端服务器的方法；其不能用于frontend区段；可用方法有map-based和consistent，在大多数场景下推荐使用默认的map-based方法。 map-based：hash表是一个包含了所有在线服务器的静态数组。其hash值将会非常平滑，会将权重考虑在列，但其为静态方法，对在线服务器的权重进行调整将不会生效，这意味着其不支持慢速启动。此外，挑选服务器是根据其在数组中的位置进行的，因此，当一台服务器宕机或添加了一台新的服务器时，大多数连接将会被重新派发至一个与此前不同的服务器上，对于缓存服务器的工作场景来说，此方法不甚适用。 consistent：hash表是一个由各服务器填充而成的树状结构；基于hash键在hash树中查找相应的服务器时，最近的服务器将被选中。此方法是动态的，支持在运行时修改服务器权重，因此兼容慢速启动的特性。添加一个新的服务器时，仅会对一小部分请求产生影响，因此，尤其适用于后端服务器为cache的场景。不过，此算法不甚平滑，派发至各服务器的请求未必能达到理想的均衡效果，因此，可能需要不时的调整服务器的权重以获得更好的均衡性。 log12log globallog &lt;address&gt; &lt;facility&gt; [&lt;level&gt; [&lt;minlevel&gt;]] 为每个实例启用事件和流量日志，因此可用于所有区段。每个实例最多可以指定两个log参数，不过，如果使用了“log global”且”global”段已经定了两个log参数时，多余了log参数将被忽略。 global：当前实例的日志系统参数同”global”段中的定义时，将使用此格式；每个实例仅能定义一次“log global”语句，且其没有任何额外参数； &lt;address&gt;：定义日志发往的位置，其格式之一可以为&lt;IPv4_address:PORT&gt;，其中的port为UDP协议端口，默认为514；格式之二为Unix套接字文件路径，但需要留心chroot应用及用户的读写权限； &lt;facility&gt;：可以为syslog系统的标准facility之一； &lt;level&gt;：定义日志级别，即输出信息过滤器，默认为所有信息；指定级别时，所有等于或高于此级别的日志信息将会被发送； maxconn1maxconn &lt;conns&gt; 设定一个前端的最大并发连接数，因此，其不能用于backend区段。对于大型站点来说，可以尽可能提高此值以便让haproxy管理连接队列，从而避免无法应答用户请求。当然，此最大值不能超出“global”段中的定义。此外，需要留心的是，haproxy会为每个连接维持两个缓冲，每个缓冲的大小为8KB，再加上其它的数据，每个连接将大约占用17KB的RAM空间。这意味着经过适当优化后，有着1GB的可用RAM空间时将能维护40000-50000并发连接。 如果为 &lt;conns&gt; 指定了一个过大值，极端场景下，其最终占据的空间可能会超出当前主机的可用内存，这可能会带来意想不到的结果；因此，将其设定了一个可接受值方为明智决定。其默认为2000。 default_backend1default_backend &lt;backend&gt; 在没有匹配的”use_backend”规则时为实例指定使用的默认后端，因此，其不可应用于backend区段 在”frontend”和”backend”之间进行内容交换时，通常使用”use-backend”定义其匹配规则；而没有被规则匹配到的请求将由此参数指定的后端接收 &lt;backend&gt;：指定使用的后端的名称； 使用案例： 123use_backend dynamic if url_dynuse_backend static if url_css url_img extension_imgdefault_backend dynamic server1server &lt;name&gt; &lt;address&gt;[:port] [param*] 为后端声明一个server，因此，不能用于defaults和frontend区段。 &lt;name&gt;：为此服务器指定的内部名称，其将出现在日志及警告信息中；如果设定了”http-send-server-name”，它还将被添加至发往此服务器的请求首部中； &lt;address&gt;：此服务器的的IPv4地址，也支持使用可解析的主机名，只不过在启动时需要解析主机名至相应的IPv4地址； [:port]：指定将连接请求所发往的此服务器时的目标端口，其为可选项；未设定时，将使用客户端请求时的同一相端口； [param*]：为此服务器设定的一系参数；其可用的参数非常多，具体请参考官方文档中的说明，下面仅说明几个常用的参数； 服务器或默认服务器参数： backup：设定为备用服务器，仅在负载均衡场景中的其它server均不可用于启用此server； check：启动对此server执行健康状态检查，其可以借助于额外的其它参数完成更精细的设定，如： inter &lt;delay&gt;：设定健康状态检查的时间间隔，单位为毫秒，默认为2000；也可以使用fastinter和downinter来根据服务器端状态优化此时间延迟； rise &lt;count&gt;：设定健康状态检查中，某离线的server从离线状态转换至正常状态需要成功检查的次数； fall &lt;count&gt;：确认server从正常状态转换为不可用状态需要检查的次数； cookie &lt;value&gt;：为指定server设定cookie值，此处指定的值将在请求入站时被检查，第一次为此值挑选的server将在后续的请求中被选中，其目的在于实现持久连接的功能； maxconn &lt;maxconn&gt;：指定此服务器接受的最大并发连接数；如果发往此服务器的连接数目高于此处指定的值，其将被放置于请求队列，以等待其它连接被释放； maxqueue &lt;maxqueue&gt;：设定请求队列的最大长度； observe &lt;mode&gt;：通过观察服务器的通信状况来判定其健康状态，默认为禁用，其支持的类型有“layer4”和“layer7”，“layer7”仅能用于http代理场景； redir &lt;prefix&gt;：启用重定向功能，将发往此服务器的GET和HEAD请求均以302状态码响应；需要注意的是，在prefix后面不能使用/，且不能使用相对地址，以免造成循环；例如：server srv1 172.16.100.6:80 redir http://imageserver.magedu.com check weight &lt;weight&gt;：权重，默认为1，最大值为256，0表示不参与负载均衡； 检查方法： option httpchk option httpchk &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt;：不能用于frontend段，例如： 1234backend https_relay mode tcp option httpchk OPTIONS * HTTP/1.1\r\nHost:\ www.magedu.com server apache1 192.168.1.1:443 check port 80 使用案例： 12server first 172.16.100.7:1080 cookie first check inter 1000server second 172.16.100.8:1080 cookie second check inter 1000 capture request header1capture request header &lt;name&gt; len &lt;length&gt; 捕获并记录指定的请求首部最近一次出现时的第一个值，仅能用于“frontend”和“listen”区段。捕获的首部值使用花括号{}括起来后添加进日志中。如果需要捕获多个首部值，它们将以指定的次序出现在日志文件中，并以竖线“|”作为分隔符。不存在的首部记录为空字符串，最常需要捕获的首部包括在虚拟主机环境中使用的“Host”、上传请求首部中的“Content-length”、快速区别真实用户和网络机器人的“User-agent”，以及代理环境中记录真实请求来源的“X-Forward-For”。 &lt;name&gt;：要捕获的首部的名称，此名称不区分字符大小写，但建议与它们出现在首部中的格式相同，比如大写首字母。需要注意的是，记录在日志中的是首部对应的值，而非首部名称。 &lt;length&gt;：指定记录首部值时所记录的精确长度，超出的部分将会被忽略。 可以捕获的请求首部的个数没有限制，但每个捕获最多只能记录64个字符。为了保证同一个frontend中日志格式的统一性，首部捕获仅能在frontend中定义。 capture response header1capture response header &lt;name&gt; len &lt;length&gt; 捕获并记录响应首部，其格式和要点同请求首部。 stats enable 启用基于程序编译时默认设置的统计报告，不能用于“frontend”区段。只要没有另外的其它设定，它们就会使用如下的配置： stats uri : /haproxy?stats stats realm : “HAProxy Statistics” stats auth : no authentication stats scope : no restriction 尽管“stats enable”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。下面是一个配置案例。 123456789backend public_www server websrv1 172.16.100.11:80 stats enable stats hide-version stats scope . stats uri /haproxyadmin?stats stats realm Haproxy\ Statistics stats auth statsadmin:password stats auth statsmaster:password stats hide-version1stats hide-version 启用统计报告并隐藏HAProxy版本报告，不能用于“frontend”区段。默认情况下，统计页面会显示一些有用信息，包括HAProxy的版本号，然而，向所有人公开HAProxy的精确版本号是非常有风险的，因为它能帮助恶意用户快速定位版本的缺陷和漏洞。尽管“stats hide-version”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。具体请参照“stats enable”一节的说明。 stats realm1stats realm &lt;realm&gt; 启用统计报告并高精认证领域，不能用于“frontend”区段。haproxy在读取realm时会将其视作一个单词，因此，中间的任何空白字符都必须使用反斜线进行转义。此参数仅在与“stats auth”配置使用时有意义。 &lt;realm&gt;：实现HTTP基本认证时显示在浏览器中的领域名称，用于提示用户输入一个用户名和密码。 尽管“stats realm”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。具体请参照“stats enable”一节的说明。 stats scope1stats scope &#123; &lt;name&gt; | "." &#125; 启用统计报告并限定报告的区段，不能用于“frontend”区段。当指定此语句时，统计报告将仅显示其列举出区段的报告信息，所有其它区段的信息将被隐藏。如果需要显示多个区段的统计报告，此语句可以定义多次。需要注意的是，区段名称检测仅仅是以字符串比较的方式进行，它不会真检测指定的区段是否真正存在。 &lt;name&gt;：可以是一个“listen”、“frontend”或“backend”区段的名称，而“.”则表示stats scope语句所定义的当前区段。 尽管“stats scope”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。下面是一个配置案例。 1234backend private_monitoring stats enable stats uri /haproxyadmin?stats stats refresh 10s stats auth1stats auth &lt;user&gt;:&lt;passwd&gt; 启用带认证的统计报告功能并授权一个用户帐号，其不能用于“frontend”区段。 &lt;user&gt;：授权进行访问的用户名； &lt;passwd&gt;：此用户的访问密码，明文格式； 此语句将基于默认设定启用统计报告功能，并仅允许其定义的用户访问，其也可以定义多次以授权多个用户帐号。可以结合“stats realm”参数在提示用户认证时给出一个领域说明信息。在使用非法用户访问统计功能时，其将会响应一个“401 Forbidden”页面。其认证方式为HTTP Basic认证，密码传输会以明文方式进行，因此，配置文件中也使用明文方式存储以说明其非保密信息故此不能相同于其它关键性帐号的密码。 尽管“stats auth”一条就能够启用统计报告，但还是建议设定其它所有的参数，以免其依赖于默认设定而带来非期后果。 stats admin1stats admin &#123; if | unless &#125; &lt;cond&gt; 在指定的条件满足时启用统计报告页面的管理级别功能，它允许通过web接口启用或禁用服务器，不过，基于安全的角度考虑，统计报告页面应该尽可能为只读的。此外，如果启用了HAProxy的多进程模式，启用此管理级别将有可能导致异常行为。 目前来说，POST请求方法被限制于仅能使用缓冲区减去保留部分之外的空间，因此，服务器列表不能过长，否则，此请求将无法正常工作。因此，建议一次仅调整少数几个服务器。下面是两个案例，第一个限制了仅能在本机打开报告页面时启用管理级别功能，第二个定义了仅允许通过认证的用户使用管理级别功能。 12345678backend stats_localhost stats enable stats admin if LOCALHOSTbackend stats_auth stats enable stats auth haproxyadmin:password stats admin if TRUE option httplog1option httplog [ clf ] 启用记录HTTP请求、会话状态和计时器的功能。 clf：使用CLF格式来代替HAProxy默认的HTTP格式，通常在使用仅支持CLF格式的特定日志分析器时才需要使用此格式。 默认情况下，日志输入格式非常简陋，因为其仅包括源地址、目标地址和实例名称，而“option httplog”参数将会使得日志格式变得丰富许多，其通常包括但不限于HTTP请求、连接计时器、会话状态、连接数、捕获的首部及cookie、“frontend”、“backend”及服务器名称，当然也包括源地址和端口号等。 option logasap12option logasapno option logasap 启用或禁用提前将HTTP请求记入日志，不能用于“backend”区段。 默认情况下，HTTP请求是在请求结束时进行记录以便能将其整体传输时长和字节数记入日志，由此，传较大的对象时，其记入日志的时长可能会略有延迟。“option logasap”参数能够在服务器发送complete首部时即时记录日志，只不过，此时将不记录整体传输时长和字节数。此情形下，捕获“Content-Length”响应首部来记录传输的字节数是一个较好选择。下面是一个例子。 12345listen http_proxy 0.0.0.0:80 mode http option httplog option logasap log 172.16.100.9 local2 option forwardfor1option forwardfor [ except &lt;network&gt; ] [ header &lt;name&gt; ] [ if-none ] 允许在发往服务器的请求首部中插入“X-Forwarded-For”首部。 &lt;network&gt;：可选参数，当指定时，源地址为匹配至此网络中的请求都禁用此功能。 &lt;name&gt;：可选参数，可使用一个自定义的首部，如“X-Client”来替代“X-Forwarded-For”。有些独特的web服务器的确需要用于一个独特的首部。 if-none：仅在此首部不存在时才将其添加至请求报文问道中。 HAProxy工作于反向代理模式，其发往服务器的请求中的客户端IP均为HAProxy主机的地址而非真正客户端的地址，这会使得服务器端的日志信息记录不了真正的请求来源，“X-Forwarded-For”首部则可用于解决此问题。HAProxy可以向每个发往服务器的请求上添加此首部，并以客户端IP为其value。 需要注意的是，HAProxy工作于隧道模式，其仅检查每一个连接的第一个请求，因此，仅第一个请求报文被附加此首部。如果想为每一个请求都附加此首部，请确保同时使用了“option httpclose”、“option forceclose”和“option http-server-close”几个option。 下面是一个例子。 123frontend www mode http option forwardfor except 127.0.0.1 errorfile1errorfile &lt;code&gt; &lt;file&gt; 在用户请求不存在的页面时，返回一个页面文件给客户端而非由haproxy生成的错误代码；可用于所有段中。 &lt;code&gt;：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有200、400、403、408、500、502、503和504； &lt;file&gt;：指定用于响应的页面文件； 例如： 123errorfile 400 /etc/haproxy/errorpages/400badreq.httperrorfile 403 /etc/haproxy/errorpages/403forbid.httperrorfile 503 /etc/haproxy/errorpages/503sorry.http errorloc 和 errorloc30212errorloc &lt;code&gt; &lt;url&gt;errorloc302 &lt;code&gt; &lt;url&gt; 请求错误时，返回一个HTTP重定向至某URL的信息；可用于所有配置段中。 &lt;code&gt;：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有200、400、403、408、500、502、503和504； &lt;url&gt;：Location首部中指定的页面位置的具体路径，可以是在当前服务器上的页面的相对路径，也可以使用绝对路径；需要注意的是，如果URI自身错误时产生某特定状态码信息的话，有可能会导致循环定向； 需要留意的是，这两个关键字都会返回302状态吗，这将使得客户端使用同样的HTTP方法获取指定的URL，对于非GET法的场景(如POST)来说会产生问题，因为返回客户的URL是不允许使用GET以外的其它方法的。如果的确有这种问题，可以使用errorloc303来返回303状态码给客户端。 errorloc3031errorloc303 &lt;code&gt; &lt;url&gt; 请求错误时，返回一个HTTP重定向至某URL的信息给客户端；可用于所有配置段中。 &lt;code&gt;：指定对HTTP的哪些状态码返回指定的页面；这里可用的状态码有400、403、408、500、502、503和504； &lt;url&gt;：Location首部中指定的页面位置的具体路径，可以是在当前服务器上的页面的相对路径，也可以使用绝对路径；需要注意的是，如果URI自身错误时产生某特定状态码信息的话，有可能会导致循环定向； 例如： 12345backend webserver server 172.16.100.6 172.16.100.6:80 check maxconn 3000 cookie srv01 server 172.16.100.7 172.16.100.7:80 check maxconn 3000 cookie srv02 errorloc 403 /etc/haproxy/errorpages/sorry.htm errorloc 503 /etc/haproxy/errorpages/sorry.htm ACL基本说明Haproxy 的 ACL 用于实现基于请求报文的首部、响应报文的内容或其它的环境状态信息来做出转发决策，这大大增强了其配置弹性。其配置法则通常分为两步，首先去定义 ACL，即定义一个测试条件，而后在条件得到满足时执行某特定的动作，如阻止请求或转发至某特定的后端。定义 ACL 的语法格式如下。 1acl &lt;aclname&gt; &lt;criterion&gt; [flags] [operator] &lt;value&gt; ... &lt;aclname&gt;：ACL名称，区分字符大小写，且其只能包含大小写字母、数字、-(连接线)、_(下划线)、.(点号)和:(冒号)；haproxy中，acl可以重名，这可以把多个测试条件定义为一个共同的acl； &lt;criterion&gt;：测试标准，即对什么信息发起测试；测试方式可以由[flags]指定的标志进行调整；而有些测试标准也可以需要为其在 &lt;value&gt; 之前指定一个操作符[operator]； [flags]：目前haproxy的acl支持的标志位有3个： -i：不区分 &lt;value&gt; 中模式字符的大小写； -f：从指定的文件中加载模式； --：标志符的强制结束标记，在模式中的字符串像标记符时使用； &lt;value&gt;：acl测试条件支持的值有以下四类： 整数或整数范围：如1024:65535表示从1024至65535；仅支持使用正整数(如果出现类似小数的标识，其为通常为版本测试)，且支持使用的操作符有5个，分别为eq、ge、gt、le和lt； 字符串：支持使用“-i”以忽略字符大小写，支持使用“\”进行转义；如果在模式首部出现了-i，可以在其之前使用“–”标志位； 正则表达式：其机制类同字符串匹配； IP地址及网络地址 同一个acl中可以指定多个测试条件，这些测试条件需要由逻辑操作符指定其关系。条件间的组合测试关系有三种：“与”(默认即为与操作)、“或”(使用“||”操作符)以及“非”(使用“!”操作符)。 常用的测试标准(criteria)be_sess_rate1be_sess_rate(backend) &lt;integer&gt; 用于测试指定的backend上会话创建的速率(即每秒创建的会话数)是否满足指定的条件；常用于在指定backend上的会话速率过高时将用户请求转发至另外的backend，或用于阻止攻击行为。例如： 1234backend dynamic mode http acl being_scanned be_sess_rate gt 50 redirect location /error_pages/denied.html if being_scanned fe_sess_rate1fe_sess_rate(frontend) &lt;integer&gt; 用于测试指定的frontend(或当前frontend)上的会话创建速率是否满足指定的条件；常用于为frontend指定一个合理的会话创建速率的上限以防止服务被滥用。例如下面的例子限定入站邮件速率不能大于50封/秒，所有在此指定范围之外的请求都将被延时50毫秒。 12345678frontend mail bind :25 mode tcp maxconn 500 acl too_fast fe_sess_rate ge 50 tcp-request inspect-delay 50ms tcp-request content accept if ! too_fast tcp-request content accept if WAIT_END hdr1hdr(header) &lt;string&gt; 用于测试请求报文中的所有首部或指定首部是否满足指定的条件；指定首部时，其名称不区分大小写，且在括号“()”中不能有任何多余的空白字符。测试服务器端的响应报文时可以使用shdr()。例如下面的例子用于测试首部Connection的值是否为close。 1hdr(Connection) -i close method1method &lt;string&gt; 测试HTTP请求报文中使用的方法。 path_beg1path_beg &lt;string&gt; 用于测试请求的URL是否以 &lt;string&gt; 指定的模式开头。下面的例子用于测试URL是否以/static、/images、/javascript或/stylesheets头。 1acl url_static path_beg -i /static /images /javascript /stylesheets path_end1path_end &lt;string&gt; 用于测试请求的URL是否以 &lt;string&gt; 指定的模式结尾。例如，下面的例子用户测试URL是否以jpg、gif、png、css或js结尾。 1acl url_static path_end -i .jpg .gif .png .css .js hdr_beg1hdr_beg &lt;string&gt; 用于测试请求报文的指定首部的开头部分是否符合 &lt;string&gt; 指定的模式。例如，下面的例子用记测试请求是否为提供静态内容的主机img、video、download或ftp。 1acl host_static hdr_beg(host) -i img. video. download. ftp. hdr_end1hdr_end &lt;string&gt; 用于测试请求报文的指定首部的结尾部分是否符合 &lt;string&gt; 指定的模式。例如，下面的例子用记测试请求是否为动静分离示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/statsdefaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 30000listen stats mode http bind 0.0.0.0:1080 stats enable stats hide-version stats uri /haproxyadmin?stats stats realm Haproxy\ Statistics stats auth admin:admin stats admin if TRUEfrontend http-in bind *:80 mode http log global option httpclose option logasap option dontlognull capture request header Host len 20 capture request header Referer len 60 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .jpeg .gif .png .css .js use_backend static_servers if url_static default_backend dynamic_serversbackend static_servers balance roundrobin server imgsrv1 172.16.200.7:80 check maxconn 6000 server imgsrv2 172.16.200.8:80 check maxconn 6000backend dynamic_servers balance source server websrv1 172.16.200.7:80 check maxconn 1000 server websrv2 172.16.200.8:80 check maxconn 1000 server websrv3 172.16.200.9:80 check maxconn 1000 官方文档：http://www.haproxy.org/#docs]]></content>
      <tags>
        <tag>Load Balance</tag>
        <tag>Haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Haproxy及安装配置]]></title>
    <url>%2F2018%2F03%2F01%2F130103-Haproxy%E5%8F%8A%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[简介 HAProxy 提供高可用性、负载均衡以及基于 TCP 和 HTTP 应用的代理，支持 http 的虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy 特别适用于那些负载特大的 web 站点，这些站点通常又需要会话保持或七层处理 HAProxy 运行在时下的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的 Web 服务器不被暴露到网络上。 HAProxy 实现了一种 ==事件驱动==、单一进程 模型此模型支持非常大的并发连接数。多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。事件驱动模型因为在有更好的资源和时间管理的用户端(User-Space) 实现所有这些任务，所以没有这些问题。此模型的弊端是，在多核系统上，这些程序通常扩展性较差。这就是为什么他们必须进行优化以 使每个 CPU 时间片(Cycle)做更多的工作。 HAProxy 支持连接拒绝 : 因为维护一个连接的打开的开销是很低的，有时我们很需要限制攻击蠕虫（attack bots），也就是说限制它们的连接打开从而限制它们的危害。 这个已经为一个陷于小型 DDoS 攻击的网站开发了而且已经拯救了很多站点，这个优点也是其它负载均衡器没有的。 HAProxy 支持全透明代理（已具备硬件防火墙的典型特点）: 可以用客户端IP地址或者任何其他地址来连接后端服务器. 这个特性仅在 Linux 2.4/2.6 内核打了 cttproxy 补丁后才可以使用。这个特性也使得为某特殊服务器处理部分流量同时又不修改服务器的地址成为可能。 主要版本1.4：提供较好的弹性：衍生于1.2版本，并提供了额外的新特性，其中大多数是期待已久的。 客户端侧的长连接(client-side keep-alive) TCP加速(TCP speedups) 响应池(response buffering) RDP协议 基于源的粘性(source-based stickiness) 更好的统计数据接口(a much better stats interfaces) 更详细的健康状态检测机制(more verbose health checks) 基于流量的健康评估机制(traffic-based health) 支持HTTP认证 服务器管理命令行接口(server management from the CLI) 基于ACL的持久性(ACL-based persistence) 日志分析器 1.3：内容交换和超强负载：衍生于1.2版本，并提供了额外的新特性。 内容交换(content switching)：基于任何请求标准挑选服务器池； ACL：编写内容交换规则； 负载均衡算法(load-balancing algorithms)：更多的算法支持； 内容探测(content inspection)：阻止非授权协议； 透明代理(transparent proxy)：在Linux系统上允许使用客户端IP直接连入服务器； 内核TCP拼接(kernel TCP splicing)：无copy方式在客户端和服务端之间转发数据以实现数G级别的数据速率； 分层设计(layered design)：分别实现套接字、TCP、HTTP处理以提供更好的健壮性、更快的处理机制及便捷的演进能力； 快速、公平调度器(fast and fair scheduler)：为某些任务指定优先级可实现理好的QoS； 会话速率限制(session rate limiting)：适用于托管环境； 性能可以从三个因素来评估负载均衡器的性能： 1、会话率2、会话并发能力3、数据率 HAProxy 借助于 OS 上几种常见的技术来实现性能的最大化。 1、单进程、事件驱动模型显著降低了上下文切换的开销及内存占用。 2、O(1)事件检查器(event checker)允许其在高并发连接中对任何连接的任何事件实现即时探测。 3、在任何可用的情况下，单缓冲(single buffering)机制能以不复制任何数据的方式完成读写操作，这会节约大量的CPU时钟周期及内存带宽； 4、借助于Linux 2.6 (&gt;= 2.6.27.19)上的splice()系统调用，HAProxy可以实现零复制转发(Zero-copy forwarding)，在Linux 3.5及以上的OS中还可以实现零复制启动(zero-starting)； 5、MRU内存分配器在固定大小的内存池中可实现即时内存分配，这能够显著减少创建一个会话的时长； 6、树型存储：侧重于使用作者多年前开发的弹性二叉树，实现了以O(log(N))的低开销来保持计时器命令、保持运行队列命令及管理轮询及最少连接队列； 7、优化的HTTP首部分析：优化的首部分析功能避免了在HTTP首部分析过程中重读任何内存区域； 8、精心地降低了昂贵的系统调用，大部分工作都在用户空间完成，如时间读取、缓冲聚合及文件描述符的启用和禁用等； 所有的这些细微之处的优化实现了在中等规模负载之上依然有着相当低的 CPU 负载，甚至于在非常高的负载场景中， 5% 的用户空间占用率和 95% 的系统空间占用率也是非常普遍的现象，这意味着 HAProxy 进程消耗比系统空间消耗低 20 倍以上。因此，对 OS 进行性能调优是非常重要的。即使用户空间的占用率提高一倍，其 CPU 占用率也仅为 10% ，这也解释了为何 7 层处理对性能影响有限这一现象。由此，在高端系统上 HAProxy 的 7 层性能可轻易超过硬件负载均衡设备。 在生产环境中，在 7 层处理上使用 HAProxy 作为昂贵的高端硬件负载均衡设备故障故障时的紧急解决方案也时长可见。硬件负载均衡设备在“报文”级别处理请求，这在支持跨报文请求(request across multiple packets)有着较高的难度，并且它们不缓冲任何数据，因此有着较长的响应时间。对应地，软件负载均衡设备使用 TCP 缓冲，可建立极长的请求，且有着较大的响应时间。 安装配置 HAProxy版本信息： 系统：CentOS Linux release 7.4.1708 (Core) 内核：4.14.8-1.el7.elrepo.x86_64 并启用了 BBR 算法 Haproxy：haproxy-1.7.9 编译安装 12345678910111213141516171819202122232425yum -y install openssl openssl-develcd ~wget http://www.haproxy.org/download/1.7/src/haproxy-1.7.9.tar.gz tar xf haproxy-1.7.9.tar.gz -C /usr/local/src/cd /usr/local/src/haproxy-1.7.9/cat READMEmake TARGET=linux2628 USE_OPENSSL=1 ARCH=x86_64 PREFIX=/opt/haproxymake install PREFIX=/opt/haproxy# 编译安装install -d /usr/sbin install haproxy /usr/sbin/install haproxy-systemd-wrapper /usr/sbin# 将make好的haproxy拷贝到指定目录install -d /usr/local/share/man/man1 install -m 644 doc/haproxy.1 /usr/local/share/man/man1 # 生成 man 文档cp -ar /opt/haproxy/doc/haproxy /usr/local/doc/haproxy# 生成docmkdir -pv /var/lib/haproxy# 这个目录是Haproxy配置中chroot要用到的配置 运行 haproxy 命令测试 123456789101112131415161718192021222324HA-Proxy version 1.7.9 2017/08/18Copyright 2000-2017 Willy Tarreau &lt;willy@haproxy.org&gt;Usage : haproxy [-f &lt;cfgfile|cfgdir&gt;]* [ -vdVD ] [ -n &lt;maxconn&gt; ] [ -N &lt;maxpconn&gt; ] [ -p &lt;pidfile&gt; ] [ -m &lt;max megs&gt; ] [ -C &lt;dir&gt; ] [-- &lt;cfgfile&gt;*] -v displays version ; -vv shows known build options. -d enters debug mode ; -db only disables background mode. -dM[&lt;byte&gt;] poisons memory with &lt;byte&gt; (defaults to 0x50) -V enters verbose mode (disables quiet mode) -D goes daemon ; -C changes to &lt;dir&gt; before loading files. -q quiet mode : don't display messages -c check mode : only check config files and exit -n sets the maximum total # of connections (2000) -m limits the usable amount of memory (in MB) -N sets the default, per-proxy maximum # of connections (2000) -L set local peer name (default to hostname) -p writes pids of all children to this file -de disables epoll() usage even when available -dp disables poll() usage even when available -dS disables splice usage (broken on old kernels) -dR disables SO_REUSEPORT usage -dr ignores server address resolution failures -dV disables SSL verify on servers side -sf/-st [pid ]* finishes/terminates old pids. 环境与配置在编译后的源码包目录下的 examples 目录下有一些可供参考的 init 脚本、配置文件、vim 配置等。我们来创建主配置文件 /etc/haproxyhaproxy.cfg。 12mkdir /etc/haproxy/vim /etc/haproxy/haproxy.cfg 沿用旧版本的配置模板 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#---------------------------------------------------------------------# Example configuration for a possible web application. See the# full configuration options online.## http://haproxy.1wt.eu/download/1.4/doc/configuration.txt##---------------------------------------------------------------------#---------------------------------------------------------------------# Global settings#---------------------------------------------------------------------global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the '-r' option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot /var/lib/haproxy # 这个目录需要手动创建 pidfile /var/run/haproxy.pid maxconn 4000 user nobody group nobody # 用户和组使用nobody，省去创建系统用户 daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats#---------------------------------------------------------------------# common defaults that all the 'listen' and 'backend' sections will# use if not designated in their block#---------------------------------------------------------------------defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000#---------------------------------------------------------------------# main frontend which proxys to the backends#---------------------------------------------------------------------frontend main *:5000 acl url_static path_beg -i /static /images /javascript /stylesheets acl url_static path_end -i .jpg .gif .png .css .js use_backend static if url_static default_backend app#---------------------------------------------------------------------# static backend for serving up images, stylesheets and such#---------------------------------------------------------------------backend static balance roundrobin server static 127.0.0.1:4331 check#---------------------------------------------------------------------# round robin balancing between the various backends#---------------------------------------------------------------------backend app balance roundrobin server app1 127.0.0.1:5001 check server app2 127.0.0.1:5002 check server app3 127.0.0.1:5003 check server app4 127.0.0.1:5004 check 服务控制CentOS 7 系统可以使用 systemd 的方式来管理服务，为了管理更灵活，我们选择使用控制脚本而不是 systemd，这里只是提供一个 systemd 范例。如果生产环境没有特殊要求则可以直接使用这种控制方式。 12345678910111213[root@m1 ~]# cat /usr/lib/systemd/system/haproxy.service [Unit]Description=HAProxy Load BalancerAfter=syslog.target network.target[Service]EnvironmentFile=/etc/sysconfig/haproxyExecStart=/usr/sbin/haproxy-systemd-wrapper -f /etc/haproxy/haproxy.cfg -p /run/haproxy.pid $OPTIONSExecReload=/bin/kill -USR2 $MAINPIDKillMode=mixed[Install]WantedBy=multi-user.target 因为生产环境需要，需要监听私网地址并使用 iptables 做相应的地址转换，因此使用 init 形式的服务控制脚本，这个脚本基于官方的服务脚本做了二次修改。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167#!/bin/bash## chkconfig: - 85 15# description: HA-Proxy is a TCP/HTTP reverse proxy which is particularly suited \# for high availability environments.# processname: haproxy# config: /etc/haproxy/haproxy.cfg# pidfile: /var/run/haproxy.pid# Script Author: Simon Matter &lt;simon.matter@invoca.ch&gt;# Version: 2004060600# Source function library.if [ -f /etc/init.d/functions ]; then . /etc/init.d/functionselif [ -f /etc/rc.d/init.d/functions ] ; then . /etc/rc.d/init.d/functionselse exit 0fi# Source networking configuration.. /etc/sysconfig/network# Check that networking is up.[ "$&#123;NETWORKING&#125;" = "no" ] &amp;&amp; exit 0# This is the path of our programEXEC='/usr/sbin/haproxy'if test -e $&#123;EXEC&#125;;then if test -s $&#123;EXEC&#125;;then if test ! -x $&#123;EXEC&#125;;then echo "$&#123;EXEC&#125; : Permission denied" exit 1 fi else echo "$&#123;EXEC&#125; : Can not run the empty binary file" exit 1 fielse echo "$&#123;EXEC&#125; : No such file or directory" exit 1fi# This is our service nameprog=$(basename $EXEC)# This is the path of configuration filecfgfile=/etc/haproxy/haproxy.cfg[ -f $&#123;cfgfile&#125; ] || &#123; echo "Cannot load $&#123;cfgfile&#125;: No such file or directory" exit 1&#125;pidfile=/var/run/$&#123;prog&#125;.pidlockfile=/var/lock/subsys/$&#123;prog&#125;RETVAL=0check() &#123; $&#123;EXEC&#125; -c -q -V -f $&#123;cfgfile&#125; $&#123;OPTIONS&#125;&#125;quiet_check() &#123; $&#123;EXEC&#125; -c -q -f $&#123;cfgfile&#125; $&#123;OPTIONS&#125; if [ $? -ne 0 ]; then echo "Errors found in configuration file, check it with '$&#123;prog&#125; check'." exit 1 fi&#125;start() &#123; quiet_check rh_status_q &amp;&amp; &#123; echo -n "Starting $&#123;prog&#125;: " echo_failure echo echo $"Cannot start $&#123;prog&#125;: $&#123;prog&#125; is already running . "; exit 0 &#125; echo -n "Starting $&#123;prog&#125;: " # start it up here, usually something like "daemon $exec" daemon $&#123;EXEC&#125; -D -f $&#123;cfgfile&#125; -p $&#123;pidfile&#125; RETVAL=$? echo [ $&#123;RETVAL&#125; -eq 0 ] &amp;&amp; touch $&#123;lockfile&#125; return $&#123;RETVAL&#125;&#125;stop() &#123; rh_status_q || &#123; echo -n "Stopping $&#123;prog&#125;: " echo_failure echo echo $"Cannot stop $&#123;prog&#125;: $&#123;prog&#125; is not running . "; return 0 &#125; echo -n "Stopping $&#123;prog&#125;: " # stop it here, often "killproc $prog" killproc $&#123;prog&#125; -USR1 RETVAL=$? echo [ $&#123;RETVAL&#125; -eq 0 ] &amp;&amp; &#123; rm -f $&#123;lockfile&#125; $&#123;pidfile&#125; &#125; return $&#123;RETVAL&#125;&#125;restart() &#123; quiet_check stop start&#125;reload() &#123; quiet_check test -s $&#123;pidfile&#125; || &#123; echo -n "Reloading $&#123;prog&#125;: " echo_failure echo echo $"Cannot reload $&#123;prog&#125;: $&#123;prog&#125; is not running . "; return 1 &#125; echo -n "Reloading $&#123;prog&#125;: " $&#123;EXEC&#125; -D -f $&#123;cfgfile&#125; -p $&#123;pidfile&#125; -sf $(cat $&#123;pidfile&#125;) RETVAL=$? [ $&#123;RETVAL&#125; -eq 0 ] &amp;&amp; echo_success || echo_failure echo return $&#123;RETVAL&#125;&#125;rh_status() &#123; status $&#123;prog&#125;&#125;rh_status_q() &#123; rh_status &gt;/dev/null 2&gt;&amp;1&#125;condrestart() &#123; [ -e $&#123;lockfile&#125; ] &amp;&amp; restart || :&#125;# See how we were called.case "$1" in start|stop|restart|reload|check|condrestart) $1 ;; status) rh_status ;; *) echo echo -e $"\tUsage: $&#123;prog&#125; &#123; check | start | stop | restart | reload | condrestart | status &#125;" echo exit 1 ;;esac exit $?]]></content>
      <tags>
        <tag>Load Balance</tag>
        <tag>Haproxy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cobbler无人值守安装CentOS]]></title>
    <url>%2F2018%2F01%2F23%2F205210-Cobbler%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85CentOS%2F</url>
    <content type="text"><![CDATA[简介Cobbler 是一个 Linux 服务器快速网络安装的服务，而且在经过调整也可以支持网络安装 windows。该工具使用 Python 开发，小巧轻便（才15k行 Python 代码），可以通过网络启动（PXE ）的方式来快速安装、重装物理服务器和虚拟机，同时还可以管理 DHCP，DNS，TFTP、RSYNC 以及 yum 仓库、构造系统 ISO 镜像。 Cobbler 是较早前的 Kickstart 的升级版，优点是比较容易配置。它可以使用命令行方式管理，也提供了基于 Web 的界面管理工具(cobbler-web)，还提供了 API 接口，可以方便二次开发使用。 Cobbler 内置了一个轻量级配置管理系统，但它也支持和其它配置管理系统集成，如 Puppet，暂时不支持 SaltStack。Cobbler 客户端 Koan 支持虚拟机安装和操作系统重新安装，使重装系统更便捷。 核心组件 Distros distro(发行版)，这里指的是操作系统的发行版 每一个要装的发行版操作系统都应该被单独定义成一个distro 常见的 distro 如 CentOS 6.8 ，CentOS 6.9，CentOS 7.4等发行版 Profiles and Sub-Profiles 基于 distro (可以是一个也可以是多个)，借助不同的 Kickstart 文件配置出不同的业务环境来，这每一个环境就是一个 profile 一个 distro 和一个与之相关联的配置文件( Kickstart )并结合其他的环境配置构成了一个 profile，Kickstart 是这其中的关键点 一个 profile 是构建在 distro 之上的，能适用于多种服务器角色部署的一个逻辑组件 sub-profile 是子 profile ，只有在构建极为复杂的环境时才有可能会用到 sub-profile Systems 在 profile 的基础之上，为特定主机指派上特定的、独有的一些系统级别的配置信息，从而实现定义至操作系统级别 Repos repository，仓库。Kickstart 需要借助 yum 的 repository 才能安装完成操作系统。 Repos 主要用于定义 repository Images 用于实现在虚拟化环境当中，用来管理虚拟机的磁盘映像文件 Management Classes File Resources Package Resources 集成的服务 PXE 服务支持 DHCP 服务管理 DNS 服务管理(可选bind,dnsmasq) 电源管理 Kickstart 服务支持 YUM 仓库管理 TFTP(PXE启动时需要) Apache(提供 Kickstart 的安装源，并提供定制化的 Kickstart 配置) 基本工作流程服务器端 123456789第一步，启动Cobbler服务第二步，进行Cobbler错误检查，执行cobbler check命令第三步，进行配置同步，执行cobbler sync命令第四步，复制相关启动文件文件到TFTP目录中第五步，启动DHCP服务，提供地址分配第六步，DHCP服务分配IP地址第七步，TFTP传输启动文件第八步，Server端接收安装信息第九步，Server端发送ISO镜像与Kickstart文件 客户端 123456789第一步，客户端以PXE模式启动第二步，客户端获取IP地址第三步，通过TFTP服务器获取启动文件第四步，进入Cobbler安装选择界面第五步，客户端确定加载信息第六步，根据配置信息准备安装系统第七步，加载Kickstart文件第八步，传输系统安装的其它文件第九步，进行安装系统 安装和配置官方手册 环境说明 虚拟机版本：VMware® Workstation 14 Pro Cobbler 服务器上需要搭建 DHCP 服务器为新安装的操作系统分配 IP 地址，但在同一局域网多个 DHCP 服务会有冲突，因此虚拟机采用 NAT 模式 避免出现依赖关系上的错误，使用全新的操作系统，这里使用的是 CentOS 7.4.1708 Cobbler 的 IP 地址为 192.168.127.10 cobbler 的安装需要依赖 epel 源，使用 yum 查看 Cobbler 的信息，可以看到 Repo 字段对应的源是 epel 12curl -o /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repoyum info cobbler 设置语言环境、禁用 SELINUX 、停用防火墙等配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# install vimyum -y install vim-enhanced# Set languagelangfile='/etc/locale.conf'export LANG="en_US.UTF-8";sed -ri '/LANG/s/=.*/="en_US.UTF-8"/' $&#123;langfile&#125;# Turn off selinuxsetenforce 0fileList=(/etc/sysconfig/selinux /etc/selinux/config)for f in $&#123;fileList[@]&#125;;do sed -ri 's/(^SELINUX=).*/\1disabled/' $&#123;f&#125;done# Disable the DNS function of sshdegrep -q '^UseDNS no' /etc/ssh/sshd_config || \sed -ri '/#UseDNS /aUseDNS no' /etc/ssh/sshd_config# Turn off some services/usr/bin/systemctl stop firewalld.service;/usr/bin/systemctl disable firewalld.service;/usr/bin/systemctl is-enabled firewalld.service;# Add firewall policyIPT='/sbin/iptables'# ---------------------------------------for chain in INPUT OUTPUT FORWARD;do $&#123;IPT&#125; -t filter -P $&#123;chain&#125; ACCEPT &amp;&gt;/dev/nulldoneunset chain# ---------------------------------------for chain in PREROUTING POSTROUTING OUTPUT;do $&#123;IPT&#125; -t nat -P $&#123;chain&#125; ACCEPT &amp;&gt;/dev/nulldoneunset chain# ---------------------------------------for chain in PREROUTING INPUT FORWARD OUTPUT POSTROUTING;do $&#123;IPT&#125; -t mangle -P $&#123;chain&#125; ACCEPT &amp;&gt;/dev/nulldoneunset chain# ---------------------------------------for table in filter nat mangle;do $&#123;IPT&#125; -F -t $&#123;table&#125; &amp;&gt;/dev/null $&#123;IPT&#125; -X -t $&#123;table&#125; &amp;&gt;/dev/nulldone 添加了 epel 源后直接 yum 安装 1234567yum -y install cobbler cobbler-web pykickstart httpd dhcp tftp-server# cobbler # cobbler程序包# cobbler-web # cobbler的web端程序包# pykickstart # 用于cobbler检查kickstart语法错误# httpd # Apache的web服务# dhcp # dhcp服务程序包，也可以使用dnsmasq配置成DHCP服务器# tftp-server # tftp服务 查看包中生成了哪些文件 123456789101112131415161718192021222324[root@cobbler ~]# rpm -ql cobbler # 查看安装的文件，下面列出部分。/etc/cobbler # 配置文件目录/etc/cobbler/settings # cobbler主配置文件，yaml格式，cobbler是python写的程序。/etc/cobbler/dhcp.template # dhcp服务的配置模板/etc/cobbler/tftpd.template # tftp服务的配置模板/etc/cobbler/rsync.template # rsync服务的配置模板/etc/cobbler/iso # iso模板配置文件目录/etc/cobbler/pxe # pxe模板文件目录/etc/cobbler/power # 电源的配置文件目录/etc/cobbler/users.conf # web服务授权配置文件/etc/cobbler/users.digest # web访问的用户名密码配置文件/etc/cobbler/dnsmasq.template # DNS服务的配置模板/etc/cobbler/modules.conf # cobbler模块配置文件/var/lib/cobbler # cobbler数据目录/var/lib/cobbler/config # 配置文件/var/lib/cobbler/kickstarts # 默认存放kickstart文件/var/lib/cobbler/loaders # 存放的各种引导程序/var/www/cobbler # 系统安装镜像目录/var/www/cobbler/ks_mirror # 导入的系统镜像列表/var/www/cobbler/images # 导入的系统镜像启动文件/var/www/cobbler/repo_mirror # yum源存储目录/var/log/cobbler # 日志目录/var/log/cobbler/install.log # 客户端系统安装日志/var/log/cobbler/cobbler.log # cobbler日志 依赖关系说明 Cobbler的运行依赖于dhcp、tftp、rsync 及 dns 服务 dhcp 可由 dhcpd（isc）提供，也可由 dnsmasq 提供； tftp 可由 tftp-server 程序包提供，也可由 cobbler 功能提供； rsync 由 rsync 程序包提供，dns 可由 bind 提供，也可由 dnsmasq 提供； Cobbler 可自行管理这些服务中的部分甚至是全部，但需要配置文件 /etc/cobbler/settings 中的manange_dhcp、manager_tftpd、manager_rsync、manager_dns 分别来进行定义 由于各种服务都有着不同的实现方式，如若需要进行自定义，需要通过修改/etc/cobbler/modules.conf配置文件中各服务的模块参数的值来实现。 将 httpd 加入开机启动服务列表并立即启动服务 123systemctl enable httpd --nowsystemctl is-enabled httpdsystemctl status httpd 修改 cobbler 的 dhcp 模版文件 /etc/cobbler/dhcp.template，此模板会覆盖 dhcp 本身的配置文件，所以在此之前 确保没有启动dhcp服务也没有修改dhcp的配置文件 123456789101112131415161718192021222324subnet 192.168.127.0 netmask 255.255.255.0 &#123; option routers 192.168.127.2; option domain-name-servers 192.168.127.2; option subnet-mask 255.255.255.0; range dynamic-bootp 192.168.127.130 192.168.127.230; default-lease-time 21600; max-lease-time 43200; next-server $next_server; class "pxeclients" &#123; match if substring (option vendor-class-identifier, 0, 9) = "PXEClient"; if option pxe-system-type = 00:02 &#123; filename "ia64/elilo.efi"; &#125; else if option pxe-system-type = 00:06 &#123; filename "grub/grub-x86.efi"; &#125; else if option pxe-system-type = 00:07 &#123; filename "grub/grub-x86_64.efi"; &#125; else if option pxe-system-type = 00:09 &#123; filename "grub/grub-x86_64.efi"; &#125; else &#123; filename "pxelinux.0"; &#125; &#125;&#125; 如果是多网卡环境还需要指定 dhcp 使用的网卡，修改 /usr/lib/systemd/system/dhcpd.service 文件中 ExecStart 最后面加上网卡名称，然后重载 systemctl，将 dhcpd 加入开机启动服务列表并立即启动服务 1234systemctl daemon-reloadsystemctl enable dhcpd --nowsystemctl is-enabled dhcpdsystemctl status dhcpd 将 cobblerd 加入开机启动服务列表并立即启动服务 123systemctl enable cobblerd --nowsystemctl is-enabled cobblerdsystemctl status cobblerd 配置检查使用 Cobbler 的检查工具检查配置存在的问题并依次解决 12345678910111213[root@Cobbler ~]# cobbler checkThe following are potential configuration items that you may want to fix:1 : The 'server' field in /etc/cobbler/settings must be set to something other than localhost, or kickstarting features will not work. This should be a resolvable hostname or IP for the boot server as reachable by all machines that will use it.2 : For PXE to be functional, the 'next_server' field in /etc/cobbler/settings must be set to something other than 127.0.0.1, and should match the IP of the boot server on the PXE network.3 : change 'disable' to 'no' in /etc/xinetd.d/tftp4 : Some network boot-loaders are missing from /var/lib/cobbler/loaders, you may run 'cobbler get-loaders' to download them, or, if you only want to handle x86/x86_64 netbooting, you may ensure that you have installed a *recent* version of the syslinux package installed and can ignore this message entirely. Files in this directory, should you want to support all architectures, should include pxelinux.0, menu.c32, elilo.efi, and yaboot. The 'cobbler get-loaders' command is the easiest way to resolve these requirements.5 : enable and start rsyncd.service with systemctl6 : debmirror package is not installed, it will be required to manage debian deployments and repositories7 : The default password used by the sample templates for newly installed machines (default_password_crypted in /etc/cobbler/settings) is still set to 'cobbler' and should be changed, try: "openssl passwd -1 -salt 'random-phrase-here' 'your-password-here'" to generate new one8 : fencing tools were not found, and are required to use the (optional) power management features. install cman or fence-agents to use themRestart cobblerd and then run 'cobbler sync' to apply changes. 修改 /etc/cobbler/settings 文件中的 server 参数的值为提供 cobbler 服务的主机相应的 IP 地址或主机名，如server: 192.168.127.10 12cp /etc/cobbler/settings&#123;,.bak&#125;sed -ri 's#^server: 127.0.0.1#server: 192.168.127.10#' /etc/cobbler/settings 修改 /etc/cobbler/settings 文件中的 next_server 参数的值为提供 PXE 服务的主机相应的IP地址，如next_server: 192.168.127.10。server，pxe服务器的IP由于这里使用的是同一台机器，所以填 Cobbler 服务器的 IP 即可 1sed -ri 's#^next_server: 127.0.0.1#next_server: 192.168.127.10#' /etc/cobbler/settings 修改 /etc/xinetd.d/tftp 文件中的 disable 参数修改为 disable = no 1234567891011cp /etc/xinetd.d/tftp&#123;,.bak&#125;sed -ri '/disable(\t| )*=/s#yes#no#g' /etc/xinetd.d/tftpsystemctl enable tftp.socket --nowsystemctl status tftp.socketchmod +x /etc/rc.d/rc.local echo 'systemctl enable tftp.socket --now' &gt;&gt; /etc/rc.d/rc.localsystemctl enable tftp.service --nowsystemctl status tftp.service 根据提示执行 cobbler get-lders 命令，最后提示 *** TASK COMPLETE *** 表示成功 将 rsyncd 加入开机启动服务列表并立即启动服务 123systemctl enable rsyncd.service --nowsystemctl is-enabled rsyncd.servicesystemctl status rsyncd.service 使用 yum 安装 debmirror 12yum -y install debmirrorsed -ri '/^(@dists=|@arches).*/s/^/#/g' /etc/debmirror.conf 生成自定义密码密码来取代默认的密码，为了更安全，建议使用复杂度较高的密码 123openssl passwd -1 -salt litingjie 123456$1$litingji$qUWL9htxlLybWLhSuyL8g/sed -ri 's#^(default_password_crypted:).*#\1 "$1$litingji$qUWL9htxlLybWLhSuyL8g/"#' /etc/cobbler/settings 使用 yum 安装 cman fence-agents 1yum -y install cman fence-agents 配置使用用 cobbler 管理DHCP 1sed -ri 's#^(manage_dhcp:).*#\1 1#g' /etc/cobbler/settings 为防止循环装系统，适用于服务器第一启动项是PXE启动 1sed -ri '/^pxe_just_once:.*/s#0#1#g' /etc/cobbler/settings 重启 cobblerd 服务，再次检查 123systemctl restart cobblerd.service[root@Cobbler ~]# cobbler checkNo configuration problems found. All systems go. 同步 cobbler 的配置，可以看到同步做了哪些操作 1cobbler sync 获取 Usage 1234cobblercobbler --helpcobbler distro --helpcobbler profile --help 选项说明 12345678cobbler check 核对当前设置是否有问题cobbler list 列出所有的cobbler元素cobbler report 列出元素的详细信息cobbler sync 同步配置到数据目录,更改配置最好都要执行下cobbler reposync 同步yum仓库cobbler distro 查看导入的发行版系统信息cobbler system 查看添加的系统信息cobbler profile 查看配置信息 安装CentOS6.9Cobbler基本配置做好之后便可以创建多个 distro (发行版)来安装不同版本系统了 挂载 CentOS 6.9 镜像 12mount -r /dev/cdrom /mnt/ls /mnt/ 创建ks(ksckstart)文件 12cp /var/lib/cobbler/kickstarts/sample_end.ks /var/lib/cobbler/kickstarts/CentOS-6.9.cfgvim /var/lib/cobbler/kickstarts/CentOS-6.9.cfg 配置后的文件内容 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# This kickstart file should only be used with EL &gt; 5 and/or Fedora &gt; 7.# For older versions please use the sample.ks kickstart file.#platform=x86, AMD64, or Intel EM64T# System authorization information#auth --useshadow --enablemd5authconfig --enableshadow --passalgo=sha512# System bootloader configurationbootloader --location=mbr --driveorder=sda --append="nomodeset crashkernel=auto rhgb quiet"# Partition clearing informationclearpart --all --initlabel# Use text mode installtext# Firewall configurationfirewall --enabled# Run the Setup Agent on first bootfirstboot --disable# System keyboardkeyboard us# System languagelang en_US.UTF-8# Use network installationurl --url=$tree# If any cobbler repo definitions were referenced in the kickstart profile, include them here.$yum_repo_stanza# Network information$SNIPPET('network_config')# Reboot after installationreboot# Installation logging levellogging --level=info#Root passwordrootpw --iscrypted $default_password_crypted# System servicesservices --disabled="NetworkManager"services --disabled="postfix"# SELinux configurationselinux --disabled# Do not configure the X Window Systemskipx# System timezonetimezone Asia/Shanghai# Install OS instead of upgradeinstall# Clear the Master Boot Recordzerombr# Allow anaconda to partition the system as neededautopart%pre$SNIPPET('log_ks_pre')$SNIPPET('kickstart_start')$SNIPPET('pre_install_network_config')# Enable installation monitoring$SNIPPET('pre_anamon')%end%packages@base@compat-libraries@developmentvim-enhancedbind-utils%end%post --nochroot$SNIPPET('log_ks_post_nochroot')%end%post$SNIPPET('log_ks_post')# Start yum configuration$yum_config_stanza# End yum configuration$SNIPPET('post_install_kernel_options')$SNIPPET('post_install_network_config')$SNIPPET('func_register_if_enabled')$SNIPPET('download_config_files')$SNIPPET('koan_environment')$SNIPPET('redhat_register')$SNIPPET('cobbler_register')# Enable post-install boot notification$SNIPPET('post_anamon')# Start final steps$SNIPPET('kickstart_done')# End final steps%end 将镜像中的文件导入Cobbler，创建 distro 1234567891011121314cobbler import --helpcobbler import --path=/mnt/ --name="CentOS-6.9_x86_64" --arch=x86_64 --kickstart=/var/lib/cobbler/kickstarts/CentOS-6.9.cfg # --path 镜像路径 # --name 为安装源定义一个名字 # --arch 指定安装源是32位、64位、ia64, 目前支持的选项有: x86│x86_64│ia64 # 安装源的唯一标示就是根据name参数来定义，本例导入成功后，安装源的唯一标示就是：CentOS-6.9_x86_64，如果重复，系统会提示导入失败。# 导入完成后的文件存放在/var/www/cobbler/ks_mirror/下以name命名的目录下ls /var/www/cobbler/ks_mirror/# 查看元素，同步数据cobbler listcobbler sync# 同步完成后会生成 /var/lib/tftpboot/pxelinux.cfg/default 信息查看 12cobbler distro report --name=CentOS-6.9-x86_64cobbler profile report --name=CentOS-6.9-x86_64 如果不想要这个 distro 了，则按照下面的方法删除 12cobbler profile remove --name=CentOS-6.9-x86_64cobbler distro remove --name=CentOS-6.9-x86_64 客户机引导时出现选择页面，local 和CentOS-6.9-x86_64，干扰自动部署。此时需要编辑 /var/lib/tftpboot/pxelinux.cfg/default，修改 TIMEOUT 为 100，即等待时间为 10 秒，修改 ONTIMEOUT 为对应的 Label CentOS-6.9-x86_64 ，即超过了等待时间后默认安装哪个系统。重启服务 systemctl restart cobblerd，需要注意的是，如果此时执行了 cobbler sync 就会重新生成 defatul 文件，之前的配置将被覆盖。 安装CentOS7.4挂载 CentOS 7.4 镜像 123umount /dev/cdrommount -r /dev/cdrom /mnt/ls /mnt/ 创建ks(ksckstart)文件 12cp /var/lib/cobbler/kickstarts/sample_end.ks /var/lib/cobbler/kickstarts/CentOS-7.4.cfgvim /var/lib/cobbler/kickstarts/CentOS-7.4.cfg 配置后的文件内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107# This kickstart file should only be used with EL &gt; 5 and/or Fedora &gt; 7.# For older versions please use the sample.ks kickstart file.#platform=x86, AMD64, or Intel EM64T# System authorization information#auth --useshadow --enablemd5authconfig --enableshadow --passalgo=sha512# System bootloader configurationbootloader --location=mbr# Partition clearing informationclearpart --all --initlabel# Use text mode installtext# Firewall configurationfirewall --disabled# Run the Setup Agent on first bootfirstboot --disable# System keyboardkeyboard us# System languagelang en_US.UTF-8# Use network installationurl --url=$tree# If any cobbler repo definitions were referenced in the kickstart profile, include them here.$yum_repo_stanza# Network information$SNIPPET('network_config')# Reboot after installationreboot# Installation logging levellogging --level=info#Root passwordrootpw --iscrypted $default_password_crypted# System servicesservices --disabled="NetworkManager"services --disabled="postfix"services --disabled="firewalld"# SELinux configurationselinux --disabled# Do not configure the X Window Systemskipx# System timezonetimezone Asia/Shanghai# Install OS instead of upgradeinstall# Clear the Master Boot Recordzerombr# Allow anaconda to partition the system as needed#autopartpart /boot --fstype="xfs" --asprimary --size=200part swap --fstype="swap" --asprimary --size=2000part / --fstype="xfs" --asprimary --size=1 --grow%pre$SNIPPET('log_ks_pre')$SNIPPET('kickstart_start')$SNIPPET('pre_install_network_config')# Enable installation monitoring$SNIPPET('pre_anamon')%end%packages@^minimal@compat-libraries@core@developmentbash-completionkexec-toolstreewgetopenssh-clientsglibcgmpbzip2bind-utilsnet-toolsmtr lrzsznmaptcpdumpdos2unixvim-enhanced%end%post --nochroot$SNIPPET('log_ks_post_nochroot')%end%post$SNIPPET('log_ks_post')# Start yum configuration$yum_config_stanza# End yum configuration$SNIPPET('post_install_kernel_options')$SNIPPET('post_install_network_config')$SNIPPET('func_register_if_enabled')$SNIPPET('download_config_files')$SNIPPET('koan_environment')$SNIPPET('redhat_register')$SNIPPET('cobbler_register')# Enable post-install boot notification$SNIPPET('post_anamon')# Start final steps$SNIPPET('kickstart_done')# End final steps%end 将镜像中的文件导入Cobbler，创建 distro 123456789101112131415cobbler import --helpcobbler import --path=/mnt/ --name="CentOS-7.4-x86_64" --arch=x86_64 --kickstart=/var/lib/cobbler/kickstarts/CentOS-7.4.cfg # --path 镜像路径# --name 为安装源定义一个名字# --arch 指定安装源是32位、64位、ia64, 目前支持的选项有: x86│x86_64│ia64# 安装源的唯一标示就是根据name参数来定义，本例导入成功后，安装源的唯一标示就是：CentOS_7.4.1708_x86_64，如果重复，系统会提示导入失败。# 导入完成后的文件存放在/var/www/cobbler/ks_mirror/下以name命名的目录下ls /var/www/cobbler/ks_mirror/# 查看元素，同步数据cobbler listcobbler sync# 同步完成后会生成 /var/lib/tftpboot/pxelinux.cfg/default 修改安装系统的内核参数：在 CentOS7 系统有一个地方变了，就是网卡名变成 eno***** 这种形式，为了运维标准化，我们需要将它变成我们常用的 eth0 123cobbler profile edit --name=CentOS-7.4-x86_64 --kopts='net.ifnames=0 biosdevname=0'cobbler profile report --name=CentOS-7.4-x86_64# 可以看到Kickstart那里的配置cfg文件地址被改变了 信息查看 12cobbler distro report --name=CentOS-7.4-x86_64cobbler profile report --name=CentOS-7.4-x86_64 客户机引导时出现选择页面，local 和 CentOS-6.9-x86_64 和 CentOS-7.4-x86_64，干扰自动部署。此时需要编辑 /var/lib/tftpboot/pxelinux.cfg/default，修改 TIMEOUT 为 100，即等待时间为 10 秒，修改 ONTIMEOUT 为对应的 Label CentOS-7.4-x86_64 ，即超过了等待时间后默认安装哪个系统。重启服务 systemctl restart cobblerd，需要注意的是，如果此时执行了 cobbler sync 就会重新生成 defatul 文件，之前的配置将被覆盖。 开机画面显示的修改，需要编辑 /etc/cobbler/pxe/pxedefault.template 123MENU TITLE Cobbler | http://cobbler.github.io/# 改为自定义title，如下MENU TITLE Cobbler | Cobbler Install 使用web安装CentOS6.8在进行 web 端使用时，我们保持默认直接访问 web 页面即可，账号密码默认均为 cobbler，而且 CentOS7 中 cobbler 只支持 https 访问，浏览器访问 https://192.168.127.10/cobbler_web/ 挂载CentOS6.8镜像 12mount -r /dev/cdrom /mnt/ls /mnt/ 导入镜像 导入过程使用rsync进行导入，三个进程消失表示导入完毕 12345[root@Cobbler ~]# pgrep -af rsync504 /usr/bin/rsync --daemon --no-detach1177 rsync -a /mnt/ /var/www/cobbler/ks_mirror/CentOS-6.8-x86_64 --progress1178 rsync -a /mnt/ /var/www/cobbler/ks_mirror/CentOS-6.8-x86_64 --progress1179 rsync -a /mnt/ /var/www/cobbler/ks_mirror/CentOS-6.8-x86_64 --progress web 界面也可以看到相关的日志，running 代表正在运行，complete 代表已完成 创建ks文件 编写文件，参照本站的 6.9 系统 ks 文件，编写好后点击 Save 即可保存 为 Profile 选择对应的 ks 文件：依次点击 Profiles =&gt; profile名字 =&gt; Kickstart 选择对应的 ks 文件 其他选项：如果是要安装 CentOS7 及以上的系统，不想使用原有的网卡名称而是想统一成 eth* 格式，需要修改内核参数 方式一：命令行修改 1cobbler profile edit --name=CentOS-7.5-x86_64 --kopts='net.ifnames=0 biosdevname=0' 方式二：web页面修改 依次点击 Profiles =&gt; profile名字 =&gt; Kernel Options =&gt; 填写 biosdevname=0 net.ifnames=0 =&gt; Save 查看导入完成的文件并新开机器安装系统进行验证 1cat /var/lib/tftpboot/pxelinux.cfg/default web端的用户认证方式cobbler_web 支持多种认证方式，如 authn_configfile、authn_ldap 或 authn_pam 等，查看 /etc/cobbler/modules.conf 中 [authentication] 段的 module 参数及其注释说明，可以知道值默认为authn_denyall，即拒绝所有用户登录。如果需要自定义认证功能，请根据下面两种能认证用户登录 cobbler_web 的方式。 使用authn_pam模块认证cobbler_web用户 首先修改 /etc/cobbler/modules.conf 中 [authentication] 段的 module 参数的值为 authn_pam，接着添加系统用户，用户名和密码按需设定即可 12useradd cblradminecho 'cblrpass' | passwd --stdin cblradmin 而后将 cblradmin 用户添加至 cobbler_web 的 admin 组中。修改 /etc/cobbler/users.conf 文件，将 cblradmin 用户名添加为 admin 参数的值即可 12[admins]admin = "cblradmin" 最后重启cobblerd服务，通过 http://YOUR_COBBLERD_IP/cobbler_web 访问即可 使用authn_configfile模块认证cobbler_web用户 首先修改 /etc/cobbler/modules.conf 中 [authentication] 段的 module 参数的值为 authn_configfile 接着创建其认证文件 /etc/cobbler/users.digest，并添加所需的用户即可。需要注意的是，添加第一个用户时，需要为 htdigest 命令使用 -c 选项，后续添加其他用户时不能再使用 -c；另外，cobbler_web 的 realm 只能为 Cobbler。如下所示。 1htdigest -c /etc/cobbler/users.digest Cobbler cblradmin 最后重启 cobblerd 服务，通过 http://YOUR_COBBLERD_IP/cobbler_web 访问即可 常见错误tftp 启动异常 123[root@Cobbler ~]# netstat -tunlp | grep 69[root@Cobbler ~]# systemctl start tftpA dependency job for tftp.service failed. See 'journalctl -xe' for details. 这是因为 tftp socket 的问题，启动 tftp socke 并将其加入开机启动列表，当有需要的时候 systemd 会自动启动 tftp 服务 1234567[root@Cobbler ~]# systemctl enable tftp.socket --now[root@Cobbler ~]# systemctl status tftp.socket [root@Cobbler ~]# systemctl start tftp.service[root@Cobbler ~]# netstat -tunlp | grep 69 udp 0 0 0.0.0.0:69 0.0.0.0:* 1/systemd [root@Cobbler ~]# chmod +x /etc/rc.d/rc.local [root@Cobbler ~]# echo &apos;systemctl enable tftp.socket --now&apos; &gt;&gt; /etc/rc.d/rc.local 参考链接：https://docs.fedoraproject.org/en-US/Fedora/23/html/Installation_Guide/pxe-tftpd.html No space left on device 12umount: /run/initramfs/squashfs: not mounted/sbin/dmsquash-live-root: line 273: printf: write error: No space left on device 出现这个错误的原因是内存不足2G，将内存调为2G或以上即可]]></content>
      <tags>
        <tag>Cobbler</tag>
        <tag>Kickstart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kickstart无人值守安装CentOS6.8]]></title>
    <url>%2F2018%2F01%2F22%2F162310-Kickstart%E6%97%A0%E4%BA%BA%E5%80%BC%E5%AE%88%E5%AE%89%E8%A3%85CentOS6.8%2F</url>
    <content type="text"><![CDATA[要想同时上线几十甚至上百台服务器，在短时间内完成系统安装，如果通过光驱、U盘的方式逐台安装，不仅效率低，也不利于维护。 Kickstart是一种无人值守的安装方式。它的工作原理是在安装过程中记录人工干预填写的各种参数，并生成一个名为 ks.cfg 的文件。如果在自动安装过程中出现要填写参数的情况，安装程序首先会去查找 ks.cfg 文件，如果找到合适的参数，就采用所找到的参数；如果没有找到合适的参数，便会弹出对话框让安装者手工填写。所以，如果 ks.cfg 文件涵盖了安装过程中所有需要填写的参数，那么安装者完全可以只告诉安装程序从何处下载 ks.cfg 文件，然后就去忙自己的事情。等安装完毕，安装程序会根据 ks.cfg 中的设置重启/关闭系统，并结束安装。 Cobbler 集中和简化了通过网络安装操作系统需要使用到的 DHCP、TFTP 和 DNS 服务的配置，它不仅有一个命令行界面，还提供了一个 Web 界面，大大降低了使用者的入门水平。 简单地说，Cobbler 是对 Kickstart 的封装，简化安装步骤、使用流程，降低使用者的门槛 PXE什么是PXE？ PXE(Pre-boot Execution Environment，预启动执行环境)是由Intel公司开发的最新技术，工作于Client/Server的网络模式，支持工作站通过网络从远端服务器下载映像，并由此支持通过网络启动操作系统。 通过网络接口启动计算机，不依赖本地存储设备（如硬盘）或本地已安装的操作系统 在启动过程中，PXE客户端会调用网际协议(IP)、用户数据报协议(UDP)、动态主机设定协议(DHCP)、小型文件传输协议(TFTP)等网络协议。 终端要求服务器分配IP地址，再用TFTP（trivial file transfer protocol）或MTFTP(multicast trivial file transfer protocol)协议下载一个启动软件包到本机内存中执行，由这个启动软件包完成终端基本软件设置，从而引导预先安装在服务器中的终端操作系统。 严格来说，PXE 并不是一种安装方式，而是一种引导方式。进行 PXE 安装的必要条件是在要安装的计算机中必须包含一个 PXE 支持的网卡（NIC），即网卡中必须要有 PXE Client。PXE 协议可以使计算机通过网络启动。此协议分为 Client端 和 Server 端，而PXE Client则在网卡的 ROM 中。当计算机引导时，BIOS 把 PXE Client 调入内存中执行，然后由 PXE Client 将放置在远端的文件通过网络下载到本地运行。运行 PXE 协议需要设置 DHCP 服务器和 TFTP 服务器。DHCP 服务器会给 PXE Client（将要安装系统的主机）分配一个 IP 地址，由于是给 PXE Client 分配 IP 地址，所以在配置 DHCP 服务器时需要增加相应的 PXE 设置。此外，在 PXE Client 的 ROM 中，已经存在了 TFTP Client，那么它就可以通过 TFTP 协议到 TFTP Server 上下载所需的文件了。 PXE技术与RPL技术不同之处为RPL是静态路由，PXE是动态路由。RPL是根据网卡上的ID号加上其他记录组成的一个Frame（帧）向服务器发出请求。而服务器中已有这个ID数据，匹配成功则进行远程启动。PXE则是根据服务器端收到的工件站MAC地址，使用DHCP服务为这个MAC地址指定个IP地址。每次启动可能同一台工作站有与上次启动有不同的IP，即动态分配地址。 PXE工作过程 1、PXE Client向DHCP发送请求 PXE Client开机后，PXE BootROM（自启动芯片）获得控制权之前执行自我测试，然后以UDP发送一个广播请求（FIND帧） ，向本网络中的DHCP服务器索取IP； 2、DHCP服务器提供信息 DHCP 收到客户端的请求，送回DHCP响应应，包括用户端的IP地址、预设通信通道、PXE文件的放置位置(一般放在一台TFTP服务器上) 以及开机映像文件； 3、 PXE客户端请求下载启动文件 客户端收到服务器发回的响应后则会回应一个帧，以请求传送启动所需文件，并把自己的MAC地址写到服务器端的Netnames.db文件中。 启动所需文件包含：pxelinux.0、pxelinux.cfg / default、vmlinuz、initrd.img等文件。 4、Boot Server响应客户端请求并传送文件 当服务器收到客户端的请求后，他们之间之后将有更多的信息在客户端与服务器之间作应答, 用以决定启动参数。 BootROM基于TFTP通讯协议从Boot Server下载启动安装程序所必须的文件(pxelinux.0、pxelinux.cfg / default)。default文件下载完成后，会根据该文件中定义的引导顺序，启动Linux安装程序的引导内核。 5、请求下载自动应答文件 客户端通过pxelinux.cfg / default文件成功的引导Linux安装内核后，安装程序首先必须确定你通过什么安装介质来安装linux，如果是通过网络安装(NFS, FTP, HTTP)，则会在这个时候初始化网络，并定位安装源位置。接着会读取default文件中指定的自动应答文件ks.cfg所在位置，根据该位置请求下载该文件。 注意： 在第2步和第5步初始化2次网络，这是由于PXE获取的是安装用的内核以及安装程序等，而安装程序要获取的是安装系统所需的二进制包以及配置文件。因此PXE模块和安装程序是相对独立的，PXE的网络配置并不能传递给安装程序，从而进行两次获取IP地址过程，但IP地址在DHCP的租期内是一样的。 6、客户端安装操作系统 将ks.cfg文件下载回来后，通过该文件找到OS Server，并按照该文件的配置请求下载安装过程需要的软件包。OS Server和客户端建立连接后，将开始传输软件包，客户端将开始安装操作系统。安装完成后，将提示重新引导计算机。 PXE + Kickstart 配置并安装系统流程图 系统服务器 OS Server 可以使用 http、nfs、ftp 服务器，此处使用 http 作为系统文件下载服务器 系统环境 虚拟机：VMware® Workstation 12 Pro系统：CentOS release 6.8 12service iptables stopsetenforce permissive 网络环境 虚拟机NAT8模式的地址段 192.168.247.0 255.255.255.0，可以在虚拟网络编辑器自定义设定 Windows的物理机将自己可以上网的网卡在属性中共享给 VMware Network Adapter VMnet8，确保虚拟机可以联网，以便网络yum源安装软件 DHCP、TFTP、HTTP均安装在一台服务器，IP地址为 192.168.247.6，网络模式为NAT8 注意： 虚拟机网卡采用NAT模式，不要使用桥接模式，因为后续会搭建DHCP服务器，在同一局域网多个DHCP服务会有冲突。 VMware的NAT模式的dhcp服务也关闭，避免干扰。 “编辑” - “虚拟网络编辑器” - “使用本地DHCP服务将IP地址分配给虚拟机”，将其关闭 基本设置完成后，Windows物理机中VMware Network Adapter VMnet8的网卡上的IP为192.168.247.1，netmask为255.255.255.0，此网卡作为本子网的网关 DHCP配置1234567891011121314151617181920212223242526272829yum -y install dhcp# 安装DHCP\cp -arf /usr/share/doc/dhcp-4.1.1/dhcpd.conf.sample /etc/dhcp/dhcpd.conf cp /etc/dhcp/dhcpd.conf&#123;,.bak&#125;;cat &gt;| /etc/dhcp/dhcpd.conf &lt;&lt; 'EOF'ddns-update-style interim;ignore client-updates;allow booting; # 定义能够PXE启动allow bootp; # 定义支持bootpsubnet 192.168.247.0 netmask 255.255.255.0 &#123; range 192.168.247.100 192.168.247.200; # 可分配的起始IP-结束IP option subnet-mask 255.255.255.0; # 子网掩码 option routers 192.168.247.1; # 设置路由器地址（网关） default-lease-time 21600; # 设置默认的IP租用期限 max-lease-time 43200; # 设置最大的IP租用期限 filename "pxelinux.0"; # 告知客户端从TFTP根目录下载pxelinux.0文件 next-server 192.168.247.6; # 告知客户端TFTP服务器的ip ，此处为本机IP &#125; EOF# 配置dchpdsed -i 's@\(DHCPDARGS=\).*@\1eth0@' /etc/sysconfig/dhcpd# 绑定网卡/etc/init.d/dhcpd start# 服务启动chkconfig dhcpd on# 添加开机启动 TFTP配置TFTP（Trivial File Transfer Protocol,简单文件传输协议）是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。端口号为69。 1234567891011yum -y install tftp-server# 安装sed -ri 'sS(disable( |\t)+= ).*S\1noS' /etc/xinetd.d/tftp# 将disable后的值改为no/etc/init.d/xinetd restartchkconfig xinetd on# 因为tftp服务是挂载在超级进程xinetd 下的，所以通过启动xinetd 来启动tftp服务。netstat -unlpt | grep --color 69 HTTP配置可以用Apache或Nginx提供HTTP服务。Python的模块web服务会有报错，不建议采用。 12345678yum -y install httpd# 安装/etc/init.d/httpd start# 启动chkconfig --level 2345 httpd on# 添加开机自启 OS Server准备CentOS6.8的镜像，插入服务器，拷贝系统安装文件。 1234install -cdv /mnt/cdrommount -r /dev/cdrom /mnt/cdromdf -hcp -r /mnt/cdrom /var/www/html/CentOS-6.8 浏览器访问 http://192.168.247.6/CentOS-6.8/ 检验配置是否正确 配置 PXE 启动程序syslinux是一个功能强大的引导加载程序，而且兼容各种介质。它是一个小型的 Linux 操作系统，它的目的是简化首次安装 Linux 的时间，并建立修护或其它特殊用途的启动盘。如果没有找到 pxelinux.0 这个文件，可以安装一下。 123456789101112yum -y install syslinux# 安装cp /usr/share/syslinux/pxelinux.0 /var/lib/tftpboot/# 复制启动菜单程序文件cp -a /var/www/html/CentOS-6.8/isolinux/* /var/lib/tftpboot/ls /var/lib/tftpboot/mkdir -p /var/lib/tftpboot/pxelinux.cfgcp -a /var/www/html/CentOS-6.8/isolinux/isolinux.cfg /var/lib/tftpboot/pxelinux.cfg/default# 新建一个pxelinux.cfg目录，存放客户端的配置文件 pxe的配置文件default参数配置 1vim /var/lib/tftpboot/pxelinux.cfg/default 配置后的文件内容 12345678910111213141516171819202122232425262728293031323334353637383940default linux # 默认启动的是 'label linux' 中标记的启动内核prompt 1 # 开启会显示命令行'boot: '提示符。prompt值为0时则不提示，将会直接启动'default'参数中指定的内容。timeout 30 # timeout时间是引导时等待用户手动选择的时间，设为1可直接引导，单位为1/10秒。display boot.msg# 菜单背景图片、标题、颜色。menu background splash.jpgmenu title Welcome to CentOS 6.8!menu color border 0 #ffffffff #00000000menu color sel 7 #ffffffff #ff000000menu color title 0 #ffffffff #00000000menu color tabmsg 0 #ffffffff #00000000menu color unsel 0 #ffffffff #00000000menu color hotsel 0 #ff000000 #ffffffffmenu color hotkey 7 #ffffffff #ff000000menu color scrollbar 0 #ffffffff #00000000# label指定在boot:提示符下输入的关键字，比如boot:linux[ENTER]，这个会启动label linux下标记的kernel和initrd.img文件。label linux # 一个标签就是前面图片的一行选项。 menu label ^Install or upgrade an existing system menu default kernel vmlinuz # 指定要启动的内核。同样要注意路径，默认是/var/lib/tftpboot目录。 append ks=http://192.168.247.6/CentOS-6.8/ks.cfg initrd=initrd.img ksdevice=eth0 # 指定追加给内核的参数，告诉系统，从哪里获取ks.cfg文件# initrd.img是一个最小的linux系统.# 如果有多张网卡，默认会弹出让你选择需要从哪张网卡获取，导致无法实现全自动化,使用ksdevice指定默认网卡label vesa menu label Install system with ^basic video driver kernel vmlinuz append initrd=initrd.img nomodesetlabel rescue menu label ^Rescue installed system kernel vmlinuz append initrd=initrd.img rescuelabel local menu label Boot from ^local drive localboot 0xfffflabel memtest86 menu label ^Memory test kernel memtest append - ks.cfg通常，在安装操作系统的过程中，需要大量的和服务器交互操作，为了减少这个交互过程，Kickstart 就诞生了。使用这种 Kickstart，只需事先定义好一个 Kickstart 自动应答配置文件 ks.cfg（通常存放在安装服务器上），并让安装程序知道该配置文件的位置，在安装过程中安装程序就可以自己从该文件中读取安装配置，这样就避免了在安装过程中多次的人机交互，从而实现无人值守的自动化安装。 生成 Kickstart 配置文件的三种方法 每安装好一台 CentOS 机器，CentOS 安装程序都会创建一个 Kickstart 配置文件，记录你的真实安装配置（生成的文件 /root/anaconda-ks.cfg）。如果你希望实现和某系统类似的安装，可以基于该系统的 Kickstart 配置文件来生成你自己的 Kickstart 配置文件。 CentOS 提供了一个图形化的 Kickstart 配置工具。在任何一个安装好的 Linux 系统上运行该工具，就可以很容易地创建你自己的 Kickstart 配置文件。Kickstart 配置工具命令为 redhat-config-kickstart （RHEL3）或 system-config-kickstart （RHEL4，RHEL5）。网上有很多用 CentOS 桌面版生成 ks 文件的文章。 阅读 Kickstart 配置文件的手册。用任何一个文本编辑器都可以创建你自己的 Kickstart 配置文件。 ks.cfg文件组成 命令段：键盘类型，语言，安装方式等系统的配置，有必选项和可选项，如果缺少某项必选项，安装时会中断并提示用户选择此项的选项 软件包段：在安装过程中默认安装的软件包，安装软件时会自动分析依赖关系。 123456%packages@compat-libraries@development# @groupname：指定安装的包组# package_name：指定安装的包# -package_name：指定不安装的包 脚本段(可选) 12345%pre# 安装系统前执行的命令或脚本(由于只依赖于启动镜像，支持的命令很少)%post# 安装系统后执行的命令或脚本(基本支持所有命令) 这里使用 anaconda-ks.cfg 并做了更改，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140# Kickstart file automatically generated by anaconda.# CentOS 6.8 # Platform=x86, AMD64, or Intel EM64T #version=DEVELfirstboot --disable# Firewall configurationfirewall --disabled# Install OS instead of upgrade install# Use text mode install #text# 6.X系统可能文本模式安装导致初始化失败，此项注释# Use graphical installgraphical# Use network installationurl --url="http://192.168.247.6/CentOS-6.8"# 这个选项告诉安装程序：到服务器192.168.247.6 的HTTP根目录下的CentOS-6.8目录下寻找安装介质# System languagelang en_US.UTF-8# System keyboardkeyboard us# System timezonetimezone Asia/Shanghai# Network informationnetwork --onboot no --device eth0 --bootproto dhcp --noipv6# Root passwordrootpw --iscrypted $6$ZE3J70TVR5F1LApI$N.4/XjFTpzcwe3fdbBda4RACxjJWNcBZ0WWe57goL2prx1xjk0ayhVL42uEVdyh5A1tu0BMqUb7/UjEk4QJhX0# System authorization informationauth --useshadow --passalgo=sha512# Do not configure the X Window Systemskipx# SELinux configurationselinux --disabled# Installation logging levellogging --level=info# Reboot after installationreboot# 此选项必须存在，也必须文中设定位置，不然kickstart显示一条消息，并等待用户按任意键后才重新引导；# System bootloader configurationbootloader --location=mbr --password="hehedadada"key --skip# 如果是红帽系统，此选项可以跳过输入序列号过程；如果是CentOS 系列，则可以不保留此项内容；# Clear the Master Boot Recordzerombr# Partition clearing informationclearpart --all --initlabel# 此条命令必须添加，不然系统会让用户手动选择是否清除所有数据，这就需要人为干预了，从而导致自动化过程失败；# Disk partitioning informationpart /boot --asprimary --fstype="ext4" --size=500part swap --fstype="swap" --size=2048part / --asprimary --fstype="ext4" --grow --size=1%packages@base@compat-libraries@developmentvim-enhancedbind-utilsntpdatenmaptcpdumpdos2unix%post# 禁用 ctrl+alt+del/bin/sed -ri 'sSexec /sbin/shutdown -r now.*S#&amp;Sg' /etc/init/control-alt-delete.conf # 关闭 IPv6if test -s /etc/modprobe.conf;then /bin/sed -ri 's#(^options ipv6 disable=).*#\11#;s#(^alias net-pf-10 ).*#\1off#' /etc/modprobe.conf;else &#123;/bin/cat &gt;&gt;/etc/modprobe.conf &lt;&lt;- 'EOF'options ip_conntrack hashsize=65536options ipv6 disable=1alias net-pf-10 offEOF &#125;fi/sbin/chkconfig ip6tables off# 禁用Zero Configuration Network# 当系统无法连接DHCP server的时候，就会尝试通过ZEROCONF来获取IP,并添加一条169.254.0.0/16的路由条目Netwfile="/etc/sysconfig/network"if /bin/fgrep -q 'NOZEROCONF=' $&#123;Netwfile&#125;;then /bin/sed -ri 's#(NOZEROCONF=).*#\1yes#' $&#123;Netwfile&#125;else echo 'NOZEROCONF=yes' &gt;&gt; $&#123;Netwfile&#125;fi# 禁用sshd使用DNS功能/bin/egrep -q '^UseDNS no' /etc/ssh/sshd_config || /bin/sed -ri '/#UseDNS /aUseDNS no' /etc/ssh/sshd_config# 对grep系列命令添加别名，支持颜色高亮显示echo "alias grep='grep --color'" &gt;&gt; /root/.bashrc;echo "alias egrep='egrep --color'" &gt;&gt; /root/.bashrc;echo "alias fgrep='fgrep --color'" &gt;&gt; /root/.bashrc;# 记录bash历史命令的执行时间time='HISTTIMEFORMAT="%Y-%m-%d\ %H:%M:%S "'if /bin/egrep -qs "$&#123;time&#125;" /etc/profile;then :else /bin/sed -ri '/export PATH USER.*HISTSIZE/a'"$&#123;time&#125;"'\nexport HISTTIMEFORMAT' /etc/profilefi# 启用vim的语法高亮/bin/egrep -q '^syntax' /root/.vimrc || echo 'syntax on' &gt;&gt; /root/.vimrc# 关闭不常用服务for i in `/sbin/chkconfig --list | /bin/awk '/2:on/&#123;if($1~/apmd|crond|network|snmpd|sshd|syslog/)&#123;&#125;else&#123;print $1&#125;&#125;'`;do /sbin/chkconfig --level 2345 $&#123;i&#125; offdoneunset i/bin/sed -r -i 's/(^id:)./\12/' /etc/inittab%end 注意事项 保证网络配置正常，避免发生网络冲突（比如虚拟机使用本网段的第二个地址作为tftp服务器有可能导致tftp无法响应客户端） iptables 均为关闭状态 安装模式最好保持默认（某些系统使用文本模式安装将导致失败） 确保配置了自动清除分区的参数 如果有多网卡环境的待安装服务器，pxelinux.cfg/default 中要使用 ksdevice 选择默认网卡 确保 selinux 状态 setenforce 0 ks.cfg文件参数 关键字 含义 install 告知安装程序，这是一次全新安装，而不是upgrade(升级) url --url=”http://192.168.247.6/CentOS-6.8/“ 通过HTTP从远程服务器上的安装树中安装。 url --url ftp://:@/ 通过FTP从远程服务器上的安装树中安装。 nfs --server=nfsserver.example.com --dir=/tmp/install-tree 从指定的NFS服务器安装 text 使用文本模式安装 lang 设置在安装过程中使用的语言以及系统的缺省语言。lang en_US.UTF-8 keyboard 设置系统键盘类型。keyboard us zerombr 清除mbr引导信息。 bootloader bootloader --location=mbr --driveorder=sda --append=”crashkernel=auto rhgb quiet” --location= 指定引导记录被写入的位置.有效的值如下:mbr(缺省),partition(在包含内核的分区的第一个扇区安装引导装载程序)或none(不安装引导装载程序)。 --driveorder,指定在BIOS引导顺序中居首的驱动器。 --append=,指定内核参数.要指定多个参数,使用空格分隔它们。 network 为通过网络的kickstart安装以及所安装的系统配置联网信息。 network --bootproto=dhcp --device=eth0 --onboot=yes --noipv6 --hostname=CentOS6 --bootproto=[dhcp/bootp/static]中的一种，缺省值是dhcp。bootp和dhcp被认为是相同的。 static方法要求在kickstart文件里输入所有的网络信息。 network --bootproto=static --ip=10.0.0.100 --netmask=255.255.255.0 --gateway=10.0.0.2 --nameserver=10.0.0.2 请注意所有配置信息都必须在一行上指定,不能使用反斜线来换行。 --ip=,要安装的机器的IP地址. --gateway=,IP地址格式的默认网关. --netmask=,安装的系统的子网掩码. --hostname=,安装的系统的主机名. --onboot=,是否在引导时启用该设备. --noipv6=,禁用此设备的IPv6. --nameserver=,配置dns解析. timezone 设置系统时区 timezone Asia/Shanghai authconfig 系统认证信息。authconfig --enableshadow --passalgo=sha512 设置密码加密方式为sha512 启用shadow文件。 rootpw root密码 clearpart 清空分区。clearpart --all --initlabel --all 从系统中清除所有分区--initlable 初始化磁盘标签 part 磁盘分区。 part /boot --fstype=ext4 --asprimary –size=500 part swap --size=2048 part / --fstype=ext4 --grow --asprimary --size=200 --fstype=,为分区设置文件系统类型.有效的类型为ext2,ext3,ext4,swap和vfat。 --asprimary,强迫把分区分配为主分区,否则提示分区失败。 --size=,以MB为单位的分区最小值.在此处指定一个整数值,如500.不要在数字后面加MB。 --grow,告诉分区使用所有可用空间(若有),或使用设置的最大值。 selinux 关闭selinux。selinux –disabled firewall 关闭防火墙。firewall –disabled logging 设置日志级别。logging --level=info 参考文档：https://access.redhat.com/documentation/zh-TW/Red_Hat_Enterprise_Linux/6/html/Installation_Guide/ch-kickstart2.html]]></content>
      <tags>
        <tag>Cobbler</tag>
        <tag>Kickstart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chmod权限被改为000后的恢复]]></title>
    <url>%2F2018%2F01%2F20%2F172607-chmod%E6%9D%83%E9%99%90%E8%A2%AB%E6%94%B9%E4%B8%BA000%E5%90%8E%E7%9A%84%E6%81%A2%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[使用库文件的管理程序 ld-linux-x86-64.so.2 调用 chmod 1/lib64/ld-linux-x86-64.so.2 /bin/chmod 755 /bin/chmod 使用 busybox 的 chmod 授权 1busybox chmod 755 /bin/chmod 使用 dd 生成一个 chmod 1234567mv /bin/chmod /bin/chmod.origcp -a /bin/chown /bin/chmoddd if=/bin/chmod.orig of=/bin/chmod95+1 records in95+1 records out48712 bytes (49 kB) copied,0.00117323 s, 41.5 MB/s 使用 facl 额外授权 123setfacl -m u::rx /bin/chmod chmod 755 /bin/chmod setfacl -b /bin/chmod 复制一个可执行文件，然后使用 chmod 命令覆盖 123cp /bin/ls chmod\cp /bin/chmod .\cp -a chmod /bin/chmod 使用 install 命令的 -m 选项也可以设置权限 12install -ma+x /bin/chmod .cp chmod /bin/chmod 使用 perl 修改文件权限 1perl -e 'chmod 0755, "/bin/chmod"' 使用 Python 修改文件权限 1python -c 'import os; os.chmod("/bin/chmod", 0755)']]></content>
      <tags>
        <tag>Maintenance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS的lib库误操作和修复]]></title>
    <url>%2F2018%2F01%2F20%2F164155-CentOS%E7%9A%84lib%E5%BA%93%E8%AF%AF%E6%93%8D%E4%BD%9C%E5%92%8C%E4%BF%AE%E5%A4%8D%2F</url>
    <content type="text"><![CDATA[Linux 系统的 lib目录下的库对系统的正常运行起着非常关键的作用，一旦误操作将导致系统瘫痪。 问题表现 由于操作失误，把 /usr/lib64 重命名成了 /usr/lib64.bak，结果发现执行命令的时候报错了。 1234567891011# mv命令无法使用-bash: /bin/mv: /lib64/ld-linux-x86-64.so.2: bad ELF interpreter: No such file or directory# cp命令无法使用-bash: /bin/cp: /lib64/ld-linux-x86-64.so.2: bad ELF interpreter: No such file or directory# ls命令无法使用-bash: /bin/ls: /lib64/ld-linux-x86-64.so.2: bad ELF interpreter: No such file or directory# ssh命令无法使用-bash: /usr/bin/ssh: /lib64/ld-linux-x86-64.so.2: bad ELF interpreter: No such file or directory 想使用 mv 把文件重命名回来已经不行了，就连重新 ssh 远程都远程不了。 修复方法 1、如果机器允许重启，最直接的办法就是挂载光盘进入修复模式将名字改回来，或者是安装 glibc 2、系统一般情况下会设置 LD_LIBRARY_PATH， LD_PRELOAD 这两个环境变量，来改变应用程序所调用库文件的路径。这两个环境变量只对应用程序有效，可能会对 shell 命令不起作用。 123export LD_LIBRARY_PATH=/usr/lib64.bakexport LD_PRELOAD=/usr/lib64.bakcp /usr/lib64.bak /usr/lib64 3、使用 ld-linux-x86-64.so.2 修复。在一个正常的操作系统上 /lib64/ld-linux-x86-64.so.2 其实只是个软链，真实文件是 /usr/lib64/ld-2.17.so，这个文件本身并不是库文件，可以简单的认为他是库文件的管理程序。ld-linux-x86-64.so.2 是操作系统的核心，并不受 LD_LIBRARY_PATH 环境变量的影响。如果想改变其调用方式，可以查看 man文档。 1/lib64/ld-linux-x86-64.so.2 --library-path /lib64.bak /bin/cp /lib64.bak /lib64 -afr 其他问题 如果是误删除 /lib64/ld-linux-x86-64.so.2 了怎么办呢？还是和上面第三种方法相同，删除的只是软连接文件，使用原始文件将其链接回来即可。 1/lib64/ld-2.17.so --library-path /lib64/ld-2.17.so /bin/ln -sv /lib64/ld-2.17.so /lib64/ld-linux-x86-64.so.2 误删除了 /lib64，这个是致命的故障。如果你现在还没有关闭 SSH 连接，请使用内置命令 while read 的方式把重要的配置文件输出到屏幕，然后复制粘贴出来，算是做一个备份。至于机器，只能重启挂载光盘进修复模式恢复了。如果是云主机则尝试恢复快照，没快照就认栽吧。]]></content>
      <tags>
        <tag>Maintenance</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[curl-7.57.0源码包编译安装和移植]]></title>
    <url>%2F2018%2F01%2F19%2F214844-curl-7-57-0%E6%BA%90%E7%A0%81%E5%8C%85%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E5%92%8C%E7%A7%BB%E6%A4%8D%2F</url>
    <content type="text"><![CDATA[Linux系统中一般自带curl命令，大部分选项和参数基本能满足日常工作需要。对于一些新的功能就需要是用编译安装的版本。本文编译安装的目的主要是让 curl 支持 --dns-servers，实现 DNS 解析。 Man Page：https://curl.haxx.se/docs/manpage.html 编译安装 OpenSSL要保证安装后的 OpenSSL 能兼容 CentOS6 以上系统针对 https 协议内容的访问，需要依赖较高版本的 OpenSSL 12345678910111213141516yum -y install perl perl-devel# 源码安装openssl需要perl编译环境wget --no-check-certificate https://www.openssl.org/source/old/1.0.2/openssl-1.0.2m.tar.gz ;tar xf openssl-1.0.2m.tar.gz ;cd openssl-1.0.2m ;./config -fPIC --prefix=/usr/local/openssl/ enable-shared# --prefix：指定安装目录# -fPIC:编译 openssl 的静态库# enable-shared:编译动态库make &amp;&amp; make install /usr/local/openssl/bin/openssl version # 版本查看 库文件配置 12345678echo "/usr/local/openssl/lib/" &gt;&gt; /etc/ld.so.conf.d/openssl-1.0.2m.conf# 将库文件路径写入/etc/ld.so.conf文件中，方便调用库文件ldconfig# 在默认搜寻目录(/lib和/usr/lib)以及动态库配置文件/etc/ld.so.conf内所列的目录下，搜索出可共享的动态链接库ldconfig -p | grep '/usr/local/openssl/lib'# 打印出当前缓存文件所保存的所有共享库的名字并过滤openssl相关项 编译安装 c-aresc-ares是一个C语言的异步DNS解析库，可以很方便的和使用者的事件循环统一起来，实现DNS的非阻塞异步解析，libcurl, libevent, gevent, nodejs 都在使用。curl 如果需要使用 --dns-servers 参数的话要在编译 curl 时对c-ares 进行支持 12345wget https://c-ares.haxx.se/download/c-ares-1.12.0.tar.gztar xf c-ares-1.12.0.tar.gz cd c-ares-1.12.0./configure --prefix=/usr/local/c-ares-1.12.0make &amp;&amp; make install 编译安装 curl-7.57.0CURL 的官方安装文档：http://curl.haxx.se/docs/install.html 12345678910111213wget https://curl.haxx.se/download/curl-7.57.0.tar.bz2tar xf curl-7.57.0.tar.bz2 cd curl-7.57.0./configure --prefix=/usr/local/curl-7.57.0/ --enable-ares=/usr/local/c-ares-1.12.0/ --with-ssl=/usr/local/openssl/ LIBS="-ldl -lrt "# 需要依赖的库：libdl.so.2、librt.so.1，因此需要使用LABS参数指定库连接make &amp;&amp; make install/usr/local/curl-7.57.0/bin/curl -V# 查看版本ln -sv /usr/local/curl-7.57.0/bin/curl /usr/local/sbin/curl7# 创建软连接 测试 123456789101112curl7 -I --dns-servers 8.8.8.8 www.baidu.comHTTP/1.1 200 OKServer: bfe/1.0.8.18Date: Fri, 19 Jan 2018 14:59:44 GMTContent-Type: text/htmlContent-Length: 277Last-Modified: Mon, 13 Jun 2016 02:50:25 GMTConnection: Keep-AliveETag: "575e1f71-115"Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transformPragma: no-cacheAccept-Ranges: bytes 源码包的移植编译好的包需要依赖很多库，为了解决移植后的库依赖的问题，我们可以在移植之前将所有依赖的库拷贝到程序的 lib目录下 使用 ldd 命令列出动态库依赖关系 1234567891011[root@Test ~]$ ldd /usr/local/curl-7.57.0/bin/curl linux-vdso.so.1 =&gt; (0x00007fffb6df5000) libcurl.so.4 =&gt; /usr/local/curl-7.57.0/lib/libcurl.so.4 (0x00002ac39067a000) libssl.so.1.0.0 =&gt; /usr/local/curl-7.57.0/lib/libssl.so.1.0.0 (0x00002ac3908e3000) libcrypto.so.1.0.0 =&gt; /usr/local/curl-7.57.0/lib/libcrypto.so.1.0.0 (0x00002ac390b4f000) librt.so.1 =&gt; /usr/local/curl-7.57.0/lib/librt.so.1 (0x0000003184000000) libc.so.6 =&gt; /usr/local/curl-7.57.0/lib/libc.so.6 (0x0000003182400000) libcares.so.2 =&gt; /usr/local/c-ares-1.12.0/lib/libcares.so.2 (0x00002ac390f65000) libdl.so.2 =&gt; /usr/local/curl-7.57.0/lib/libdl.so.2 (0x0000003182800000) libpthread.so.0 =&gt; /usr/local/curl-7.57.0/lib/libpthread.so.0 (0x0000003182c00000) /lib64/ld-linux-x86-64.so.2 (0x0000003182000000) 拷贝相关的库到程序的lib目录 123cp /usr/local/openssl/lib/libssl.so.1.0.0 /usr/local/curl-7.57.0/lib/cp /usr/local/openssl/lib/libcrypto.so.1.0.0 /usr/local/curl-7.57.0/lib/cp /usr/local/c-ares-1.12.0/lib/libcares.so.2 /usr/local/curl-7.57.0/lib/ 创建可移植的压缩包 12cd /usr/local/tar -jcf curl-7.57.0.tar.bz2 curl-7.57.0 使用 scp 命令从本机移植到另外一台机器X，在 X 机器添加库搜索路径 123456789scp -P 22 curl-7.57.0.tar.bz2 XXX.XXX.XXX.XXX:/opt/ssh -p 22 XXX.XXX.XXX.XXX# 以下操作均在X机器上执行cd /opt/tar xf curl-7.57.0.tar.bz2 -C /usr/local/echo '/usr/local/curl-7.57.0/lib/' &gt; /etc/ld.so.conf.d/curl-7.57.0.confldconfigln -sv /usr/local/curl-7.57.0/bin/curl /usr/local/sbin/curl7 测试 123456789101112/curl7 -I --dns-servers 8.8.8.8 www.baidu.comHTTP/1.1 200 OKServer: bfe/1.0.8.18Date: Sat, 20 Jan 2018 08:16:53 GMTContent-Type: text/htmlContent-Length: 277Last-Modified: Mon, 13 Jun 2016 02:50:26 GMTConnection: Keep-AliveETag: "575e1f72-115"Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transformPragma: no-cacheAccept-Ranges: bytes]]></content>
      <tags>
        <tag>OpenSSL</tag>
        <tag>curl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用dig命令写一个定时解析脚本]]></title>
    <url>%2F2017%2F12%2F25%2F121210-%E4%BD%BF%E7%94%A8dig%E5%91%BD%E4%BB%A4%E5%86%99%E4%B8%80%E4%B8%AA%E5%AE%9A%E6%97%B6%E8%A7%A3%E6%9E%90%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[使用 dig 命令可以很方便地解析域名，有些域名的 A 记录中 IP 地址比较固定，而有些域名的 A 记录会不定时的变动，要想收集这类域名的 A 记录就需要实时更新。因此我写了一个定时解析的 Shell 脚本，配合 Linux 的计划任务去定时解析。 要使用 dig 命令，需要确认提供该命令的软件包是否安装。如果没有安装则使用 yum 安装即可。 1rpm -qa bind-utils 下面是脚本的内容 1234567891011121314151617181920212223242526272829303132333435363738#!/bin/bashDNS_IP="8.8.8.8"# 要请求哪个DNS服务器进行域名解析serverListfile=$1# dig 命令有一个参数 -f 指定文件，这里定义传给 dig 的文件answerFile=""# Answer_file="/tmp/baidu.res"# 定义域名解析结果的输出文件路径# 如果不指定，默认会输出到 /tmp/ 下的一个和脚本名一样且后缀为 .res 的文件IP_filter()&#123; /bin/egrep '^(\b([1-9][0-9]?|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5]))(\.([0-9]|[1-9][0-9]|1[0-9]&#123;2&#125;|2[0-4][0-9]|25[0-5])\b)&#123;3&#125;'&#125;# 定义一个过滤IP的函数#------------------------------------------------scriptName=`/bin/basename $0`if /usr/bin/expr "$&#123;scriptName&#125;" : ".*\.sh$" &gt;/dev/null ;then if [[ ! -f $1 ]]; then echo -e "\n\tUsage : $(basename $0) filename\n" echo -e "\n\t必须指定一个域名列表文件\n" exit 3 fi outFilename=$(basename $&#123;serverListfile&#125;) answerFile="/tmp/$(echo $&#123;outFilename&#125; | cut -d "." -f 1).res"else echo -e "\n\t脚本必须以 '.sh' 结尾 \n" exit 3fi/bin/gawk '!a[$0]++' &lt; &lt;(IP_filter &lt; &lt;(/usr/bin/dig @$&#123;DNS_IP&#125; -f $&#123;serverListfile&#125; +short) ) | \/bin/sort -t "." -k 1.1,1n -k 2,2.0n -k 3.1,3.0n -k 4,4n &gt;&gt; $&#123;answerFile&#125;/bin/gawk '!a[$0]++' $&#123;answerFile&#125; | /bin/sort -t "." -k 1.1,1n -k 2,2.0n -k 3.1,3.0n -k 4,4n -o $&#123;answerFile&#125; 使用示例 1234567891011121314151617181920212223242526272829303132333435[root@m1 ~]# lscrondig.sh nordstrom.list[root@m1 ~]# [root@m1 ~]# cat nordstrom.list www.nordstrom.comm.shop.nordstrom.comn.nordstrommedia.comnordstrom.compredictivesearch.nordstrom.comrecs.p13n.nordstrom.comsecure.nordstrom.comsecure.nordstromimage.comshop.nordstrom.comsid.nordstrom.comtag.aws.nordstromdata.comwww.nordstromrack.comwww.hautelookcdn.com[root@m1 ~]# [root@m1 ~]# [root@m1 ~]# chmod +x crondig.sh [root@m1 ~]# ./crondig.sh nordstrom.list [root@m1 ~]# lscrondig.sh nordstrom.list nordstrom.res[root@m1 ~]# [root@m1 ~]# cat nordstrom.res 13.35.99.313.35.99.2913.35.99.6213.35.99.9523.208.140.452.40.114.14254.200.207.29184.85.168.88184.86.23.205184.86.210.115 加入计划任务，每隔 15 分钟解析一次即可 12[root@m1 ~]# tail -1 /etc/crontab */15 * * * * root /root/crondig.sh /root/nordstrom.list &amp;&gt;/dev/null]]></content>
      <tags>
        <tag>ShellScripts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用谷歌的BBR拥塞算法为TCP加速]]></title>
    <url>%2F2017%2F12%2F24%2F110110-%E4%BD%BF%E7%94%A8%E8%B0%B7%E6%AD%8C%E7%9A%84BBR%E6%8B%A5%E5%A1%9E%E7%AE%97%E6%B3%95%E4%B8%BATCP%E5%8A%A0%E9%80%9F%2F</url>
    <content type="text"><![CDATA[BBR简述Google 开源了其 TCP BBR 拥塞控制算法，并提交到了 Linux 内核，从 4.9 开始，Linux 内核已经用上了该算法。 BBR 算法的目的是要尽量跑满带宽，并且尽量不要有排队的情况。它可以起到单边加速 TCP 连接的效果。 TCP BBR 致力于解决两个问题 在有一定丢包率的网络链路上充分利用带宽 降低网络链路上的 buffer 占用率，从而降低延迟 BBR算法的优势 https://www.zhihu.com/question/53559433 一键配置脚本该脚本用于 CentOS 系列 6 和 7 版本的系统，执行后将升级内核并且通过 yum 安装，可能下载较慢，可手动下载 rpm 包 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281#!/usr/bin/env bash:&lt;&lt;:------------------------------------------------ FileName : google_bbr_centos.sh Author : Silence Create Time : 2017-05-09 15:09:16 Last modified : 2017-11-26 17:56:25 Mail : Version : 0.0.1 Description : Auto install latest kernel for TCP BBR CopyRight :------------------------------------------------:# Set up a default search path.PATH="/sbin:/usr/sbin:/bin:/usr/bin:/usr/local/sbin:/usr/local/bin:/root/bin"export PATH# Make sure umask is saneumask 022# terminal sequence to set color to a 'success' color (currently: green)SETCOLOR_SUCCESS="echo -en \\033[0;32m"# terminal sequence to set color to a 'failure' color (currently: red)SETCOLOR_FAILURE="echo -en \\033[0;31m"# terminal sequence to set color to a 'warning' color (currently: yellow)SETCOLOR_WARNING="echo -en \\033[0;33m"# terminal sequence to reset to the default color.SETCOLOR_NORMAL="echo -en \\033[0;39m"# Log that something succeededecho_info()&#123; echo -en "[ "; $&#123;SETCOLOR_SUCCESS&#125;; echo -en " Info "; $&#123;SETCOLOR_NORMAL&#125;; echo -en " ] "; echo "$@"&#125;# Log that something Errorecho_error()&#123; echo -en "[ "; $&#123;SETCOLOR_FAILURE&#125;; echo -en " Error "; $&#123;SETCOLOR_NORMAL&#125;; echo -en " ] "; echo "$@"&#125;# Log a warningecho_warning()&#123; echo -en "[ "; $&#123;SETCOLOR_WARNING&#125;; echo -en " Warning "; $&#123;SETCOLOR_NORMAL&#125;; echo -en " ] "; echo "$@"&#125;bbr_sysctl_config()&#123; sed -i '/net.core.default_qdisc/d' /etc/sysctl.conf sed -i '/net.ipv4.tcp_congestion_control/d' /etc/sysctl.conf echo "net.core.default_qdisc = fq" &gt;&gt; /etc/sysctl.conf echo "net.ipv4.tcp_congestion_control = bbr" &gt;&gt; /etc/sysctl.conf sysctl -p &gt;/dev/null 2&gt;&amp;1&#125;get_os() &#123; [ -f /etc/redhat-release ] &amp;&amp; awk '&#123;print ($1,$3~/^[0-9]/?$3:$4)&#125;' /etc/redhat-release &amp;&amp; return [ -f /etc/os-release ] &amp;&amp; awk -F'[= "]' '/PRETTY_NAME/&#123;print $3,$4,$5&#125;' /etc/os-release &amp;&amp; return [ -f /etc/lsb-release ] &amp;&amp; awk -F'[="]+' '/DESCRIPTION/&#123;print $2&#125;' /etc/lsb-release &amp;&amp; return&#125;get_char() &#123; SAVEDSTTY=`stty -g` stty -echo stty cbreak dd if=/dev/tty bs=1 count=1 2&gt; /dev/null stty -raw stty echo stty $SAVEDSTTY&#125;clearecho "------------- System Information --------------"echoecho " OS : $(get_os)"echo " Arch : $(uname -m) $(getconf LONG_BIT) Bit"echo " Kernel : $(uname -r)"echoecho "-----------------------------------------------"echo " Auto upgrade latest kernel and turn on TCP BBR"echo "-----------------------------------------------"echoecho "Press any key to start...or Press Ctrl+C to cancel"char=$(get_char)echo#------------------------------------------------# Test the operator is root or not#------------------------------------------------if test "$&#123;EUID&#125;" -ne 0 -o "$&#123;USER&#125;" != "root";then echo_error "Only root can run this script ... " exit 5else echo_info "Operator is root "fi#************************************************#------------------------------------------------ # Check network is rechable or not#------------------------------------------------dstname="www.baidu.com"if (ping $&#123;dstname&#125; -c 3 -i 0.01 -w 2 -q 1&gt;/dev/null 2&gt;&amp;1)then echo_info "Network is rechable "else RETVAL=$? echo_error "Network is unreachable , please check " exit 5fi#************************************************#------------------------------------------------# Check your OS is Redhat release or not #------------------------------------------------rla="$(egrep -i "centos|red hat|redhat" /etc/issue)"rlb="$(egrep -i "centos|red hat|redhat" /proc/version)"if [ -f /etc/centos-release -o -n "$&#123;rla&#125;" -o -n "$&#123;rlb&#125;" ]; then echo_info "OS is Redhat release" else echo_error "Only support for CentOS" exit 5fi#************************************************#------------------------------------------------# Check bbr status#------------------------------------------------conGestion="$(set -- $(sysctl -n net.ipv4.tcp_available_congestion_control);echo $1)"# Get the congestion_control from Kernel parameterbbrmodules="$(lsmod | fgrep tcp_bbr)"# Show the status of tcp_bbr module in the Linux Kernelif [ "$&#123;conGestion&#125;" = "bbr" -a -n "$&#123;bbrmodules&#125;" ];then echo_info "TCP BBR has been installed. Nothing to do..." exit 5fi#************************************************#------------------------------------------------# Check version of kernel is newer or not#------------------------------------------------kernelRelease="$(uname -r)"newORold=$(set -- $&#123;kernelRelease%%-*&#125; 4.9;test "$(echo -e "$1\n$2" | sort -rV | head -1)" == "$1" &amp;&amp; echo newer || echo older )if test "$&#123;newORold&#125;" == 'newer';then echo_info "Version of your kernel is greater than 4.9 , directly setting TCP BBR..." bbr_sysctl_config echo_info "Setting TCP BBR ..." echo_info 'Complete ! ' exit 5fi#************************************************#------------------------------------------------# Install elrepo#------------------------------------------------OS_X="`grep -Po '(?&lt;=\brelease )[\d]' /etc/redhat-release`"if test ! -z "$&#123;OS_X//[0-9]/&#125;";then echo_error "Not available for your system :("else echo_info "Installing elrepo"firpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.orgcase $OS_X in 6) rpm -Uvh http://www.elrepo.org/elrepo-release-6-8.el6.elrepo.noarch.rpm ;; 7) rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpm ;; *) echo_error "Not support for CentOS$&#123;OS_X&#125;" exit 5 ;;esacif [ ! -s /etc/yum.repos.d/elrepo.repo ]; then echo_error "Install elrepo failed , please check " exit 5fi#************************************************#------------------------------------------------# Upgrade kernel#------------------------------------------------yum --enablerepo=elrepo-kernel -y install kernel-ml kernel-ml-develecho_info "Query package :"echo '------------------------------------------------'rpm -qa kernel-mlecho '------------------------------------------------'echoif [ $? -ne 0 ]; then echo_error "Install latest kernel failed, please check it." exit 5fi#************************************************#------------------------------------------------# config for grub#------------------------------------------------case $OS_X in 6) if [ ! -s "/boot/grub/grub.conf" ]; then echo_error "/boot/grub/grub.conf wrong, please check it." exit 5 fi echo_info "List of kernel that is available" echo '------------------------------------------------' awk '/title/&#123;$1="";print&#125;' /etc/grub.conf echo '------------------------------------------------' echo sed -ri 's/^default=.*/default=0/g' /boot/grub/grub.conf ;; 7) if [ ! -s "/boot/grub2/grub.cfg" ]; then echo_error "/boot/grub2/grub.cfg wrong, please check it." exit 5 fi echo_info "List of kernel that is available" echo '------------------------------------------------' awk -F'[\047]+' '/^menuentry/&#123;print $2&#125;' /boot/grub2/grub.cfg echo '------------------------------------------------' echo grub_default_kernel=$(awk -F'[\047]+' '/^menuentry/&#123;print "\047"$2"\047";exit&#125;' /boot/grub2/grub.cfg) echo "grub2-set-default 0" echo grub2-set-default 0 echo "grub2-mkconfig -o /boot/grub2/grub.cfg" echo grub2-mkconfig -o /boot/grub2/grub.cfg ;; *) echo_error "Not support for CentOS$&#123;OS_X&#125;" exit 5 ;;esac#************************************************bbr_sysctl_config#------------------------------------------------# Waitting for reboot#------------------------------------------------echoecho_warning "The system needs to reboot."echo read -p 'Do you want to restart system ? [yes/no] ' yesOrnocase "$&#123;yesOrno&#125;" in y|Y|[yY][eE]|[yY][eE][sS]) reboot ;; n|N|[nN][oO]) echo_info "Reboot has been canceled..." exit 5 ;;esac#************************************************ 参考命令查看内核模块的信息 1modinfo tcp_bbr 查看可用内核 1awk -F'[\047]+' '/^menuentry/&#123;print $2&#125;' /boot/grub2/grub.cfg 查看当前内核的版本 1uname -r 修改开机时默认使用的内核 123grub2-set-default 'CentOS Linux (4.14.2-1.el7.elrepo.x86_64) 7 (Core)'# 或使用索引号0、1、2.....grub2-set-default 0 查看内核修改结果 1grub2-editenv list 重新生成 grub2 的配置文件 1grub2-mkconfig -o /boot/grub2/grub.cfg GRUB 2 操作帮助： http://fedoraproject.org/wiki/GRUB_2/zh-cn]]></content>
      <categories>
        <category>配置</category>
      </categories>
      <tags>
        <tag>Kernel</tag>
        <tag>grub2</tag>
        <tag>ShellScripts</tag>
        <tag>BBR</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核参数rp_filter]]></title>
    <url>%2F2017%2F03%2F20%2F212135-Linux%E5%86%85%E6%A0%B8%E5%8F%82%E6%95%B0rp_filter%2F</url>
    <content type="text"><![CDATA[说明内核的 rp_filter 参数用于控制系统是否开启对数据包源地址的校验，Linux 内核文档 中的描述： 1234567891011121314151617rp_filter - INTEGER0 - No source validation.1 - Strict mode as defined in RFC3704 Strict Reverse Path Each incoming packet is tested against the FIB and if the interface is not the best reverse path the packet check will fail. By default failed packets are discarded.2 - Loose mode as defined in RFC3704 Loose Reverse Path Each incoming packet&apos;s source address is also tested against the FIB and if the source address is not reachable via any interface the packet check will fail. Current recommended practice in RFC3704 is to enable strict modeto prevent IP spoofing from DDos attacks. If using asymmetric routingor other complicated routing, then loose mode is recommended. The max value from conf/&#123;all,interface&#125;/rp_filter is usedwhen doing source validation on the &#123;interface&#125;. Default value is 0. Note that some distributions enable itin startup scripts. rp_filter参数有三个值： 0：不开启源地址校验 1：开启严格的反向路径校验。对每个进来的数据包，校验其反向路径是否是最佳路径。如果反向路径不是最佳路径，则直接丢弃该数据包 2：开启松散的反向路径校验。对每个进来的数据包，校验其源地址是否可达，即反向路径是否能通（通过任意网口），如果反向路径不通，则直接丢弃该数据包 应用场景假设一台 Linux 服务器在提供 Web 服务的同时又充当了路由器的功能，并且该服务器有多个网卡，配置的 IP 地址也不属于同一运营商。 如图所示，在服务器的 eth0 网卡上配置了电信 IP 125.88.177.76，在 eth1 网卡上配置了移动 IP 183.232.239.248。电信的网络质量比较好，通常配置默认网关为电信 IP 的网关。至于移动 IP 如何到达它的网关并访问互联网的，因为涉及到 Linux 的高级路由，这里不再讨论。 现在来自 IP 是 211.138.190.130 的客户端，向这台机器移动 IP 的 Web 服务服务发送请求，即 eth1 上的183.232.239.248:80。系统 rp_filter 参数的配置为： 1234[root@m1 ~]# sysctl -p --pattern &apos;rp_filter&apos;net.ipv4.conf.default.rp_filter = 1net.ipv4.conf.all.rp_filter = 1[root@m1 ~]# 如上图红色箭头所示，客户端发送请求到服务器端的 eth1 网卡，服务器端收到请求开始进行对客户端 211.138.190.130 的响应，此时查看本机的路由表发现到客户端 211.138.190.130 是从 eth0 出去的，并且内核的参数 rp_filter = 1，因此系统会严格校验数据包的反向路径，请求数据包入网卡和响应数据包出网卡不是同一个网卡，这时候系统会判断该反向路径不是最佳路径，而直接丢弃该请求数据包。 为了避免这种问题，配置 /etc/sysctl.conf 禁用 rp_filter ，然后使用 sysctl -p 刷新到内存即可立即生效 123# Controls source route verificationnet.ipv4.conf.default.rp_filter = 0net.ipv4.conf.all.rp_filter = 0 或者，你还可以指定一条静态路由让响应数据包出网卡和请求数据包入网卡变成一样的，这样反向路径就是最佳路径了，内核不会丢弃。 1ip route add to 211.138.190.130 via 183.232.239.1 dev eth1 作用启用了 rp_filter 之后可以减少 DDoS 攻击：校验数据包的反向路径，如果反向路径不合适，则直接丢弃数据包，避免过多的无效连接消耗系统资源。 还可以防止 IP Spoofing：校验数据包的反向路径，如果客户端伪造的源 IP 地址对应的反向路径不在路由表中，或者反向路径不是最佳路径，则直接丢弃数据包，不会向伪造 IP 的客户端回复响应。]]></content>
      <tags>
        <tag>Network</tag>
        <tag>Kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的策略路由]]></title>
    <url>%2F2017%2F03%2F17%2F170119-Linux%E7%9A%84%E7%AD%96%E7%95%A5%E8%B7%AF%E7%94%B1%2F</url>
    <content type="text"><![CDATA[刚开始学习 Linux 系统的网络时，基本都使用 ifconfig 及 route 之类的命令，工作之后发现功能更强大的 ip 命令，这个命令是由 iproute 这个软件在 RedHat 系列的 Linux 系统中是默认安装的。使用 ip -V 命令即可看到版本信息，如果由于某些原因找不到这个软件，可以在联网的情况下用 yum install iproute 命令即可顺利安装。 策略路由策略路由 策略是指对于 IP 包的路由是以我们根据需要而定下的一些策略为主要依据进行路由的。例如我们可以有这样的策略：“所有来直自网A的包，选择X路径；其他选择Y路径”，或者是“所有TOS为A的包选择路径F；其他选者路径K”。 Cisco 的网络操作系统 (Cisco IOS) 从11.0开始就采用新的策略路由机制。而 Linux 是在内核 2.1 开始采用策略路由机制的。策略路由机制与传统的路由算法相比主要是引入了多路由表以及规则的概念。 多路由表（multiple Routing Tables） 传统的路由算法是仅使用一张路由表的。但是在有些情形底下，我们是需要使用多路由表的。 如图所示，一个局域网通过路由器与互联网相连，路由器与互联网有两条线路相连，其中路径B的速度比较快，路径A的速度比较慢。对于局域网内的大多数用户来说对速度并没有特殊的要求，所以可以让他们用比较慢的路由；但是还有一些特殊的用户却是对速度的要求比较苛刻，所以他们需要使用速度比较快的路由。如果使用一张路由表上是没有办法实现这种要求的，如果根据源地址或其它参数，对不同的用户使用不同的路由表，这样就可以大大提高路由器的性能。 规则（rule） 我们可以用自然语言这样描述规则： 规则一：“所有来自 192.16.152.24 的 IP 包，使用路由表 10， 本规则的优先级是 990” 规则三：“所有到 192.168.127.127 的 IP 包，使用路由表 11，本规则的优先级是 991” 规则二：“所有的包，使用路由表 253，本规则的优先级是 32767” 我们可以看到，规则包含 3 个要素： 什么样的包，将应用本规则（所谓的SELECTOR，可能是filter更能反映其作用）； 符合本规则的包将对其采取什么动作（ACTION），例如：使用哪个路由个表； 本规则的优先级。优先级别越高的规则越先匹配（数值越小优先级别越高）。 策略性路由的配置方法传统的 Linux 下配置路由的工具是 route，而实现策略路由配置的工具是 iproute2 工具包。策略路由的配置主要包括接口地址的配置、路由的配置、规则的配置。 接口地址的配置 IP Addr使用 ip addr 来实现接口地址的配置 12[root@m5 ~]# ip addr add 192.168.127.136/24 brd 192.168.127.255 dev eth0[root@m5 ~]# ip addr add 192.168.127.137/24 brd 192.168.127.255 dev eth0 这样就在 eth0 网卡添加了两个 IP 地址，其中 24 表示子网掩码（掩码中 1 的个数），brd 是 broadcast 的简写，说明了广播地址是 192.168.127.255 配置完成后可以查看网卡上的 IP 信息 123456[root@m5 ~]# ip addr show dev eth0 | grep -v valid2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:23:43:a0 brd ff:ff:ff:ff:ff:ff inet 192.168.127.135/24 brd 192.168.127.255 scope global eth0 inet 192.168.127.136/24 brd 192.168.127.255 scope global secondary eth0 inet 192.168.127.137/24 brd 192.168.127.255 scope global secondary eth0 如果不指定网卡名将查看所有网卡的 IP 信息 123456789101112131415[root@m5 ~]# ip addr show 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:23:43:a0 brd ff:ff:ff:ff:ff:ff inet 192.168.127.135/24 brd 192.168.127.255 scope global eth0 valid_lft forever preferred_lft forever inet 192.168.127.136/24 brd 192.168.127.255 scope global secondary eth0 valid_lft forever preferred_lft forever3: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:23:43:aa brd ff:ff:ff:ff:ff:ff inet 192.168.1.130/24 brd 192.168.1.255 scope global dynamic eth1 valid_lft 1579sec preferred_lft 1579sec 其中 addr 可以简写为 a，show 可以使用 list 代替，也可简写为 l 12345678910111213[root@m5 ~]# ip a s eth0 | grep inet inet 192.168.127.135/24 brd 192.168.127.255 scope global eth0 inet 192.168.127.136/24 brd 192.168.127.255 scope global secondary eth0[root@m5 ~]# ip a l eth0 | grep inet inet 192.168.127.135/24 brd 192.168.127.255 scope global eth0 inet 192.168.127.136/24 brd 192.168.127.255 scope global secondary eth0[root@m5 ~]# ip a | grep inet inet 127.0.0.1/8 scope host lo inet 192.168.127.135/24 brd 192.168.127.255 scope global eth0 inet 192.168.127.136/24 brd 192.168.127.255 scope global secondary eth0 inet 192.168.1.130/24 brd 192.168.1.255 scope global dynamic eth1 当然你也可以从网卡上删除无用的 IP 地址 1[root@m5 ~]# ip addr del 192.168.127.137/24 brd 192.168.127.255 dev eth0 如果清空某个网卡上的所有 IP 地址，则使用 flush，切记一定要指定网卡名，否则会清空本机所有网卡的所有 IP，导致机器失联。 12345[root@m5 ~]# ip addr flush dev eth1[root@m5 ~]# ip addr show dev eth13: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000 link/ether 00:0c:29:23:43:aa brd ff:ff:ff:ff:ff:ff[root@m5 ~]# 路由的配置 IP Route使用 ip route 进行路由的配置 Linux 最多可以支持 255 张路由表，其中有 3 张表是内置的： 表255 本地路由表（Local table）本地接口地址，广播地址，已及 NAT 地址都放在这个表。该路由表由系统自动维护，管理员不能直接修改。 表254 主路由表（Main table）如果没有指明路由所属的表，所有的路由都默认都放在这个表里，一般来说，旧的路由工具（如route）所添加的路由都会加到这个表。一般是普通的路由。 表253 默认路由表 （Default table）一般来说默认的路由都放在这张表，但是如果特别指明放的也可以是所有的网关路由。 还有一张表 0 是保留的，在文件 /etc/iproute2/rt_tables 可以查看和配置路由表的 TABLE_ID 及路由表名称。 路由配置命令的格式如下： 12Usage: ip route &#123; list | flush &#125; SELECTOR ip route &#123; add | del | change | append | replace &#125; ROUTE 使用 show 或 list 子命令可以查看路由表的内容 12345678910111213[root@m5 ~]# ip route list table main default via 192.168.127.2 dev eth0 192.168.1.0/24 dev eth1 proto kernel scope link src 192.168.1.130 192.168.127.0/24 dev eth0 proto kernel scope link src 192.168.127.135 [root@m5 ~]# ip route show table main default via 192.168.127.2 dev eth0 192.168.1.0/24 dev eth1 proto kernel scope link src 192.168.1.130 192.168.127.0/24 dev eth0 proto kernel scope link src 192.168.127.135 [root@m5 ~]# ip route show dev eth0 table maindefault via 192.168.127.2 192.168.127.0/24 proto kernel scope link src 192.168.127.135 如果不指定 TABLE_ID 或路由表名称，则会查看默认的路由表， TABLE_ID 为 254，即 main 表。 12345678910[root@m5 ~]# ip route show default via 192.168.127.2 dev eth0 192.168.1.0/24 dev eth1 proto kernel scope link src 192.168.1.130 192.168.127.0/24 dev eth0 proto kernel scope link src 192.168.127.135 [root@m5 ~]# ip route show table 254default via 192.168.127.2 dev eth0 192.168.1.0/24 dev eth1 proto kernel scope link src 192.168.1.130 192.168.127.0/24 dev eth0 proto kernel scope link src 192.168.127.135 [root@m5 ~]# 使用 add 子命令添加路由。 123456[root@m5 ~]# ip route add to 0/0 via 192.168.127.2 dev eth0 table 110[root@m5 ~]# ip route add to 8.8.8.0/24 via 192.168.127.2 dev eth0 table 110[root@m5 ~]# ip route show table 110default via 192.168.127.2 dev eth0 8.8.8.0/24 via 192.168.127.2 dev eth0 [root@m5 ~]# 第一条命令是向路由表 （TABLE_ID） 110 中添加一条路由，路由的内容是设置 192.168.127.2 为表 110 的默认网关，其中 0/0 也可以写为 default。即：目标网络是所有（0/0，即默认），经过（via）本机的网关（下一跳） 192.168.127.2 ，从 eth0 网卡出去。 第二条命令是向路由表 （TABLE_ID） 110 中添加一条路由，到目标网络 8.8.8.0/24，经过（via）本机的网关 192.168.127.2 （下一跳）从 eth0 网卡出去。 一旦不小心加错了路由，可以使用 del 删除。 123456789101112[root@m5 ~]# ip route add 1.2.3.0/24 via 192.168.127.2 dev eth0 table 110[root@m5 ~]# ip route show table 110default via 192.168.127.2 dev eth0 1.2.3.0/24 via 192.168.127.2 dev eth0 8.8.8.0/24 via 192.168.127.2 dev eth0 [root@m5 ~]# ip route del 1.2.3.0/24 via 192.168.127.2 dev eth0 table 110[root@m5 ~]# ip route show table 110default via 192.168.127.2 dev eth0 8.8.8.0/24 via 192.168.127.2 dev eth0 对于错误的路由还可以使用 replace 或 change 来直接修改。 123456789101112131415161718[root@m5 ~]# ip route show table 110default via 192.168.127.2 dev eth0 1.2.3.0/24 via 192.168.127.2 dev eth0 8.8.8.0/24 via 192.168.127.2 dev eth0 [root@m5 ~]# ip route change 1.2.3.0/24 via 192.168.1.129 dev eth1 table 110[root@m5 ~]# ip route show table 110default via 192.168.127.2 dev eth0 1.2.3.0/24 via 192.168.1.129 dev eth1 8.8.8.0/24 via 192.168.127.2 dev eth0 [root@m5 ~]# ip route replace 1.2.3.0/24 via 192.168.127.2 dev eth0 table 110[root@m5 ~]# ip route show table 110default via 192.168.127.2 dev eth0 1.2.3.0/24 via 192.168.127.2 dev eth0 8.8.8.0/24 via 192.168.127.2 dev eth0 对于路由条目比较多的情况，可以使用 show match 来匹配包含或等于指定网段的路由。 1234567[root@m5 ~]# ip route show match 1.2.3.0/24 table 110default via 192.168.127.2 dev eth0 1.2.3.0/24 via 192.168.1.129 dev eth1 [root@m5 ~]# ip route show match 1.2.3.1 table 110 default via 192.168.127.2 dev eth0 1.2.3.0/24 via 192.168.1.129 dev eth1 使用 show root 可以查看在指定的网段内的路由条目。 1234567891011[root@m5 ~]# ip route show root 1.2.0.0/16 table 1101.2.3.0/24 via 192.168.1.129 dev eth1 [root@m5 ~]# ip route show root 1.0.0.0/1 table 110 1.2.3.0/24 via 192.168.1.129 dev eth1 8.8.8.0/24 via 192.168.127.2 dev eth0 [root@m5 ~]# ip route add 1.2.1.0/24 via 192.168.1.129 dev eth1 table 110[root@m5 ~]# ip route show root 1.2.0.0/16 table 110 1.2.1.0/24 via 192.168.1.129 dev eth1 1.2.3.0/24 via 192.168.1.129 dev eth1 使用 flush 将会清空指定的路由表中的所有条目，请注意一定要指定路由表，否则会清空本机默认路由表 main 表中的所有条目，导致机器失联。 1234567[root@m5 ~]# ip route show table 110default via 192.168.127.2 dev eth0 1.2.3.0/24 via 192.168.127.2 dev eth0 8.8.8.0/24 via 192.168.127.2 dev eth0 [root@m5 ~]# ip route flush table 110[root@m5 ~]# ip route show table 110 在多路由表的路由体系里，所有的路由的操作，例如往路由表中添加路由，或者在路由表里寻找特定的路由，需要指明要操作的路由表，所有没有指明路由表，默认是对主路由表 main（表254）进行操作。 1234567891011121314151617181920212223242526[root@m5 ~]# ip route show match 1.2.1.0/24default via 192.168.127.2 dev eth0 [root@m5 ~]# ip route show root 1.2.0.0/16[root@m5 ~]# ip route add 1.2.5.0/24 via 192.168.1.129 dev eth1 [root@m5 ~]# ip route show default via 192.168.127.2 dev eth0 1.2.5.0/24 via 192.168.1.129 dev eth1 192.168.1.0/24 dev eth1 proto kernel scope link src 192.168.1.130 192.168.127.0/24 dev eth0 proto kernel scope link src 192.168.127.135 [root@m5 ~]# ip route show dev eth0default via 192.168.127.2 192.168.127.0/24 proto kernel scope link src 192.168.127.135 [root@m5 ~]# ip route show dev eth11.2.5.0/24 via 192.168.1.129 192.168.1.0/24 proto kernel scope link src 192.168.1.130 [root@m5 ~]# ip route show match 1.2.5.3default via 192.168.127.2 dev eth0 1.2.5.0/24 via 192.168.1.129 dev eth1 [root@m5 ~]# ip route show root 1.2.0.0/161.2.5.0/24 via 192.168.1.129 dev eth1 请注意，上面的几条命令都没有指明要操作哪张路由表，默认就操作的是主路由表 main（表254）。 规则的配置 IP Rule在 Linux 里，总共可以定义 232 个优先级的规则，一个优先级只能有一条规则。有 3 个规则是默认的。 123456789Usage: ip rule &#123; add | del &#125; SELECTOR ACTION ip rule &#123; flush | save | restore &#125; ip rule [ list [ SELECTOR ]]SELECTOR := [ not ] [ from PREFIX ] [ to PREFIX ] [ tos TOS ] [ fwmark FWMARK[/MASK] ] [ pref NUMBER ] ACTION := [ table TABLE_ID ] [ nat ADDRESS ] [ realms [SRCREALM/]DSTREALM ] [ goto NUMBER ]TABLE_ID := [ local | main | default | NUMBER ] 首先我们可以看看路由表默认的所有规则： 12345[root@m5 ~]# ip rule list0: from all lookup local 32766: from all lookup main 32767: from all lookup default [root@m5 ~]# 优先级 0，优先级别最高的规则，规则规定所有的包，都必须首先使用 local 表（255）进行路由。本规则不能被更改和删除。 优先级 32766，规定所有的包，使用表 main 进行路由。本规则可以被更改和删除。 优先级 32767，规定所有的包，使用表 default 进行路由。本规则可以被更改和删除。 在默认情况下进行路由时，首先会根据规则 0 在本地路由表 local 里寻找路由，如果目的地址是本网络，或是广播地址的话，在这里就可以找到合适的路由；如果路由失败，就会匹配下一个不空的规则，默认情况的下一条规则是 32766 规则，在这里将会在主路由表里寻找路由；如果失败，就会匹配 32767 规则，即寻找默认路由表。如果失败，路由将失败。从这里可以看出，策略路由是往前兼容的。 除了默认的规则之外，还可以添加自定义的规则。 1234567[root@m5 ~]# ip rule add from 0/0 table 110 pref 32800 [root@m5 ~]# ip rule show0: from all lookup local 32766: from all lookup main 32767: from all lookup default 32800: from all lookup 110 [root@m5 ~]# 这一条命令将向规则链增加一条规则，规则匹配的对象是所有的数据包，动作是选用策略路由表 110 里的路由，这条规则的优先级是 32800。其中 from 0/0 也可以写成 from all，或者直接省略不写也是可行的。 12345678[root@m5 ~]# ip rule add from 192.168.1.112/32 tos 0x10 table 2 pref 1500 prohibit[root@m5 ~]# ip rule0: from all lookup local 1500: from 192.168.1.112 tos lowdelay lookup 2 prohibit32766: from all lookup main 32767: from all lookup default 32800: from all lookup 110 [root@m5 ~]# 这一条命令将向规则链增加一条规则，规则匹配的对象是来源 IP 为 192.168.3.112，tos 等于0x10 的包，使用策略路由表 2 里的路由，这条规则的优先级是 1500。 上面的规则是以源地址为关键字，作为是否匹配的依据的。除了源地址外，还可以用以下的信息： from 匹配来源地址 to 匹配目的地址 tos 匹配 IP 包头的TOS（type of sevice）域 dev 匹配物理接口 fwmark 匹配防火墙 MARK 标记 采取的动作除了指定表，还可以指定下面的动作： table 指明所使用的表，也可使用 lookup nat 透明网关 prohibit 丢弃该包，并发送 COMM.ADM.PROHIITED 的 ICMP 信息 reject 单纯丢弃该包 unreachable 丢弃该包， 并发送 NET UNREACHABLE 的 ICMP 信息 如果想删除添加的自定义路由，将添加命令中的 add 改为 del 即可。 策略路由的应用 如上图所示，在传统的 IDC 机房中，会有很多不同客户托管的服务器，它们一般都是一台机器配置一个公网 IP。 现在，假设我们需要电信、网通、移动三个运营商的多个 IP 资源，如果托管三台机器到此机房不仅增加硬件成本，还容易会造成维护混乱。因此我们将多运营商线路的 IP 都配置到一台服务器的多个网卡上，结合策略路由就能很好的解决这个问题。 如图所示，电信、网通、移动各使用两个公网 IP，要求电信 IP 走电信网关，网通 IP 走网通网关，移动 IP 走移动网关，互不干扰。 为了方便配置，我们将电信的第一个 IP 配置在 eth0 网卡上 123456789101112[root@m5 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0TYPE=EthernetNAME=eth0DEVICE=eth0BOOTPROTO=staticONBOOT=yesIPADDR=61.132.229.25NETMASK=255.255.255.224PREFIX=27BROADCAST=61.132.229.31NETWORK=61.132.229.0GATEWAY=61.132.229.1 网通的第一个 IP 配置在 eth1 网卡上 123456789101112[root@m5 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth1TYPE=EthernetNAME=eth1DEVICE=eth1BOOTPROTO=staticONBOOT=yesIPADDR=103.214.48.3NETMASK=255.255.255.0PREFIX=24BROADCAST=103.214.48.255NETWORK=103.214.48.0# GATEWAY=103.214.48.1 移动的第一个 IP 配置在 eth2 网卡上 123456789101112[root@m5 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth2TYPE=EthernetNAME=eth2DEVICE=eth2BOOTPROTO=staticONBOOT=yesIPADDR=112.29.175.205NETMASK=255.255.255.0PREFIX=24BROADCAST=112.29.175.255NETWORK=112.29.175.0# GATEWAY=112.29.175.1 注释掉网通和移动的 GATEWAY 指令是因为在同一优先级下只能有一个默认网关，我们选择电信的网关作为本机的默认网关。然后使用 ip addr 命令将各运营商的第二个 IP 地址配置在对应的网卡上。 123[root@m5 ~]# ip addr add 61.132.229.26/27 brd 61.132.229.31 dev eth0[root@m5 ~]# ip addr add 103.214.48.4/24 brd 103.214.48.255 dev eth0[root@m5 ~]# ip addr add 112.29.175.206/24 brd 112.29.175.255 dev eth0 再创建各个运营商线路对应的策略路由表。 123[root@m5 ~]# echo &apos;10 tel&apos; &gt;&gt; /etc/iproute2/rt_tables[root@m5 ~]# echo &apos;11 cnc&apos; &gt;&gt; /etc/iproute2/rt_tables [root@m5 ~]# echo &apos;12 cm&apos; &gt;&gt; /etc/iproute2/rt_tables 为不同策略路由表添加对应的默认网关和直连路由。 12345678[root@m5 ~]# ip route add default via 61.132.229.1 dev eth0 table tel[root@m5 ~]# ip route add $(ip route show dev eth0 scope link | head -1 | /bin/cut -d &quot;p&quot; -f 1) dev eth0 table tel[root@m5 ~]# ip route add default via 103.214.48.1 dev eth1 table cnc[root@m5 ~]# ip route add $(ip route show dev eth1 scope link | head -1 | /bin/cut -d &quot;p&quot; -f 1) dev eth1 table cnc[root@m5 ~]# ip route add default via 112.29.175.1 dev eth2 table cm[root@m5 ~]# ip route add $(ip route show dev eth2 scope link | head -1 | /bin/cut -d &quot;p&quot; -f 1) dev eth2 table tel 为各个网卡上的 IP 地址做来源匹配规则，即：来自电信的 IP 去看电信的策略路由表，来自网通的 IP 去看网通的策略路由表，来自移动的 IP 去看移动的策略路由表。 12345678[root@m5 ~]# ip rule add from 61.132.229.25/32 lookup tel pref 1000[root@m5 ~]# ip rule add from 61.132.229.26/32 lookup tel pref 1001[root@m5 ~]# ip rule add from 103.214.48.3/32 lookup cnc pref 1002[root@m5 ~]# ip rule add from 103.214.48.4/32 lookup cnc pref 1003[root@m5 ~]# ip rule add from 112.29.175.205/32 lookup cm pref 1004[root@m5 ~]# ip rule add from 112.29.175.206/32 lookup cm pref 1005 各个策略路由表中已经实现创建了对应的默认网关和直连路由，由此一来就完成了 Linux 下的多网卡多运营商线路多 IP 地址的配置。 参考链接：http://linux-ip.net/html/routing-tables.html]]></content>
      <tags>
        <tag>Network</tag>
        <tag>iproute</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iptables实现不连续地址的SNAT]]></title>
    <url>%2F2017%2F03%2F15%2F130127-iptables%E5%AE%9E%E7%8E%B0%E4%B8%8D%E8%BF%9E%E7%BB%AD%E5%9C%B0%E5%9D%80%E7%9A%84SNAT%2F</url>
    <content type="text"><![CDATA[想要从内网直接去访问外网的服务器肯定是不可能的，因为互联网中的机器都是公网通信，它看到内网来源后不知道该响应给谁，这就要用到源地址转换。源地址转换实质上就是把要出去的数据包中的源地址做了修改。 Linux 上基于 iptables 可实现源地址转换，即 SNAT。一般情况下一台主机配置一个公网 IP 就可以了，但是在有些场合因为业务需要，机器上要配置多个地址，这些地址可能是连续的，不连续的，一部分连续，一部分不连续，针对不同的情况，做 SNAT 也不同。 网卡上只有一个 IP 直接 SNAT 即可 12# eth1 111.161.126.234iptables -t nat -I POSTROUTING -o eth1 -s 192.168.0.0/16 -j SNAT --to 111.161.126.234 网卡上有在同一个子网的多个连续的 IP 12345eth0 111.161.74.179eth0 111.161.74.180eth0 111.161.74.181eth0 111.161.74.182eth0 111.161.74.183 这种情况可以选择其中一个 IP 做 SNAT，但是既然已经有这么多 IP 了就应该充分利用资源。使用 - 可以在 SNAT 的时候指定连续的 IP 范围，这样能够达到某种负载均衡的效果 1iptables -t nat -I POSTROUTING -o eth0 -s 192.168.0.0/16 -j SNAT --to 111.161.74.179-111.161.74.183 网卡上的 IP 都在同一子网，但是都不连续 123eth0 111.32.133.22eth0 111.32.133.25eth0 111.32.133.29 这种情况在 CentOS 5 上可以使用 SAME 和多个 --to 来达到上面的 SNAT 效果 1iptables -t nat -I POSTROUTING -o eth0 -s 192.168.0.0/16 -j SAME --to 111.32.133.22 --to 111.32.133.25 --to 111.32.133.29 但是 CentOS 5 的系统已经很少使用了，并且高版本的系统也不支持这种写法了。要解决这个问题，可以使用 state 模块和 statistic 来根据连接状态做负载均衡。既然是 3 个不连续的地址，我们就可以视为 3 个要 SNAT 的对象，根据这个来匹配 NEW 状态的数据包，匹配到的数据包中每 3 个数据包作为一个循环体，其中第 1 个数据包 SNAT 到第 1 个 IP，第 2 个数据包 SNAT 到第 2 个 IP，以此类推，当前循环体操作完之后将操作下一个循环体的 3 个数据包。要注意一下，我们人所说的第 1 个，在计算机上是从 0 开始的。如果到最后还是没有被匹配到，就 SNAT 到其中任意一个 IP ，这个规则就相当于是默认的 SNAT 规则。 12345iptables -t nat -A POSTROUTING -o eth0 -s 192.168.0.0/16 -m state --state NEW -m statistic --mode nth --every 3 --packet 0 -j SNAT --to 111.32.133.22iptables -t nat -A POSTROUTING -o eth0 -s 192.168.0.0/16 -m state --state NEW -m statistic --mode nth --every 3 --packet 1 -j SNAT --to 111.32.133.25iptables -t nat -A POSTROUTING -o eth0 -s 192.168.0.0/16 -m state --state NEW -m statistic --mode nth --every 3 --packet 2 -j SNAT --to 111.32.133.29iptables -t nat -A POSTROUTING -o eth0 -s 192.168.0.0/16 -j SNAT --to 111.32.133.22# 默认 SNAT 规则 同一子网部分连续 123eth1 42.81.58.226eth1 42.81.58.227eth1 42.81.58.230 这种情况我们可以把连续的 IP 当做一个 SNAT 对象，这样就是两个 SNAT 对象。同样还是按照上面的方法处理 1234iptables -t nat -A POSTROUTING -o eth1 -s 192.168.0.0/16 -m state --state NEW -m statistic --mode nth --every 2 --packet 0 -j SNAT --to 42.81.58.226-42.81.58.227iptables -t nat -A POSTROUTING -o eth1 -s 192.168.0.0/16 -m state --state NEW -m statistic --mode nth --every 2 --packet 1 -j SNAT --to 42.81.58.230iptables -t nat -A POSTROUTING -o eth1 -s 192.168.0.0/16 -j SNAT --to 42.81.58.226-42.81.58.227# 默认 SNAT 规则 不同子网都是连续 1234567891011eth2 220.181.122.74eth2 220.181.122.75eth2 220.181.122.76eth2 220.181.122.77eth2 220.181.122.78 # -------------------eth2 111.202.106.82eth2 111.202.106.83eth2 111.202.106.84eth2 111.202.106.85eth2 111.202.106.86 还是一样，连续的 IP 当做一个 SNAT 对象 1234iptables -t nat -A POSTROUTING -o eth2 -s 192.168.0.0/16 -m state --state NEW -m statistic --mode nth --every 2 --packet 0 -j SNAT --to 220.181.122.74-220.181.122.78 iptables -t nat -A POSTROUTING -o eth2 -s 192.168.0.0/16 -m state --state NEW -m statistic --mode nth --every 2 --packet 1 -j SNAT --to 111.202.106.82-111.202.106.86iptables -t nat -A POSTROUTING -o eth2 -s 192.168.0.0/16 -j SNAT --to 220.181.122.74-220.181.122.78# 默认 SNAT 规则]]></content>
      <tags>
        <tag>Network</tag>
        <tag>iptables</tag>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习使用iptables]]></title>
    <url>%2F2017%2F03%2F10%2F094107-%E5%AD%A6%E4%B9%A0%E4%BD%BF%E7%94%A8iptables%2F</url>
    <content type="text"><![CDATA[基础知识防火墙 工作于主机或网络边缘，对于进出的报文根据事先定义的规则做检查，对被匹配到的报文作出相应处理的组件 iptables linux 的包过滤功能，即 linux 防火墙，它由 netfilter 和 iptables 两个组件组成。真正实现防火墙功能的是 netfilter，它是一个 Linux 内核模块，工作于 Kernel space 做实际的包过滤。 Netfilter 的官方站点 http://www.netfilter.org ，此站点的 FAQ 是开始学习 iptables 和 Netfilter 的好地方。 四表五链netfilter 使用表（Tables）和 链（Chains）来组织网络包的处理规则（Rules）。按照从高到低的优先级，它默认定义了以下表和链： 防火墙规则的匹配顺序因为 iptables 是利用数据包过滤的机制， 所以它会分析数据包的表头数据，将表头数据与定义的规则做匹配，根据匹配结果来决定该数据包是否可以进入主机或者是被丢弃。 也就是说如果数据包能被防火墙规则匹配到就进行相应的动作（Target），否则就继续进行下一条规则的匹配，直到有一条规则能匹配到为止，而重点在于规则的匹配顺序。 假设我们在一台主机已经事先定义好了 10 条防火墙规则，那么当互联网中来了一个数据包想要进入这台主机时， 防火墙是如何分析和匹配这个数据包的呢？ 当数据包要进入到主机之前，会先经由 NetFilter 进行检查，也就是 iptables 规则。 检查通过则接受 (ACCEPT) 进入本机取得资源，如果检查不通过，则可能予以丢弃 (DROP) 。 上图主要是为了说明 规则是有顺序的，当数据包被 Rule 1 做匹配时， 如果数据包能被它匹配到，就进行 Action 1 的动作，而不会再被后续的 Rule 2, Rule 3…. 等做匹配了。 而如果这个数据包并没有被 Rule 1 匹配到，那就会开始进行 Rule 2 的匹配，同理数据包就会被一个一个规则做匹配，直到有一条规则能匹配到为止。 如果所有的规则都无法匹配到这个数据包，此时就会交给默认策略( Policy) 来决定数据包的去向。 所以一旦定义的规则顺序排列错误，那就会产生很严重的后果。 比如我们有一台 Linux 服务器提供 Web 服务，那么就要针对 port 80 来启用通过的规则，但是后来发现有一个来源为 192.168.100.100 的 IP 总是恶意地尝试入侵 Web 服务器，所以这时候应该编写规则将这个 IP 拒绝，其他将请求 Web 服务的数据包通过， 最后把所有的不是请求 Web 服务的数据包都给丢弃。就这三个规则而言，应该如何设定匹配顺序呢？ Rule 1 先把来自 192.168.100.100 的 IP 执行丢弃动作 DROP Rule 2 再让请求 Web 服务的数据包通过 Rule 3 将所有的数据包丢弃 这样的排列顺序就能符合我们的需求，一旦你没有搞清楚将顺序排错了，变成： Rule 1 先让请求 Web 服务的数据包通过 Rule 2 再把来自 192.168.100.100 的 IP 执行丢弃动作 DROP Rule 3 将所有的数据包丢弃 此时那个 192.168.100.100 将可以正常请求 Web 服务，因为它会被定义的第一条规则匹配到并且让它通过，一旦有一条规则匹配了，就不会再去进行第二条规则的匹配。 数据包的处理过程暂时不考虑由哪个表处理，在只看链处理过程的情况下，数据包一般是这样来处理的 其中路由判断是判断数据包的目标，也就是判断 Destination = localhost ?? 而实际上的处理过程比较复杂，数据包要经过多个 table 来处理。 对于 Web 服务器来说，要想让客户端对它发送 web 请求，就得处理 filter 的 INPUT 链； 对于用作局域网路由器的 Linux 来说，就得要分析 nat 的各个链以及 filter 的 FORWARD 链才行。 总而言之，各个表以及链之间是有关联的： 上面的图示很复杂，不过基本上 iptables 可以控制三种数据包的流向： 数据包进入 Linux 主机使用资源 (路径 A)，在路由判断后已经确定是向 Linux 主机发送请求的数据包，比如客户端向 web 服务器端发送的请求，主要会经过 filter 的 INPUT 链来进行处理； 数据包的目的地不是本机，而是经过本机做转发，没有使用本机的资源，向其后端主机流动 (路径 B)： 在路由判断之前进行数据包表头的修订作业后，发现到数据包主要是要经过防火墙而去后端，此时就会经过路径 B 来跑动。 主要经过的链是 nat 的 PREROUTING， filter 的 FORWARD 以及 nat 的 POSTROUTING。 数据包由本机发送出去 (路径 C)： 例如服务器端要响应客户端的请求，或者是本机作为客户端向其他服务器主动发送的数据包，都是经过路径 C 来处理的。先是经过路由判断， 决定了输出的路径后，再由 filter 的 OUTPUT 链来处理，当然最终还会经过 nat 的 POSTROUTING 链。 由于 mangle 这个表的过滤很少被使用，将上面图里 mangle 拿掉的话，那就容易看的多了： iptables命令iptables 命令用来编写规则，规则就是指向标，对不同的连接和数据包做过滤，或者允许它们去向什么地方。 它的语法格式如下： 1iptables [-t table] command CHAIN [match] [target/jump] [-t table] 用来指定要操作的表。一般情况下不是必须要指定使用的表，因为 iptables 不指定 table 就默认使用 filter 表来执行所有的命令。 command 告诉程序该做什么，比如插入一条规则还是追加一条规则，或者是删除一条规则。 CHAIN 说明了要操作哪一条链 match 来根据包的特点来匹配数据包，其中会细致地描述包的某个特点，比如来源 IP 地址，网络接口，端口，协议类型等，以使这个包区别于其它所有的包。 target/jump 说明了对 match 到的数据包做什么操作，或者告诉数据包它应该去往何处。若数据包符合所有的 match，内核就用 target 来处理它，或者说把包发往 target。比如我们可以让内核把包发送到当前表中的其他链（可能是自定义链），或者只是丢弃这个包而没有什么处理，或者向发送者返回某个特殊的应答信息。非常重要的一点是 target 指令必须在最后。 iptables 虽然不是服务但在红帽的 5 和 6 版本系统上有服务脚本 /etc/init.d/iptables，服务脚本的主要作用在于生效保存的规则，装载及移除相关内核模块： 123456iptable_natiptable_filteriptable_mangleiptable_rawip_natip_conntrack 在红帽 7 上 ip_nat 换为了 nf_nat ， ip_conntrack 换为了 nf_conntrack，并且它使用 firewalld.service 服务来处理数据包而没有 iptables.service，也没有服务脚本 1234567[root@m1 ~]# systemctl status firewalld.service iptables.service● firewalld.service - firewalld - dynamic firewall daemon Loaded: loaded (/usr/lib/systemd/system/firewalld.service; disabled; vendor preset: enabled) Active: inactive (dead) Docs: man:firewalld(1)Unit iptables.service could not be found.[root@m1 ~]# 如果想要使用 iptables.service ，通过 yum 直接安装即可 1yum install iptables-services tableraw raw 表优先级最高，它支持一个特殊的 target，即 TRACE ，使用内核记录下每条匹配该包的对应 iptables 规则信息。利用这个 target ，可以实现对 iptables 规则的跟踪调试。 1iptables -t raw -A OUTPUT -p icmp -j TRACE 使用 raw 表添加了 iptables 规则后，将不经过连接跟踪模块，一般是为了不让 iptables 做数据包连接追踪来达到提高性能的目的。比如一台访问量比较高的 web 服务器，可以让 80 端口不再经过 iptables 做数据包的链接跟踪处理，以提高用户的访问速度。 在 raw 表的规则处理完后，将跳过 nat 表和 nf_conntrack 处理，即不再做地址转换和数据包的链接跟踪处理。 1iptables -t raw -I PREROUTING -p tcp --dport 80 -j ACCEPT mangle 在 mangle 表中可以进行高级路由信息数据包的修改。不建议在这个表里做任何过滤性的操作，不管是 DNAT，SNAT 或 MASQUERADE。 nat Network Address Translation 简称 nat ，在 nat 表中主要用来实现网络地址转换，它处理源、目标 IP 和端口的转换，与本机资源无关。 filter filter 表用来匹配并过滤数据包，我们就是在这里根据包的内容对包做 DROP 或 ACCEPT 的。当然也可以预先在其他地方做些过滤，但是 filter 表才是设计用来做过滤的，所以说用它做过滤最合适不过了。 command使用 -L 或 --list 列出指定链中所有的规则，默认列出 filter 表中所有链的内容。. 1iptables -L 结合 -L 使用的还有几个附属选项，-n 或 --numeric 以数字形式显示地址和端口号，不对其进行解析。 1iptables -nL -v 或 --verbose 显示链及规则详细信息。 1iptables -vL --line-numbers 显示规则的序号 1iptables -L --line-numbers 最常用的情况是把这几个选项结合起来，使得其屏幕输出显得更人性化 12345iptables -vnL --line-numbersiptables -vnL INPUT --line-numbersiptables -t nat -vnLiptables -t nat -vnL PREROUTINGiptables -t nat -vnL PREROUTING --line-numbers -x 或 --exact 显示计数器的精确值而不是近似值 1iptables -vnL INPUT -x 使用 -P 或 --policy 设置指定链的默认策略，如果将默认策略设置为 DROP 时，请事先将自己信任的数据放行，比如 TCP 协议的 22 号端口，即 ssh 。在列出规则时，每一个链上都有一个 policy 的信息，它后面第一个字段就是默认的策略 123iptables -P INPUT ACCEPTiptables -P OUTPUT ACCEPTiptables -P FORWARD ACCEPT 使用 -I 或 --insert 在指定链中插入一条新的规则，默认在链的开头插入 123iptables -t filter -I INPUT -p tcp --dport 22 -j ACCEPTiptables -t filter -I INPUT -p tcp --dport 22 # 不写 -j target 将会交给默认策略处理iptables -t filter -I INPUT 5 -p tcp --dport 22 # 将规则插入到第五条 使用 -A 或 --append 在指定链的末尾处追加一条新的规则 1iptables -t filter -A INPUT -p tcp --dport 22 -j ACCEPT 使用 -D 或 --delete 删除指定链中的某条规则，可以按照内容确定要删除的规则 1iptables -t filter -D INPUT -p tcp --dport 22 -j ACCEPT 还可以根据规则的序号删除，规则删除后将重新进行编号，这一点一定要注意 12iptables -t filter -vnL INPUT --line-numbersiptables -t filter -D INPUT 3 使用 -R 或 --replace 修改、替换指定链中的一条规则，按规则序号或内容确定 1iptables -t filter -R INPUT 2 -p icmp -j ACCEPT 使用 -F 或 --flush 清空指定链中的所有规则，默认清空表中所有链的内容 1234iptables -t mangle -F# 清空 mangle 表中所有链中的规则iptables -t filter -F INPUT# 清空 filter 表中 INPUT 链中的所有规则 使用 -N 或 --new-chain 新建一条用户自己定义的规则链 12345678iptables -t filter -N DOCKER# 在 filter 表中新建一个名为 DOCKER 的自定义链iptables -t filter -I DOCKER -j ACCEPT# 在自定义的链 DOCKER 中添加对应匹配条件的处理规则iptables -t filter -I FORWARD -o docker0 -j DOCKER# 在 FORWARD 中添加规则，用来匹配符合条件的数据包，并将其交给自定义链处理 使用 -X 或 --delete-chain 删除指定表中用户自定义的规则链，如果自定义链被其他链中的规则引用则无法删除，需要提前将有引用的规则删除，并清空自定义链中的规则 1234iptables -X DOCKERiptables -D FORWARD -o docker0 -j DOCKERiptables -F DOCKERiptables -X DOCKER 使用 -E 或 --rename-chain 重命名自定义链 12iptables -N 'test-chain'iptables -E 'test-chain' 'TEST-CHAIN' 使用 -Z 或 --zero 将指定链中的所有规则的包字节计数器归零，不指定链则将所有链中的计数器置零 12iptables -Ziptables -Z INPUT 使用 -V 或 --version 查看 iptables 命令工具的版本信息 1iptables -V 使用 -h 或 --help 查看命令帮助信息 1iptables -h chain说到链还是得把简化的处理流程图再拿过来： 默认链 PREROUTING：进入 netfilter 后的数据包在进入路由判断前执行的规则 INPUT：路由判断后，目的地是本机，要进入本机内部获取本地服务资源 FORWARD：路由判断后目的地不是本机，经过本机做转发的数据包而执行的规则。与本机没有关联。 OUTPUT：由本机产生，需向外发的数据包执行的规则 POSTROUTING：路由判断后发送到网卡接口前，数据包准备离开 netfilter 时执行的规则 自定义链 自定义链必须在默认链调用后才能发挥作用，如果没有被自定义链中的任何规则匹配，还应该有返回机制。用户可以删除自定义的空链，但不可以删除默认链。 计数器 每一条规则都有两个内置的计数器，在 pkts 一列将会记录被规则被匹配到的报文个数，bytes 一列将会记录被匹配的报文大小之和 1234[root@study ~]# iptables -vnL INPUTChain INPUT (policy ACCEPT 1608 packets, 176K bytes) pkts bytes target prot opt in out source destination [root@study ~]# match匹配模式分为通用匹配和扩展匹配 通用匹配通用匹配适用于所有的规则，无需依赖模块，自己本身就能完成检查匹配。 匹配参数 说明 ！ 使用叹号对条件取反 -p,--protocol 指定协议（tcp，udp，icmp等），可使用all来指定所有协议 -s,--src,--source 指定数据包源地址，可使用IP地址、网络地址、主机名 -d,--dst,--destination 指定目的地址 -i,--in-interface 指定数据报文流入接口，用于PREROUTING、INPUT、FORWARD -o,--out-interface 指定数据报文流出接口，用于OUTPUT、POSTROUTING、FORWARD 使用 -i 或 -o 可以使用 + 做通配，比如 -i eth+ 指的是从 eth 网卡进入的数据包。 扩展匹配扩展匹配，需要依赖模块来完成检查匹配。扩展匹配比较特殊，其中有些专门针对不同的协议，还有一些针对的是状态（state），所有者（owner），访问的频率限制（limit）等。你可以通过 man iptables-extensions 查看相关的帮助。 扩展匹配又分为了隐式扩展和显式扩展 隐式扩展隐式扩展，不用特别指明由那个模块进行，当使用 -p {tcp|udp|icmp} 中的一种时，可以直接使用扩展专用选项 扩展条件 扩展选项 说明 -p tcp，--protocol tcp --sport，--source-port 来源端口，可以是连续的，例如 1024:65535 --dport，--destination-port 目的端口 --tcp-flags tcp 标志位 --syn 第一次握手 -p udp，--protocol udp --sport，--source-port 来源端口 --dport，--destination-port 目的端口 -p icmp，--protocol icmp --icmp-type icmp 类型 --tcp-flags mask comp 用于匹配 TCP 标志位。其中只检查 mask 指定的 TCP 的标志位（逗号分开的标志位列表），comp 表示此列表出现在 mask 中，且必须为 1。如果没有出现在 mask 中，而 comp 中出现的，必须为 0 匹配 TCP 三次握手的第一次，即匹配四个 TCP 标志位（SYN,FIN,ACK,RST），其中 SYN 为 1，其他为 0 123iptables -t nat -I PREROUTING -p tcp --tcp-flags SYN,FIN,ACK,RST SYN -j ACCEPT# 等价于iptables -t nat -I PREROUTING -p tcp --syn -j ACCEPT 再比如匹配四个 TCP 标志位（SYN,FIN,ACK,RST），其中 SYN 和 ACK 为 1，其他为 0 1iptables -t nat -I PREROUTING -p tcp --tcp-flags SYN,FIN,ACK,RST SYN,ACK -j ACCEPT --icmp-type 用来匹配 ICMP 报文类型，可以使报文类型代码。其中 8 等同于 echo-request， 0 等同于 echo-reply。 1234567# 允许本机能 ping 其他主机iptables -A OUTPUT -p icmp --icmp-type echo-request -j ACCEPTiptables -A INPUT -p icmp --icmp-type echo-reply -j ACCEPT# -----------------------------------------------# 允许其他主机能 ping 本机iptables -A INPUT -p icmp --icmp-type 8 -j ACCEPTiptables -A OUTPUT -p icmp --icmp-type 0 -j ACCEPT 代码的摘要，具体可以参考 rfc文档 以及 网络博客 1234567891011 0 Echo Reply 3 Destination Unreachable 4 Source Quench 5 Redirect 8 Echo11 Time Exceeded12 Parameter Problem13 Timestamp14 Timestamp Reply15 Information Request16 Information Reply 显式扩展显式扩展必须使用 -m 或 --match 选项指明是由哪个模块进行的扩展，此功能可以使用额外的匹配机制 -m state：状态扩展，结合 nf_conntrack 模块追踪回话的状态 --state 匹配连接的状态 NEW 新连接发起的请求 ESTABLISHED 已经建立的连接(即:对于新请求的响应) INVALID 非法连接请求 RELATED 相关连的连接(由命令发起，例如 ftp ) 1234iptables -t filter -I INPUT -p tcp --dport 22 -m state --state NEW -j ACCEPT# 将与本机新建立 ssh 连接的数据包放行iptables -t filter -I INPUT -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT# 状态为 NEW 或 ESTABLISHED 的 ssh 连接都放行 -m multiport：离散的多端口扩展 --source-ports，--sports 指定多个源端口 --destination-ports，--dports 指定多个目的端口 --ports 源和目的端口 12iptables -t filter -I INPUT -p tcp -m multiport --dports 21,22,80 -j ACCEPT# 将协议为 TCP 目标端口为 21,22,80 的数据包放行 -m iprange：匹配IP范围。 --src-range 匹配源 IP 范围 --dst-range 匹配目的 IP 范围 12iptables -t filter -I INPUT -m iprange --src-range 192.168.1.100-192.168.1.200 -j ACCEPT# 将来源IP范围是 192.168.1.100-192.168.1.20 的数据包放行 -m connlimit：连接数限定。 --connlimit-above n，匹配连接数达到 n，一般进行取反使用 12iptables -A INPUT -d 192.168.2.2 -p tcp --dport 80 -m connlimt !--connlimt-above 5 -j ACCEPT# 连接数未达到 5 个则放行，否则按默认规则处理（一般默认规则是丢弃） -m limit：令牌桶过滤器，不控制最大上限。 --limit n[/second|/minute|/hour|/day] 用来在单位时间内最多允许 n 个数据包，3/minute 表示每分钟最多 3 个 --limit-burst 来匹配峰值，即匹配蜂拥而至的连接数有多大，默认为 5 123iptables -I INPUT -d 192.168.2.2 -p icmp --icmp-type 8 -m limit --limit 5/minute --limit-burst 6 -j ACCEPTiptables -I INPUT -d 192.168.2.2 -p icmp --icmp-type 8 -j DROP # 目标为本机，协议为 icmp，限定每分钟最多可以连接5个(1/12s)，一批最高峰值为6个，即前6个速度比较快，后面的按照 5/minute 作回应 -m string：匹配请求的报文中的字符串，字符匹配检查高效算法：kmp， bm。 --algo {kmp|bm} 指定算 --string &quot;STRING&quot; 指定普通字符串 --hex-string &quot;HEX_STRING&quot;, 指定编码成16进制格式的字符串 1234iptables -I OUTPUT -s 192.168.2.2 -m string --algo kmp --string "H7N9" -j REJECT# 源地址为 192.168.2.2，并且报文中匹配到 H7N9 则丢弃iptables -I FORWARD -p tcp -m string --string "qq.com" --algo bm -j DROPiptables -I FORWARD -p udp -m string --string "qq.com" --algo bm -j DROP -m time：基于时间做访问控制，在有些限制时间段访问网络的情况下十分有用 --datestart YYYY[-MM][-DD[Thh[:mm[:ss]]]] 起始日期 --datestop YYYY[-MM][-DD[Thh[:mm[:ss]]]] 终止日期 --timestart hh:mm[:ss] 起始时间 --timestop hh:mm[:ss] 终止时间 --weekdays Sa[,Su] 一周中的哪些天 12iptables -I INPUT -d 172.16.100.7 -p tcp --dport 80 -m time --timestart 08:20 --timestop 18:40 --weekdays Mon,Tue,Thu,Fri -j REJECT# 周一、二、四、五的 8:20 到 18:40 禁止其他主机访问本机（172.16.100.7）的80端口 -m mac：基于包的 MAC 源地址做访问控制，它也可以用叹号 ! 取反。因为 MAC addresses 只用于 Ethernet 类型的网络，所以只能用于 Ethernet 接口。而且它只能在 PREROUTING，FORWARD 和 INPUT 链里使用。 --mac-source 指定源 MAC 地址，格式只能是 XX:XX:XX:XX:XX:XX， 1iptables -A FORWARD -m mac --mac-source 00:00:00:00:00:01 -j DROP 在局域网中如果有人在下载比较大的文件，会占用极大的带宽而影响到了其他人的网络访问，这时候我们在防火墙上针对这个来源的 IP 做 limit 或者直接 DROP 就好了，但是如果这个人发现自己被封网了，就自己指定了静态地址并且换了另外一个 IP ，这时候就需要针对 MAC 地址做限制了，限制了 MAC 来源之后，不管怎么换 IP 地址都无济于事。 -m comment：对规则做说明、注释 --comment &#39;string&#39; 指定注释为 string，注释最长 256 个字符 1iptables -A INPUT -s 192.168.1.0/24 -p tcp --dport 80 -j ACCEPT -m comment --comment "This is my local Lan" 添加了注释的规则，即便是在很久以后回头查看规则的时候你就能很直观地知道这个规则是用来做什么的 12345[root@m2 ~]# iptables -vnL INPUTChain INPUT (policy ACCEPT 34 packets, 3072 bytes) pkts bytes target prot opt in out source destination 0 0 ACCEPT tcp -- * * 192.168.1.0/24 0.0.0.0/0 tcp dpt:80 /* This is my local Lan */[root@m2 ~]# Targettarget 指的是由规则指定的操作，对规则匹配到的包做什么样的动作 ACCEPT使用 -j ACCEPT 放行，一旦数据包满足了指定的匹配条件就允许数据包通过，并且不会再去匹配当前链中的其他规则或同一个表内的其他规则，但它还要通过其他表中的链，而且在那儿可能会被 DROP 也说不准。 放行 TCP 协议目标端口是 22 的数据包 123iptables -t filter -I INPUT -p tcp --destination-port 22 -j ACCEPT# 等价于iptables -I INPUT -p tcp --dport 22 -j ACCEPT 放行本机到本机的连接 12iptables -A INPUT -i lo -j ACCEPTiptables -A OUTPUT -o lo -j ACCEPT DROP使用 -j DROP 丢弃，不做任何回应。在某些情况下，这个 target 会引起意外的结果，因为它不会向发送者返回任何信息，也不会向路由器返回信息，这就可能会使连接的另一方的 sockets 因苦等回音而亡。解决这个问题的较好的办法是使用 REJECT 1iptables -I INPUT -p tcp --dport 22 -j DROP 很多情况下我们并不期望所有的来源都能访问某些服务器，只允许一个或多个 IP ，一个或多个网段来访问。比如，在局域网中有一个 Web 服务器为 192.168.100.100，只允许 192.168.1.0/24 来访问，其他的拒绝。要实现这样的功能，在 Web 服务器上有两种做法，我们假设两种情况下的默认策略都是 ACCEPT 。 一种是先允许信任的地址段，最后再拒绝所有的。也就是说来自 192.168.1.0/24 匹配到第一条规则，否则就被第二条规则匹配到并丢弃 12iptables -t filter -A INPUT -p tcp -s 192.168.1.0/24 --dport 80 -j ACCEPTiptables -t filter -A INPUT -p tcp --dport 80 -j DROP 另一种则把不是我们信任的地址段直接丢弃，如果是信任的地址段就不会被这个规则匹配到，然后交给默认规则处理。看上去这种方法更好，一条就搞定了。 1iptables -t filter -A INPUT -p tcp ! -s 192.168.1.0/24 --dport 80 -j DROP 现在由于业务有了新的变动，需要再加入一个信任的地址段 192.168.2.0/24，于是你又按照第二种方法加入了一条规则 1iptables -t filter -A INPUT -p tcp ! -s 192.168.2.0/24 --dport 80 -j DROP 看上去把来源不是 192.168.1.0/24 内的包丢弃，然后再把来源不是 192.168.2.0/24 内的包丢弃就可以了，但是最后测试的时候你发现 Web 服务器好像谁都不能访问了。我们来分析一下原因： 当来源是 192.168.1.123 发起的请求时，第一条规则没有被匹配，继续向下走让第二条做匹配，匹配成功然后被丢弃，也就是上图中蓝色箭头所指向的方向 当来源是 192.168.2.123 发起的请求时，第一条规则匹配成功然后被丢弃，也就是上图中蓝色箭头所指向的方向 这样一来，不管谁来请求都被 DROP 掉了。所以应当使用第一种先允许再拒绝的方法 123iptables -t filter -A INPUT -p tcp -s 192.168.1.0/24 --dport 80 -j ACCEPTiptables -t filter -A INPUT -p tcp -s 192.168.2.0/24 --dport 80 -j ACCEPTiptables -t filter -A INPUT -p tcp --dport 80 -j DROP 当来源是 192.168.3.123 发起的请求时，第一条规则没有匹配到，然后交给第二条规则，也没有匹配到，再交给第三条规则，匹配成功然后被丢弃，也就是上图中蓝色箭头所指向的方向 REJECT使用 -j REJECT 拒绝数据包通过，并且向发送者返回错误信息。这个 target 只能用在 filter表中 INPUT、FORWARD、OUTPU和它们的子链里，而且包含 REJECT 的链也只能被它们调用，否则不能发挥作用。它只有一个选项 --reject-with，是用来控制返回的错误信息的种类的。可用的信息类型有： icmp-net-unreachable icmp-host-unreachable icmp-port-unreachable icmp-proto-unreachable icmp-net-prohibited icmp-host-prohibited 。 其中缺省的是 icmp-port-unreachable。 1iptables -I INPUT -p icmp -j REJECT --reject-with icmp-port-unreachable 另外一个类型是 tcp-reset，只能用于TCP协议。 它的作用是告诉 REJECT 返回一个 TCP RST 包（这个包以文雅的方式关闭TCP连接，正如 iptables 的 man page 中说的，tcpreset 主要用来阻止身份识别探针（即113/tcp，当向被破坏的邮件主机发送邮件时，探针常被用到，否则它不会接受你的信） 1iptables -I INPUT -p tcp --sport 113 -j REJECT --reject-with tcp-reset SNAT这个 target 是用来做来源IP地址转换的，就是重写包的源IP地址。SNAT 只能用在 nat 表的 POSTROUTING 链里。只要会话连接中的的第一个符合条件的包被 SNAT 了，那么这个连接的其他所有的包都会自动地被 SNAT，而且这个规则还会应用于这个连接所在流的所有数据包。 局域网中的主机想要通过防火墙访问互联网时，就需要用到它。先在内核里打开 ip 转发功能，然后再写一个 SNAT 规则，就可以把所有从本地网络出去的包的源地址改为外网地址了。如果不这样做而是直接转发本地网的包的话，互联网中的服务器发现是个内网 IP 发送过来的请求，就不知道往哪儿发送响应了，因为内网属于私有专用网络，不能在互联网上直接使用的。 在这里 SNAT 的作用就是让所有从局域网发出去的的包看起来都是从防火墙发出的。 123echo 1 &gt; /proc/sys/net/ipv4/ip_forward# 临时开启转发iptables -t nat -I POSTROUTING -o eth0 -s 192.168.1.0/24 -j SNAT --to 12.34.56.78 要永久开启转发需要编辑 /etc/sysctl.conf，并配置 net.ipv4.ip_forward = 1，再执行 sysctl -p 即可 如果一个网卡上有多个连续的 IP 还可以对一个范围内的 IP 做 SNAT，以达到负载均衡的效果，每个会话流被随机分配一个 IP，但对于同一个会话，在会话期间使用的是同一个 IP 。 1iptables -t nat -I POSTROUTING -o eth0 -s 192.168.1.0/24 -j SNAT --to 12.34.56.78-12.34.56.80 在指定 -p tcp 或 -p udp 的前提下在 SNAT 的时候还可以指定源端口的范围 1iptables -t nat -I POSTROUTING -p tcp -o eth0 -s 192.168.1.0/24 -j SNAT --to 12.34.56.78-12.34.56.80:1024-32000 这样的话包的源端口就被限制在 1024-32000了。注意，如果可能的话 iptables 总是想尽可能避免任何的端口的变更，也就是说，它总是尽力使用建立连接时所用的端口。 但是如果两台主机使用了相同的源端口，iptables 将会把他们的其中之一映射到另外的一个端口。如果没有指定端口范围， 所有的在 512 以内的源端口会被映射到 512 以内的另一个端口，512 和 1023 之间的将会被映射到 1024 内的另一个端口，其他的将会被映射到大于或等于于 1024 的另一个端口，即同范围映射。这种映射和目的端口无关，因此，如果客户端想要发送请求到防火墙外的 HTTP 服务器，它是不会被映射到 FTP 所用的端口的。 MASQUERADE这个 target 和 SNAT 的作用是一样的，但是它可以自动获得可用的 IP 而不是像 SNAT 那样需要指定 --to-source。 MASQUERADE 是被专门设计用于那些动态获取 IP 地址的连接的，比如拨号上网、DHCP连接等，这些情况下 SNAT 就会有很大的局限性。如果有固定的 IP 地址的话，最好还是用SNAT，因为 MASQUERADE 在获取可用 IP 的时候会带来额外的资源消耗。 另外，当网卡停用时 MASQUERADE 不会记住任何连接，而 SNAT 是会将连接跟踪的数据保留下来一段时间，并且 SNAT 会占用很多链接追踪的内存资源。 所以当 IP 地址是动态获取而不固定时，使用 MASQUERADE，有固定的 IP 地址时最好用 SNAT。 还要注意 MASQUERADE 和 SNAT 一样，只能用于 nat 表的 POSTROUTING 链。它也可以指定源端口或范围，如果是指定单个端口用 --to-ports 1025，指定端口范围用 --to-1024-3000 12iptables -t nat -I POSTROUTING -o eth0 -s 192.168.1.0/24 j MASQUERADE# 不管现在 eth0上获得了怎样的动态 IP，使用 MASQUERADE 都会自动读取网卡上可用 IP 然后做 SNAT 出去，这样就实现了很好的动态SNAT地址转换 DNAT这个 target 是用来做目标 IP 地址转换的，就是重写包的目的 IP 地址。如果一个包被匹配了，那么和它属于同一个流的所有的包都会被自动转换，然后就可以被路由到正确的主机或网络。目的地址也可以是一个范围，这样的话 DNAT会为每一个流随机分配一个地址。因此可以用这个 target 做某种类型的负载均衡。为了便于理解，下面阐述为映射。 注意，DNAT 必须在 POSTROUTING 之前进行，因为交给 POSTROUTING 的时候目标地址就已经确定了，此时做 DNAT 已经为时已晚。并且 DNAT 只能用在 nat 表的 PREROUTING 和 OUTPUT 链中，或者是被这两条链调用的链里。 如图所示，如果你的 Web 、MySQL、FTP 服务器在局域网内部，而且没有外网 IP 地址，那就可以使用这个 target 让防火墙把所有到它自己的端口的分别映射到局域网内部的各个主机上。 123iptables -t nat -I PREROUTING 1 -p tcp -d 12.34.56.78 --dport 80 -j DNAT --to 192.168.1.101:80iptables -t nat -I PREROUTING 2 -p tcp -d 12.34.56.78 --dport 3306 -j DNAT --to 192.168.1.102:3306iptables -t nat -I PREROUTING 3 -p tcp -d 12.34.56.78 --dport 21 -j DNAT --to 192.168.1.103:21 在默认情况下，很多服务器的 SSH 服务都监听在 22 号端口，如果是 ssh 到局域网的一台服务器查看配置，执行一些维护命令该怎么办呢？ 第一个想到的就是按照刚才的方式再做 22 端口的映射 123iptables -t nat -I PREROUTING 1 -p tcp -d 12.34.56.78 --dport 22 -j DNAT --to 192.168.1.101:22iptables -t nat -I PREROUTING 2 -p tcp -d 12.34.56.78 --dport 22 -j DNAT --to 192.168.1.102:22iptables -t nat -I PREROUTING 3 -p tcp -d 12.34.56.78 --dport 22 -j DNAT --to 192.168.1.103:22 根据匹配规则的顺序，结果可想而知，最后只映射到了局域网其中一台机器上。当再次 ssh 连接 Firewall 时发现连接的却是其他机器，这是因为到它的 ssh 连接被 DNAT 到了局域网内部的主机，这显然是不切合实际的。要解决这个问题，除了修改 SSH 服务的端口号，还可以在 Firewall 上映射不同端口到不同机器的 22 端口 123456iptables -t nat -I PREROUTING 1 -p tcp -d 12.34.56.78 --dport 1231 -j DNAT --to 192.168.1.101:22# 1231 端口映射为 Web Server 的 22 端口iptables -t nat -I PREROUTING 2 -p tcp -d 12.34.56.78 --dport 1232 -j DNAT --to 192.168.1.102:22# 1232 端口映射为 MySQL Server 的 22 端口iptables -t nat -I PREROUTING 3 -p tcp -d 12.34.56.78 --dport 1233 -j DNAT --to 192.168.1.103:22# 1233 端口映射为 FTP Server 的 22 端口 由此一来，想要 ssh 连接局域网内部多个主机只需要指定对应的端口号就可以了。 对于访问量比较高的 Web 服务器，可以通过 Squid 做缓存来提高访问效率。通常会把客户端发送的资源请求映射到 Squid 缓存服务器上，如果没有现有的缓存则回源站服务器请求。 12iptables -t nat -I PREROUTING 1 -p tcp -d 12.34.56.78 --dport 80 -j DNAT --to 192.168.1.106:3128iptables -t nat -I PREROUTING 2 -p tcp -d 12.34.56.78 --dport 443 -j DNAT --to 192.168.1.106:3128 在规则越来越多的时候，要匹配的规则就会越来越多，处理速度就会随之越来越慢，所以规则的精简是十分重要的，上面的规则可以使用 multiport 简化为一条： 1iptables -t nat -I PREROUTING 1 -p tcp -d 12.34.56.78 -m multiport --dports 80,443 -j DNAT --to 192.168.1.106:3128 现在，我们已经把所有从互联网来的到防火墙的 1232 端口去的包都映射到在局域网内部的 MySQL 服务器的 22 端口上，并且在这之前为了能让内网访问外网我们还做了 SNAT。如果在外网机器上试验一下，一切正常。但是再从内网机器里试验一下，却完全不能用，这其实是路由的问题。下面我们来好好分析这个问题。 包从 User1 发起，他的外网是 1.2.3.4 ，向 12.34.56.78 的 1232 端口发送请求 包到达防火墙，然后被防火墙做 DNAT，目标变成了向 192.168.1.102 的 22 端口发送请求 防火墙转发这个包，而且包会经过很多其他的链检验及处理 包离开防火墙走并到达 192.168.102，即 MySQL 服务器 此时 MySQL 服务器看到的来源没有变化，还是 1.2.3.4 MySQL 服务器试图进行数据包的响应，此时变成了 MySQL 作为源，User1 作为目标进行响应 MySQL 服务器在路由数据库中看到他要响应的目标是 1.2.3.4 ，这属于来自外网的一个IP（scope global），因此经过默认网关，即防火墙做出响应。一般情况下，防火墙就是内网服务器的缺省网关。 防火墙再对返回包做 SNAT，这样 User1 看到的就是防火墙回复了之前的请求。 那么，从局域网内部发起的请求时如何处理的呢？ 包从 User2 发起，他的地址为局域网的 192.168.1.110，向 12.34.56.78 的 1232 端口发送请求，上图绿色箭头 包到达防火墙，然后被防火墙做 DNAT，目标变成了向 192.168.1.102 的 22 端口发送请求 防火墙转发这个包，而且还会经过其他的处理。 包离开防火墙走并到达 192.168.102，即 MySQL 服务器，上图红色箭头 此时 MySQL 服务器看到的来源没有变化，还是 192.168.1.110 MySQL 服务器试图进行数据包的响应，此时变成了 MySQL 作为源，User2 作为目标进行响应 MySQL 服务器试图响应这个包，但是它在路由数据库中看到包是来自同一个网络的 192.168.1.110 ，也就是 User2，这属于直连网络（scope link）不需要防火墙转发 。因此 MySQL 服务器会把响应的包直接发送给 User2 。上图黑色箭头 响应的包的确到达了 User2，但它会很困惑，因为他是把请求发送给了防火墙，结果防火墙没有响应自己，却莫名其妙收到了一个其他机器的包。这样肯定没有办法建立连接，但 User2 会等待防火墙的响应，最终超过指定的时间会话被关闭（Connection timed out）。 这就是 IP 传输包的特点，只根据目的地的不同改变目的地址，但不因传输过程中要经过很多路由器而随着路由器改变其源地址，除非你单独进行源地址的改变。其实这一步的处理和对外来包的处理是一样的，只不过内网包的问题就在于此。 针对这个问题有个简单的解决办法，因为这些包都要进入防火墙，而且它们都去往需要做 DNAT 才能到达的那个地址，所以我们只要对做了 DNAT 的这些包再做 SNAT 操作即可。 12iptables -t nat -I PREROUTING 1 -p tcp -d 12.34.56.78 --dport 1232 -j DNAT --to 192.168.1.102:22iptables -t nat -I POSTROUTING 1 -p tcp -d 192.168.1.102 --dport 22 -j SNAT --to 192.168.1.100 对照规则和上面的流程图你应该很容易就搞清楚是到底如何工作的了。 REDIRECT这个 target 把要转发的包的目的地址改写为我们自己机器的 IP 和端口，这个在局域网中相当于做了透明代理，客户机根本不知道有代理的存在，并且可以正常上网。 REDIRECT 只能用在 nat 表的 PREROUTING、OUTPUT 链和被它们调用的自定义链里。它只有一个选项 --to ，其完整格式是 --to-ports 在使用 -p tcp 或 -p udp 的前提下，有三种指定端口的方式：1、不使用这个选项，目的端口不会被改变2、指定一个端口，用 --to-ports 80803、指定端口范围，用 --to-ports 8080-8090 别人都使用 80 端口提供 Web 服务，如果你想要把 8080 映射到自己的 80 而不是直接 80 对外提供 Web 服务，用 REDIRECT 就能完美地解决这个问题，本机生成的包都会被映射到 127.0.0.1 1iptables -t nat -I PREROUTING -p tcp --dport 8080 -j REDIRECT --to 80 RETURN它使包返回上一层，顺序是：子链 =&gt; 父链 =&gt; 默认策略。具体地说，就是若包在子链中遇到了 RETURN，则返回父链的下一条规则继续进行匹配，若是在父链（或称主链，比如INPUT）中遇到了RETURN，就要被缺省的策略（一般是ACCEPT或DROP）操作了。 举个例子说明一下，假设一个包进入了 INPUT 链，匹配了某条规则并且 target 为 -j DOCKER ，然后数据包进入了子链 DOCKER 。在子链中又匹配了某条规则，恰巧 target 为 -j RETURN，那包就返回父链 INPUT 链并继续进行下一条规则的匹配。如果在 INPUT链里又遇到了 -j RETURN，那这个包就要被缺省的策略（一般是ACCEPT 或 DROP）处理了。 TOSTOS 是用来设置 IP 头中的 Type of Service 字段的。这个字段长一个字节，可以控制包的路由情况。它也是 iproute2 及其子系统可以直接使用的字段之一。值得注意的是，如果你有几个独立的防火墙和路由器，而且还想在他们之间利用包的头部来传递路由信息，TOS 是唯一的办法。 -p 选项除了可以指定 tcp 或 udp 还可以使用协议号来代替协议，比如： 123iptables -I INPUT -p 6 -j ACCEPT# 等价于iptables -I INPUT -p tcp -j ACCEPT 不同的协议都有各自的协议号，具体可以参照本篇文章末尾的表格 TOS 只能在 mangle 表内使用，要想设置 TOS 的值，值的形式可以是名字或者使相应的数值（十进制或16进制的）。一般情况下，建议使用名字而不使用数值形式，因为以后这些数值可能会有所改变， 而名字一般是固定的。TOS 字段有 8 个二进制位，所以可能的值是 0-255（十进制）或 0x00-0xFF（16进制）。 123iptables -t mangle -I PREROUTING -p 135 -m tos ! --tos 0 -j TOS --set-tos=0iptables -t mangle -I PREROUTING -p 47 -m tos ! --tos 0 -j TOS --set-tos=0iptables -t mangle -A PREROUTING -p tcp --dport 22 -j TOS --set-tos 0x10 如前所述，最好使用预定义的值：1、Minimize-Delay 16 (0x10)，要求找一条路径使延时最小，一些标准服务如 telnet、SSH、FTP- control 就需要这个选项。2、Maximize-Throughput 8 (0x08)，要求找一条路径能使吞吐量最大，标准服务 FTP-data 能用到这个。3、Maximize-Reliability4 (0x04)，要求找一条路径能使可靠性最高，使用它的有 BOOTP 和 TFTP。4、Minimize-Cost 2 (0x02)，要求找一条路径能使费用最低，一般情况下使用这个选项的是一些视频音频流协议，如RTSP（Real Time Stream Control Protocol）。5、Normal-Service 0 (0x00)，一般服务，没有什么特殊要求。这个值也是大部分包的缺省值。 完整的列表可以通过命令 iptables -j TOS -h 得到 1234567891011TOS target vlibxtables.so.10 options: --set-tos value[/mask] Set Type of Service/Priority field to value (Zero out bits in mask and XOR value into TOS) --set-tos symbol Set TOS field (IPv4 only) by symbol (this zeroes the 4-bit Precedence part!) Accepted symbolic names for value are: (0x10) 16 Minimize-Delay (0x08) 8 Maximize-Throughput (0x04) 4 Maximize-Reliability (0x02) 2 Minimize-Cost (0x00) 0 Normal-Service TTLTTL 可以修改 IP 头中 Time To Live 字段的值。它有很大的作用，我们可以把所有外出包的 Time To Live 值都改为一样的，比如 64，这是 Linux 的默认值。 有些 ISP 不允许我们共享连接（他们可以通过 TTL 的值来区分是不是有多个机器使用同一个连接），如果我们把 TTL 都改为一样的值，他们就不能再根据 TTL 来判断了。 TTL 只能在 mangle 表内使用，它有 3 个选项 1234TTL target options --ttl-set value Set TTL to &lt;value 0-255&gt; --ttl-dec value Decrement TTL by &lt;value 1-255&gt; --ttl-inc value Increment TTL by &lt;value 1-255&gt; --ttl-set 用来设置 TTL 的值。 这个值不要太大也不要太小，大约 64 就很好。值太大会影响网络，而且有点不道德，为什么这样说呢？如果有些路由器的配置不太正确，包的 TTL 又非常大，那它们就会在这些路由器之间往返很多次，值越大，占用的带宽越多。这个 target 就可以被用来限制包能走多远，一个比较恰当的距离是刚好能到达 DNS 服务器的距离。 1iptables -t mangle -A PREROUTING -i eth0 -j TTL --ttl-set 64 --ttl-dec 设定 TTL要被减掉的值 1iptables -t mangle -I PREROUTING -i eth1 -j TTL --ttl-dec 3 假设一个进来的包的 TTL 是 53，那么当它离开我们这台机子时，TTL 就变为 49 了。为什么不是 50 呢？ 因为经过我们这台机器，TTL 本身就要减 1，还要被 iptables 的 TTL 再减 3，当然总共就是减去 4 了。 使用这个 target 可以限制“使用我们的服务的用户” 离我们有多远。比如用户总是使用比较近的 DNS，那我们就可以对我们的 DNS 服务器发出的包进行几个 --ttl-dec。意思也就是，我们只想让距离 DNS 服务器近一些的用户访问我们的服务，当然用 --set-ttl 控制会更方便。 --ttl-inc 设定 TTL 要被增加的值 1iptables -t mangle -A PREROUTING -i eth0 -j TTL --ttl-inc 4 假设一个进来的包的 TTL 是 53，那么当它离开我们这台机子时，TTL 应是多少呢？答案是 53+4-1=56，原因同 --ttl-dec。 在防火墙上没有操作 TTL 之前，从局域网的机器使用 traceroute 做路由追踪可以看到经过了防火墙（网关） 1234567891011traceroute to 182.61.200.7 (182.61.200.7), 30 hops max, 60 byte packets 1 192.168.1.101 0.237 ms 0.224 ms 0.440 ms 2 192.168.127.2 0.403 ms 0.364 ms 0.310 ms 3 * * * 4 * * * 5 * * * 6 * * * 7 * * * 8 * * * 9 * * *10 * * * 使用 --ttl-inc 这个选项可以使我们的防火墙更加隐蔽，而不被 traceroute 发现， 方法就是设置 --ttl-inc 1 。原因很简单，数据包每经过一个路由器，TTL 就要自动减 1，但在我们的防火墙里这个 1 又被补上了，也就是说 TTL 的值没变，那么 traceroute 就会认为我们的防火墙是不存在的。 1234567891011traceroute to 182.61.200.7 (182.61.200.7), 30 hops max, 60 byte packets 1 * * * 2 * * * 3 * * * 4 * * * 5 * * * 6 * * * 7 * * * 8 * * * 9 * * *10 * * * 实际上使用三个选项中的任意一个，只要修改了 TTL 的值就可以不被 traceroute 追踪到。 MARK为数据包做 mark 标记，这个值只能在 mangle 表里使用。因为 mark 比较特殊，它不是包本身的一部分，而是在包穿越计算机的过程中由内核分配的和它相关联的一个字段。它可以和本地的高级路由功能联用，以使不同的包能使用不同的策略路由，队列要求等等。 12345iptables -t mangle -I PREROUTING -p tcp -s 10.0.0.0/8 -d 31.13.95.48 --dport 80 -j MARK --set-mark 2# 对相应符合条件的数据包进行标记 ip rule add fwmark 2 lookup 12 prio 997# 对标记的数据包做策略路由 TCPMSS在 ip foward 的时候内核会检查 mss 和 mtu 值来决定是否分片，而 mss 和 tcp 连接有关。为达到最佳的传输效能 TCP 在建立连接时会协商 MSS（最大分段长度，一般为1460字节）值，即 MTU（最大传输单元，不超过1500字节）减去 IP 数据包包头 20 字节和 TCP 数据包头 20 字节，取最小的 MSS 值为本次连接的最大 MSS 值。一般 tcp 通信中一些数据包不允许分片，所以需要在发送的时候，直接发送一个比较小的数据报文，不然就会被网络处理的时候丢弃掉。在 ADSL 拨号环境中由于 PPP 包头占用 8 字节，MTU 为 1492 字节，MSS 为 1452 字节，如果不能正确设置会导致网络不正常。 iptables 中 TCPMSS 就是用来调整 TCP 数据包中 MSS 的数值的，配合使用的有两个选项 123TCPMSS target mutually-exclusive options: --set-mss value explicitly set MSS option to specified value --clamp-mss-to-pmtu automatically clamp MSS value to (path_MTU - 20) --set-mss value 将设置手动指定的 MSS 值 1234iptables -t mangle -I PREROUTING -i pppoe-wan -p tcp --tcp-flags SYN,FIN,ACK,RST SYN -j TCPMSS --set-mss 1360# 从 pppoe-wan 进来，握手信号的包iptables -t mangle -I POSTROUTING -o pppoe-wan -p tcp --tcp-flags SYN,FIN,ACK,RST SYN,ACK -j TCPMSS --set-mss 1360# 从 pppoe-wan 出去，响应握手信号的包 --clamp-mss-to-pmtu 将根据 MTU 自动调整 MSS，它只能用在 FORWARD, OUTPUT 和 POSTROUTING 链 1iptables -t mangle -I POSTROUTING -o pppoe-wan -p tcp --tcp-flags SYN,FIN,ACK,RST SYN -j TCPMSS --clamp-mss-to-pmtu 如果想匹配指定的 MSS 范围的包，并且把它的 MSS 值改为特定的，则需要依赖于显示扩展的 tcpmss 模块 12iptables -t mangle -I PREROUTING -i ppp+ -p tcp --syn -m tcpmss --mss 1400:1500 -j TCPMSS --set-mss 1360iptables -t mangle -I POSTROUTING -o ppp+ -p tcp --tcp-flags SYN,FIN,ACK,RST -m tcpmss --mss 1400:1500 -j TCPMSS --set-mss 1360 LOG这个 target 是专门用来记录包的有关信息的。这些信息可能是非法的，那就可以用来除错。LOG 会返回包的有关细节，如 IP 头的大部分和其他有趣的信息。这个功能是通过内核的日志工具完成的，一般是 rsyslogd。返回的信息可用 dmesg 阅读，或者可以直接查看 rsyslogd 的日志文件，也可以用其他的什么程序来看。 LOG 对调试规则有很大的帮助，你可以看到包去了哪里、经过了什么规则的处理，什么样的规则处理什么样的包，等等。当你在生产服务器上调试一个不敢保证 100% 正常的规则集时，用 LOG 代替 DROP 是比较好的，有详细的信息可看，错误就容易定位解决了。 LOG 有5个选项，你可以用它们指定需要的信息类型或针对不同的信息设定一 些值以便在记录中使用。 123456LOG target options: --log-level level Level of logging (numeric or see syslog.conf) --log-prefix prefix Prefix log messages with this prefix. --log-tcp-sequence Log TCP sequence numbers. --log-tcp-options Log TCP options. --log-ip-options Log IP options. --log-level 告诉 iptables 和 rsyslog 使用哪个记录等级。记录等级的详细信息可以查看文件 /etc/rsyslog.conf，一般来说有以下几种，它们的级别依次是：debug，info，notice，warning，warn，err，error，crit，alert， emerg，panic。其中，error 和 err、warn 和 warning、panic 和 emerg 分别是同义词，也就是说作用完全一样的。这三种级别的信息量太大，所以不太建议使用。信息级别说明了被记录信息所反映的问题的严重程度。所有信息都是通过内核的功能被记录的。 先在文件 /etc/rsyslog.conf 里设置 kern.=info /var/log/iptables，然后再让所有关于 iptables 的 LOG 信息使用级别 info，就可以把所有的信息存入文件 /var/log/iptables 内。其中也可能会有其他的信息，它们是内核中使用 info 这个等级的其他部分产生的。如果你不想这样做，那么所有日志默认在 /var/log/messages 文件中记录，然后将数据包传递给下一条规则。 12iptables -I INPUT -p ICMP -j LOG --log-level infoiptables -I INPUT -p ICMP -j LOG --log-level notice 在其他机器做 ping 测试后，回来查看 tail /var/log/messages 你将看到相关的日志信息。 --log-prefix 告诉 iptables 在记录的信息之前加上指定的前缀。这样用 grep 或其他工具就容易追踪特定的问题，而且也方便从不同的规则输出。前缀最多能有 29 个英文字符，这已经是包括空白字符和其他特殊符号的总长度了。 1iptables -I INPUT -p ICMP -j LOG --log-level info --log-prefix "INPUT icmp packets: " --log-tcp-sequence 把包的 TCP 序列号和其他日志信息一起记录下来。TCP 序列号可以唯一标识一个包，在重组时也是用它来确定每个分组在包里的位置。注意，这个选项可能会带来危险， 因为这些记录被未授权的用户看到的话，可能会使他们更容易地破坏系统。其实任何 iptables 的输出信息都增加了这种危险，“言多必失”，“沉默是金”。 1iptables -A INPUT -p tcp -j LOG --log-tcp-sequence --log-tcp-options 记录 TCP 包头中的字段大小不变的选项。这对一些除错是很有价值的，通过它提供的信息，可以知道哪里可能出错，或者哪里已经出了错。 1iptables -A FORWARD -p tcp -j LOG --log-tcp-options --log-ip-options 记录IP包头中的字段大小不变的选项。这对一些除错是很有价值的，还可以用来跟踪特定地址的包。 1iptables -A FORWARD -p tcp -j LOG --log-ip-options 连接跟踪机制 conntrack在 iptables 里，包是和被跟踪连接的四种不同状态有关的。它们是 NEW，ESTABLISHED，RELATED 和 INVALID 。使用 --state 匹配操作，就能很容易地控制 “谁或什么能发起新的会话”。 所有在内核中由 Netfilter 的特定框架做的连接跟踪称作 conntrack（connection tracking）。 除了本机产生的包由 OUTPUT 链处理外，所有连接跟踪都是在 PREROUTING 链里进行处理的，也就是说 iptables 会在 PREROUTING 链里重新计算所有的状态。如果我们发送一个初始包出去，状态就会在 OUTPUT 链里被设置为 NEW，当我们收到回应的包时，状态就会在 PREROUTING 链里被设置为 ESTABLISHED。如果第一个包不是本机产生的，那就会在 PREROUTING 链里被设置为 NEW 状态。 nf_conntracknf_conntrack 是 Linux 内核 NAT 的模块，实时记录当前主机上 client 和 server 彼此建立的连接关系，且可以追踪某个连接和其他某个连接处于何种状态，既可以追踪 TCP 协议，也可以追踪 UDP 协议和 ICMP 协议。 默认的 timeout 是 432000秒（五天）。每个 nf_conntrack 记录约会占用 292 Bytes 的内存，所以系统所能记录的nf_conntrack 也是有限的，如果超过了这个限度，就会出现内核级错误 nf_conntrack: table full, dropping packet，其结果就是无法再有任何的网络连接了。另外，在使用 iptables 命令查看 nat 表时，由于内核模块的依赖关系，将会自动激活 nf_conntrack 模块，如果在访问量非常繁忙的服务器上执行此操作将会导致大量请求被丢弃。这时候就需要修改它能记录的最大值了。你也可以在 /proc/sys/net/nf_conntrack_max 里查看、设置，也可以编辑文件 /etc/sysctl.conf 来实现。 conntrack记录在 /proc/net/nf_conntrack 中记录了当前被跟踪的连接 12ipv4 2 tcp 6 300 SYN_SENT src=192.168.127.1 dst=192.168.127.131 sport=3069 dport=22 \[UNREPLIED] src=192.168.127.131 dst=192.168.127.1 sport=22 dport=3069 [ASSURED] mark=0 zone=0 use=2 通过这个文件就可以知道某个特定的连接处于什么状态。首先显示的是协议，这里是 tcp，接着是十进制的 6 即 tcp 的协议类型代码。之后的 300 是这条 conntrack 记录的生存时间，它会有规律地被消耗，直到收到这个连接的更多的包。那时这个值就被设为当时那个状态的缺省值。接下来的是这个连接在当前时间点的状态。上面的例子说明这个包处在 SYN_SENT 状态，这个值是 iptables 显示的，以便我们好理解，而内部用的值稍有不同。SYN_SENT 说明我们正在观察的这个连接只在一个方向发送了一 TCP SYN 包。再下面是源地址、目的地址、源端口和目的端口。其中有个特殊的词 UNREPLIED，说明这个连接还没有收到任何回应。最后是希望接收的应答包的信息，他们的地址和端口和前面是相反的。 连接跟踪记录的信息依据 IP 所包含的协议不同而不同，所有相应的值都是在头文件中定义的，即 1/usr/include/linux/netfilter/nf_conntrack*.h 当一个连接在两个方向上都有传输时，conntrack 记录就删除 [UNREPLIED] 标志，然后重置。在末尾有 [ASSURED] 的记录说明两个方向已没有流量。这样的记录是确定的，在连接跟踪表满时，是不会被删除的， 没有 [ASSURED] 的记录就要被删除。连接跟踪表能容纳多少记录是被一个变量控制的，它可由内核中的 ip- sysctl 函数设置。默认值取决于你的内存大小，128MB 可以包含 8192 条目录，256MB 是 16376 条。所以，需要合理调整 nf_conntrack_max 的值。 数据包在用户空间的状态NEW 说明这个包是我们看到的第一个包。意思就是这是 conntrack 模块看到的某个连接第一个包，它即将被匹配了。比如我们看到一个 SYN 包，是我们所留意的连接的第一个包，就要匹配它。第一个包也可能不是 SYN 包，但它仍会被认为是 NEW 状态。 ESTABLISHED 已经注意到两个方向上的数据传输，而且会继续匹配这个连接的包。只要发送请求并收到响应，连接就是 ESTABLISHED 的了。一个连接要从 NEW 变 为 ESTABLISHED，只需要接到响应包即可，不管这个包是发往防火墙的，还是要由防火墙转发的。ICMP 的错误和重定向等信息包也被看作是 ESTABLISHED，只要它们是发出请求后得到的响应。 RELATED 当一个连接和某个已处于 ESTABLISHED 状态的连接有关系时，就被认为是 RELATED 的了。换句话说，一个连接要想是 RELATED 的，首先要有一个 ESTABLISHED 的连接。这个 ESTABLISHED 连接再产生一个主连接之外的连接，这个新的连接就是 RELATED 的了，当然前提是 conntrack 模块要能理解 RELATED。ftp 就是个很好的例子，FTP-data 连接就是和 FTP-control 有 RELATED 的。注意，大部分还有一些 UDP 协议都依赖这个机制。这些协议是很复杂的，它们把连接信息放在数据包里，并且要求这些信息能被正确理解。 INVALID 说明数据包不能被识别属于哪个连接或没有任何状态。有几个原因可以产生这种情况，比如，内存溢出，收到不知属于哪个连接的 ICMP 错误信息。一般这种状态的数据包都最好 DROP 。 这些状态可以一起使用，以便匹配数据包。这可以使我们的防火墙非常强壮和有效。以前我们经常打开 1024 以上的所有端口来放行应答的数据。现在有了状态机制就不需再这样了。因为我们可以只开放那些有应答数据的端口，其他的都可以关闭，这样就安全多了。 对于本机 SSH 服务的 22 号端口，就可以通过状态机制处理了。 1234iptables -I INPUT -d 192.168.2.133 -p tcp --dport 22 -m state --state NEW,ESTABLISHED -j ACCEPT# 将目的地为本机，目的端口 22，状态为新请求或者已建立的连接放行iptables -A OUTPUT -s 192.168.2.133 -m state --state ESTABLISED -j ACCEPT# 将本机发出去的，状态为已建立的连接放行 对于 FTP 连接的规则，需要事先装载 nf_conntrack_ftp 和 nf_nat_ftp 模块 1234modprobe nf_conntrack_ftpmodprobe nf_nat_ftpiptables -A INPUT -d 192.168.2.133 -p tcp -m state --state ESTABLISHED,RELATED -j ACCEPTiptables -I OUTPUT -s 192.168.2.133 -m state --state ESTABLISHED,RELATED -j ACCEPT 规则的保存和恢复iptables 提供了两个工具来处理大规则集： iptables-save 和 iptables-restore，iptables-save 用来把规则集保存到一个特殊格式的文本文件里，而 iptables-restore 是用来把这个文件重新装入内核空间的。 处理效率使用 iptables-save 和 iptables-restore 的一个最重要的原因是，它们能提高装载、保存规则的速度。 iptables-save 运行一次就可以把整个规则集从内核里提取出来，并保存到文件里，而 iptables-restore 是每次将规则装入一个表。使用脚本更改规则的问题是，改动每个规则都要调用 iptables 命令，而每一次调用 iptables，它首先要把 Netfilter 内核空间中的整个规则集都提取出来， 然后再插入或追加，或做其他的改动，最后再把新的规则集从它的内存空间插入到内核空间中。相对于一次操作一个表而言，这会花费很多时间。 iptables-restore的不足iptables-restore 最大的缺点就是不能替代所有的脚本来设置规则，也就是不能用来做复杂的规则集。最常见的情况就是，一个动态获取 IP 的主机，使用脚本就可以很方便地得到这个 IP，用 iptables-restore 却是无法实现的。 有一个笨办法是先装入 iptables-restore 文件，再运行一个特定的脚本把动态的规则载入。虽然可行，但是 iptables-restore 并不适合于使用动态 IP 的场合，如果你想在配置文件里使用选项来实现不同的要求，iptables-restore 也不适用。 iptables-saveiptables-save 用来把当前的规则存入一个文件里以备 iptables-restore 使用。它的使用很简单，只有两个参数： 1iptables-save [-c] [-t table] 使用 -c 保存包和字节计数器的值，这可以使我们在重启防火墙后不丢失对包和字节的统计。默认情况下是不保存的计数器的数值的。 使用 -t 指定要保存的表，默认是保存所有的表。 1234567891011121314151617181920212223# Generated by iptables-save v1.2.6a on Wed Apr 24 10:19:17 2002*filter:INPUT ACCEPT [404:19766]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [530:43376]COMMIT# Completed on Wed Apr 24 10:19:17 2002# Generated by iptables-save v1.2.6a on Wed Apr 24 10:19:17 2002*mangle:PREROUTING ACCEPT [451:22060]:INPUT ACCEPT [451:22060]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [594:47151]:POSTROUTING ACCEPT [594:47151]COMMIT# Completed on Wed Apr 24 10:19:17 2002# Generated by iptables-save v1.2.6a on Wed Apr 24 10:19:17 2002*nat:PREROUTING ACCEPT [0:0]:POSTROUTING ACCEPT [3:450]:OUTPUT ACCEPT [3:450]COMMIT# Completed on Wed Apr 24 10:19:17 2002 上面的输出格式中 # 后面的是注释，表都以 *&lt;table-name&gt; 开始。每个表都包含链和规则，链的详细说明是 &lt;chain-name&gt; &lt;chain-policy&gt; [&lt;packet-counter&gt;:&lt;byte-counter&gt;]。每个表的描述都以关键字 COMMIT 结束，在 iptables-restore 的时候遇到它就说明此时要把规则装入内核了。 默认情况下命令的执行结果会输出到屏幕，想要保存到文件，直接输出重定向即可： 1iptables-save -c &gt; /etc/iptables.save iptables-restoreiptables-restore 用来载入由 iptables-save 保存的规则集。它不能直接读取文件，只能通过标准输入重定向载入规则。 1iptables-restore [-c] [-n] 使用 -c 要求载入包和字节计数器，如果你用 iptables-save 保存了计数器，现在想重新装入，就必须用这个参数。它的长选项格式是 --counters。 使用 -n 告诉 iptables-restore 不要覆盖已有的表或表内的规则。默认情况是清除所有已存在的规则。它的长选项格式是 --noflush。如果使用了这个选项，你的规则就很有可能出现很多重复，所以不太建议使用。 1iptables-restore -c &lt; /etc/iptables.save 这样规则集应该正确地装入内核并正常工作了。如果有问题，就要开始排错了。 iptables.service如果你用的是红帽 7 系列的系统，并且安装了 iptables-services，那么 /etc/sysconfig/iptables 就作为了 iptables.service 规则存放的文件， /etc/sysconfig/iptables-config 作为 iptables.service 的服务配置文件 。你可以使用 /usr/libexec/iptables/iptables.init save 保存规则。 编写规则抵御常见攻击SYN FLOOD 方法一，限制请求速度 1234567iptables -N SYN_FLOOD# 自定义链 SYN_FLOODiptables -A INPUT -p tcp --syn -j SYN_FLOOD # 对第一次握手 SYN 包进行 jump ，跳转到自定义链 iptables -A SYN_FLOOD -m limit --limit 1/s --limit-burst 4 -j RETURN iptables -A SYN_FLOOD -j DROP# 限定每秒最多可以连接1个，一批最高峰值为4个，即前4个速度比较快，后面的按照1/s返回主链进行回应。否则将丢弃 方法二，限制单个IP最大连接数，也可以用于限制访问量过大的IP 12iptables -A INPUT -i eth0 -p tcp --syn -m connlimit --connlimit-above 15 -j DROP# 限定单个 IP 连接，超过15个就丢弃 Dos 123456iptables -I INPUT 1 -p tcp -m multiport --dport 22 -m connlimit --connlimit-above 5 -j DROP# 单个 IP 最多 5 个会话iptables -I INPUT 2 -p tcp --dport 22 -m state --state NEW -m recent --set --name SSH # 只要是新的连接请求，就把它加入到 SSH 列表中，此处需要使用 recent 模块iptables -I INPUT 3 -p tcp --dport 22 -m state --state NEW -m recent --update --seconds 300 --hitcount 3 --name SSH -j DROP# 5分钟(300s)内尝试次数达到3次，就拒绝为 SSH 列表中的这个 IP 提供服务。被限制5分钟后即可恢复访问。 反弹木马 12iptables -A OUTPUT -m state --state NEW -j DROP# 防止本机向外发送连接请求（如果本机有类似 DNS 请求的数据则据具体情况而待） ping攻击 12iptables -A INPUT -p icmp --icmp-type echo-request -m limit --limit 1/m -j ACCEPT# 限制连接速率 防火墙脚本清除规则脚本 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#!/usr/bin/env bash:&lt;&lt;:------------------------------------------------ FileName : flush-iptables-rules.sh Author : Silence Version : 0.0.1 Description :------------------------------------------------ :# Check if iptable module is loadedPROC_iptables_NAMES=/proc/net/ip_tables_names[ ! -e "$PROC_iptables_NAMES" ] &amp;&amp; exit 0# Get active tablesNF_TABLES=$(cat "$PROC_iptables_NAMES" 2&gt;/dev/null)# Check if firewall is configured (has tables)[ -z "$NF_TABLES" ] &amp;&amp; exit 1# only usable for rootif [ $EUID != 0 ]; then echo -n $"iptables: Only usable by root."; exit 4fiif [ ! -x /sbin/iptables ]; then echo -n $"iptables: /sbin/iptables does not exist."; warning; echo exit 5fi# Flush firewall rules and delete chains.echo -n $"iptables: Flushing firewall rules: "# For all tablesfor i in $NF_TABLES; do # Flush firewall rules. iptables -t $i -F; # Delete firewall chains. iptables -t $i -X; # Set counter to zero. iptables -t $i -Z; # Set policy for configured tables. policy=ACCEPT echo -n "$i " case "$i" in raw) for chain in PREROUTING OUTPUT;do iptables -t $i -P $&#123;chain&#125; $policy done unset chain ;; filter) for chain in INPUT OUTPUT FORWARD;do iptables -t $i -P $&#123;chain&#125; $policy done unset chain ;; nat) for chain in PREROUTING POSTROUTING OUTPUT;do iptables -t $i -P $&#123;chain&#125; $policy done unset chain ;; mangle) for chain in PREROUTING POSTROUTING INPUT OUTPUT FORWARD;do iptables -t $i -P $&#123;chain&#125; $policy done unset chain ;; security) : Ignore the security table ;; *) : Do nothing ;; esacdoneecho TCP/IP协议号https://www.frozentux.net/iptables-tutorial/cn/other/protocols.txt 协议号 协议类型 说明 0 HOPOPT IPv6 逐跳选项 1 ICMP Internet 控制消息 2 IGMP Internet 组管理 3 GGP 网关对网关 4 IP IP 中的 IP（封装） 5 ST 流 6 TCP 传输控制 7 CBT CBT 8 EGP 外部网关协议 9 IGP 任何专用内部网关 （Cisco 将其用于 IGRP） 10 BBN-RCC-MON BBN RCC 监视 11 NVP-II 网络语音协议 12 PUP PUP 13 ARGUS ARGUS 14 EMCON EMCON 15 XNET 跨网调试器 16 CHAOS Chaos 17 UDP 用户数据报 18 MUX 多路复用 19 DCN-MEAS DCN 测量子系统 20 HMP 主机监视 21 PRM 数据包无线测量 22 XNS-IDP XEROX NS IDP 23 TRUNK-1 第 1 主干 24 TRUNK-2 第 2 主干 25 LEAF-1 第 1 叶 26 LEAF-2 第 2 叶 27 RDP 可靠数据协议 28 IRTP Internet 可靠事务 29 ISO-TP4 ISO 传输协议第 4 类 30 NETBLT 批量数据传输协议 31 MFE-NSP MFE 网络服务协议 32 MERIT-INP MERIT 节点间协议 33 SEP 顺序交换协议 34 3PC 第三方连接协议 35 IDPR 域间策略路由协议 36 XTP XTP 37 DDP 数据报传送协议 38 IDPR-CMTP IDPR 控制消息传输协议 39 TP++ TP++ 传输协议 40 IL IL 传输协议 41 IPv6 Ipv6 42 SDRP 源要求路由协议 43 IPv6-Route IPv6 的路由标头 44 IPv6-Frag IPv6 的片断标头 45 IDRP 域间路由协议 46 RSVP 保留协议 47 GRE 通用路由封装 48 MHRP 移动主机路由协议 49 BNA BNA 50 ESP IPv6 的封装安全负载 51 AH IPv6 的身份验证标头 52 I-NLSP 集成网络层安全性 TUBA 53 SWIPE 采用加密的 IP 54 NARP NBMA 地址解析协议 55 MOBILE IP 移动性 56 TLSP 传输层安全协议 使用 Kryptonet 密钥管理 57 SKIP SKIP 58 IPv6-ICMP 用于 IPv6 的 ICMP 59 IPv6-NoNxt 用于 IPv6 的无下一个标头 60 IPv6-Opts IPv6 的目标选项 61 任意主机内部协议 62 CFTP CFTP 63 任意本地网络 64 SAT-EXPAK SATNET 与后台 EXPAK 65 KRYPTOLAN Kryptolan 66 RVD MIT 远程虚拟磁盘协议 67 IPPC Internet Pluribus 数据包核心 68 任意分布式文件系统 69 SAT-MON SATNET 监视 70 VISA VISA 协议 71 IPCV Internet 数据包核心工具 72 CPNX 计算机协议网络管理 73 CPHB 计算机协议检测信号 74 WSN 王安电脑网络 75 PVP 数据包视频协议 76 BR-SAT-MON 后台 SATNET 监视 77 SUN-ND SUN ND PROTOCOL-Temporary 78 WB-MON WIDEBAND 监视 79 WB-EXPAK WIDEBAND EXPAK 80 ISO-IP ISO Internet 协议 81 VMTP VMTP 82 SECURE-VMTP SECURE-VMTP 83 VINES VINES 84 TTP TTP 85 NSFNET-IGP NSFNET-IGP 86 DGP 异类网关协议 87 TCF TCF 88 EIGRP EIGRP 89 OSPFIGP OSPFIGP 90 Sprite-RPC Sprite RPC 协议 91 LARP 轨迹地址解析协议 92 MTP 多播传输协议 93 AX.25 AX.25 帧 94 IPIP IP 中的 IP 封装协议 95 MICP 移动互联控制协议 96 SCC-SP 信号通讯安全协议 97 ETHERIP IP 中的以太网封装 98 ENCAP 封装标头 99 任意专用加密方案 100 GMTP GMTP 101 IFMP Ipsilon 流量管理协议 102 PNNI IP 上的 PNNI 103 PIM 独立于协议的多播 104 ARIS ARIS 105 SCPS SCPS 106 QNX QNX 107 A/N 活动网络 108 IPComp IP 负载压缩协议 109 SNP Sitara 网络协议 110 Compaq-Peer Compaq 对等协议 111 IPX-in-IP IP 中的 IPX 112 VRRP 虚拟路由器冗余协议 113 PGM PGM 可靠传输协议 114 任意 0 跳协议 115 L2TP 第二层隧道协议 116 DDX D-II 数据交换 (DDX) 117 IATP 交互式代理传输协议 118 STP 计划传输协议 119 SRP SpectraLink 无线协议 120 UTI UTI 121 SMP 简单邮件协议 122 SM SM 123 PTP 性能透明协议 124 ISIS over IPv4 125 FIRE 126 CRTP Combat 无线传输协议 127 CRUDP Combat 无线用户数据报 128 SSCOPMCE 129 IPLT 130 SPS 安全数据包防护 131 PIPE IP 中的专用 IP 封装 132 SCTP 流控制传输协议 133 FC 光纤通道 134-254 未分配 255 保留 参考链接：https://www.linuxtopia.org/Linux_Firewall_iptables/https://www.frozentux.net/iptables-tutorial/cn/iptables-tutorial-cn-1.1.19.htmlhttp://cn.linux.vbird.org/linux_server/0250simple_firewall_3.php]]></content>
      <tags>
        <tag>Network</tag>
        <tag>iptables</tag>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识SElinux]]></title>
    <url>%2F2016%2F05%2F01%2F092111-%E5%88%9D%E8%AF%86SElinux%2F</url>
    <content type="text"><![CDATA[SELinux(Security-Enhanced Linux) 是美国国家安全局（NSA）对于强制访问控制的实现，是 Linux 历史上最杰出的新安全子系统。NSA 是在 Linux 社区的帮助下开发了一种访问控制体系，在这种访问控制体系的限制下，进程只能访问那些在他的任务中所需要文件。 SElinux 的用途在于增强系统抵御 0-Day 攻击(利用尚未公开的漏洞实现的攻击行为)的能力。所以它不是网络防火墙或 ACL 的替代品，在用途上也不重复。 使用 getenforce 命令可获取当前 SELinux 运行状态，可能返回结果有三种：Enforcing、Permissive 和 Disabled。Disabled 代表 SELinux 被禁用，Permissive 代表仅记录安全警告但不阻止可疑行为，Enforcing 代表记录警告且阻止可疑行为。 1getenforce 使用 setenforce 命令可以立刻改变 SELinux 运行状态，在 Enforcing 和 Permissive 之间切换，结果会一直保持至关机。一个典型的用途是看看到底是不是 SELinux 导致某个服务或者程序无法运行。若是在 setenforce 0 之后服务或者程序依然无法运行，那么就可以肯定不是 SELinux 导致的。 1setenforce [ Enforcing | Permissive | 1 | 0 ] 若是想要永久变更系统 SELinux 运行环境，可以通过更改配置文件 /etc/sysconfig/selinux 实现。注意当从 Disabled 切换到 Permissive 或者 Enforcing 模式后需要重启计算机。 SELinux 运行策略可在配置文件 /etc/sysconfig/selinux 进行配置 ，文件中还包含了 SELinux 运行策略的信息，通过改变变量 SELINUXTYPE 的值实现，该值有两种可能：targeted 代表仅针对预制的几种网络服务和访问请求使用 SELinux 保护，strict 代表所有网络服务和访问请求都要经过 SELinux 参考文档：http://blog.csdn.net/myarrow/article/details/9856095/]]></content>
      <tags>
        <tag>Service</tag>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基础邮件服务器]]></title>
    <url>%2F2016%2F04%2F27%2F194119-%E5%9F%BA%E7%A1%80%E9%82%AE%E4%BB%B6%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[概述 MUA（Mail User Agent）邮件用户代理：接收邮件所使用的邮件客户端程序，使用IMAP或POP3协议与服务器通信，它提供了阅读、发送和接收电子邮件的用户接口。常见的客户端：outlook、foxmail等 MTA（Mail Transfer Agent）邮件传送代理：通过SMTP协议负责邮件的存储、发送和转发。监视MUA的请求，根据电子邮件的目标地址找出对应的邮件服务器，将信件在服务器之间传输并将接受到的邮件进行缓冲。在linux环境中常见的MTA有：sendmail、qmail等 MDA（Mail Deliver Agent）邮件投递代理：将MTA接收到的邮件保存到磁盘或指定地方，通常会进行垃圾邮件及病毒扫描。常用的MDA：procmail、dropmail等 MRA（Mail Retrieval Agent）邮件取回代理：负责实现IMAP与POP3协议，与MUA进行交互。常用的MRA：dovecot MSA（Mail Submission Agent）邮件提交代理：检查邮件安全性与垃圾等，处理额外的工作 开源邮件系统 Sendmail：资格最老，运行稳定，但安全性欠佳 Qmail：更好的执行效率，配置管理也很方便，但兼容性不高 Postfix：兼容Sendmail，采用模块化设计，在投递效率、稳定性、服务性能及安全方面都很优秀 一封邮件的流程 发件人：MUA =&gt; 发送 =&gt; MTA =&gt; 若干个MTA… =&gt; MTA =&gt; MDA &lt;= 收取 &lt;= MUA：收件人 MUA并非直接将邮件发送至收件人手中，而是通过MTA代为传递，Sendmail和Postfix就是扮演MTA的角色 一封邮件从MUA发出后，可能通过一个或多个MTA传递，最终到达MDA。然后存放在某个文件或特殊的数据库里，我们将这个长期保存邮件的地方称之为邮箱 一旦邮件到达邮箱，就原地不动了，等用户再通过MUA将其取走，就是用Outlook，Foxmail等软件收信的过程 MUA到MTA，以及MTA到MTA之间使用的协议就是SMTP协议，而收邮件时，MUA到MDA之间使用的协议最常用的是POP3或IMAP。 邮件应用协议 简单邮件传输协议(SMTP)，用来发送或中转发出的电子邮件，占用tcp 25端口。 第三版邮局协议(POP3)，用于将服务器上把邮件存储到本地主机，占用tcp 110端口。 第四版互联网信息访问协议(IMAP4)，用于在本地主机上访问邮件，占用tcp 143端口。 注意事项：如果想搭建企业级的电子邮件系统，请考虑以下几点： 反垃圾与反病毒模块：阻止垃圾邮件或病毒邮件对企业邮箱的干扰。 邮件加密：保证邮件内容不被嗅探、篡改。 邮件监控审核：监控全体职员邮件中有无敏感词，透露企业资料等。 稳定性：有较好的防DDOS攻击的能力，保证系统在线率等。 搭建邮件服务器准备工作 邮件服务依赖于 DNS 服务，事先确保 DNS 服务已经为邮件应用配置完成。为了方便，此处将邮件服务器和DNS服务器配置为一台：192.168.247.108。主机名为 mail.test.com ，区域为 test.com ，邮件服务器为 mail.test.com 修改主机名 123name="mail.test.com"sed -ri 's#(HOSTNAME=).*#\1'"$&#123;name&#125;"'#' /etc/sysconfig/network hostname $&#123;name&#125; DNS配置 1234567891011zone "test.com" IN &#123; type master; file "test.com.zone"; allow-update &#123; none; &#125;;&#125;;# 邮件服务器需要用到反向解析，否则会在互联网被视为垃圾邮件服务器zone "247.168.192.in-addr.arpa" IN &#123; type master; file "192.168.247.zone"; allow-update &#123; none; &#125;;&#125;; 正向区域文件/var/named/test.com.zone 1234567891011$TTL 1D@ IN SOA ns1.test.com. admin.test.com. ( 20160217 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum IN NS ns1 IN MX 10 mailns1 IN A 192.168.247.108mail IN A 192.168.247.108 反向区域文件/var/named/192.168.247.zone 12345678910$TTL 1D@ IN SOA ns1.test.com. admin.test.com. ( 20160217 ; serial 1D ; refresh 1H ; retry 1W ; expire 3H ) ; minimum IN NS ns1.test.com.108 IN PTR ns1.test.com.108 IN PTR mail.test.com. 权限修改 123456cd /var/named/chown named.named test.com.zone 192.168.247.zone chmod 640 test.com.zone 192.168.247.zone # 语法检查named-checkzone "test.com" test.com.zone named-checkzone "247.168.192.in-addr.arpa" 192.168.247.zone 软件包、服务、用户环境配置 依赖包安装 123yum -y groupinstall "Development Libraries" "Development Tools"yum -y install db*-devel yum -y install cyrus-sasl* 如果系统有sendmail，需要把sendmail关掉 12service sendmail stopchkconfig sendmail off 为了更好的支持sasl，因此编译安装postfix；如果有rpm的postfix，要删除掉并且把postfix用户等信息也删除掉。 12345rpm -e postfix --nodepsuserdel -r postfixuserdel -r postdropgroupdel postfixgroupdel postdrop 安装 postfixPostfix是一款由IBM出资研发的免费开源的邮局服务程序，兼容于Sendmail服务程序，即Sendmail用户可以很方便的迁移到Postfix程序，且收发件性能远超过Sendmail，能够自动增加减少进程的数量，保证邮局系统的高性能与稳定性，另外Postfix是由诸多的小模块组成，每个小模块完成特定的功能，使得管理员可以灵活的组合这些模块。 单独使用Postfix服务程序并不能让用户完成收发邮件的操作，因为一个基础的电子邮局系统至少需要有SMTP服务器、POP3/IMAP服务器，为了能够部署一个基础的电子邮件系统，我们需要使用到下面的软件： Postfix：提供邮件发送服务，即SMTP。 Dovecot：提供邮件收取服务，即POP3。 OutLook Express：客户端收发邮件的工具。 123456789101112131415# 创建用户组，ID号最好大于1000groupadd -g 2828 postfixuseradd -g postfix -u 2828 -s /sbin/nologin -M postfixgroupadd -g 2829 postdropuseradd -g postdrop -u 2829 -s /sbin/nologin -M postdrop# 编译安装tar xf postfix-3.2.0.tar.gzcd postfix-3.2.0make tidymake makefiles 'CCARGS=-DUSE_SASL_AUTH -DUSE_CYRUS_SASL -I/usr/include/sasl' 'AUXLIBS=-L/usr/lib64/sasl2 -lsasl2'make &amp;&amp; make install# 创建邮件别名库newaliasesll /etc/aliases* 配置 postfixPostfix 邮局服务程序的配置文件： 文件 作用 /usr/sbin/postfix 主服务程序 /etc/postfix/master.cf master主程序的配置文件。 /etc/postfix/main.cf postfix服务的配置文件。 /var/log/maillog 记录邮件传递过程的日志。 /usr/libexec/postfix 服务程序目录 /var/spool/postfix 邮件队列目录 Postfix 服务程序主配置文件: 参数 作用 myhostname 邮件系统的主机名。 mydomain 邮件系统的域名。 myorigin 从本机寄出邮件的域名名称。 inet_interfaces 监听的网卡接口。 mydestination 可接收邮件的主机名或域名。 mynetworks 设置可转发那些主机的邮件。 relay_domains 设置可转发那些网域的邮件 编辑 Postfix 主配置文件，直接执行辅助配置工具 postconf，可列出 postfix 服务所支持的所有配置。结合 -n 选项可排除默认配置，只列出非默认的配置。结合 -d 选项可查看默认配置。 12345# 备份main.cf文件，创建新的main.cf文件postconf -n &gt; tmp.filemv /etc/postfix/main.cf&#123;,.bak&#125;mv tmp.file /etc/postfix/main.cfvim /etc/postfix/main.cf 123456789101112131415161718192021222324252627282930313233command_directory = /usr/sbincompatibility_level = 2daemon_directory = /usr/libexec/postfixdata_directory = /var/lib/postfixdebug_peer_level = 2debugger_command = PATH=/bin:/usr/bin:/usr/local/bin:/usr/X11R6/bin ddd $daemon_directory/$process_name $process_id &amp; sleep 5html_directory = noinet_protocols = ipv4mail_owner = postfixmailq_path = /usr/bin/mailqmanpage_directory = /usr/local/manmeta_directory = /etc/postfixnewaliases_path = /usr/bin/newaliasesqueue_directory = /var/spool/postfixreadme_directory = nosample_directory = /etc/postfixsendmail_path = /usr/sbin/sendmailsetgid_group = postdropshlib_directory = nounknown_local_recipient_reject_code = 550myhostname = mail.test.com # 邮件服务器自己的主机名，应改和邮件服务器上hostname命令结果保持一致mydomain = test.com # 邮件域myorigin = $mydomain # 发件域：发件人所在的域名，即做发件地址伪装（a@mail.test.com=&gt;a@test.com）mydestination = $myhostname, localhost.$mydomain, localhost,$mydomain# 投递域#home_mailbox = inet_interfaces = 192.168.247.108,127.0.0.1# 指定postfix系统监听的网络接口 注意： postfix服务器支持两种邮件存储方式：Mailbox和Maildir。当指定存储位置最后一位为“/”时，自动使用Maildir方式存储。Mailbox存储方式将同一用户的所有邮件内容存储在同一个文件中，通常对应为目录“/var/spool/mail”中以用户名命名的文件。Maildir存储方式使用目录结构来储存用户的邮件内容，每一个用户对应有一个文件夹，每一封邮件作为为一个独立的文件保存，通常位于用户的主目录下。 为了不修改原有的邮件存放地址，这个地方需要把home_mailbox注释掉。 在postfix的配置文件中，参数行和注释行是不能处在同一行中的； 任何一个参数的值都不需要加引号，否则，引号将会被当作参数值的一部分来使用； 每修改参数及其值后执行 postfix reload 即可令其生效；但若修改了inet_interfaces，则需重新启动postfix； 如果一个参数的值有多个，可以将它们放在不同的行中，只需要在其后的每个行前多置一个空格即可；postfix会把第一个字符为空格或tab的文本行视为上一行的延续 postfix服务创建 sysv 服务脚本：/etc/rc.d/init.d/postfix 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#!/bin/bash## postfix Postfix Mail Transfer Agent## chkconfig: 2345 80 30# description: Postfix is a Mail Transport Agent, which is the program \# that moves mail from one machine to another.# processname: master# pidfile: /var/spool/postfix/pid/master.pid# config: /etc/postfix/main.cf# config: /etc/postfix/master.cf # Source function library.. /etc/rc.d/init.d/functions # Source networking configuration.. /etc/sysconfig/network # Check that networking is up.[ $NETWORKING = "no" ] &amp;&amp; exit 3 [ -x /usr/sbin/postfix ] || exit 4[ -d /etc/postfix ] || exit 5[ -d /var/spool/postfix ] || exit 6 RETVAL=0prog="postfix" start() &#123; # Start daemons. echo -n $"Starting postfix: " /usr/bin/newaliases &gt;/dev/null 2&gt;&amp;1 /usr/sbin/postfix start 2&gt;/dev/null 1&gt;&amp;2 &amp;&amp; success || failure $"$prog start" RETVAL=$? [ $RETVAL -eq 0 ] &amp;&amp; touch /var/lock/subsys/postfix echo return $RETVAL&#125; stop() &#123; # Stop daemons. echo -n $"Shutting down postfix: " /usr/sbin/postfix stop 2&gt;/dev/null 1&gt;&amp;2 &amp;&amp; success || failure $"$prog stop" RETVAL=$? [ $RETVAL -eq 0 ] &amp;&amp; rm -f /var/lock/subsys/postfix echo return $RETVAL&#125; reload() &#123; echo -n $"Reloading postfix: " /usr/sbin/postfix reload 2&gt;/dev/null 1&gt;&amp;2 &amp;&amp; success || failure $"$prog reload" RETVAL=$? echo return $RETVAL&#125; abort() &#123; /usr/sbin/postfix abort 2&gt;/dev/null 1&gt;&amp;2 &amp;&amp; success || failure $"$prog abort" return $?&#125; flush() &#123; /usr/sbin/postfix flush 2&gt;/dev/null 1&gt;&amp;2 &amp;&amp; success || failure $"$prog flush" return $?&#125; check() &#123; /usr/sbin/postfix check 2&gt;/dev/null 1&gt;&amp;2 &amp;&amp; success || failure $"$prog check" return $?&#125; restart() &#123; stop start&#125; # See how we were called.case "$1" in start) start ;; stop) stop ;; restart) stop start ;; reload) reload ;; abort) abort ;; flush) flush ;; check) check ;; status) status master ;; condrestart) [ -f /var/lock/subsys/postfix ] &amp;&amp; restart || : ;; *) echo $"Usage: $0 &#123;start|stop|restart|reload|abort|flush|check|status|condrestart&#125;" exit 1esac exit $? 启动postfix服务 1234chmod +x /etc/rc.d/init.d/postfix postfix checkchkconfig postfix onservice postfix start 部署 DovecotDovecot 是一个开源的 IMAP 和 POP3 邮件服务器，支持 Linux/Unix 系统。 123yum -y install openssl-devel pam-devel dovecotchkconfig --add dovecotchkconfig --level 2345 dovecot on 修改主配置文件 1vim /etc/dovecot/dovecot.conf 12345678# 修改第24行的支持邮局协议。protocols = imap pop3 lmtp# 修改第26行监听选项，如果不支持IPv6使用*listen = *# 允许登陆网段地址，全部允许即为（0.0.0.0/0）#login_trusted_networks = 192.168.247.0/24 允许明文认证 /etc/dovecot/conf.d/10-auth.conf 1disable_plaintext_auth = no 配置邮件的格式与存储路径 /etc/dovecot/conf.d/10-mail.conf 12mail_location = mbox:~/mail:INBOX=/var/mail/%u# 这里的路径一定要和postfix的保持一致（postconf | grep mail_spool_directory） 启动Dovecot服务程序 12chkconfig dovecot onservice dovecot restart 部署Cyrus SASL在Postfix邮件系统中，可以使用Cyrus SASL（Cyrus Simple Authentication and Security Layer，Cyrus简单认证安全层）软件来实现基本的SMTP认证。Postfix通过连接Cyrus SASL的函数库，调用认证服务saslauthd来核对系统账号和密码 12345yum -y install cyrus-sasl*# 设置cyrus SASL 函数库echo -e 'pwcheck_method:saslauthd\nmech_list: PLAIN LOGIN' &gt;&gt; /usr/lib64/sasl2/smtpd.confcp /usr/lib64/sasl2/smtpd.conf /etc/sasl2/ 配置 1vim /etc/sysconfig/saslauthd 123MECH=shadow# 认证方式改为帐号密码认证。# saslauthd -v 可显示当前主机saslauthd服务支持的认证方式 12service saslauthd startchkconfig --level 2345 saslauthd on 修改postfix配置文件，加入配置 123456789101112131415161718192021222324252627282930313233#####################---CYRUS-SASL---#####################broken_sasl_auth_clients = yes# 是否通过sasl来验证clientsmtpd_recipient_restrictions=permit_mynetworks,permit_sasl_authenticated,reject_invalid_hostname,reject_non_fqdn_hostname,reject_unknown_sender_domain,reject_non_fqdn_sender,reject_non_fqdn_recipient,reject_unknown_recipient_domain,reject_unauth_pipelining,reject_unauth_destination# 收件人限定# permit_mynetworks 允许本地网络# permit_sasl_authenticated 允许sasl验证通过的用户# reject_invalid_hostname 拒绝主机名不合法的主机来收发邮件# reject_non_fqdn_hostname 拒绝非fqdn格式的主机来收发邮件# reject_unknown_sender_domain 拒绝无法识别的发件人# reject_non_fqdn_sender 拒绝非fqdn格式的发件人# reject_non_fqdn_sender 拒绝非fqdn格式的收件人# reject_unknown_recipient_domain 拒绝无法识别的收件人域# reject_unauth_pipelining 拒绝无法验证的管道# reject_unauth_destination 拒绝未认证的目标，此项必须放到最后smtpd_sasl_auth_enable = yes# 启用sasl认证功能smtpd_sasl_local_domain = $myhostname# 基于sasl认证的时候，我们本地的域smtpd_sasl_security_options = noanonymous# 禁止匿名发信smtpd_sasl_path = smtpd# 指定要使用ssl功能的服务器程序 mynetworks = 127.0.0.0/8# 只允许给本地中继（注意：上面的smtpd_recipient_restrictions明确规定了permit_sasl_authenticated，允许给通过sasl认证的用户做邮件中继）# 设置内网和本地IP指定你所在的网络的网络地址# postfix根据其值来区别用户是远程的还是本地的，如果是本地网络用户则允许其访问 帐号的添加和测试 邮箱账号采用的是系统账号，属组应该为邮件组mail，所以邮箱开通的时候，实际上是创建了一个系统账号。 命令要求 123456789101112131415userdel -r test1userdel -r test2useradd -u 1300 -g mail -s /usr/bin/passwd test1echo test1 | passwd --stdin test1useradd -u 1301 -g mail -s /usr/bin/passwd test2echo test2 | passwd --stdin test2 # -c 添加新账号说明，一般是账号名称，但是每个字的首字母大写。# -u uid编号，我们添加的时候，要先查看/etc/passwd的内容，看当前最后一个账号的uid，然后确定这里填写的数字。# -g gid编号，这个必须是mail组，否则会导致权限不足# -s 的设置也是固定的，不可更改，邮箱用户将不应直接登录邮件服务器。# test1 账号名称。testsaslauthd -u test1 -p test1# 帐号认证测试 使用outlook进行两个用户之间邮件的发送接收测试 常见问题 映射表问题 12345# /var/log/mail/log中显示Recipient address rejected: User unknown in local recipient table# 修改postfix主配置local_recipient_maps = 权限问题 12345# /var/log/mail/log中显示Mar 25 02:19:34 mail dovecot: pop3(test1): Couldn't open INBOX top=0/0, retr=0/0, del=0/0, size=0Mar 25 02:19:34 mail dovecot: pop3-login: Login: user=&lt;test2&gt;, method=PLAIN, rip=192.168.247.1, lip=192.168.247.108, mpid=51169Mar 25 02:19:34 mail dovecot: pop3(test2): Error: chown(/home/test2/mail/.imap/INBOX, -1, 12(mail)) failed: Operation not permitted (egid=2831(test2), group based on /var/mail/test2)# 权限不足，添加邮件帐号时指定属组为mail即可 日志 /var/log/mail/log 被勿删 1234567# maillog日志是在syslog.conf文件中定义的，内容如下：# Log all the mail messages in one place.mail.* -/var/log/maillog# 重启log服务即可：service rsyslog restart 邮件服务器收发正常但OE无法收信 核对postfix中的邮箱路径 postconf -d | grep mail_spool_directory 与dovecot中的邮箱路径 mail_location = mbox:~/mail:INBOX=/var/mail/%u 是否一致 客户端和服务器端时间是否正确及是否同步（执行/usr/sbin/ntpdate time.nist.gov进行时间同步） 为 postfix 开启基于hash的别名文件支持在 main.cf 中添加如下配置 12alias_database = hash:/etc/aliasesalias_maps = hash:/etc/aliases 在 /etc/aliases 文件中定义新的别名项，其格式通常为以冒号隔开的两个字段，前一个字段为初始目标邮件地址，后一个字段为实际发往的地址，如： 12net_operation : zhangsan,lisi,wangwu# 发送给net_operation@test.com的邮件将发送给张三、李四、王五 将 /etc/aliases 转换为 hash 格式： 12postalias /etc/aliasesservice postfix reload postfix基于客户端的访问控制postfix内置了多种反垃圾邮件的机制，其中就包括“客户端”发送邮件限制。 客户端判别机制可以设定一系列客户信息的判别条件： 123456smtpd_client_restrictions：当客户端发起连接请求时，判别此客户端IP的访问权限smtpd_helo_restrictions ： 限定哪些客户端可以发送helo指令smtpd_sender_restrictions ：限定哪些客户端可以发送mail from指令smtpd_recipient_restrictions：限定哪些用户可以发送rctp to指令smtpd_data_restrictions：限定哪些用户可以发送data指令以上每一项参数分别用于检查SMTP会话过程中的特定阶段，即客户端提供相应信息的阶段。 如果DATA命令之前的所有内容都被接受，客户端接着就可以开始传送邮件内容了。邮件内容通常由两部分组成，前半部分是标题(header)，其可以由header_check过滤，后半部分是邮件正文(body)，其可以由check_body过滤。这两项实现的是邮件“内容检查”。 postfix的默认配置如下： 12345678910smtpd_client_restrictions =smtpd_data_restrictions =smtpd_end_of_data_restrictions =smtpd_etrn_restrictions =smtpd_helo_restrictions =smtpd_recipient_restrictions = permit_mynetworks, reject_unauth_destinationsmtpd_sender_restrictions =# 这限制了只有mynetworks参数中定义的本地网络中的客户端才能通过postfix转发邮件，# 其它客户端则不被允许，从而关闭了开放式中继(open relay)的功能。 Postfix有多个内置的限制条件，如上面的 permit_mynetworks 和 reject_unauth_destination，但管理员也可以使用访问表(access map)来自定义限制条件。自定义访问表的条件通常使用 check_client_access ，check_helo_access， check_sender_access， check_recipient_access进行，它们后面通常跟上 type:mapname 格式的访问表类型和名称。其中，check_sender_access 和 check_recipient_access 用来检查客户端提供的邮件地址，因此其访问表中可以使用完整的邮件地址，如 admin@test.com；也可以只使用域名，test.com；还可以只有用户名的部分，如 marion@。 实现示例1 这里以禁止 172.16.100.200 这台主机通过工作在 172.16.100.1上 的 postfix 服务发送邮件为例演示说明其实现过程。访问表使用 hash 的格式。 1234567891011# 首先，编辑/etc/postfix/access文件，以之作为客户端检查的控制文件，在里面定义如下一行：172.16.100.200 REJECT# 其次，将此文件转换为hash格式postmap /etc/postfix/access# 然后，配置postfix使用此文件对客户端进行检查# 编辑/etc/postfix/main.cf文件，添加如下参数：smtpd_client_restrictions = check_client_access hash:/etc/postfix/access# 最后，让postfix重新载入配置文件即可进行发信控制的效果测试了。 实现示例2 这里以禁止通过本服务器向 microsoft.com 域发送邮件为例演示其实现过程。访问表使用 hash 的格式。 1234567891011# 首先，建立/etc/postfix/denydstdomains文件(文件名任取)，在里面定义如下一行：microsoft.com REJECT# 其次，将此文件转换为hash格式postmap /etc/postfix/denydstdomains# 然后，配置postfix使用此文件对客户端进行检查# 编辑/etc/postfix/main.cf文件，添加如下参数：smtpd_recipient_restrictions = check_recipient_access hash:/etc/postfix/denydstdomains, permit_mynetworks, reject_unauth_destination# 最后，让postfix重新载入配置文件即可进行发信控制的效果测试了。 检查表格式的说明 hash类的检查表都使用类似如下的格式： 123pattern action# 检查表文件中，空白行、仅包含空白字符的行和以#开头的行都会被忽略。# 以空白字符开头后跟其它非空白字符的行会被认为是前一行的延续，是一行的组成部分。 关于pattern 其 pattern 通常有两类地址：邮件地址和主机名称/地址。 12345678910111213邮件地址的pattern格式如下：user@domain 用于匹配指定邮件地址；domain.tld 用于匹配以此域名作为邮件地址中的域名部分的所有邮件地址；user@ 用于匹配以此作为邮件地址中的用户名部分的所有邮件地址；主机名称/地址的pattern格式如下：domain.tld 用于匹配指定域及其子域内的所有主机；.domain.tld 用于匹配指定域的子域内的所有主机；net.work.addr.essnet.work.addrnet.worknet 用于匹配特定的IP地址或网络内的所有主机；network/mask CIDR格式，匹配指定网络内的所有主机； 关于 action 1234567891011接受类的动作：OK 接受其pattern匹配的邮件地址或主机名称/地址；全部由数字组成的action 隐式表示OK；拒绝类的动作(部分)：4NN text 5NN text # 其中4NN类表示过一会儿重试；5NN类表示严重错误，将停止重试邮件发送；# 421和521对于postfix来说有特殊意义，尽量不要自定义这两个代码；REJECT optional text... 拒绝；text为可选信息；DEFER optional text... 拒绝；text为可选信息； 常见需求的配置特定人员发送特定邮件公司需求只有公司高层才可以向全体员工发送邮件，除此之外均无权向全体员工发送邮件 公司高层邮箱 12345wanglujing@test.comrenlina@test.com caiyanyan@test.comqinwen@test.com shiwanting@test.com 全体员工邮箱 1allemp@test.com 用到的参数 主配置文件中需要用到的参数(具体的请参考《postfix权威指南》，在第十一章 反垃圾邮件) smtmpd_restriction_classes自定义规范等级的名称,列出管理员自定义的所有规范等级，每一组规范等级，都是由一系列UBE（挡信）限制条件组成。 check_client_access 客户端 check_sender_access 发件人 check_recipient_access 收件人 check_recipient_access maptype:mapname check_recipient_access指向一个含有邮件地址、网域名称、人名的访问表，用于对比客户端在RCPT TO命令中提供的收件地址，如果发现相符的索引键，则postfix执行相对应的值所提定的动作。 check_sender_access maptype:mapnamecheck_sender_access 指向一个含有邮件地址，网域名称,人名的访问表，用于对比客户端在MAIL FROM命令中提供的寄件人邮件地址，如果发现相符的索引键，则postfix执行相对应的值所指定的动作。 涉及的处理动作 OK 通过当前过滤规则的检查，postfix继续检查下一组过滤规则。 REJECT 拒绝邮件，后面可以加上一段简短信息，说明拒绝的理由，这段信息会连同拒绝码一起返回给客户端，并且被记录在postfix日志文件中。 实现方法 定义规范等级，分别为 local_sender_all，allow_to_all 1234# 在postfix主配置文件中，末尾添加下列语句smtpd_restriction_classes = local_sender_all,allow_to_alllocal_sender_all = check_sender_access hash:/etc/postfix/plugin/local_sender_all,rejectallow_to_all = check_recipient_access hash:/etc/postfix/plugin/allow_to_all,reject 创建限定的收件人文件 12install -cdv /etc/postfix/pluginvim /etc/postfix/plugin/allow_to_all 1allemp@test.com allow_to_all 创建限定的发件人文件 1vim /etc/postfix/plugin/local_sender_all 12345wanglujing@test.com OK renlina@test.com OK caiyanyan@test.com OK qinwen@test.com OK shiwanting@test.com OK 使用 postmap 生成数据库文件 12postmap /etc/postfix/plugin/allow_to_all postmap /etc/postfix/plugin/local_sender_all 邮件发送控制 对于外域到本域的邮件，必须接收，否则，收不到任何来自外部的邮件 对于本域到外域的邮件，只允许从本机发出，否则其他人通过伪造本域地址就可以向外域发信 对于外域到外域的邮件，直接拒绝，否则我们的邮件服务器就是Open Relay，将被视为垃圾邮件服务器 设置发件人的规则 12smtpd_sender_restrictions = permit_mynetworks, check_sender_access hash:/etc/postfix/plugin/sender_access, permit# 以上规则先判断是否是本域地址，如果是则允许，然后再从sender_access文件里检查发件人是否存在，拒绝存在的发件人，最后允许其他发件人。 设置收件人的规则 12smtpd_recipient_restrictions = permit_mynetworks, check_recipient_access hash:/etc/postfix/plugin/recipient_access, reject# 以上规则先判断是否是本域地址，如果是则允许，然后再从recipient_access文件里检查收件人是否存在，允许存在的收件人，最后拒绝其他收件人。]]></content>
      <tags>
        <tag>Service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Samba服务]]></title>
    <url>%2F2016%2F04%2F23%2F214135-Samba%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[SambaSamba 是 SMB/CIFS 网络协议的重新实现, 它作为 NFS 的补充使得在 Linux 和 Windows 系统中进行文件共享、打印机共享更容易实现。它是在 Linux 和 UNIX 系统上实现 SMB 协议的一个免费软件，由服务器及客户端程序构成。 Samba 服务器的工作原理是：客户端向 Samba 服务器发起请求，请求访问共享目录，Samba 服务器接收请求，查询 smb.conf 文件，查看共享目录是否存在，以及来访者的访问权限，如果来访者具有相应的权限，则允许客户端访问，最后将访问过程中系统的信息以及采集的用户访问行为信息存放在日志文件中。 安装配置1yum -y install samba Samba的配置文件一般就放在 /etc/samba 目录中，主配置文件名为 smb.conf，文件中记录着大量的规则和共享信息，所以是 samba 服务非常重要的核心配置文件，完成 samba 服务器搭建的大部分主要配置都在该文件中进行。 123cd /etc/sambacp -a smb.conf&#123;,.bak&#125;vim smb.conf 配置参考 123456789101112131415161718192021[global] workgroup = Samba netbios name = SambaServer server string = Linux Samba Server TestServer security = user# workgroup：在Windows中显示的工作组# netbios name：在Windows中显示出来的计算机名# server string ：Samba服务器说明，可以自定义# security：验证和登录方式，share为共享；user为用户认证[shared] path = /opt/shared writeable = no browseable = yes guest ok = yes# [shared]：在Windows中显示出来是共享的目录# path = 设置要共享的目录的路径# writeable 是否可写# browseable 是否可以浏览；可以浏览意味着，在工作组下能看到共享文件夹# guest ok 匿名用户以guest身份是登录 建立目录、用户并授权。Samba 的所有用户都必须是系统里已存在的用户。密码是独立的，不是 /etc/shadow 中的密码 1234install -cdv /opt/shareduseradd testsmbpasswd -a testchown -R test.test /opt/shared/ 启动 smbd 和 nmbd 服务 1systemctl enable --now smb nmb 使用 Windows 的运行输入\\Samba 服务器的地址访问测试 附加配置12345678910111213141516171819# [global]字段可选配置：# dos charset = GB2312# 将Windows 客户端的文字编码设置为简体中文 GB2312# unix charset =GB2312# 指定Samba所在的CentOS服务端新建文件或目录时的编码为 GB2312# display charset= GB2312# 指定使用SWAT（一种通过浏览器控制Samba的工具）时页面的默认文字编码# directory mask = 0777# force directorymode = 0777# directorysecurity mask = 0777# force directorysecurity mode = 0777# 指定新建目录的权限# create mask =0777# force createmode = 0777# security mask =0777# force securitymode = 0777# 指定新建文件的权限]]></content>
      <tags>
        <tag>Service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FTP服务]]></title>
    <url>%2F2016%2F04%2F19%2F094135-FTP%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[FTPFTP 是File Transfer Protocol（文件传输协议）的英文简称，用于Internet上的控制文件的双向传输。基于不同的操作系统有不同的FTP应用程序，而所有这些应用程序都遵守同一种协议以传输文件。 在FTP的使用当中，用户经常遇到两个概念：”下载”（Download）和”上传”（Upload）。”下载”文件就是从远程主机拷贝文件至自己的计算机上；”上传”文件就是将文件从自己的计算机中拷贝至远程主机上。 两种连接FTP会话时包含了两个连接，一个叫控制连接，一个叫数据连接。 控制连接和FTP服务器进行沟通的连接。连接FTP、发送FTP指令都是通过控制通道来完成的。在收到断开连接命令前，始终保持连接。 数据连接和FTP服务器进行文件传输或者列表的连接。数据传输时建立，传输结束时终止。 FTP协议中，控制连接均由客户端发起，而数据连接有两种工作方式：PORT方式和PASV方式 主动模式（PORT模式） FTP Client 首先和 FTP Server 的 TCP 21 端口建立控制连接，通过这个连接发送命令，客户端需要接收数据时在这个控制连接上发送 PORT 命令。 PORT 命令包含了客户端用什么端口(一个大于1024的端口)接收数据。在传送数据的时候，服务器端通过自己的 TCP 20 端口主动连接客户端并发送数据。 FTP server 必须和 clien t建立一个新的连接用来传送数据。 被动模式（PASV模式） 在建立控制连接的时候和 PORT 模式类似，当客户端通过这个连接发送 PASV 命令的时候，FTP server 打开一个位于1024和5000之间的随机端口并且通知客户端在这个端口上传送数据的请求，然后 FTP server 将通过这个端口进行数据的传送，这个时候FTP server不再需要建立一个新的和客户端之间的连接传送数据。 如果从C/S模型这个角度来说，PORT对于服务器来说是OUTBOUND，而PASV模式对于服务器是INBOUND，这一点请特别注意，尤其是在使用防火墙的企业里，这一点非常关键，如果设置错了，那么客户将无法连接。 文件说明12yum -y install vsftpdrpm -ql vsftpd 文件 文件作用 /etc/vsftpd/vsftpd.conf 主配置文件 /usr/sbin/vsftpd Vsftpd的主程序 /usr/lib/systemd/system/vsftpd.service 服务控制文件 /etc/pam.d/vsftpd PAM认证文件（此文件中file=/etc/vsftpd/ftpusers字段，指明阻止访问的用户来自/etc/vsftpd/ftpusers文件中的用户） /etc/vsftpd/ftpusers 禁止使用vsftpd的用户列表文件。记录不允许访问FTP服务器的用户名单，管理员可以把一些对系统安全有威胁的用户账号记录在此文件中，以免用户从FTP登录后获得大于上传下载操作的权利，而对系统造成损坏。 /etc/vsftpd/user_list 禁止或允许使用vsftpd的用户列表文件。这个文件中指定的用户缺省情况（即在/etc/vsftpd/vsftpd.conf中设置userlist_deny=YES）下不能访问FTP服务器，在设置了userlist_deny=NO时,仅允许user_list中指定的用户访问FTP服务器。 /var/ftp 匿名用户主目录；本地用户主目录为：/home/用户主目录，即登录后进入自己家目录 /var/ftp/pub 匿名用户的下载目录，此目录需赋权根chmod 1777 pub（1为特殊权限，使上载后无法删除） /etc/logrotate.d/vsftpd.log Vsftpd的日志文件，可在主配置文件进行修改 用户类型匿名用户 在FTP服务器上没有账号，用户名为 anonymous 或 ftp，/var/ftp 作为 ftp 访问的根目录 本地用户 在FTP服务器上拥有帐号，可以登录到服务器上。该账号既可以作为登录帐号使用，也可以作为 ftp 帐号使用。其家目录目录作为其 ftp 访问的根目录。 虚拟用户（Guest用户） 在FTP服务器上拥有帐号，但该账号只能作为ftp帐号使用，不能访问除家目录之外的内容。 参数配置vsftpd的配置文件中以 # 开始注释，配置参数要顶格写，等号前后没有空格 登录欢迎信息Login Banners 12345678# 是否激活目录欢迎信息功能# 如果两个指令都做了配置，那么banner_file将覆盖ftpd_bannerftpd_banner=Welcome to blah FTP service.#banner_file=/etc/vsftpd/banner# 默认情况下，欢迎信息是通过该目录下的.message文件获得的# 此文件保存自定义的欢迎信息，由用户自己建立#dirmessage_enable=YES 禁锢用户在其家目录 1234567891011# 对于ftp访问ftp服务器时应该对其chrootchroot_local_user=YES# 用户登录FTP服务器后是否具有访问自己目录以外的其他文件的权限# 设置为YES时，用户被锁定在自己的home目录中，vsftpd将在下面chroot_list_file选项值的位置寻找chroot_list文件# 必须与下面的设置项配合#chroot_list_enable=YES# 被列入此文件的用户，在登录后将不能切换到自己目录以外的其他目录# 从而有利于FTP服务器的安全管理和隐私保护。此文件需自己建立#chroot_list_file=/etc/vsftpd/chroot_list 匿名用户配置 12345678910111213# 是否允许匿名登录FTP服务器，默认设置为YES允许# 用户可使用用户名ftp或anonymous进行ftp登录，口令为用户的E-mail地址。# 如不允许匿名访问则设置为NOanonymous_enable=YES# 是否允许匿名用户有写权限#anon_upload_enable=YES# 是否允许匿名用户有删除权限#anon_other_write_enable=YES# 是否允许匿名用户创建文件夹权限#anon_mkdir_write_enable=YES 连接限制 1234567891011121314151617181920212223# 设置数据传输中空闲超时时间# 即当数据传输结束后，用户连接FTP服务器的时间不应超过600秒。可以根据实际情况对该值进行修改#idle_session_timeout=600# 设置数据连接超时时间，即数据传输的超时时间#data_connection_timeout=120# 最大并发连接数max_clients=100# 每IP可同时发起并发请求max_per_ip=5# 绑定监听的IP地址 #listen_address=192.168.0.2# 绑定监听的端口#listen_port=21# Make sure PORT transfer connections originate from port 20 (ftp-data).# 是否设定FTP服务器将启用FTP数据端口的连接请求# ftp-data数据传输，21为连接控制端口connect_from_port_20=YES 传输速率 1234# 匿名用户的传输速率（包括上传和下载），单位为bytes/second，0为不限制anon_max_rate=51200# 本地用户传输速率，单位为“字节/秒”local_max_rate=51200 上传文件的umask 123456# 上传后文件的权限掩码，本地用户默认掩码为077# 匿名用户上传文件的umaskanno_umask=022# 可以设置本地用户的文件掩码为缺省022local_umask=077 修改匿名用户上传文件的属主和属主 123456789# 如果未指定属主数组，则默认为`ftp`# 设定是否允许改变上传文件的属主，与下面一个设定项配合使用# 注意，不推荐使用root用户上传文件#chown_uploads=YES# 设置想要改变的上传文件的属主，如果需要，则输入一个系统用户名# 可以把上传的文件都改成root属主。#chown_username=user1 黑白名单 1234567# ftpusers中用户禁止访问（登录时可以看到密码输入提示，但仍无法访问）# 若此项设为YES，则user_list文件中的用户允许登录FTP服务器# 而如果同时设置了userlist_deny=YES，则user_list文件中的用户将不允许登录FTP服务器，甚至连输入密码提示信息都没有#userlist_enable=YES/NO# 设置是否阻止user_list文件中的用户登录FTP服务器，默认为YES#userlist_deny=YES/NO user_list 配置文件有两种用法 黑名单：user_list 中的用户都拒绝 123456789userlist_enable=YESuserlist_deny=YES``` - 白名单：user_list中的用户都不拒绝，允许``` bashuserlist_enable=YESuserlist_deny=NO 以下是两个选项的具体表现形式和两种搭配使用方式的效果： 配置 作用 userlist_enable=YES ftpusers中用户允许访问 user_list中用户允许访问 userlist_enable=NO ftpusers中用户禁止访问 user_list中用户允许访问 userlist_deny=YES ftpusers中用户禁止访问（登录时可以看到密码输入提示，但仍无法访问） user_list 中用户禁止访问 userlist_deny=NO ftpusers中用户禁止访问 user_list中用户允许访问 userlist_enable=YES 并且userlist_deny=YES ftpusers中用户禁止访问 user_list中用户禁止访问（登录时不会出现密码提示，直接被服务器拒绝） userlist_enable=YES 并且 userlist_deny=NO ftpusers中用户禁止访问 user_list中用户允许访问 被动模式设置12345678# 是否开户被动模式 pasv_enable=yes # 被动模式最小端口 pasv_min_port=5000 # 被动模式最大端口 pasv_max_port=6000 其他配置参考链接：http://os.51cto.com/art/201008/221842.htm 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283# 是否允许本地用户(即linux系统中的用户帐号)登录FTP服务器，默认设置为YES允许# 本地用户登录后会进入用户主目录，而匿名用户登录后进入匿名用户的下载目录/var/ftp/pub# 若只允许匿名用户访问，前面加上#注释掉即可阻止本地用户访问FTP服务器# 主要是为虚拟宿主用户，如果该项目设定为NO那么所有虚拟用户将无法访问。#local_enable=YES# 是否允许用户对FTP服务器文件具有写权限，默认设置为YES允许#write_enable=YES # 是否允许匿名用户上传文件，须修改全局的write_enable=YES。默认为YES#anon_upload_enable=YES# 是否允许匿名用户创建新文件夹#anon_mkdir_write_enable=YES # 是否让系统自动维护上传和下载的日志文件# 默认情况该日志文件为/var/log/vsftpd.log,也可以通过下面的xferlog_file选项对其进行设定# 默认值为NOxferlog_enable=YES# 设定系统维护记录FTP服务器上传和下载情况的日志文件# /var/log/vsftpd.log是默认的，也可以另设其它# 该文件默认不存在。必须要手动touch出来#xferlog_file=/var/log/vsftpd.log# 是否以标准xferlog的格式书写传输日志文件# 默认为/var/log/xferlog，也可以通过xferlog_file选项对其进行设定# 默认值为NO#xferlog_std_format=YES# 是否将原本输出到/var/log/vsftpd.log中的日志，输出到系统日志#syslog_enable# 运行vsftpd需要的非特权系统用户，缺省是nobody#nopriv_user=ftpsecure# 是否识别异步ABOR请求。# 如果FTP client会下达“async ABOR”这个指令时，这个设定才需要启用# 而一般此设定并不安全，所以通常将其取消#async_abor_enable=YES# 是否以ASCII方式传输数据。默认情况下，服务器会忽略ASCII方式的请求。# 启用此选项将允许服务器以ASCII方式传输数据# 不过，这样可能会导致由"SIZE /big/file"方式引起的DoS攻击#ascii_upload_enable=YES#ascii_download_enable=YES# 黑名单设置。如果很讨厌某些email address，就可以使用此设定来取消他的登录权限# 可以将某些特殊的email address抵挡住。#deny_email_enable=YES# 当上面的deny_email_enable=YES时，可以利用这个设定项来规定哪些邮件地址不可登录vsftpd服务器# 此文件需用户自己创建，一行一个email address即可#banned_email_file=/etc/vsftpd/banned_emails# 是否允许递归查询。默认为关闭，以防止远程用户造成过量的I/O#ls_recurse_enable=YES# 是否允许监听。# 如果设置为YES，则vsftpd将以独立模式运行，由vsftpd自己监听和处理IPv4端口的连接请求listen=YES# 设定是否支持IPV6。如要同时监听IPv4和IPv6端口，# 则必须运行两套vsftpd，采用两套配置文件# 同时确保其中有一个监听选项是被注释掉的#listen_ipv6=YES# 设置PAM外挂模块提供的认证服务所使用的配置文件名，即/etc/pam.d/vsftpd文件# 此文件中file=/etc/vsftpd/ftpusers字段，说明了PAM模块能抵挡的帐号内容来自文件/etc/vsftpd/ftpusers中#pam_service_name=vsftpd# 禁止用户登陆FTP后使用"ls -R"的命令。该命令会对服务器性能造成巨大开销。如果该项被允许，那么挡多用户同时使用该命令时将会对该服务器造成威胁。ls_recurse_enable=NO# 是否使用tcp_wrappers作为主机访问控制方式。# tcp_wrappers可以实现linux系统中网络服务的基于主机地址的访问控制# 在/etc目录中的hosts.allow和hosts.deny两个文件用于设置tcp_wrappers的访问控制# 前者设置允许访问记录，后者设置拒绝访问记录。# 如想限制某些主机对FTP服务器192.168.57.2的匿名访问，编缉/etc/hosts.allow文件，如在下面增加两行命令：# vsftpd:192.168.57.1:DENY 和vsftpd:192.168.57.9:DENY# 表明限制IP为192.168.57.1/192.168.57.9主机访问IP为192.168.57.2的FTP服务器# 此时FTP服务器虽可以PING通，但无法连接tcp_wrappers=YES]]></content>
      <tags>
        <tag>Service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DHCP 服务]]></title>
    <url>%2F2016%2F04%2F15%2F090119-DHCP%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[DHCPDHCP（Dynamic Host Configuration Protocol，动态主机配置协议）是一个局域网的网络协议，使用UDP协议工作。主要有两个用途：给内部网络或网络服务供应商自动分配IP地址。 DHCP有3个端口，其中 UDP 67 和 UDP 68 为正常的DHCP服务端口，分别作为DHCP Server和DHCP Client的服务端口；546 端口用于DHCPv6 Client，而不用于DHCPv4，是为DHCP failover服务，这是需要特别开启的服务，DHCP failover是用来做“双机热备”的。 功能 保证任何IP地址在同一时刻只能由一台DHCP客户机所使用。 DHCP应当可以给用户分配永久固定的IP地址。 DHCP应当可以同用其他方法获得IP地址的主机共存（如手工配置IP地址的主机）。 DHCP服务器应当向现有的BOOTP客户端提供服务。 工作原理 ① DHCP Client以广播方式发出DHCP Discover报文。 ② 所有的DHCP Server都能够接收到DHCP Client发送的DHCP Discover报文，所有的DHCP Server都会给出响应，向DHCP Client发送一个DHCP Offer报文。 DHCP Offer报文中“Your(Client) IP Address”字段就是DHCP Server能够提供给DHCP Client使用的IP地址，且DHCP Server会将自己的IP地址放在“option”字段中以便DHCP Client区分不同的DHCP Server。DHCP Server在发出此报文后会存在一个已分配IP地址的纪录。 ③ DHCP Client只能处理其中的一个DHCP Offer报文，一般的原则是DHCP Client处理最先收到的DHCP Offer报文。 DHCP Client会发出一个广播的DHCP Request报文，在选项字段中会加入选中的DHCP Server的IP地址和需要的IP地址。 ④ DHCP Server收到DHCP Request报文后，判断选项字段中的IP地址是否与自己的地址相同。如果不相同，DHCP Server不做任何处理只清除相应IP地址分配记录；如果相同，DHCP Server就会向DHCP Client响应一个DHCP ACK报文，并在选项字段中增加IP地址的使用租期信息。 ⑤ DHCP Client接收到DHCP ACK报文后，检查DHCP Server分配的IP地址是否能够使用。如果可以使用，则DHCP Client成功获得IP地址并根据IP地址使用租期自动启动续延过程；如果DHCP Client发现分配的IP地址已经被使用，则DHCP Client向DHCPServer发出DHCP Decline报文，通知DHCP Server禁用这个IP地址，然后DHCP Client开始新的地址申请过程。 ⑥ DHCP Client在成功获取IP地址后，随时可以通过发送DHCP Release报文释放自己的IP地址，DHCP Server收到DHCP Release报文后，会回收相应的IP地址并重新分配。 分配机制注意：只有动态分配可以重复使用客户端不再需要的地址。 自动分配方式（Automatic Allocation） DHCP服务器为主机指定一个永久性的IP地址，一旦DHCP客户端第一次成功从DHCP服务器端租用到IP地址后，就可以永久性使用该地址。 动态分配方式（Dynamic Allocation） DHCP服务器给主机指定一个具有时间限制的IP地址，时间到期或主机明确表示放弃该地址时，该地址可以被其他主机使用。 手工分配方式（Manual Allocation） 客户端的IP地址是由网络管理员指定的，DHCP服务器只是将指定的IP地址告诉客户端主机。 安装配置12345# 安装rpm包yum -y install dhcp # 生成配置文件模板cp /etc/dhcp/dhcpd.conf&#123;,.bak&#125;cp /usr/share/doc/dhcp-4.2.5/dhcpd.conf.example /etc/dhcp/dhcpd.conf 文件 /etc/dhcp/dhcpd.conf 配置说明 1234567891011121314151617181920212223242526272829303132ddns-update-style interim; #表示dhcp服务器和dns服务器的动态信息更新模式ignore client-updates;#忽略客户端更新 subnet 192.168.247.0 netmask 255.255.255.0 &#123; #dhcp服务器所分配的ip地址所在的网段为192.168.247.0 子网掩码为255.255.255.0 option routers 192.168.247.1; #路由器地址，即给客户端提供的网关地址 option subnet-mask 255.255.255.0; #子网掩码 # option domain-name "example.org"; # 搜索域，具体为/etc/resov.conf中search行对应的域 option domain-name-servers 114.114.114.114; # DNS服务器地址，最多三个，以逗号隔开 range 192.168.247.100 192.168.247.200; # 租用IP地址的范围，linux环境下从后往前分配 default-lease-time 600; #默认租约时间 max-lease-time 7200; #最大租约时间 host myhost &#123; #固定分配，myhost为标识符，无实际意义 hardware ethernet MAC_ADDRESS; #指定dhcp客户的mac地址 fixed-address 192.168.247.155; #给指定的mac地址分配ip &#125; &#125;]]></content>
      <tags>
        <tag>Service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS中resolv.conf的配置实验]]></title>
    <url>%2F2016%2F04%2F11%2F110119-CentOS%E4%B8%ADresolv.conf%E7%9A%84%E9%85%8D%E7%BD%AE%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[通常情况下，在 Linux 中可以用来配置 DNS 地址的文件有两个： 解析配置文件 /etc/resolv.conf，文件中的注释行可以采用 # 或者 ; 开头 网卡 ifcfg 配置文件 /etc/sysconfig/network-scripts/ifcfg-eth* resolv.conf 的配置参数通过查看 man手册页，会看到有很多相关的参数，这里只说比较常用的几个 nameserver这个参数会指定系统使用的 DNS 的 IP 地址，在生产环境中，经常会看到 /etc/resolv.conf 中配置了一个或多个 nameserver 。配置了多个 nameserver 后，系统使用这些 DNS 的顺序并未进行轮询、随机、或者均衡调度，并且系统总是使用第一个 nameserver 对应的地址来进行 DNS 的查询。 123456789[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8nameserver 9.9.9.9nameserver 114.114.114.114nameserver 1.2.4.8nameserver 180.76.76.76nameserver 223.5.5.5[root@bogon ~]# [root@bogon ~]# dig +short +tries=1 www.redhat.com www.centos.org www.kernel.org 解析的同时，使用 tcpdump 命令分析通信数据，从结果中可以看到，使用 dig 对三个域名的解析只用到了第一个 nameserver 的地址，即 8.8.8.8 123456789[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes20:51:38.162534 IP 192.168.127.154.58459 &gt; 8.8.8.8.53: 27136+ [1au] A? www.redhat.com. (43)20:51:38.165500 IP 8.8.8.8.53 &gt; 192.168.127.154.58459: 27136 4/0/0 CNAME ds-www.redhat.com.edgekey.net., CNAME ds-www.redhat.com.edgekey.net.globalredir.akadns.net., CNAME e3396.ca2.s.tl88.net., A 210.192.117.211 (185)20:51:38.166018 IP 192.168.127.154.58937 &gt; 8.8.8.8.53: 37326+ [1au] A? www.centos.org. (43)20:51:38.449824 IP 8.8.8.8.53 &gt; 192.168.127.154.58937: 37326 1/3/4 A 85.12.30.226 (161)20:51:38.450397 IP 192.168.127.154.47932 &gt; 8.8.8.8.53: 5121+ [1au] A? www.kernel.org. (43)20:51:38.546600 IP 8.8.8.8.53 &gt; 192.168.127.154.47932: 5121 3/6/1 CNAME git.kernel.org., CNAME hkg.git.kernel.org., A 147.75.42.139 (237) 换成一次解析一个域名 1234[root@bogon ~]# dig +short +tries=1 www.baidu.com[root@bogon ~]# dig +short +tries=1 www.qq.com[root@bogon ~]# dig +short +tries=1 www.taobao.com[root@bogon ~]# dig +short +tries=1 www.amazon.com 结果同上，也是只用到了第一个 nameserver 的地址，即 8.8.8.8 1234567891011[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth0, link-type EN10MB (Ethernet), capture size 262144 bytes20:54:35.061088 IP 192.168.127.154.54374 &gt; 8.8.8.8.53: 11030+ [1au] A? www.baidu.com. (42)20:54:35.062881 IP 8.8.8.8.53 &gt; 192.168.127.154.54374: 11030$ 3/0/0 CNAME www.a.shifen.com., A 220.181.112.244, A 220.181.111.188 (93)20:54:35.071402 IP 192.168.127.154.57419 &gt; 8.8.8.8.53: 31566+ [1au] A? www.qq.com. (39)20:54:35.073641 IP 8.8.8.8.53 &gt; 192.168.127.154.57419: 31566$ 1/0/0 A 123.151.148.111 (44)20:54:35.081402 IP 192.168.127.154.37311 &gt; 8.8.8.8.53: 3036+ [1au] A? www.taobao.com. (43)20:54:35.083099 IP 8.8.8.8.53 &gt; 192.168.127.154.37311: 3036$ 2/0/0 CNAME www.taobao.com.danuoyi.tbcache.com., A 124.238.232.220 (96)20:54:35.090256 IP 192.168.127.154.34286 &gt; 8.8.8.8.53: 18338+ [1au] A? www.amazon.com. (43)20:54:35.427330 IP 8.8.8.8.53 &gt; 192.168.127.154.34286: 18338 3/4/1 CNAME www.cdn.amazon.com., CNAME d3ag4hukkh62yn.cloudfront.net., A 13.33.230.194 (258) 如果第一个 nameserver 对应的地址是不可用的 IP ，域名的解析均是从第一个 nameserver 对用的地址进行查询的，系统会按照 nameserver 设定的顺序从上往下进行顺序尝试，当无法获取结果后将尝试使用下一个，并且系统不会记录任何一个 nameserver 的工作状态。 12345678[root@bogon ~]# cat /etc/resolv.conf nameserver 123.45.67.8nameserver 8.8.8.8nameserver 9.9.9.9nameserver 114.114.114.114nameserver 1.2.4.8nameserver 180.76.76.76nameserver 223.5.5.5 1[root@bogon ~]# dig +short +tries=1 www.redhat.com www.centos.org www.kernel.org 抓包结果 123456789101112[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes21:09:32.043033 IP 124.160.121.68.48453 &gt; 123.45.67.8.53: 3179+ [1au] A? www.redhat.com. (43)21:09:33.042929 IP 124.160.121.68.37014 &gt; 8.8.8.8.53: 3179+ [1au] A? www.redhat.com. (43)21:09:33.327958 IP 8.8.8.8.53 &gt; 124.160.121.68.37014: 3179 4/0/1 CNAME ds-www.redhat.com.edgekey.net., CNAME ds-www.redhat.com.edgekey.net.globalredir.akadns.net., CNAME e3396.ca2.s.tl88.net., A 122.224.45.211 (196)21:09:33.328311 IP 124.160.121.68.54898 &gt; 123.45.67.8.53: 13619+ [1au] A? www.centos.org. (43)21:09:34.328397 IP 124.160.121.68.43004 &gt; 8.8.8.8.53: 13619+ [1au] A? www.centos.org. (43)21:09:34.563133 IP 8.8.8.8.53 &gt; 124.160.121.68.43004: 13619 1/0/1 A 85.12.30.226 (59)21:09:34.563347 IP 124.160.121.68.33925 &gt; 123.45.67.8.53: 13240+ [1au] A? www.kernel.org. (43)21:09:35.563401 IP 124.160.121.68.36621 &gt; 8.8.8.8.53: 13240+ [1au] A? www.kernel.org. (43)21:09:35.624542 IP 8.8.8.8.53 &gt; 124.160.121.68.36621: 13240 3/0/1 CNAME git.kernel.org., CNAME hkg.git.kernel.org., A 147.75.42.139 (95) 如果有多个 nameserver 不可用时，对于 dig 和 ping 命令而言生效的只有前三个，当前三个 nameserver 都不可用时，不会再向其余的 nameserver请求解析。对于 curl 命令来说生效的是全部，依次从上向下轮询，直到找到能有所响应的为止。 1234567891011121314151617[root@bogon ~]# cat /etc/resolv.conf nameserver 123.45.67.8nameserver 123.45.67.9nameserver 123.45.67.10nameserver 123.45.67.11nameserver 123.45.67.12nameserver 8.8.8.8nameserver 9.9.9.9nameserver 114.114.114.114nameserver 1.2.4.8nameserver 180.76.76.76nameserver 223.5.5.5[root@bogon ~]# [root@bogon ~]# dig +short +tries=1 www.redhat.com www.centos.org www.kernel.org ;; connection timed out; no servers could be reached;; connection timed out; no servers could be reached;; connection timed out; no servers could be reached 抓包结果 123456789101112[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes21:25:18.162523 IP 124.160.121.68.35636 &gt; 123.45.67.8.53: 34369+ [1au] A? www.redhat.com. (43)21:25:19.162528 IP 124.160.121.68.35529 &gt; 123.45.67.9.53: 34369+ [1au] A? www.redhat.com. (43)21:25:20.162618 IP 124.160.121.68.44291 &gt; 123.45.67.10.53: 34369+ [1au] A? www.redhat.com. (43)21:25:25.162806 IP 124.160.121.68.57363 &gt; 123.45.67.8.53: 36309+ [1au] A? www.centos.org. (43)21:25:26.162892 IP 124.160.121.68.37002 &gt; 123.45.67.9.53: 36309+ [1au] A? www.centos.org. (43)21:25:27.162974 IP 124.160.121.68.56470 &gt; 123.45.67.10.53: 36309+ [1au] A? www.centos.org. (43)21:25:32.163160 IP 124.160.121.68.52253 &gt; 123.45.67.8.53: 59858+ [1au] A? www.kernel.org. (43)21:25:33.163201 IP 124.160.121.68.36526 &gt; 123.45.67.9.53: 59858+ [1au] A? www.kernel.org. (43)21:25:34.163285 IP 124.160.121.68.42950 &gt; 123.45.67.10.53: 59858+ [1au] A? www.kernel.org. (43) 从上面的结果可以看到，dig 在请求解析每个域名时，都会向前三个 nameserver 请求 12345678910111213141516171819202122[root@bogon ~]# cat /etc/resolv.confnameserver 123.45.67.1nameserver 123.45.67.2nameserver 123.45.67.3nameserver 123.45.67.4nameserver 123.45.67.5nameserver 123.45.67.6nameserver 123.45.67.7nameserver 123.45.67.8nameserver 8.8.8.8[root@bogon ~]# curl -I www.baidu.comHTTP/1.1 200 OKAccept-Ranges: bytesCache-Control: private, no-cache, no-store, proxy-revalidate, no-transformConnection: Keep-AliveContent-Length: 277Content-Type: text/htmlDate: Sat, 12 May 2018 11:44:10 GMTEtag: &quot;575e1f5c-115&quot;Last-Modified: Mon, 13 Jun 2016 02:50:04 GMTPragma: no-cacheServer: bfe/1.0.8.18 抓包结果 12345678910111213[root@bogon ~]# tcpdump -nn -i eth1 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes19:43:37.708473 IP 124.160.121.68.52347 &gt; 123.45.67.1.53: 57511+ A? www.baidu.com. (31)19:43:42.709785 IP 124.160.121.68.44730 &gt; 123.45.67.2.53: 57511+ A? www.baidu.com. (31)19:43:47.397695 IP 124.160.121.68.52848 &gt; 123.45.67.3.53: 57511+ A? www.baidu.com. (31)19:43:50.531180 IP 124.160.121.68.32775 &gt; 123.45.67.4.53: 57511+ A? www.baidu.com. (31)19:43:54.282260 IP 124.160.121.68.34249 &gt; 123.45.67.5.53: 57511+ A? www.baidu.com. (31)19:43:57.415747 IP 124.160.121.68.45492 &gt; 123.45.67.6.53: 57511+ A? www.baidu.com. (31)19:44:02.417119 IP 124.160.121.68.53927 &gt; 123.45.67.7.53: 57511+ A? www.baidu.com. (31)19:44:05.862921 IP 124.160.121.68.48605 &gt; 123.45.67.8.53: 57511+ A? www.baidu.com. (31)19:44:09.933530 IP 124.160.121.68.55600 &gt; 8.8.8.8.53: 57511+ A? www.baidu.com. (31)19:44:10.038720 IP 8.8.8.8.53 &gt; 124.160.121.68.55600: 57511 3/0/0 CNAME www.a.shifen.com., A 61.135.169.121, A 61.135.169.125 (90) domain1domain &lt;Local domain name&gt; 这个参数用于系统在进行 DNS 查询时，如果请求的域名无法正常解析时自动补充 domain 的参数值。 当请求解析的内容中含有域时，即无论系统请求哪一个主机名时，系统默认都会先加上根域 .，但是如果不包含域，则会将 domain 中设定的域填充进去。这是官方文档中的一段描述： 123the domain part is taken to be everything after the first '.'.Finally, if the hostname does not contain a domain part, the root domain is assumed. 当请求解析的内容不包含有域时，不管请求的内容是不是合法的，系统都直接填充 domain 参数。 12345678910111213[root@bogon ~]# cat /etc/resolv.conf domain baidu.comnameserver 8.8.8.8nameserver 9.9.9.9nameserver 114.114.114.114[root@bogon ~]# [root@bogon ~]# ping -c 1 wwwPING www.a.shifen.com (61.135.169.121) 56(84) bytes of data.64 bytes from 61.135.169.121 (61.135.169.121): icmp_seq=1 ttl=54 time=28.3 ms--- www.a.shifen.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 28.390/28.390/28.390/0.000 ms 抓包结果 1234567[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes15:34:53.581383 IP 124.160.121.68.42899 &gt; 8.8.8.8.53: 62551+ A? www.baidu.com. (31)15:34:53.711318 IP 8.8.8.8.53 &gt; 124.160.121.68.42899: 62551 3/0/0 CNAME www.a.shifen.com., A 61.135.169.121, A 61.135.169.125 (90)15:34:53.740080 IP 124.160.121.68.45679 &gt; 8.8.8.8.53: 35362+ PTR? 121.169.135.61.in-addr.arpa. (45)15:34:53.790788 IP 8.8.8.8.53 &gt; 124.160.121.68.45679: 35362 NXDomain 0/1/0 (97) 12[root@bogon ~]# ping -c 1 baiduping: baidu: Name or service not known 1234567[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes15:40:46.521311 IP 124.160.121.68.54008 &gt; 8.8.8.8.53: 51825+ A? baidu.baidu.com. (33)15:40:46.619891 IP 8.8.8.8.53 &gt; 124.160.121.68.54008: 51825 NXDomain 0/1/0 (76)15:40:46.619961 IP 124.160.121.68.37288 &gt; 8.8.8.8.53: 59104+ A? baidu. (23)15:40:46.668562 IP 8.8.8.8.53 &gt; 124.160.121.68.37288: 59104 0/1/0 (93) 请求解析的内容包含有域时，不管请求的内容是不是合法的，系统都会先直接解析而不是直接填充 domain 参数 12345[root@bogon ~]# cat /etc/resolv.conf domain .orgnameserver 8.8.8.8nameserver 9.9.9.9nameserver 114.114.114.114 请求解析的内容包含有域，且该域有对应的 A 记录 1234567[root@bogon ~]# ping -c1 baidu.comPING baidu.com (123.125.115.110) 56(84) bytes of data.64 bytes from 123.125.115.110 (123.125.115.110): icmp_seq=1 ttl=54 time=33.6 ms--- baidu.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 33.654/33.654/33.654/0.000 ms 1234567[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes15:52:51.006971 IP 124.160.121.68.35960 &gt; 8.8.8.8.53: 29630+ A? baidu.com. (27)15:52:51.054703 IP 8.8.8.8.53 &gt; 124.160.121.68.35960: 29630 2/0/0 A 123.125.115.110, A 220.181.57.216 (59)15:52:51.088759 IP 124.160.121.68.52785 &gt; 8.8.8.8.53: 12744+ PTR? 110.115.125.123.in-addr.arpa. (46)15:52:51.134573 IP 8.8.8.8.53 &gt; 124.160.121.68.52785: 12744 NXDomain 0/1/0 (100) 请求解析的内容包含有域，但该域不合法或者没有对应的A记录 12[root@bogon ~]# ping -c1 baidu123.comping: baidu123.com: Name or service not known 抓包结果 12345[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes15:56:01.274770 IP 124.160.121.68.60947 &gt; 8.8.8.8.53: 32132+ A? baidu123.com. (30)15:56:01.666132 IP 8.8.8.8.53 &gt; 124.160.121.68.60947: 32132 0/1/0 (96) search1search &lt;Search list for host-name lookup&gt; 指定一组域名（用空格分割），当仅写出主机名时，就开始依次进行这些域名的匹配，如果第一个域名没有匹配到，那么用第二个进行匹配，以此类推，直到匹配完所有列出的域名，给出最终的结果。 123456789101112[root@bogon ~]# cat /etc/resolv.confsearch redhat.com centos.org baidu.com kernel.orgnameserver 8.8.8.8nameserver 9.9.9.9nameserver 114.114.114.114[root@bogon ~]# [root@bogon ~]# ping -c 1 -W 1 -q panPING yiyun.n.shifen.com (111.206.37.70) 56(84) bytes of data.--- yiyun.n.shifen.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 26.970/26.970/26.970/0.000 ms 抓包结果 1234567891011[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes21:54:13.539662 IP 124.160.121.68.41382 &gt; 8.8.8.8.53: 51406+ A? pan.redhat.com. (32)21:54:13.641746 IP 8.8.8.8.53 &gt; 124.160.121.68.41382: 51406 0/1/0 (76)21:54:13.641866 IP 124.160.121.68.43018 &gt; 8.8.8.8.53: 15888+ A? pan.centos.org. (32)21:54:13.876920 IP 8.8.8.8.53 &gt; 124.160.121.68.43018: 15888 NXDomain 0/1/0 (83)21:54:13.876974 IP 124.160.121.68.39758 &gt; 8.8.8.8.53: 2584+ A? pan.baidu.com. (31)21:54:13.979307 IP 8.8.8.8.53 &gt; 124.160.121.68.39758: 2584 3/0/0 CNAME yiyun.n.shifen.com., A 111.206.37.70, A 153.37.235.66 (92)21:54:14.006705 IP 124.160.121.68.54116 &gt; 8.8.8.8.53: 20521+ PTR? 70.37.206.111.in-addr.arpa. (44)21:54:14.055034 IP 8.8.8.8.53 &gt; 124.160.121.68.54116: 20521 NXDomain 0/1/0 (98) 12[root@bogon ~]# ping -c 1 -W 1 -q x1y2z3ping: x1y2z3: Name or service not known 1234567891011[root@bogon ~]# tcpdump -nn -i eth0 udp port 5321:57:47.079874 IP 124.160.121.68.59551 &gt; 8.8.8.8.53: 14646+ A? x1y2z3.redhat.com. (35)21:57:47.388342 IP 8.8.8.8.53 &gt; 124.160.121.68.59551: 14646 0/1/0 (79)21:57:47.388416 IP 124.160.121.68.40022 &gt; 8.8.8.8.53: 10171+ A? x1y2z3.centos.org. (35)21:57:47.702240 IP 8.8.8.8.53 &gt; 124.160.121.68.40022: 10171 NXDomain 0/1/0 (86)21:57:47.702297 IP 124.160.121.68.56305 &gt; 8.8.8.8.53: 15347+ A? x1y2z3.baidu.com. (34)21:57:47.804776 IP 8.8.8.8.53 &gt; 124.160.121.68.56305: 15347 NXDomain 0/1/0 (77)21:57:47.821951 IP 124.160.121.68.40022 &gt; 8.8.8.8.53: 10171+ A? x1y2z3.kernel.org. (35)21:57:47.832714 IP 8.8.8.8.53 &gt; 124.160.121.68.40022: 10171 NXDomain 0/1/0 (94)21:57:47.804841 IP 124.160.121.68.52432 &gt; 8.8.8.8.53: 1360+ A? x1y2z3. (24)21:57:47.857440 IP 8.8.8.8.53 &gt; 124.160.121.68.52432: 1360 NXDomain 0/1/0 (99) options用来设定一些选项，实现不同的功能 timeout可选选项，系统一次 DNS 解析 timeout 的时间值，单位为秒。系统默认值为 5，最大可以设定的值是 30 1timeout:n 下面对于 timeout 的实验我们都在 /etc/resolv.conf 中配置无效的 DNS 在查看了 dig 命令的帮助手册之后发现它也有个 timeout 参数 +time=T，在不指定该参数的情况下默认为 5 秒，那么我们 不在 resolv.conf 中配置 timeout 来进行测试看一下： 1234567[root@bogon ~]# cat /etc/resolv.confnameserver 123.45.67.1nameserver 123.45.67.2nameserver 123.45.67.3[root@bogon ~]# [root@bogon ~]# dig +tries=5 +time=2 +short www.baidu.com ;; connection timed out; no servers could be reached 抓包结果 1234567891011121314151617181920212223[root@bogon ~]# tcpdump -nn -i eth0 udp port 53 tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes17:00:22.378172 IP 124.160.121.68.39149 &gt; 123.45.67.1.53: 18650+ [1au] A? www.baidu.com. (42)17:00:23.378136 IP 124.160.121.68.37930 &gt; 123.45.67.2.53: 18650+ [1au] A? www.baidu.com. (42)17:00:24.378219 IP 124.160.121.68.58526 &gt; 123.45.67.3.53: 18650+ [1au] A? www.baidu.com. (42)17:00:26.378269 IP 124.160.121.68.39149 &gt; 123.45.67.1.53: 18650+ [1au] A? www.baidu.com. (42)17:00:27.378355 IP 124.160.121.68.37930 &gt; 123.45.67.2.53: 18650+ [1au] A? www.baidu.com. (42)17:00:28.378442 IP 124.160.121.68.58526 &gt; 123.45.67.3.53: 18650+ [1au] A? www.baidu.com. (42)17:00:30.378527 IP 124.160.121.68.39149 &gt; 123.45.67.1.53: 18650+ [1au] A? www.baidu.com. (42)17:00:31.378614 IP 124.160.121.68.37930 &gt; 123.45.67.2.53: 18650+ [1au] A? www.baidu.com. (42)17:00:32.378703 IP 124.160.121.68.58526 &gt; 123.45.67.3.53: 18650+ [1au] A? www.baidu.com. (42)17:00:34.378786 IP 124.160.121.68.39149 &gt; 123.45.67.1.53: 18650+ [1au] A? www.baidu.com. (42)17:00:35.378870 IP 124.160.121.68.37930 &gt; 123.45.67.2.53: 18650+ [1au] A? www.baidu.com. (42)17:00:36.378958 IP 124.160.121.68.58526 &gt; 123.45.67.3.53: 18650+ [1au] A? www.baidu.com. (42)17:00:38.379040 IP 124.160.121.68.39149 &gt; 123.45.67.1.53: 18650+ [1au] A? www.baidu.com. (42)17:00:39.379122 IP 124.160.121.68.37930 &gt; 123.45.67.2.53: 18650+ [1au] A? www.baidu.com. (42)17:00:40.379210 IP 124.160.121.68.58526 &gt; 123.45.67.3.53: 18650+ [1au] A? www.baidu.com. (42) 为了便于区分，上述内容人工填充了空行。从上面可以看到 dig 向三个 nameserver 分别请求解析，向每个 nameserver 请求解析的时间间隔为 1 秒而不是 2 秒 dig 在五次对文件中的 nameserver 轮询，每次轮询之间的时间间隔为 2 秒 如果我们在 /etc/resolv.conf 中配置了 timeout，到底是以 dig 的为准还是以 /etc/resolv.conf 中的为准？ 当 dig 的 timeout 大于 resolv.conf 中的 timeout 时 12345678[root@bogon ~]# cat /etc/resolv.confoptions timeout:3nameserver 123.45.67.1nameserver 123.45.67.2nameserver 123.45.67.3[root@bogon ~]# [root@bogon ~]# dig +tries=5 +timeout=4 +short www.baidu.com ;; connection timed out; no servers could be reached 抓包结果 12345678910111213141516171819202122[root@bogon ~]# tcpdump -nn -i eth0 udp port 53 tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes16:06:44.330997 IP 124.160.121.68.60827 &gt; 123.45.67.1.53: 12194+ [1au] A? www.baidu.com. (42)16:06:45.331000 IP 124.160.121.68.45589 &gt; 123.45.67.2.53: 12194+ [1au] A? www.baidu.com. (42)16:06:46.331082 IP 124.160.121.68.43181 &gt; 123.45.67.3.53: 12194+ [1au] A? www.baidu.com. (42)16:06:49.331133 IP 124.160.121.68.60827 &gt; 123.45.67.1.53: 12194+ [1au] A? www.baidu.com. (42)16:06:50.331220 IP 124.160.121.68.45589 &gt; 123.45.67.2.53: 12194+ [1au] A? www.baidu.com. (42)16:06:51.331312 IP 124.160.121.68.43181 &gt; 123.45.67.3.53: 12194+ [1au] A? www.baidu.com. (42)16:06:54.331403 IP 124.160.121.68.60827 &gt; 123.45.67.1.53: 12194+ [1au] A? www.baidu.com. (42)16:06:55.331488 IP 124.160.121.68.45589 &gt; 123.45.67.2.53: 12194+ [1au] A? www.baidu.com. (42)16:06:56.331571 IP 124.160.121.68.43181 &gt; 123.45.67.3.53: 12194+ [1au] A? www.baidu.com. (42)16:06:59.331658 IP 124.160.121.68.60827 &gt; 123.45.67.1.53: 12194+ [1au] A? www.baidu.com. (42)16:07:00.331747 IP 124.160.121.68.45589 &gt; 123.45.67.2.53: 12194+ [1au] A? www.baidu.com. (42)16:07:01.331837 IP 124.160.121.68.43181 &gt; 123.45.67.3.53: 12194+ [1au] A? www.baidu.com. (42)16:07:04.331913 IP 124.160.121.68.60827 &gt; 123.45.67.1.53: 12194+ [1au] A? www.baidu.com. (42)16:07:05.332004 IP 124.160.121.68.45589 &gt; 123.45.67.2.53: 12194+ [1au] A? www.baidu.com. (42)16:07:06.332093 IP 124.160.121.68.43181 &gt; 123.45.67.3.53: 12194+ [1au] A? www.baidu.com. (42) dig 没有指定 timeout 参数则使用默认值 5 秒 12[root@bogon ~]# dig +tries=5 +short www.baidu.com ;; connection timed out; no servers could be reached 抓包结果 1234567891011121314151617181920212223[root@bogon ~]# tcpdump -nn -i eth0 udp port 53 tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes16:25:06.558406 IP 124.160.121.68.54373 &gt; 123.45.67.1.53: 51295+ [1au] A? www.baidu.com. (42)16:25:07.558450 IP 124.160.121.68.46082 &gt; 123.45.67.2.53: 51295+ [1au] A? www.baidu.com. (42)16:25:08.558486 IP 124.160.121.68.47769 &gt; 123.45.67.3.53: 51295+ [1au] A? www.baidu.com. (42)16:25:11.558564 IP 124.160.121.68.54373 &gt; 123.45.67.1.53: 51295+ [1au] A? www.baidu.com. (42)16:25:12.558629 IP 124.160.121.68.46082 &gt; 123.45.67.2.53: 51295+ [1au] A? www.baidu.com. (42)16:25:13.558724 IP 124.160.121.68.47769 &gt; 123.45.67.3.53: 51295+ [1au] A? www.baidu.com. (42)16:25:16.558808 IP 124.160.121.68.54373 &gt; 123.45.67.1.53: 51295+ [1au] A? www.baidu.com. (42)16:25:17.558894 IP 124.160.121.68.46082 &gt; 123.45.67.2.53: 51295+ [1au] A? www.baidu.com. (42)16:25:18.558976 IP 124.160.121.68.47769 &gt; 123.45.67.3.53: 51295+ [1au] A? www.baidu.com. (42)16:25:21.559058 IP 124.160.121.68.54373 &gt; 123.45.67.1.53: 51295+ [1au] A? www.baidu.com. (42)16:25:22.559147 IP 124.160.121.68.46082 &gt; 123.45.67.2.53: 51295+ [1au] A? www.baidu.com. (42)16:25:23.559230 IP 124.160.121.68.47769 &gt; 123.45.67.3.53: 51295+ [1au] A? www.baidu.com. (42)16:25:26.559320 IP 124.160.121.68.54373 &gt; 123.45.67.1.53: 51295+ [1au] A? www.baidu.com. (42)16:25:27.559404 IP 124.160.121.68.46082 &gt; 123.45.67.2.53: 51295+ [1au] A? www.baidu.com. (42)16:25:28.559488 IP 124.160.121.68.47769 &gt; 123.45.67.3.53: 51295+ [1au] A? www.baidu.com. (42) 当 dig 的 timeout 小于 resolv.conf 中的 timeout 时 12345678[root@bogon ~]# cat /etc/resolv.confoptions timeout:10nameserver 123.45.67.1nameserver 123.45.67.2nameserver 123.45.67.3[root@bogon ~]#[root@bogon ~]# dig +tries=3 +time=2 +short www.baidu.com ;; connection timed out; no servers could be reached 抓包结果 123456789101112131415[root@bogon ~]# tcpdump -nn -i eth0 udp port 53 tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes16:31:54.273506 IP 124.160.121.68.49564 &gt; 123.45.67.1.53: 31368+ [1au] A? www.baidu.com. (42)16:31:55.273448 IP 124.160.121.68.58295 &gt; 123.45.67.2.53: 31368+ [1au] A? www.baidu.com. (42)16:31:56.273534 IP 124.160.121.68.43357 &gt; 123.45.67.3.53: 31368+ [1au] A? www.baidu.com. (42)16:32:06.273581 IP 124.160.121.68.49564 &gt; 123.45.67.1.53: 31368+ [1au] A? www.baidu.com. (42)16:32:07.273668 IP 124.160.121.68.58295 &gt; 123.45.67.2.53: 31368+ [1au] A? www.baidu.com. (42)16:32:08.273755 IP 124.160.121.68.43357 &gt; 123.45.67.3.53: 31368+ [1au] A? www.baidu.com. (42)16:32:18.273872 IP 124.160.121.68.49564 &gt; 123.45.67.1.53: 31368+ [1au] A? www.baidu.com. (42)16:32:19.273953 IP 124.160.121.68.58295 &gt; 123.45.67.2.53: 31368+ [1au] A? www.baidu.com. (42)16:32:20.274030 IP 124.160.121.68.43357 &gt; 123.45.67.3.53: 31368+ [1au] A? www.baidu.com. (42) 多次测试后发现： 对于 dig 来说，自身的 timeout 和 /etc/resolv.conf 二者的 timeout 都指的是每次轮询完文件 nameserver 的超时时间，而不是每个 nameserver 的超时时间 而对于 ping 来说，自身的 timeout 指的是每个包的超时时间，/etc/resolv.conf 的 timeout 指的是每个 nameserver 的超时时间，不是每次轮询的时间 只要 /etc/resolv.conf 配置了 timeout 就直接忽略 dig 的 timeout ，以 /etc/resolv.conf 中配置的为准；否则就以 dig 设定的（未设定则使用默认值）为准 attempts可选选项，系统尝试解析的次数，如果未设定则默认值是 2。系统允许最大值是 5，即当系统请求解析失败多少次之后，才会给系统或者程序返回解析失败的结果。对于 dig 命令来说，文件中配置的 attempts 如果是一个小数，则可能会提示语法错误，如果是 0 则不会进行解析。 1attempts:n 因为 dig 命令也有个尝试次数的参数 +tries=T，默认是请求三次。不管 /etc/resolv.conf 有没有配置 attempts，在使用 dig 的时候都会以 dig 的为准。这里我们要对 /etc/resolv.conf 文件中的配置做实验，就使用 ping 来测试。 12345678910111213[root@bogon ~]# cat /etc/resolv.confoptions timeout:3options attempts:2nameserver 123.45.67.1nameserver 123.45.67.2nameserver 123.45.67.3[root@bogon ~]#[root@bogon ~]# time ping -c 3 www.baidu.com ping: www.baidu.com: Name or service not knownreal 0m36.040suser 0m0.000ssys 0m0.004s 抓包结果 1234567891011121314151617[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes17:57:48.821495 IP 124.160.121.68.37237 &gt; 123.45.67.1.53: 62997+ A? www.baidu.com. (31)17:57:51.824546 IP 124.160.121.68.42482 &gt; 123.45.67.2.53: 62997+ A? www.baidu.com. (31)17:57:53.826591 IP 124.160.121.68.48320 &gt; 123.45.67.3.53: 62997+ A? www.baidu.com. (31)17:57:57.830621 IP 124.160.121.68.37237 &gt; 123.45.67.1.53: 62997+ A? www.baidu.com. (31)17:58:00.833656 IP 124.160.121.68.42482 &gt; 123.45.67.2.53: 62997+ A? www.baidu.com. (31)17:58:02.835688 IP 124.160.121.68.48320 &gt; 123.45.67.3.53: 62997+ A? www.baidu.com. (31)17:58:06.839767 IP 124.160.121.68.54390 &gt; 123.45.67.1.53: 47323+ A? www.baidu.com. (31)17:58:09.842821 IP 124.160.121.68.60543 &gt; 123.45.67.2.53: 47323+ A? www.baidu.com. (31)17:58:11.844871 IP 124.160.121.68.51676 &gt; 123.45.67.3.53: 47323+ A? www.baidu.com. (31)17:58:15.848917 IP 124.160.121.68.54390 &gt; 123.45.67.1.53: 47323+ A? www.baidu.com. (31)17:58:18.851953 IP 124.160.121.68.60543 &gt; 123.45.67.2.53: 47323+ A? www.baidu.com. (31)17:58:20.853984 IP 124.160.121.68.51676 &gt; 123.45.67.3.53: 47323+ A? www.baidu.com. (31) 上面的抓包结果看上去有些费解。我们先算一下时间，已知 /etc/resolv.conf 中的 timeout 对于 ping 来说指的是每个 nameserver 的超时时间，我们设置了 3 个无效的 DNS ，超时时间为 3 ，因此尝试（轮询）一次的时间为 3 x 3 =9 , 两次尝试应该是 18 s 才对，为什么看到的却是 36 呢？这是因为 ping 在进行一次解析的时候会做两个不同的记录的询问请求，一个是 A 记录，另一个是 PTR 记录。当然 PTR 记录是得到 A 记录之后再做的，如果没有得到 A 记录就会再请求一次 A 记录。 我们不妨设置两个 DNS，第一个无效，第二个设为有效的来看看： 12345678910111213141516171819[root@bogon ~]# cat /etc/resolv.confoptions timeout:3options attempts:2nameserver 123.45.67.1nameserver 8.8.8.8[root@bogon ~]# [root@bogon ~]# time ping -c 3 www.baidu.comPING www.a.shifen.com (61.135.169.125) 56(84) bytes of data.64 bytes from 61.135.169.125 (61.135.169.125): icmp_seq=1 ttl=54 time=28.4 ms64 bytes from 61.135.169.125 (61.135.169.125): icmp_seq=2 ttl=54 time=28.3 ms64 bytes from 61.135.169.125 (61.135.169.125): icmp_seq=3 ttl=54 time=28.3 ms--- www.a.shifen.com ping statistics ---3 packets transmitted, 3 received, 0% packet loss, time 4084msrtt min/avg/max/mdev = 28.356/28.378/28.405/0.195 msreal 0m7.215suser 0m0.002ssys 0m0.004s 抓包结果 123456789101112131415[root@bogon ~]# tcpdump -nn -i eth0 icmp or udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes18:11:43.480899 IP 124.160.121.68.60040 &gt; 123.45.67.1.53: 29894+ A? www.baidu.com. (31)18:11:46.483955 IP 124.160.121.68.57979 &gt; 8.8.8.8.53: 29894+ A? www.baidu.com. (31)18:11:46.579031 IP 8.8.8.8.53 &gt; 124.160.121.68.57979: 29894 3/0/0 CNAME www.a.shifen.com., A 61.135.169.125, A 61.135.169.121 (90)18:11:46.579360 IP 124.160.121.68 &gt; 61.135.169.125: ICMP echo request, id 14864, seq 1, length 6418:11:46.607733 IP 61.135.169.125 &gt; 124.160.121.68: ICMP echo reply, id 14864, seq 1, length 6418:11:46.607865 IP 124.160.121.68.36510 &gt; 123.45.67.1.53: 16127+ PTR? 125.169.135.61.in-addr.arpa. (45)18:11:49.610912 IP 124.160.121.68.53473 &gt; 8.8.8.8.53: 16127+ PTR? 125.169.135.61.in-addr.arpa. (45)18:11:49.660012 IP 8.8.8.8.53 &gt; 124.160.121.68.53473: 16127 NXDomain 0/1/0 (97)18:11:49.662472 IP 124.160.121.68 &gt; 61.135.169.125: ICMP echo request, id 14864, seq 2, length 6418:11:49.690812 IP 61.135.169.125 &gt; 124.160.121.68: ICMP echo reply, id 14864, seq 2, length 6418:11:50.663851 IP 124.160.121.68 &gt; 61.135.169.125: ICMP echo request, id 14864, seq 3, length 6418:11:50.692213 IP 61.135.169.125 &gt; 124.160.121.68: ICMP echo reply, id 14864, seq 3, length 64 分析： 118:11:43.480899 IP 124.160.121.68.60040 &gt; 123.45.67.1.53: 29894+ A? www.baidu.com. (31) 向第一个 DNS 开始第一次尝试，做第一件事：询问 A 记录 118:11:46.483955 IP 124.160.121.68.57979 &gt; 8.8.8.8.53: 29894+ A? www.baidu.com. (31) 第一个 DNS 无效，在等待超时时间 options timeout:3 也就是 3 秒之后，向第二个 DNS 第一次尝试，做第一件事：询问 A 记录 12318:11:46.579031 IP 8.8.8.8.53 &gt; 124.160.121.68.57979: 29894 3/0/0 CNAME www.a.shifen.com., A 61.135.169.125, A 61.135.169.121 (90)18:11:46.579360 IP 124.160.121.68 &gt; 61.135.169.125: ICMP echo request, id 14864, seq 1, length 6418:11:46.607733 IP 61.135.169.125 &gt; 124.160.121.68: ICMP echo reply, id 14864, seq 1, length 64 第二个 DNS 有效，并返回了 A 记录 ，立刻发送了一个 ICMP 包并且得到了响应 118:11:46.607865 IP 124.160.121.68.36510 &gt; 123.45.67.1.53: 16127+ PTR? 125.169.135.61.in-addr.arpa. (45) 得到百度的响应之后并没有继续发送剩余的 ICMP 报文，而是又向第一个 DNS 请求了 PTR 记录的解析，注意这里并不是进行了第二次尝试，而是在做第一次尝试中的第二件事情：询问 PTR 记录 1218:11:49.610912 IP 124.160.121.68.53473 &gt; 8.8.8.8.53: 16127+ PTR? 125.169.135.61.in-addr.arpa. (45)18:11:49.660012 IP 8.8.8.8.53 &gt; 124.160.121.68.53473: 16127 NXDomain 0/1/0 (97) 第一个 DNS 无效，在等待超时时间 options timeout:3 也就是 3 秒之后，向第二个DNS 请求做第一次尝试中的第二件事情：询问 PTR 记录 123418:11:49.662472 IP 124.160.121.68 &gt; 61.135.169.125: ICMP echo request, id 14864, seq 2, length 6418:11:49.690812 IP 61.135.169.125 &gt; 124.160.121.68: ICMP echo reply, id 14864, seq 2, length 6418:11:50.663851 IP 124.160.121.68 &gt; 61.135.169.125: ICMP echo request, id 14864, seq 3, length 6418:11:50.692213 IP 61.135.169.125 &gt; 124.160.121.68: ICMP echo reply, id 14864, seq 3, length 64 发送剩余的两个 ICMP 报文 我们再算一下时间： 两个 DNS ，每个 DNS 都进行了一次尝试，做了两个不同的事情（询问A记录，再询问 PTR 记录），第一个 DNS 尝试一次的过程中超时两次时间是 6 秒，第二个 DNS 未超时，总共加起来是 7 秒左右 那么有没有可能是 PTR 记录是 ping 进行了第二次错误解析尝试呢（一次错误等待时长为 3 s，所以 attemps 设置为2，等待时长是 3s * 2 = 6s，正好与 time ping 的执行结果相吻合） 为了更有说服力，我们把尝试次数改为一次，前两个 DNS 设置为无效，第三个 DNS 有效，再做一次实验 123456[root@bogon ~]# cat /etc/resolv.confoptions timeout:3options attempts:1nameserver 123.45.67.1nameserver 123.45.67.2nameserver 8.8.8.8 我们假设 PTR 记录是 ping 进行了第二次错误解析尝试，而文件 /etc/resolv.conf 中我们只允许尝试一次，那么根据假设，等待的时间应该是 第一个 DNS 超时时间 3s 加上 第二个 DNS 超时时间 3s，总共为 6s，是不是这样呢？ 1234567891011[root@bogon ~]# time ping -c 1 www.baidu.comPING www.a.shifen.com (61.135.169.121) 56(84) bytes of data.64 bytes from 61.135.169.121 (61.135.169.121): icmp_seq=1 ttl=54 time=27.9 ms--- www.a.shifen.com ping statistics ---1 packets transmitted, 1 received, 0% packet loss, time 0msrtt min/avg/max/mdev = 27.960/27.960/27.960/0.000 msreal 0m10.189suser 0m0.004ssys 0m0.002s 抓包结果 12345678910111213[root@bogon ~]# tcpdump -nn -i eth0 icmp or udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes18:50:27.858495 IP 124.160.121.68.56337 &gt; 123.45.67.1.53: 51295+ A? www.baidu.com. (31)18:50:30.861543 IP 124.160.121.68.35679 &gt; 123.45.67.2.53: 51295+ A? www.baidu.com. (31)18:50:32.863588 IP 124.160.121.68.48112 &gt; 8.8.8.8.53: 51295+ A? www.baidu.com. (31)18:50:32.962175 IP 8.8.8.8.53 &gt; 124.160.121.68.48112: 51295 3/0/0 CNAME www.a.shifen.com., A 61.135.169.121, A 61.135.169.125 (90)18:50:32.962437 IP 124.160.121.68 &gt; 61.135.169.121: ICMP echo request, id 15252, seq 1, length 6418:50:32.990376 IP 61.135.169.121 &gt; 124.160.121.68: ICMP echo reply, id 15252, seq 1, length 6418:50:32.990478 IP 124.160.121.68.42683 &gt; 123.45.67.1.53: 23619+ PTR? 121.169.135.61.in-addr.arpa. (45)18:50:35.993528 IP 124.160.121.68.34443 &gt; 123.45.67.2.53: 23619+ PTR? 121.169.135.61.in-addr.arpa. (45)18:50:37.995573 IP 124.160.121.68.48473 &gt; 8.8.8.8.53: 23619+ PTR? 121.169.135.61.in-addr.arpa. (45)18:50:38.042414 IP 8.8.8.8.53 &gt; 124.160.121.68.48473: 23619 NXDomain 0/1/0 (97) 从上述结果可以看到，ping 再做一次尝试的过程中存在了两种不同记录的查询，A 记录和 PTR 记录，因此 PTR 记录是 ping 进行了第二次错误解析尝试 的假设不成立。因此对于 ping 来说一次尝试的超时时间应该是 （PTR的超时时间 + A 记录的超时时间） * 无法解析的 nameserver 的个数 即 6 x 2 =12 如果是下面的配置，使用 ping 的话超时时间就应该是 一次尝试：6 x 3 =18，两次尝试 36s，第一个实验中令人费解的时间此时已经有了来路 123456[root@bogon ~]# cat /etc/resolv.confoptions timeout:3options attempts:2nameserver 123.45.67.1nameserver 123.45.67.2nameserver 123.45.67.3 rotate为了避免 DNS 查询每次都从第一个 nameserver 开始，来均衡各个 nameserver 的压力。如果第一个 nameserver 失效时，使用这个选项就可以提高解析的效率。另外 rotate 可能会优先使用可用的 DNS。要注意很多云主机上都有自己分配好的 DNS ，如果此时用了 rotate 将会在一定程度上影响效率，因为对于云主机来说，自家的 DNS 肯定比公共的响应要快。 我们取消options rotate 参数。这样既保证了 aws 上使用自己的快速 DNS，也保证了在他自己平台上一旦DNS 失效，咱们全部的 AWS 业务可以使用 公共 DNS 进行解析。参数如下： options timeout:1options attempts:2options single-request-reopen 12345678910111213141516[root@bogon ~]# cat /etc/resolv.confoptions rotatenameserver 123.45.67.1nameserver 123.45.67.2nameserver 8.8.8.8[root@bogon ~]# [root@bogon ~]# time ping www.baidu.com -c 5 -qPING www.a.shifen.com (61.135.169.121) 56(84) bytes of data.--- www.a.shifen.com ping statistics ---5 packets transmitted, 5 received, 0% packet loss, time 4000msrtt min/avg/max/mdev = 27.947/28.093/28.183/0.169 msreal 0m9.137suser 0m0.001ssys 0m0.004s 抓包结果 12345678[root@bogon ~]# tcpdump -nn -i eth0 udp port 53tcpdump: verbose output suppressed, use -v or -vv for full protocol decodelistening on eth1, link-type EN10MB (Ethernet), capture size 65535 bytes20:23:05.883477 IP 124.160.121.68.51976 &gt; 123.45.67.2.53: 29551+ A? www.baidu.com. (31)20:23:10.888528 IP 124.160.121.68.39697 &gt; 8.8.8.8.53: 29551+ A? www.baidu.com. (31)20:23:10.988607 IP 8.8.8.8.53 &gt; 124.160.121.68.39697: 29551 3/0/0 CNAME www.a.shifen.com., A 61.135.169.121, A 61.135.169.125 (90)20:23:11.017108 IP 124.160.121.68.55712 &gt; 8.8.8.8.53: 48423+ PTR? 121.169.135.61.in-addr.arpa. (45)20:23:11.067780 IP 8.8.8.8.53 &gt; 124.160.121.68.55712: 48423 NXDomain 0/1/0 (97) single-request-reopen1options single-request-reopen 自从 CentOS6 之后，准确的说是 glibc &gt;= 2.9 之后，Linux 系统 DNS 解析器（resolver）会使用相同的 socket 去请求 A(for IPv4) &amp; AAAA(for IPv6) 记录解析。比如在存在防火墙等机制的网络环境中，同样源目的 ip，同样源目的 port，同样的第4层协议的连接，会被防火墙看成是同一个会话，因此会存在返回包被丢弃现象，过程如下： 默认的 DNS 解析过程是这样的： 主机从一个随机的源端口（图中为 12345 ），请求 DNS 的 A 记录 主机从同一个源端口，请求 DNS 的 AAAA 记录 主机先收到 DNS 返回的 AAAA 记录（也可能先收到 A 记录） 防火墙（可能是其他硬件设备，官方给出的描述是： Some hardware ）认为本次交互通信已经完成，关闭连接 剩下的 DNS 服务器返回的 A 记录响应包被防火墙丢弃 如果我们启用参数 single-request-reopen （默认未启用），一旦出现同一个 socket 发送的两次请求处理，解析端发送第一次请求后会关闭 socket，并在发送第二次请求前打开新的 socket 对 DNS server 端进行发送解析请求 生产环境中发现在阿里云的主机上可能会出现上述问题，因此如果主机使用了 IPv6 建议启用该参数。 edns01options edns0 EDNS0：Extension Mechanisms for DNS Version 0，是 DNS 在 rfc1035 基础上对 DNS 协议的扩展。 修改原来的 DNS 协议，让其可以传输超过 512 字节的报文限制，但是必须客户端和服务端同时支持 edns0 才能使用该协议。glibc 2.6 及以上可以支持。 1234567891011121314151617181920212223[root@bogon ~]# dig @8.8.8.8 www.baidu.com; &lt;&lt;&gt;&gt; DiG 9.9.4-RedHat-9.9.4-50.el7_3.1 &lt;&lt;&gt;&gt; @8.8.8.8 www.baidu.com; (1 server found);; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 28203;; flags: qr rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 1;; OPT PSEUDOSECTION:; EDNS: version: 0, flags:; udp: 512;; QUESTION SECTION:;www.baidu.com. IN A;; ANSWER SECTION:www.baidu.com. 1049 IN CNAME www.a.shifen.com.www.a.shifen.com. 299 IN A 61.135.169.121www.a.shifen.com. 299 IN A 61.135.169.125;; Query time: 95 msec;; SERVER: 8.8.8.8#53(8.8.8.8);; WHEN: Sat May 12 20:46:23 CST 2018;; MSG SIZE rcvd: 101 总结和建议当第一个 nameser 解析超过指定的超时后会向第二个 nameserver 请求解析，此时第一个 nameserver 的 socket 已经关闭，于是不存在这种情况：虽然第一个 nameserver 已经超时了，系统在向第二个 nameserver 请求解析时，就会有可能这时第一个 nameserver 将解析结果返回给系统了 文件 /etc/resolv.conf 中参数的有效性，准确的说应该视系统命令或应用程序而定的。例如： 对于 ping 和 dig 来说他们会最多轮询三个 nameserver ，但是 curl 则是轮询所有的 nameserver 当 attempts 为小数时， nslookup 和 dig 会提示该文件语法错误 当 attmepts 为 0 时，对于 ping 来说则不会进行 DNS 解析请求，但对于 dig 和 nslookup 来说依然发送 DNS 解析请求 一旦设定 timeout 参数值，系统会直接忽略掉 dig 自身的 timeout 为了避免单个 DNS 不可用时导致解析瘫痪，最好配置两个或多个 nameserver，一般最好配置三个，适当调整 timeout 和 attempts 提高解析效率。 配置示例 1234567options timeout:1options attempts:2options rotateoptions single-request-reopennameserver 8.8.8.8nameserver 9.9.9.9nameserver 114.114.114.114 什么会修改 resolv.conf在维护的主机数量较多的时候，系统中 DNS 的配置我们应该做到统一化，随意修改或更新会造成管理混乱。比如统一只靠人为干预的方式来修改 /etc/resolv.conf ，并将其他可能会更新该文件的服务或配置禁用掉。因此我们需要找到可能会更新 /etc/resolv.conf 的来源： 用户：这个不必多说了，有权限的用户都可以配置该文件 服务或程序 网卡配置文件中的 DNS网卡配置参考文档在 Redhat 官方文档中可以找到相关说明 RHEL5 &amp; RHEL6 1DNS&#123;1,2&#125;=address where address is a name server address to be placed in /etc/resolv.conf provided that the PEERDNS directive is not set to no. 1PEERDNS=&lt;answer&gt; where &lt;answer&gt; is one of the following: yes — Modify /etc/resolv.conf if the DNS directive is set. If using DHCP, then yes is the default. no — Do not modify /etc/resolv.conf. RHEL7 To configure an interface to use particular DNS servers, add the following lines to the ifcfg file: 123PEERDNS=noDNS1=ip-addressDNS2=ip-address where ip-address is the address of a DNS server. This will cause the network service to update /etc/resolv.conf with the specified DNS servers specified. Only one DNS server address is necessary, the other is optional. By default, NetworkManager calls the DHCP client, dhclient, when a profile has been set to obtain addresses automatically by setting BOOTPROTO to dhcp in an interface configuration file. If DHCP is required, an instance of dhclient is started for every Internet protocol, IPv4 and IPv6, on an interface. If NetworkManager is not running, or is not managing an interface, then the legacy network service will call instances of dhclient as required. Important In order to apply the configuration, you need to enter the nmcli c reload command. PEERDNS=yes ：如果网卡配置文件中设置了 DNS 就会修改 /etc/resolv.conf。在网卡配置文件中如果启动方式配置了 DHCP 之后，PEERDNS 默认为 yes 我们分 DHCP 和 静态方式 来测试 DHCP方式单独配置 PEERDNS 我们先人为给系统配置公共的DNS，并且网卡配置自动获取 1234567891011121314151617[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;dhcp&quot;ONBOOT=&quot;yes&quot;[root@bogon ~]# ifdown eth0;ifup eth0Device &apos;eth0&apos; successfully disconnected.Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/4)[root@bogon ~]# cat /etc/resolv.conf # Generated by NetworkManagersearch localdomainnameserver 192.168.127.2nameserver 114.114.114.114 启动方式配置了 DHCP 之后我们知道 PEERDNS 默认为 yes，当重启了网卡之后，发现/etc/resolv.conf 确实被修改了，我们再加一条配置：PEERDNS=no 来看看 12345678910111213141516[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;dhcp&quot;PEERDNS=&quot;no&quot;ONBOOT=&quot;yes&quot;[root@bogon ~]# ifdown eth0;ifup eth0 Device &apos;eth0&apos; successfully disconnected.Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/3)[root@bogon ~]# cat /etc/resolv.conf # Generated by NetworkManagernameserver 114.114.114.114 此时发现虽然配置了 PEERDNS=no ，当重启了网卡之后/etc/resolv.conf 还是被修改了，但是少了一个 DNS 并且两次实验后文件中都会有个注释：# Generated by NetworkManager，查看进程后发现系统运行了一个服务 NetworkManager 为了排除其因素我们将此服务停止再次测试 1systemctl stop NetworkManager 先不配置 PEERDNS 选项，即默认PEERDNS=yes 1234567891011121314151617[root@bogon ~]# systemctl stop NetworkManager[root@bogon ~]# cat /etc/resolv.confnameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;dhcp&quot;ONBOOT=&quot;yes&quot;[root@bogon ~]# ifdown eth0;ifup eth0Determining IP information for eth0... done.[root@bogon ~]# cat /etc/resolv.conf ; generated by /usr/sbin/dhclient-scriptsearch localdomainnameserver 192.168.127.2 配置 PEERDNS 选项，即PEERDNS=no 1234567891011121314[root@bogon ~]# cat /etc/resolv.confnameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;dhcp&quot;PEERDNS=&quot;no&quot;ONBOOT=&quot;yes&quot;[root@bogon ~]# ifdown eth0;ifup eth0Determining IP information for eth0... done.[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8 结论： 在 PEERDNS=yes 的情况下，会生成一个 nameserver 192.168.127.2 的配置，会更改 /etc/resolv.conf 在 PEERDNS=no 的情况下，不会生成一个 nameserver 192.168.127.2 的配置，不会更改 /etc/resolv.conf 那么在 PEERDNS=yes 的情况下生成的 nameserver 192.168.127.2 到底是哪的呢？在查看了 DHCP 服务器的配置后发现获得的这个地址是 DHCP 服务器分配给客户端的 DNS 地址 PEERDNS &amp; DNS{1,2}=address 为了排除掉 NetworkManager 的因素我们将此服务停止 PEERDNS=yes &amp; DNS{1,2}=address 12345678910111213141516171819[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;dhcp&quot;PEERDNS=&quot;yes&quot;DNS1=&quot;219.141.136.10&quot;DNS2=&quot;219.141.140.10&quot;ONBOOT=&quot;yes&quot;[root@bogon ~]# ifdown eth0;ifup eth0Determining IP information for eth0... done.[root@bogon ~]# cat /etc/resolv.conf; generated by /usr/sbin/dhclient-scriptsearch localdomainnameserver 219.141.136.10nameserver 219.141.140.10 PEERDNS=no &amp; DNS{1,2}=address 12345678910111213141516[root@bogon ~]# cat /etc/resolv.confnameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;dhcp&quot;PEERDNS=&quot;no&quot;DNS1=&quot;219.141.136.10&quot;DNS2=&quot;219.141.140.10&quot;ONBOOT=&quot;yes&quot;[root@bogon ~]# ifdown eth0;ifup eth0 Determining IP information for eth0... done.[root@bogon ~]# cat /etc/resolv.confnameserver 8.8.8.8 静态指定方式单独配置 PEERDNS PEERDNS=yes 12345678910111213141516[[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;PEERDNS=&quot;yes&quot;ONBOOT=&quot;yes&quot;IPADDR=192.168.127.154NETMASK=255.255.255.0GATEWAY=192.168.127.2[root@bogon ~]# ifdown eth0;ifup eth0[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8 PEERDNS=no 12345678910111213141516[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;PEERDNS=&quot;no&quot;ONBOOT=&quot;yes&quot;IPADDR=192.168.127.154NETMASK=255.255.255.0GATEWAY=192.168.127.2[root@bogon ~]# ifdown eth0;ifup eth0[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8 PEERDNS &amp; DNS{1,2}=address PEERDNS=yes &amp; DNS{1,2}=address 12345678910111213141516171819[root@bogon ~]# cat /etc/resolv.confnameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;PEERDNS=&quot;yes&quot;ONBOOT=&quot;yes&quot;IPADDR=192.168.127.154NETMASK=255.255.255.0GATEWAY=192.168.127.2DNS1=&quot;219.141.136.10&quot;DNS2=&quot;219.141.140.10&quot;[root@bogon ~]# ifdown eth0;ifup eth0[root@bogon ~]# cat /etc/resolv.conf nameserver 219.141.136.10nameserver 219.141.140.10 PEERDNS=no &amp; DNS{1,2}=address 12345678910111213141516171819[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;PEERDNS=&quot;no&quot;ONBOOT=&quot;yes&quot;IPADDR=192.168.127.154NETMASK=255.255.255.0GATEWAY=192.168.127.2DNS1=&quot;219.141.136.10&quot;DNS2=&quot;219.141.140.10&quot;[root@bogon ~]# ifdown eth0;ifup eth0[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8 总结BOOTPROTO=&quot;dhcp&quot; 的情况： PEERDNS=yes：网卡配置文件中配置了 DNS{1,2}=address ，直接将 address 更新到 /etc/resolv.conf，不会去从 DHCP 服务器获取 DNS，如果没有配置 DNS{1,2}=address 就会尝试从 DHCP 服务器获得 DNS 并更新到 /etc/resolv.conf PEERDNS=no ：无论网卡配置文件中是否配置 DNS{1,2}=address，都不会更改 /etc/resolv.conf，也不会去从 DHCP 服务器获取 DNS BOOTPROTO=&quot;static&quot;的情况： PEERDNS=yes：网卡配置文件中配置了 DNS{1,2}=address ，直接将 address 更新到 /etc/resolv.conf，不会去从 DHCP 服务器获取 DNS，如果没有配置 DNS{1,2}=address 则不更改 /etc/resolv.conf PEERDNS=no ：无论网卡配置文件中是否配置 DNS{1,2}=address，都不会更改 /etc/resolv.conf，也不会去从 DHCP 服务器获取 DNS NetworkManager 中的 DNSNetworkManager 是用于便携式计算机和其他可移动计算机的理想解决方案。提供了完善而直观的用户界面，可使用户轻松地切换其网络环境。也就是说 NetworkManager 更适用于桌面环境的 PC 电脑，服务器上一般都是命令行界面，我们完全可以不需要使用 NetworkManager ，而且 NetworkManager 服务和 network 服务有可能会起冲突，因此我们可以将此服务禁掉。 我们先假设由于某种依赖关系的原因必须启用 NetworkManager 服务，测试看看它是否会更改系统的 DNS 。 为了排除其他因素，我们在网卡配置文件中删除 DNS{1,2}=address 相关的配置，并添加 PEERDNS=no ，然后启用 NetworkManager 服务 1systemctl start NetworkManager BOOTPROTO=&quot;dhcp&quot; 12345678910111213141516[root@bogon ~]# cat /etc/resolv.confnameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;dhcp&quot;PEERDNS=&quot;no&quot;ONBOOT=&quot;yes&quot;[root@bogon ~]# ifdown eth0;ifup eth0Device &apos;eth0&apos; successfully disconnected.Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/10)[root@bogon ~]# cat /etc/resolv.conf# Generated by NetworkManagernameserver 114.114.114.114 BOOTPROTO=&quot;static&quot; 12345678910111213141516171819[root@bogon ~]# cat /etc/resolv.conf nameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;PEERDNS=&quot;no&quot;ONBOOT=&quot;yes&quot;IPADDR=192.168.127.154NETMASK=255.255.255.0GATEWAY=192.168.127.2[root@bogon ~]# ifdown eth0;ifup eth0Device &apos;eth0&apos; successfully disconnected.Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/3)[root@bogon ~]# cat /etc/resolv.conf# Generated by NetworkManagernameserver 114.114.114.114 BOOTPROTO=&quot;dhcp&quot; + DNS{1,2}=address 123456789101112131415161718192021[root@bogon ~]# cat /etc/resolv.confnameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;dhcp&quot;PEERDNS=&quot;no&quot;ONBOOT=&quot;yes&quot;DNS1=&quot;219.141.136.10&quot;DNS2=&quot;219.141.140.10&quot;[root@bogon ~]# ifdown eth0;ifup eth0Device &apos;eth0&apos; successfully disconnected.Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/11)[root@bogon ~]# cat /etc/resolv.conf# Generated by NetworkManagernameserver 219.141.136.10nameserver 219.141.140.10nameserver 114.114.114.114 BOOTPROTO=&quot;static&quot; + DNS{1,2}=address 1234567891011121314151617181920212223[root@bogon ~]# cat /etc/resolv.confnameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;PEERDNS=&quot;no&quot;ONBOOT=&quot;yes&quot;DNS1=&quot;219.141.136.10&quot;DNS2=&quot;219.141.140.10&quot;IPADDR=192.168.127.154NETMASK=255.255.255.0GATEWAY=192.168.127.2[root@bogon ~]# ifdown eth0;ifup eth0Device &apos;eth0&apos; successfully disconnected.Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/12)[root@bogon ~]# cat /etc/resolv.conf# Generated by NetworkManagernameserver 219.141.136.10nameserver 219.141.140.10nameserver 114.114.114.114 通过测试发现，默认情况下 NetworkManager 服务运行起来，如果改了网络配置就会更新系统的 /etc/resolv.conf，如果我们的目的只是修改一下 IP 地址，重启完网卡后却更新了系统的 DNS ，这显然不符合我们的预期。那么有没有什么办法可以避免这种问题发生呢？ 查看了 NetworkManager 的服务配置文件 /etc/NetworkManager/NetworkManager.conf 之后，给出了 See &quot;man 5 NetworkManager.conf&quot; for details. 的提示，通过查看 man 手册发现了与 DNS 相关的配置： 123456dns Set the DNS (resolv.conf) processing mode. If the key is unspecified, default is used, unless /etc/resolv.conf is a symlink to /run/systemd/resolve/resolv.conf, /lib/systemd/resolv.conf or /usr/lib/systemd/resolv.conf. In that case, systemd-resolved is chosen automatically. default: NetworkManager will update /etc/resolv.conf to reflect the nameservers provided by currently active connections. none: NetworkManager will not modify resolv.conf. This implies rc-manager unmanaged 那么我们将处理模式改为 none 并重启 NetworkManager 服务再次进行测试 12345678910111213141516171819202122232425262728293031323334353637383940414243[root@bogon ~]# cat /etc/NetworkManager/NetworkManager.conf# Configuration file for NetworkManager.## See &quot;man 5 NetworkManager.conf&quot; for details.## The directory /etc/NetworkManager/conf.d/ can contain additional configuration# snippets. Those snippets override the settings from this main file.## The files within conf.d/ directory are read in asciibetical order.## If two files define the same key, the one that is read afterwards will overwrite# the previous one.[main]plugins=ifcfg-rhdns=none[logging]#level=DEBUG#domains=ALL[root@bogon ~]# cat /etc/resolv.confoptions rotatenameserver 8.8.8.8[root@bogon ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=&quot;eth0&quot;BOOTPROTO=&quot;static&quot;PEERDNS=&quot;no&quot;ONBOOT=&quot;yes&quot;DNS1=&quot;219.141.136.10&quot;DNS2=&quot;219.141.140.10&quot;IPADDR=192.168.127.154NETMASK=255.255.255.0GATEWAY=192.168.127.2[root@bogon ~]# systemctl restart NetworkManager [root@bogon ~]# cat /etc/resolv.conf # Generated by NetworkManagernameserver 219.141.136.10nameserver 219.141.140.10nameserver 114.114.114.114 修改了模式之后重启服务仍然会修改系统 DNS，是配置的参数没生效吗？我们将系统的 DNS 改回去再试一次 1234567891011121314151617[root@bogon ~]# cat /etc/resolv.conf options rotatenameserver 8.8.8.8[root@bogon ~]# systemctl restart NetworkManager [root@bogon ~]# cat /etc/resolv.conf options rotatenameserver 8.8.8.8[root@bogon ~]# ifdown eth0;ifup eth0Device &apos;eth0&apos; successfully disconnected.Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/3)[root@bogon ~]# cat /etc/resolv.confoptions rotatenameserver 8.8.8.8 这说明配置的参数可以阻止 NetworkManager 服务修改 /etc/resolv.conf DNS配置优化为了避免其他来源覆盖本机的 /etc/resoolv.conf，可以从以下几处来进行优化： 网卡配置文件中删除 DNS{1,2}=address 相关的配置，并添加 PEERDNS=no 网卡配置文件中添加 NM_CONTROLLED=no 来避免 network.service 和 NetworkManager.service 冲突 修改 NetworkManager 的处理模式，在 /etc/NetworkManager/NetworkManager.conf 中添加 dns=none 如果没有必要的话，则停止 NetworkManager.service ，并禁止开机自启动]]></content>
      <tags>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用Dnsmasq搭建本地自有DNS服务器]]></title>
    <url>%2F2016%2F04%2F07%2F214147-%E5%88%A9%E7%94%A8Dnsmasq%E6%90%AD%E5%BB%BA%E6%9C%AC%E5%9C%B0%E8%87%AA%E6%9C%89DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Dnsmasq 提供 DNS 缓存和 DHCP服务、Tftp服务功能。作为域名解析服务器(DNS)，dnsmasq可以通过缓存 DNS 请求来提高对访问过的网址的连接速度。作为DHCP 服务器，Dnsmasq 可以用于为局域网电脑分配内网ip地址和提供路由。DNS和DHCP两个功能可以同时或分别单独实现。Dnsmasq 轻量且易配置，适用于个人用户或少于50台主机的网络。此外它还自带了一个 PXE 服务器以及对邮件服务器的 mx 记录的支持，jabber 的 srv 记录的支持等。它提供的 DNS 功能和可选择的 DHCP 功能可以取代 dhcpd 服务和 bind 等服务，配置起来更简单，更适用于虚拟化和大数据环境的部署。 Dnsmasq 的应用一般情况下，我们可以用 bind 解决 dns 的问题， dhcpd 解决 dhcp 的问题，可用dnsmasq解决下面的一些维护问题： 局域网有很多机器希望使用一致的hosts文件，你需要经常维护这份列表。 你希望局域网的人访问某个域名时，拦截下来到指定的ip，做缓存节省带宽或者其它用途都可以。优先使用本地自定义dns。 阻止对某个域名的正常解析。 常见的应用： 同时提供 DNS 解析功能和 DHCP 地址分配功能，可用于机房内网、公司内网、家庭内网等类似内网环境 架设本地 DNS，在一定程度上，解决我们访问网速、广告拦截的问题 作为局域网机器批量IP维护使用，以及局域网解决特定网址域名禁止访问 Dnsmasq 基本的工作原理Dnsmasq在接受到用户的一个DNS请求时，首先会查找 /etc/hosts 这个文件，然后查找 /etc/resolv.conf 中定义的外部 DNS 。所以说 Dnsmasq 是一个很不错的外部 DNS 中继。 配置 Dnsmasq 为 DNS 缓存服务器，同时在 /etc/hosts 文件中加入本地内网解析，这样一来每当内网机器查询时就会优先查询 hosts 文件，这就等于将 /etc/hosts 共享给全内网机器使用，从而解决内网机器互相识别的问题。相比逐台机器编辑 hosts 文件或者添加 Bind DNS 记录，仅编辑一个 hosts 文件，这简直太容易了。 安装 Dnsmasq rpm包安装 123456789101112yum -y install dnsmasq# 使用yum源安装dnsmasq -v# 查看dnsmasq的版本systemctl enable dnsmasq# 加入开机启动服务systemctl daemon-reloadsystemctl start dnsmasq# 启动dnsmasq服务 源码包安装 123456789101112131415161718192021wget http://www.thekelleys.org.uk/dnsmasq/dnsmasq-2.78.tar.xz# 下载源码包tar xf dnsmasq-2.78.tar.xz cd dnsmasq-2.78# 源码包解压vim Makefile # 修改 PREFIX = /usr/local/dnsmasq# 配置安装路径make &amp;&amp; make install# 编译安装cp dnsmasq.conf.example /etc/dnsmasq.conf# 生成配置文件ln -s /usr/local/dnsmasq/sbin/dnsmasq /usr/sbin/# 生成软连接dnsmasq --version# 查看dnsmasq版本 配置 DnsmasqDnsmasq 处理 DNS 设置与 BIND 等其他 DNS 服务有所不同。所有的配置都在 /etc/dnsmasq.conf 这一个文件中完成 。官方在配置文件 /etc/dnsmasq.conf 中针对选项和参数等做了比较好的注释说明，我们可以将配置做一次备份，以便以后查阅。默认情况下 dnsmasq.conf 中只开启了最后 include 项，因此可以在 /etc/dnsmasq.conf 的前提下，将自定义的配置放到 /etc/dnsmasq.d 目录下的一个任意名字的配置文件当中。 注意： /etc/dnsmasq.d/*.conf 的优先级大于 /etc/dnsmasq.conf DNS 配置参数说明Dnsmasq配置文件是 /etc/dnsmasq.conf，下面对 Dnsmasq 常用的相关配置项进行说明。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138Dnsmasq 默认启用其 DNS 服务器，并且会监听在 0.0.0.0:53，如果要用指定的端口代替 DNS 默认的 53 端口则配置如下选项，如果设置为0，则完全禁止 DNS 功能，只使用 dhcp 服务#port=5353以下两个参数告诉 Dnsmasq 过滤一些查询：1.哪些公共DNS没有回答 2.哪些root根域不可达。从不转发格式错误的域名#domain-needed从不转发不在路由地址中的域名#bogus-privLinux 处理 DNS 请求时有个限制，在 resolv.conf 中最多只能配置三个域名服务器（nameserver），我们完全可以使用 resolv-file 来作为变通方法，当然这只是其中的一个用途之一。这个参数表示 Dnsmasq 会从指定的文件中寻找上级 DNS 服务器列表，而不是从本机的 `resolv.conf` 中读取 DNS 服务器列表。如果机器的地址是通过 DHCP 方式取得的话，该文件( `resolv.conf` )容易受到影响从而影响到 Dnsmasq，因此配置此项避免影响resolv-file 配置 Dnsmasq 额外的上流的 DNS 服务器，如果不开启就使用linux主机默认的 /etc/resolv.conf 里的nameserver，如果开启则通过下面的选项指定其他文件。#resolv-file=/etc/dnsmasq.d/upstream_dns.conf#resolv-file=/etc/dnsmasq/resolv.conf默认情况下Dnsmasq会发送查询到它的任何上游DNS服务器上，如果取消注释，则Dnsmasq则会严格按照 /etc/resolv.conf 中的 DNS Server 顺序进行查询，直到第一个成功解析成功为止#strict-order以下两个参数用来控制是否通过 /etc/resolv.conf 确定上游服务器，是否检测 /etc/resolv.conf 的变化，则取消注释。 如果你不想让Dnsmasq读取 /etc/resolv.conf 或者其他文件来获得它的servers，则取消注释#no-resolv如果你不允许Dnsmasq通过轮询 /etc/resolv.conf 或者其他文件来改变和重新读取配置，则取消注释。 #no-poll增加一个name server，一般用于内网域名#server=/localnet/192.168.0.1设置一个反向解析，所有192.168.3.0/24的地址都到10.1.2.3去解析#server=/3.168.192.in-addr.arpa/10.1.2.3增加一个本地域名，会在 /etc/hosts 或 DHCP 中进行查询#local=/localnet/增加一个域名，使得这个域名强制解析到你指定的地址上#address=/double-click.net/127.0.0.1同上，还支持ipv6#address=/www.thekelleys.org.uk/fe80::20d:60ff:fe36:f83增加查询yahoo google的IP地址和它们的子域名到vpn、search查找#ipset=/yahoo.com/google.com/vpn,search你还可以控制Dnsmasq和Server之间的查询从哪个网卡出去queries to 10.1.2.3 to be routed via eth1#server=10.1.2.3@eth1设置了个源(本地)地址10.1.2.3，用来和192.168.1.1的55端口进行通信很显然，在机器上必须有一个与此IP相关联的接口#server=10.1.2.3@192.168.1.1#55改变Dnsmasq默认的uid和gid#user=#group=如果你想让 Dnsmasq 监听在本机特定的网卡（包括回环网卡），用于 DHCP 和 DNS 请求，则设置此项#interface=你还可以指定哪个网卡你不想监听#except-interface=设置想监听的地址#listen-address=要在单台主机上以守护进程方式启动 Dnsmasq 做 DNS (缓存)服务器，如果仅为本机使用则写上127.0.0.1。#listen-address=127.0.0.1如果用此主机为局域网提供默认 DNS，请为该主机绑定固定 IP 地址，设置：#listen-address=192.168.x.x这种情况建议配置静态IP。多个ip地址设置：#listen-address=127.0.0.1,192.168.x.x 如果你想让Dnsmasq在某个网卡上只提供dns服务，则可以进行配置禁止dhcp服务#no-dhcp-interface=在支持 Dnsmasq 的系统上，Dnsmasq 绑定通配符地址，即使它只监听某些网卡。如果配置了此项，Dnsmasq 将丢弃它不应该回复的请求。即使在接口出现和更改地址时，这也具有工作的优势。如果您希望 Dnsmasq 只绑定它正在监听的接口，请取消注释#bind-interfaces默认情况下这是注释掉的，Dnsmasq 会首先寻找本地的 /etc/hosts 文件，再去寻找缓存下来的域名如果你不想使用 /etc/hosts，则取消下面的注释#no-hosts如果你想使用额外的类似/etc/hosts文件，则进行配置#addn-hosts=/etc/banner_add_hosts如果你想让hosts中的一个域自动增加一个主机名，则配置此项。例如baidu.com，他将自动添加www#expand-hosts为 Dnsmasq 设置一个域，简单地说就是给dhcp服务赋予一个域如果被设置，将会做以下事情1) 允许DHCP主机拥有完全合格的域名，只要域部分匹配这个设置2) 设置“域” 的 DHCP选项，从而设置由DHCP配置所有系统的域。3) 为 “expand-hosts” 提供 域 的部分#domain=thekelleys.org.uk为特定子网设置不同的域#domain=wireless.thekelleys.org.uk,192.168.2.0/24同上，不过子网是一个范围#domain=reserved.thekelleys.org.uk,192.68.3.100,192.168.3.200dhcp分发ip的范围，以及每个ip的租约时间#dhcp-range=192.168.0.50,192.168.0.150,12h同上，不过给出了掩码#dhcp-range=192.168.0.50,192.168.0.150,255.255.255.0,12h为某个范围或子网设置标记，以便于某些设置只针对这些范围或子网生效#dhcp-range=set:red,192.168.0.50,192.168.0.150#dhcp-range=tag:green,192.168.0.50,192.168.0.150,12h自动加载conf-dir目录下的配置文件#conf-dir=/etc/dnsmasq.d 设置dns缓存大小,默认为150条#cache-size=8192是否禁用negative caching，取消注释意味着禁用。negative caching 允许 dnsmasq 记住从上游域名服务器上得到的“没有这样的域名”的查询结果，并对于相同的查询不再重复转发轮询上游服务器。简单的讲就是在没有禁用（未取消注释）的情况下，解析失败的域名不会再向上游服务器重复转发查询。#no-negcache允许客户端缓存的时间，单位为秒#local-ttl=60开启debug模式，记录客户端查询记录到/var/log/debug中#log-queries# Log lots of extra information about DHCP transactions.#log-dhcp # Log to this syslog facility or file. (defaults to DAEMON)#log-facility=/var/log/dnsmasq.log 异步log，缓解阻塞。#log-async=20 DNS配置实例基本配置下面的配置不是所有都是必须要配置的，根据实际应用情况而定。但是建议开启转发功能，以免配置 Dnsmasq 的转发相关的功能时造成排错困难 1234567891011# 允许本机的53端口可对外访问iptables -A INPUT -p udp -m udp --dport 53 -j ACCEPTiptables -A INPUT -p tcp -m tcp --dport 53 -j ACCEPT# 转发DNS请求，开启流量转发功能，临时开启，重启后会失效，如需永久配置要编辑 /etc/sysctl.conf 开启echo '1' &gt; /proc/sys/net/ipv4/ip_forwardecho '1' &gt; /proc/sys/net/ipv6/ip_forward # IPv6 用户选用# 添加流量转发规则，将外部到53的端口的请求映射到Dnsmasq服务器的53端口iptables -t nat -A PREROUTING -p udp --dport 53 -j REDIRECT --to-ports 53iptables -t nat -A PREROUTING -p tcp --dport 53 -j REDIRECT --to-ports 53 配置DNS（缓存）服务器需要注意的是，一旦自定义的配置文件放到/etc/dnsmasq.d/中，配置文件中指定的某些文件就不能再放到这个目录里下了，因为会被 /etc/dnsmasq.conf 的 include 加载报错。因此我们创建一个目录 /etc/dnsmasq-config/ 用来存放独有的hosts、resolv等文件 创建一个自定义的配置文件 /etc/dnsmasq.d/mydnsmasq.conf ，并进行下列配置 123456789no-pollstrict-orderno-negcachecache-size=8192local-ttl=60no-hostsaddn-hosts=/etc/dnsmasq-config/hostsresolv-file=/etc/dnsmasq-config/resolv.conflisten-address=192.168.127.130 hosts配置/etc/dnsmasq-config/hosts 1234510.94.0.67 us_zero0110.94.0.68 aws-nx10.94.0.69 awsire10.94.0.70 awsuk10.94.0.71 awsvirginia resolv文件配置/etc/dnsmasq-config/resolv.conf 1234nameserver 8.8.8.8nameserver 9.9.9.9nameserver 114.114.114.114nameserver 180.96.96.96 测试 123456789101112131415dnsmasq --test# 语法检查systemctl daemon-reloadsystemctl restart dnsmasq# 服务重启dig -p 53 @192.168.127.130 awsvirginia +short# 正向解析dig -p 53 @192.168.127.130 -x 10.94.0.66# 反向解析 dig -p 53 @192.168.127.130 www.baidu.com dig -p 53 @192.168.127.130 www.baidu.com 比较两次结果中的 Query time，缓存成功的情况下，第二次的查询时间明显大幅度降低 配置域名劫持例如办公室明确规定不能访问360，我们可以将域名劫持，解析到一个不存在的内网地址。另外如果有自己独有的yum源服务器，还可以将相关域名劫持下来解析到自己的yum源服务器地址，从而达到加快速度、节省带宽的目的。 使用hosts配置域名劫持可以使用系统自带的 /etc/hosts，也可以自定义hosts，针对某个域名做静态指向，缺点是无法支持泛域名，下面以自定义为例 创建一个自定义的配置文件 /etc/dnsmasq.d/mydnsmasq.conf ，并进行下列配置 12345678no-pollstrict-orderno-negcachecache-size=8192local-ttl=60no-hostsaddn-hosts=/etc/dnsmasq-config/hostslisten-address=192.168.127.130 添加hosts 1echo '10.10.10.10 www.360.cn' &gt;&gt; /etc/dnsmasq-config/hosts 测试 12345678910dnsmasq --test# 语法检查systemctl daemon-reloadsystemctl restart dnsmasq# 服务重启dig -p 53 @192.168.127.130 www.360.cndig -p 53 @192.168.127.130 sd.360.cn# 经过测试可以发现，指定的域名被拦截，同一个域下其他的无法被拦截 使用address配置域名劫持address可以将指定的域解析为一个IP地址，即泛域名解析。 注意： 如果针对同样的域名同时配置了no-hosts、addn-hosts、address，那么 /etc/hosts 优先级最高，addn-hosts的优先级次之，address优先级最低，前提是no-hosts参数必须在 address 与 addn-hosts 之前才可以。 创建一个自定义的配置文件 /etc/dnsmasq.d/mydnsmasq.conf ，并进行下列配置 12345678no-pollstrict-orderno-negcachecache-size=8192local-ttl=60no-hostsaddress=/360.cn/10.10.10.10listen-address=192.168.127.130 测试 12345678910dnsmasq --test# 语法检查systemctl daemon-reloadsystemctl restart dnsmasq# 服务重启dig -p 53 @192.168.127.130 www.360.cndig -p 53 @192.168.127.130 sd.360.cndig -p 53 @192.168.127.130 www.baidu.com 生产环境中的DNS拦截使用 在cdn网络加速的生产环境中，通常使用了类似于Nginx这样的反向代理手段，通过加速网络向源站服务器获取资源。 假设我们想要使用curl命令做资源下载测试，并需要使用普通网络和加速网络做下载速度对比。 环境说明： 服务器A：做下载测试的服务器 源站URL：https://s3-ap-southeast-1.amazonaws.com/download-speed-sg-test/20M.tar 代理服务器：Nginx服务器为192.168.123.45，加速网络环境的服务器 实现手段： 普通网络环境的下载。直接在服务器A进行下载即可 1/usr/local/bin/curl -4 -o /dev/nul https://s3-ap-southeast-1.amazonaws.com/download-speed-sg-test/20M.tar 加速网络环境的下载。 1、在服务器A启用dnsmasq，将URL对应的域名拦截，使用自定义hosts的方式指向Nginx服务器 /etc/dnsmasq.d/nginx-test.conf 123456no-pollstrict-orderno-negcachecache-size=8192local-ttl=60addn-hosts=/opt/test/dns_host.conf /opt/test/dns_host.conf 1193.192.168.123.45 s3-ap-southeast-1.amazonaws.com 2、下载测试使用新版本的curl选项中的--dns-servers选项指定dns进行下载 123/usr/local/bin/curl -4 -o /dev/null --dns-servers 127.0.0.1 https://s3-ap-southeast-1.amazonaws.com/download-speed-sg-test/20M.tar# 系统自带的curl命令不支持--dns-servers，因此如果有这样的需求就要编译新版本的curl来支持dns 由此以来，服务器A的资源下载请求被dnsmasq转向了Nginx服务器，从而进入加速网络获取资源 泛域名配置应用在很多情况下，我们可能只需要访问某个域中其中一个域名，而其他域名不期望访问，这个需求可通过如下方式配置实现： 创建一个自定义的配置文件 /etc/dnsmasq.d/mydnsmasq.conf ，并进行下列配置 12345678910no-pollstrict-orderno-negcachecache-size=8192local-ttl=60no-hostsaddress=/google.com/10.10.10.10server=/maps.google.com/mail.google.com/## 如果使用 # 代替dns地址，则使用标准 DNS 服务器，即 Dnsmasq 默认使用的 /etc/resolv.conf 的 nameserver 指定的服务器地址listen-address=192.168.127.130 测试 1234567891011dnsmasq --test# 语法检查systemctl daemon-reloadsystemctl restart dnsmasq# 服务重启dig -p 53 @192.168.127.130 www.google.comdig -p 53 @192.168.127.130 test.google.comdig -p 53 @192.168.127.130 mail.google.comdig -p 53 @192.168.127.130 maps.google.com 另外一种情况是实现泛域名做代理，某个或某些子域名不做代理，例如下面的配置，就实现了 nordstrom.com 整个域的数据拦截下来转发到代理服务器 192.168.127.100 ，而 m.nordstrom.com 和 mail.nordstrom.com 不做代理 12address=/nordstrom.com/192.168.127.100server=/m.nordstrom.com/mail.nordstrom.com/# 把所有.cn的域名全部通过114.114.114.114这台国内DNS服务器来解析 1server=/cn/114.114.114.114 给*.apple.com 和 taobao.com 使用专用的DNS 12server=/taobao.com/223.5.5.5server=/.apple.com/223.5.5.5 把www.360.cn解析到特定的IP 1address=/www.360.cn/10.10.10.10 选择最快的上游DNS服务器经常会有这样的情景， Dnsmasq 服务器配了一堆上游服务器，转发本地的dns请求，缺省是 Dnsmasq 事实上是只挑了一个上游dns服务器来查询并转发结果，这样如果选错服务器的话会导致DNS响应变慢。 创建一个自定义的配置文件 /etc/dnsmasq.d/mydnsmasq.conf，并进行下列配置 12345all-servers# all-servers表示对以下设置的所有server发起查询，选择回应最快的一条作为查询结果返回server=8.8.8.8server=9.9.9.9server=219.141.136.10 Dnsmasq 性能优化Bind不配合数据库的情况下，经常需要重新载入并读取配置文件，这是造成性能低下的原因。根据这点教训，我们可以考虑不读取 /etc/hosts 文件。而是另外指定一个在共享内存里的文件，比如 /dev/shm/dnsrecord.txt ，这样就不费劲了，又由于内存的非持久性，重启就消失，可以定期同步硬盘上的某个内容到内存文件中。 创建一个自定义的配置文件 /etc/dnsmasq.d/mydnsmasq.conf，并进行下列配置 12no-hosts addn-hosts=/dev/shm/dnsrecord.txt 解决同步问题 123chmod +x /etc/rc.local echo "cat /etc/hosts &gt; /dev/shm/dnsrecord.txt" &gt;&gt; /etc/rc.local # 开机启动 使用计划任务定时同步内容 1*/10 * * * * cat /etc/hosts &gt; /dev/shm/dnsrecord.txt DHCP配置参数说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 选定需要监听的网卡# Only listen to routers' LAN NIC. Doing so opens up tcp/udp port 53 to# localhost and udp port 67 to world:interface=&lt;LAN-NIC&gt;# dnsmasq will open tcp/udp port 53 and udp port 67 to world to help with# dynamic interfaces (assigning dynamic ips). Dnsmasq will discard world# requests to them, but the paranoid might like to close them and let the # kernel handle them:bind-interfaces设定可分配的ip地址段和租约时间# Dynamic range of IPs to make available to LAN pcdhcp-range=192.168.111.50,192.168.111.150,12h# 同上，不过给出了掩码#dhcp-range=192.168.8.50,192.168.8.150,255.255.255.0,12h#绑定某些机器的ip-mac地址对，使其具有固定的ip地址# If you’d like to have dnsmasq assign static IPs, bind the LAN computer's# NIC MAC address:dhcp-host=aa:bb:cc:dd:ee:ff,192.168.1.50dhcp-host=00:0e:7b:ca:1c:6e,daunbook,192.168.0.12# 为192.168.0.12设置主机名：dannbook# dhcp服务的静态绑定# dhcp-host=08:00:27:D1:CF:E2,192.168.8.201,infinite 无限租期dhcp-host=08:00:27:D1:CF:E2,192.168.8.201,db2dhcp-host=08:00:27:D6:F0:9F,192.168.8.202,db3# 注意:当为某一MAC地址同时静态分配主机名和IP时，如果写到两条dhcp-host选项里（如下所示），则只会生效后面的一条。正确的选项写法如上配置。dhcp-host=08:00:27:D1:CF:E2,192.168.8.201 dhcp-host=08:00:27:D1:CF:E2,db2dhcp-host=08:00:27:D1:CF:E2,192.168.8.201dhcp-host=08:00:27:D1:CF:E2,db2# 重新启动客户端网卡。由于之前测试中客户端网卡已经申请了DHCP租期。所以这里需要修改租期文件，让客户端重新获得IP和hostname。# 设置默认租期# Set the limit on DHCP leases, the default is 150#dhcp-lease-max=150# 租期保存文件#dhcp-leasefile=/var/lib/dnsmasq/dnsmasq.leases# 通过/etc/hosts来分配对应的hostname#dhcp-host=judge# 忽略下面MAC地址的DHCP请求#dhcp-host=11:22:33:44:55:66,ignore # dhcp所在的domaindomain=freeoa.net # 设置默认路由出口# dhcp-option遵循RFC 2132（Options and BOOTP Vendor Extensions),可以通过dnsmasq --help dhcp来查看具体的配置# 很多高级的配置，如iSCSI连接配置等同样可以由RFC 2132定义的dhcp-option中给出。# option 3为default routedhcp-option=3,192.168.8.1# 设置NTP Server.这是使用option name而非选项名来进行设置#dhcp-option=option:ntp-server,192.168.8.4,10.10.0.5 #当dnsmasq绝对是网络上唯一的DHCP服务器时应该设置。对于DHCPv4，它将从严格的RFC合规性中更改行为，以便不会忽略来自未知主机的未知租约的DHCP请求。这使得新主机在任何情况下都可以获得租约，而不会出现繁琐的超时。如果数据库丢失，它也允许dnsmasq重建其租赁数据库，而不需要每个客户端重新获得租约。对于DHCPv6，它将响应中的优先级设置为255（最大值），而不是0（最小值）。dhcp-authoritative DHCP配置实例公司使用了三台Linux服务器作为网关为局域网中的其他设备提供IP和路由，以下是其中一个范例 dhcp.conf Dnsmasq的全局配置 123456789101112131415161718192021222324252627282930313233343536373839404142# global settingsno-hostsstrict-orderno-negcachecache-size=8192interface=br0no-dhcp-interface=eth0dhcp-authoritative# start,end,netmask,leasedhcp-range=172.20.35.10,172.20.35.200,255.255.252.0,18h# 为宾客或测试机指定特定的地址范围、掩码、续订期dhcp-range=net:gw7,172.20.32.10,172.20.32.200,255.255.252.0,18hdhcp-range=net:gw5,172.20.33.10,172.20.33.200,255.255.252.0,18h# 使用了两个标记 net:gw5 和 net:gw7 来标识其他两个设备，并分别指定了特定的地址范围、掩码、续订期# 默认路由（网关）dhcp-option=3,172.20.32.5# 默认的DNSdhcp-option=6,172.20.32.5# 为标记是 net:gw5 的范围指定默认路由dhcp-option=net:gw5,3,172.20.32.5# 为标记是 net:gw5 的范围指定默认DNSdhcp-option=net:gw5,6,172.20.32.5# 为标记是 net:gw7 的范围指定默认路由dhcp-option=net:gw7,3,172.20.32.7# 为标记是 net:gw7 的范围指定默认DNSdhcp-option=net:gw7,6,172.20.32.7# domain namedhcp-option=15,dhcp.netfits.com# broadcastdhcp-option=28,172.20.35.255# 为特定的MAC地址绑定特定的IPdhcp-host=2C:60:0C:1C:BE:7A,litingjie1,172.20.33.88,18h,net:gw5dhcp-host=D0:7E:35:C7:F3:67,litingjie2,172.20.33.89,18h,net:gw5dhcp-host=AC:C1:EE:30:BF:82,litingjie3,172.20.33.90,18h,net:gw5 web端的配置Dnsmasq的WEB端：https://github.com/luxiaok/DNSmasqWeb dnsmasq命令选项说明提示： 查看配置文件语法是否正确，可执行下列命令： 1dnsmasq --test 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465--test 检查配置文件语法-T, --local-ttl=&lt;time&gt; 当与从/etc/ hosts或在DHCP租约文件，默认设置的dnsmasq信息返回到本机ttl值为零，这意味着请求者不应本身缓存信息。此选项允许设定dhcp请求数据包的生存时间。这将减少在某些情况下过时的请求数据给客户端服务器造成的负载。-x, --pid-file=&lt;path&gt; 指定一个备用的路径来记录进程ID通常保存的目录为/var/dnsmasq.pid。-v, --version 打印版本号。-p, --port=&lt;port&gt; 指定DNS的端口代替标准的DNS端口（53）。设置此为零完全禁用DNS功能，只留下DHCP和/或TFTP。-P,--edns-packet-max=&lt;size&gt; 指定DNS转发支持的最大数据包大小。 默认是1280，这是以太网RFC2671建议的最大值。-i, --interface=&lt;interface name&gt; 只监听指定的接口。当此命令指定的接口被使用时，dnsmasq会自动添加本地接口到接口列表。-I, --except-interface=&lt;interface name&gt; 指定不监听的接口。-2, --no-dhcp-interface=&lt;interface name&gt; 不提供DHCP或TFTP在指定的接口，但提供DNS服务。-a,--listen-address=&lt;ipaddr&gt; 侦听指定的IP地址。监听的接口和IP地址可同时指定。如果指定监听的IP地址而指定未监听接口的，dnsmasq不会自动监听去回环节口（loopback）。所以如果配置此选项一般要明确的给出监听地址的为127.0.0.1-r, --resolv-file=&lt;file&gt; 读取文件上的域名服务器的IP地址，dnsmasq可轮询多个resolv.conf文件的域名服务器。-R, --no-resolv 不要读取/ etc / resolv.conf中。只得到命令行或配置文件中的dnsmasq上游域名服务器。-c, --cache-size=&lt;cachesize&gt; 设置的dnsmasq的缓存大小。默认为150条。设置缓存大小为零禁用缓存。-N, --no-negcache 禁用否定缓存。否定缓存允许dnsmasq记住从上游域名服务器上得到的“没有这样的域名”的查询结果，并对于相同的查询不再重复转发轮询上游服务器。-0, --dns-forward-max=&lt;queries&gt; 设置DNS的查询并发的最大数量。默认值是150。-F,--dhcp-range=[[net:]network-id,]&lt;start-addr&gt;,&lt;end-addr&gt;[[,&lt;netmask&gt;],&lt;broadcast&gt;][,&lt;defaultlease time&gt;] 启用DHCP服务器。地址将会给出了从范围&lt;start-addr&gt;到&lt;end-addr&gt;和静态定义的地址在DHCP主机选项给出。如果租用时间给出，然后租赁将会给予该时间长度。租用时间以秒或分钟（如4500）或时间（如1小时）或无限期“infinite”。最低租赁时间为两分钟。广播地址始终是可选的。-u,--user=&lt;username&gt;指定用户ID，开始的dnsmasq通常必须为root身份。-k, --keep-in-foreground 不在后台进行fork，不运行debug模式-K, --dhcp-authoritative当一个网络上只有确定的一台DHCP服务器时，此参数应该被设置成dhcp-authoritative。这样可以确保从未知主机发送的未知租约不会被忽略。这样就使得新的主机在任何情况下及时的得到租约请求相应。还有一个重要作用是，当服务器的租赁数据库丢失了，此参数可以允许dnsmasq重建租约数据库，而不用与每个客户主机逐一重新请求租约。-X, --dhcp-lease-max=&lt;number&gt; 限制的dnsmasq到DHCP租约规定的最大数目。默认为150。此限制是为了防止非法主机从服务器租赁大量的ip地址造成内存大量占用，从而形成DoS攻击。--log-dhcp 额外的DHCP日志记录：记录所有的选项发送到DHCP客户端和用于确定他们的NetID标签。-l, --dhcp-leasefile=&lt;path&gt; 使用指定的文件存储DHCP的租赁信息。存储的信息包括客户端的MAC地址，ip地址，计算机名等。-C, --conf-file=&lt;file&gt;指定一个不同的配置文件。此配置文件选项也允许在配置文件中使用，以包含多个配置文件。 参考链接 http://www.thekelleys.org.uk/dnsmasq/docs/dnsmasq-man.html http://www.freeoa.net/osuport/servap/dnsmasq-use-intro-refer_2480.html https://wiki.archlinux.org/index.php/Dnsmasq_%28%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87%29 http://www.yunweipai.com/archives/8664.html]]></content>
      <tags>
        <tag>Service</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NegativeCaching的简单理解]]></title>
    <url>%2F2016%2F04%2F03%2F130135-NegativeCaching%E7%9A%84%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[首先简单说一下DNS解析的相关流程。客户端在访问某个域名，例如 ”www.xieyidian.com” 的时候，浏览器首先会将这个域名提交到客户端配置的 DNS 服务器上，由 DNS 服务器将其解析为可识别的 IP 地址，并返回客户端，随后客户端会使用解析到的IP地址访问。 一般情况下，在成功解析一个域名后，客户端的DNS缓存会将这个信息记录下来，这样在这条缓存记录的TTL（有效存活时间）范围内，如果需要再次访问这个域名，那么不需要重新提交到DNS解析，客户端即可使用缓存中记录的IP地址直接访问。然而这就存在一个问题，假设客户端访问一个不存在的域名，或者内部网络中的所有DNS服务器都无法解析该域名，自然，DNS服务器是解析不到任何记录的。但如果客户端因为某种缘故，例如中毒，导致需要在短时间内频繁访问这个不存在或无法解析的域名，又会怎么样？客户端可能会在每次尝试访问的时候都通过DNS解析这个不存在的域名，当然，每次的结果都是无法解析，或解析失败。 如果有大量客户端都有这种情况，无疑，这会对DNS服务器造成很大压力。为了解决这种问题，现在的DNS技术中包含了这个叫做”Negative caching”的功能。简单来说，当客户端尝试通过DNS解析某个域名但解析失败后，客户端依然会在自己的缓存中记录相关的信息，但这里记录的并非解析结果，而是”Negative caching”。这样当客户端尝试再次访问不存在的域名时，因为本地的DNS缓存中已经有了相关的Negative caching记录，因此客户端不会频繁尝试通过DNS进行解析。 该功能的基本原理就是这样，详细信息请参考 RFC 2308 对于 ”逆向缓存”，这个说法我觉得有待商榷。毕竟 ”Negative caching” 保存的是”解析失败”这一信息，而非解析到的结果，因此不存在”正向”或”逆向/反向”之说，毕竟不管是域名到IP地址的正向解析，或IP地址到域名的反向解析，如果解析失败，都可能产生”Negative Caching”，因此这个缓存信息只是为了告诉客户端，这个域名目前无法成功解析，而其存在目的只是为了让客户端不再针对解析失败的请求频繁反复重新查询而已。 原文转自：https://www.xieyidian.com/803]]></content>
      <tags>
        <tag>Service</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用普通用户管理DNS服务器]]></title>
    <url>%2F2016%2F03%2F29%2F192111-%E4%BD%BF%E7%94%A8%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E7%AE%A1%E7%90%86DNS%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[使用 Bind 提供的 DNS 服务器，要想配置和管理，默认情况下需要求以 root 身份进行。如果是多人维护的情况，root 用户权限过高，这导致如果有人做了误操作将会产生十分严重的后果。并且一旦 DNS 服务器被入侵，黑客将有可能直接获取到 root 用户权限，安全代价太高。 Linux 系统规定非 root 用户一般无法启动小于 1024 的端口，而 DNS 服务器使用 named 进程默认监听于 udp 协议的 53 号端口，如果我们将其服务的端口改为非默认的大于 1024 的，就需要修改大量的配置文件，并且影响很大。 普通用户用 passwd 命令修改自己的密码，实际上最终更改的是 /etc/passwd 文件，此文件是用户管理配置文件，并且只有 root 用户才能更改。既然是 root 用户才拥有此权限，为什么我们可以通过 passwd 命令来修改密码呢，那这就要归功于 passwd 设置了 SUID 权限位了。 因此，我们完全可以对启用 DNS 服务的命令 /usr/sbin/named 也添加一个 SUID 权限，这样普通用户就能实现启动一个只有 root 才能启用小于 1024 的端口了。 123456[root@bogon ~]# useradd user1 [root@bogon ~]# echo &apos;user1&apos; | passwd user1 --stdinChanging password for user user1.passwd: all authentication tokens updated successfully.[root@bogon ~]# chmod u+s /usr/sbin/named[root@bogon ~]# su - user1 创建好普通用户和密码，对 named 命令添加 s 位权限后，就使用普通用户启动一个进程。 1234[user1@bogon ~]$ /usr/sbin/named -c /var/named/named.conf [user1@bogon ~]$ ps -ef | grep namedroot 7320 1 4 11:33 ? 00:00:00 /usr/sbin/named -c /var/named/named.confuser1 7325 7237 0 11:33 pts/1 00:00:00 grep --color=auto named 一旦配置文件更新了，普通用户也可以使用 pkill -1 PID 来重载对应的进程了。 1[user1@bogon ~]$ kill -1 7320 一切都配置完成后，使用 dig 命令测试并验证结果。 1[user1@bogon ~]$ dig -t A www.baidu.com @192.168.127.136]]></content>
      <tags>
        <tag>Service</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS服务]]></title>
    <url>%2F2016%2F03%2F25%2F212131-DNS%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[DNS基础DNS（Domain Name System，域名系统），在Internet上作为域名与IP地址相互映射的一个分布式数据库，能够使用户更方便的使用域名访问互联网，而不用去记住只能被机器识别的IP地址。域名(FQDN)和IP地址之间的转换工作称为域名解析（或主机名解析）。 ICANN，全称Internet Corporation for Assigned Names and Numbers(互联网名称与数字地址分配机构)，是一个非盈利性的国际组织，负责互联网协议(IP)地址的空间分配，协议标示符的指派，通用顶级域名 (gTLD)以及国家和地区顶级域名(ccTLD)系统的管理，以及根服务器系统的管理。官方网址是：http://www.icann.org ICANN的作用：负责协调管理DNS各技术要素以确保普遍可解析性，使所有的互联网用户都能够找到有效的地址。它是通过监督互联网运作当中独特的技术标示符的分配以及顶级域名的授权来做到这点的。 hosts映射 早期，名字到地址的转换过程十分简单。每台计算机保存一个hosts文件，里面列出所有计算机名字和对应的IP地址，然后定期从一个维护此文件的站点更新里面的记录。当我们访问某个计算机名字时，先在hosts文件找到对应的IP，然后就可以建立连接。 随着网络规模的扩大，这种方法渐渐吃不消了。主要有以下三个原因： hosts文件变得非常大 主机名字会冲突 集中的维护站点会不堪重负 域名结构 通常 Internet 主机域名的一般结构为：主机名.三级域名.二级域名.顶级域名。 Internet 的顶级域名由 Internet网络协会域名注册查询负责网络地址分配的委员会进行登记和管理，它还为 Internet的每一台主机分配唯一的 IP 地址。全世界现有三个大的网络信息中心： 位于美国的 Inter-NIC，负责美国及其他地区； 位于荷兰的RIPE-NIC，负责欧洲地区；位于日本的APNIC，负责亚太地区 监听的端口 12353/udp # 普通查询53/tcp # 从服务器到主服务器进行数据传输，为保证数据完整性，使用tcp协议953/tcp# rndc远程域名服务器控制器 DNS的功能 每个IP地址都可以有一个主机名，主机名由一个或多个字符串组成，字符串之间用小数点隔开。有了主机名，就不用死记硬背每台IP设备的IP地址，只要记住相对直观有意义的主机名就行了。这就是DNS协议所要完成的功能。 正反解析 正向解析：从域名到ip地址的解析过程 反向解析：从ip地址到域名的解析过程，反向解析一般用来进行服务器的身份验证 DNS查询 查询的优先级：本地hosts文件 =&gt; 本地缓存 =&gt; 本地DNS区域文件 分级查询：从根域开始，依次查询每一级域名的NS记录，直到查到最终的IP地址。DNS服务器根据域名的层级，进行分级查询。每一级域名都有自己的NS记录，NS记录指向该级域名的域名服务器。这些服务器知道下一级域名的各种记录。 递归查询：客户端向DNS服务器发送一次请求，DNS服务器逐级完成查询完成后直接返回结果。对于客户端来讲为递归查询，对于DNS服务器来讲是迭代查询。 迭代查询：客户端需要发起多次请求才可得到结果 默认情况下，DNS服务器使用递归方式来解析域名。递归的含义就是DNS服务器作为DNS客户端向其他DNS服务器查询此解析请求，直到获得解析结果，在此过程中，原客户端则等待DNS服务器的回复。 参考链接： http://blog.csdn.net/lycb_gz/article/details/11720247 DNS应答 权威应答如果DNS服务器在自己的区域文件里找到了客户端需要查询的记录，就会返回一个权威性应答。如果DNS服务器最近被查找过该主机记录，就会在缓存里找到记录应答客户端。如果找不到主机的A记录，就会返回（RecordNotFound）应答――同样是权威性应答。 非权威应答如果接到DNS查询请求的服务器不是指定域的名称服务器，则：首先查询其他DNS服务器直到找到，然后此服务器将找到的内容返回给客户端――非权威性应答。其次，推荐客户端到上一级DNS服务器找。―――非权威性应答。 DNS冗余 为保证服务的高可用性，DNS要求使用多台名称服务器冗余支持每个区域。某个区域的资源记录通过手动或自动方式更新到单个主名称服务器（称为主DNS服务器）上，主 DNS 服务器可以是一个或几个区域的权威名称服务器。 其它冗余名称服务器（称为辅 DNS 服务器）用作同一区域中主服务器的备份服务器，以防主服务器无法访问或宕机。辅 DNS服务器定期与主 DNS 服务器通讯，确保它的区域信息保持最新。如果不是最新信息，辅DNS服务器就会从主服务器获取最新区域数据文件的副本。这种将区域文件复制到多台名称服务器的过程称为区域复制。 服务器类型 主从服务器：主服务器数据修改，辅助服务器请求数据同步 缓存服务器 转发器 资源记录 为了将名字解析为IP地址，服务器查询它们的区(DNS数据库文件)。区中包含组成相关DNS域资源信息的资源记录（RR）。 某些资源记录不仅包括DNS域中服务器的信息，还可以用于定义域，即指定每台服务器授权了哪些域，这些资源记录就是SOA和NS资源记录。 数据库中的每一个条目称作是一个资源记录(Resource Record，RR)，它是一个五元组，可以用以下格式表示： 1234567Domain_name Time_to_live Class Type Value## Domain_name 指出这条记录适用于哪个域名# Time_to_live 用来表明记录的生存周期，也就是说最多可以缓存该记录多长时间，可省略# Class 一般总是IN；对应的是internet# Type 资源记录的类型# Value 记录的值，如果是A记录，则value是一个IPv4地址 名称 TTL值(可选) Internet 资源记录类型 值 NAME TTL IN RRT VALUE www.nettest.net 600 IN A 161.202.43.78 161.202.43.78 600 IN PTR www.nettest.net 资源记录及类型①A记录：A记录也称为主机记录，是使用最广泛的DNS记录，A记录的基本作用就是说明一个域名对应的IP是多少， 它是域名和IP地址的对应关系，表现形式为 www.contoso.com 192.168.1.1 这就是一个A记录！A记录除了进行域名IP对应以外，还有一个高级用法，可以作为低成本的负载均衡的解决方案，比如说，www.contoso.com 可以创建多个A记录，对应多台物理服务器的IP地址，可以实现基本的流量均衡！) ②NS记录：NS记录和SOA记录是任何一个DNS区域都不可或缺的两条记录，NS记录也叫名称服务器记录，用于说明这个区域有哪些DNS服务器负责解析，SOA记录说明负责解析的DNS服务器中哪一个是主服务器。因此，任何一个DNS区域都不可能缺少这两条记录。NS记录，说明了在这个区域里，有多少个服务器来承担解析的任务 ③SOA记录：NS记录说明了有多台服务器在进行解析，但哪一个才是主服务器呢，NS并没有说明，这个就要看SOA记录了，SOA名叫起始授权机构记录，SOA记录说明了在众多NS记录里那一台才是主要的服务器！ ④MX记录：全称是邮件交换记录，在使用邮件服务器的时候，MX记录是无可或缺的，比如A用户向B用户发送一封邮件，那么他需要向ＤＮＳ查询Ｂ的MX记录，DNS在定位到了B的MX记录后反馈给A用户，然后Ａ用户把邮件投递到B用户的ＭＸ记录服务器里！ ⑤Cname记录：又叫别名记录，我们可以这么理解，我们小的时候都会有一个小名，长大了都是学名，那么正规来说学名的符合公安系统的，那个小名只是我们的一个代名词而已，这也存在一个好处，就是比暴漏自己，比如一个网站 a.com 在发布的时候，他可以建立一个别名记录，把 b.com 发布出去，这样不容易被外在用户所察觉！达到隐藏自己的目的！ ⑥SRV记录：SRV记录是服务器资源记录的缩写，SRV记录是DNS记录中的新鲜面孔，在RFC2052中才对SRV记录进行了定义，因此很多老版本的DNS服务器并不支持SRV记录。那么SRV记录有什么用呢？SRV记录的作用是说明一个服务器能够提供什么样的服务！SRV记录在微软的Active Directory中有着重要地位，大家知道在NT4时代域和DNS并没有太多关系。但从Win2000开始，域就离不开DNS的帮助了，为什么呢？因为域内的计算机要依赖DNS的SRV记录来定位域控制器！表现形式为： 123456789101112ldap._tcp.contoso.com 600 IN SRV 0 100 389 NS.contoso.com# 说明：ladp: 是一个服务，该标识说明把这台服务器当做响应LDAP请求的服务器tcp：本服务使用的协议，可以是tcp，也可以是用户数据包协议《udp》contoso.com：此记录所值的域名600： 此记录默认生存时间（秒）IN： 标准DNS Internet类SRV：将这条记录标识为SRV记录0： 优先级，如果相同的服务有多条SRV记录，用户会尝试先连接优先级最低的记录100：负载平衡机制，多条SRV并且优先级也相同，那么用户会先尝试连接权重高的记录389：此服务使用的端口NS.contoso.com:提供此服务的主机 ⑦PTR记录：PTR记录也被称为指针记录，PTR记录是A记录的逆向记录，作用是把IP地址解析为域名。由于我们在前面提到过，DNS的反向区域负责从IP到域名的解析，因此如果要创建PTR记录，必须在反向区域中创建。 Bind安装配置Bind，全称是Berkeley Internet Name Domain(伯克利因特网名字域系统)。官方网址：http://www.isc.org/ 。它主要有3个版本：BIND 4，BIND 8，BIND9。 需求 已知域名 study.info 和 study.co，IP地址 192.168.127.0/24，要实现 主从权威名称服务器 12ns1.study.info 192.168.127.123ns2.study.info 192.168.127.124 邮件服务器 1mail.study.co 192.168.127.125 网站服务器 1www.study.co 192.168.127.126 ftp服务器 1ftp.study.co 192.168.127.127 别名 1www2.study.co =&gt; www.study.co PTR 1192.168.127.128 =&gt; www.study.co 安装和文件说明 配置yum源，安装bind的rpm包 12rpm -qa | grep '^bind'yum -y install bind bind-utils 文件说明 1234567891011121314/usr/sbin/named# 主程序文件/etc/named.conf# 主配置文件options&#123;....&#125;;# 全局配置段logging&#123;....&#125;;# 日志配置段zone&#123;.....&#125;;# 由本机负责解析的区域或转发的区域/var/named/# 数据文件目录/var/named/named.ca# 存放根域的配置文件 区域配置的语法结构 区域 12345zone "ZONE NAME" IN &#123; type &#123;master|slave|hint|forward&#125;; ;主 |从 |根 |转发器 file "区域数据文件";&#125;; 主区域 1file "区域数据文件"; 从区域 12file "区域数据文件";masters &#123; master_ip; &#125;; 配置 在主机 192.168.127.123上进行配置 备份好原生配置文件 12cp /etc/named.conf&#123;,.bak&#125;cat /etc/named.conf 编辑 /etc/named.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051options &#123; listen-on port 53 &#123; 192.168.127.123; &#125;; allow-transfer &#123;"none";&#125;; allow-recursion &#123;"any";&#125;; recursion yes; max-cache-ttl 900; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; recursing-file "/var/named/data/named.recursing"; secroots-file "/var/named/data/named.secroots"; allow-query &#123; localhost; &#125;; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;zone "localhost" IN &#123; type master; file "named.localhost";&#125;;zone "0.0.127.in-addr.arpa" IN &#123; type master; file "named.loopback";&#125;;zone "study.info" IN &#123; type master; file "zone.study.info";&#125;;zone "study.co" IN &#123; type master; file "zone.study.co";&#125;;zone "127.168.192.in-addr.arpa" IN &#123; type master; file "zone.192.168.127";&#125;; 创建区域文件 /var/named/zone.study.info 1234567891011$TTL 600@ IN SOA @ memory.study.co. ( 2006103002 ; Serial at current time 1D ; Refresh after 1 day 1H ; Retry after 1 houre 1M ; Expire after 1 month 1W) ; Minimum TTL of 1 weekstudy.info. IN NS ns1.study.info.@ IN NS ns2 ; 区域名称可省略，自动补全ns1 IN A 192.168.127.123ns2 IN A 192.168.127.124 创建区域文件 /var/named/zone.study.co 12345678910111213141516$TTL 600@ IN SOA @ memory.study.co. ( 2010111004 ;Serial at current time 86400 ;Refresh after 1 day 3600 ;Retry after 1 houre 2419200 ;Expire after 1 month 60480 ;Minimum TTL of 1 week)@ IN NS ns1.study.info.@ IN NS ns2.study.info.@ IN MX 10 mail.study.co.mail IN A 192.168.127.125www IN A 192.168.127.126www2 IN CNAME wwwftp IN A 192.168.127.127* IN A 192.168.127.123 ;*代表所有，即*.study.co 创建区域文件 zone.192.168.127 1234567891011$TTL 600@ IN SOA @ memory.study.co. ( 2010111004 ;Serial at current time 86400 ;Refresh after 1 day 3600 ;Retry after 1 houre 2419200 ;Expire after 1 month 60480 ;Minimum TTL of 1 week)@ IN NS ns1.study.info.@ IN NS ns2.study.info.128 IN PTR www.study.co. 对区域进行检查和文件权限，修改属主属组；重读配置文件进行测试 123456789101112chown /var/named/zone.study.* /var/named/zone.192.168.127 --reference='/etc/named.conf'chmod /var/named/zone.study.* /var/named/zone.192.168.127 --reference='/etc/named.conf'named-checkconf /etc/named.confnamed-checkzone "localhost" /var/named/named.localhost named-checkzone "0.0.127.in-addr.arpa" /var/named/named.loopback named-checkzone "study.info" /var/named/zone.study.info named-checkzone "study.co" /var/named/zone.study.conamed-checkzone "127.168.192.in-addr.arpa" /var/named/zone.192.168.127 setenforce disabled/bin/sed -ri 's/(^SELINUX=).*/\1disabled/' /etc/selinux/configsystemctl enable --now namedsystemctl status named 使用 dig 命令进行测试 1234dig @192.168.127.123 -t NS study.codig @192.168.127.123 -t A ftp.study.codig @192.168.127.123 -t A ns1.study.infodig @192.168.127.123 -t MX study.co 如果在服务运行的过程中修改了配置文件，无需重新启动服务，使用 pkill 命令即可使服务重读配置文件 1pkill -1 named 主从复制及区域传送Bind 配置 从服务器（slave）192.168.127.164 bind配置，配置完成后进行主、从DNS日期时间同步 123456setenforce disabledsed -ri 's/(^SELINUX=).*/\1disabled/' /etc/selinux/configrpm -qa | grep '^bind'yum -y install bind bind-utils cd /etc/ ; cp named.conf&#123;,.orig&#125;scp -P 22 192.168.127.123:/etc/named.conf /etc/named.conf 生成区域文件的工具: http://pgl.yoyo.org/adservers/bind-zone-file-creator.php 主 DNS 配置 在主 DNS 服务器 192.168.127.123 上修改 /etc/named.conf 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051options &#123; listen-on port 53 &#123; 192.168.127.123; &#125;; allow-transfer &#123;192.168.127.124; &#125;; // 允许区域传送的IP地址 recursion yes; notify yes; // 启用通知从服务器同步功能 max-cache-ttl 900; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; recursing-file "/var/named/data/named.recursing"; secroots-file "/var/named/data/named.secroots"; allow-query &#123; "any"; &#125;; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;zone "localhost" IN &#123; type master; file "named.localhost";&#125;;zone "0.0.127.in-addr.arpa" IN &#123; type master; file "named.loopback";&#125;;zone "study.info" IN &#123; type master; file "zone.study.info";&#125;;zone "study.co" IN &#123; type master; file "zone.study.co";&#125;;zone "127.168.192.in-addr.arpa" IN &#123; type master; file "zone.192.168.127";&#125;; 从 DNS 配置 在从 DNS 服务器上 192.168.127.124 上配置 /etc/named.conf 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253options &#123; listen-on port 53 &#123; 192.168.127.124; &#125;; // 修改监听地址 allow-transfer &#123;"none";&#125;; recursion yes; max-cache-ttl 900; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; recursing-file "/var/named/data/named.recursing"; secroots-file "/var/named/data/named.secroots"; allow-query &#123; "any"; &#125;; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;zone "." IN &#123; type hint; file "named.ca";&#125;;zone "localhost" IN &#123; type master; file "named.localhost";&#125;;zone "0.0.127.in-addr.arpa" IN &#123; type master; file "named.loopback";&#125;;zone "study.info" IN &#123; type slave; // 定义类型为从服务器 masters &#123; 192.168.127.123; &#125;; // 定义主服务器及IP file "zone.study.info";&#125;;zone "study.co" IN &#123; type slave; // 定义类型为从服务器 masters &#123; 192.168.127.123; &#125;; // 定义主服务器及IP file "zone.study.co";&#125;;zone "127.168.192.in-addr.arpa" IN &#123; type slave; // 定义类型为从服务器 masters &#123; 192.168.127.123; &#125;; // 定义主服务器及IP file "zone.192.168.127";&#125;; 区域传送测试 主从 DNS 服务器都重启进程，并查看日志是否传送成功 12systemctl restart namedtail /var/log/messages -n 50 主服务器看到的日志信息 12345678910111213Jul 18 17:09:39 study named[3249]: runningJul 18 17:09:39 study named[3249]: zone study.info/IN: sending notifies (serial 2006103002)Jul 18 17:09:39 study named[3249]: zone study.co/IN: sending notifies (serial 2010111004)Jul 18 17:09:39 study named[3249]: zone 127.168.192.in-addr.arpa/IN: sending notifies (serial 2010111004)Jul 18 17:09:39 study named[3249]: client 192.168.127.124#45719 (study.info): transfer of 'study.info/IN': AXFR startedJul 18 17:09:39 study named[3249]: client 192.168.127.124#45719 (study.info): transfer of 'study.info/IN': AXFR endedJul 18 17:09:40 study named[3249]: client 192.168.127.124#59139: received notify for zone 'study.info'Jul 18 17:09:44 study named[3249]: client 192.168.127.124#50093 (study.co): transfer of 'study.co/IN': AXFR startedJul 18 17:09:44 study named[3249]: client 192.168.127.124#50093 (study.co): transfer of 'study.co/IN': AXFR endedJul 18 17:09:44 study named[3249]: client 192.168.127.124#59139: received notify for zone 'study.co'Jul 18 17:09:46 study named[3249]: client 192.168.127.124#44996 (127.168.192.in-addr.arpa): transfer of '127.168.192.in-addr.arpa/IN': AXFR startedJul 18 17:09:46 study named[3249]: client 192.168.127.124#44996 (127.168.192.in-addr.arpa): transfer of '127.168.192.in-addr.arpa/IN': AXFR endedJul 18 17:09:46 study named[3249]: client 192.168.127.124#34993: received notify for zone '127.168.192.in-addr.arpa' 从服务器看到的日志信息 123456789101112131415161718192021222324Jul 18 17:09:04 bogon named[21703]: zone study.info/IN: Transfer started.Jul 18 17:09:04 bogon named[21703]: transfer of 'study.info/IN' from 192.168.127.123#53: connected using 192.168.127.124#44390Jul 18 17:09:04 bogon named[21703]: transfer of 'study.info/IN' from 192.168.127.123#53: failed while receiving responses: REFUSEDJul 18 17:09:04 bogon named[21703]: transfer of 'study.info/IN' from 192.168.127.123#53: Transfer completed: 0 messages, 0 records, 0 bytes, 0.003 secs (0 bytes/sec)Jul 18 17:09:39 bogon named[21703]: client 192.168.127.123#29674: received notify for zone 'study.info'Jul 18 17:09:39 bogon named[21703]: zone study.info/IN: Transfer started.Jul 18 17:09:39 bogon named[21703]: transfer of 'study.info/IN' from 192.168.127.123#53: connected using 192.168.127.124#45719Jul 18 17:09:39 bogon named[21703]: zone study.info/IN: transferred serial 2006103002Jul 18 17:09:39 bogon named[21703]: transfer of 'study.info/IN' from 192.168.127.123#53: Transfer completed: 1 messages, 6 records, 175 bytes, 0.013 secs (13461 bytes/sec)Jul 18 17:09:39 bogon named[21703]: zone study.info/IN: sending notifies (serial 2006103002)Jul 18 17:09:40 bogon named[21703]: client 192.168.127.123#49585: received notify for zone 'study.co'Jul 18 17:09:40 bogon named[21703]: zone study.co/IN: notify from 192.168.127.123#49585: refresh in progress, refresh check queuedJul 18 17:09:40 bogon named[21703]: client 192.168.127.123#49585: received notify for zone '127.168.192.in-addr.arpa'Jul 18 17:09:40 bogon named[21703]: zone 127.168.192.in-addr.arpa/IN: notify from 192.168.127.123#49585: refresh in progress, refresh check queuedJul 18 17:09:44 bogon named[21703]: zone study.co/IN: Transfer started.Jul 18 17:09:44 bogon named[21703]: transfer of 'study.co/IN' from 192.168.127.123#53: connected using 192.168.127.124#50093Jul 18 17:09:44 bogon named[21703]: zone study.co/IN: transferred serial 2010111004Jul 18 17:09:44 bogon named[21703]: transfer of 'study.co/IN' from 192.168.127.123#53: Transfer completed: 1 messages, 10 records, 265 bytes, 0.002 secs (132500 bytes/sec)Jul 18 17:09:44 bogon named[21703]: zone study.co/IN: sending notifies (serial 2010111004)Jul 18 17:09:46 bogon named[21703]: zone 127.168.192.in-addr.arpa/IN: Transfer started.Jul 18 17:09:46 bogon named[21703]: transfer of '127.168.192.in-addr.arpa/IN' from 192.168.127.123#53: connected using 192.168.127.124#44996Jul 18 17:09:46 bogon named[21703]: zone 127.168.192.in-addr.arpa/IN: transferred serial 2010111004Jul 18 17:09:46 bogon named[21703]: transfer of '127.168.192.in-addr.arpa/IN' from 192.168.127.123#53: Transfer completed: 1 messages, 5 records, 197 bytes, 0.002 secs (98500 bytes/sec)Jul 18 17:09:46 bogon named[21703]: zone 127.168.192.in-addr.arpa/IN: sending notifies (serial 2010111004) 从服务器更新测试，修改主服务器区域文件，添加一条 N S记录并修改序列号；主服务器重启进程，测试从服务器是否正常同步 rndc远程控制在主DNS生成 rndc 配置文件 1234rndc-confgen -s 127.0.0.1 -r /dev/urandom &gt; /etc/rndctouch /etc/rnd.confchmod /etc/rndc.conf --reference=/etc/named.confchown /etc/rndc.conf --reference=/etc/named.conf 文件 /etc/rndc 内容查看 123456789101112131415161718192021222324# Start of rndc.confkey "rndc-key" &#123; algorithm hmac-md5; secret "g7vCooMXxxyLTD92+C5bOg==";&#125;;options &#123; default-key "rndc-key"; default-server 127.0.0.1; default-port 953;&#125;;# End of rndc.conf# Use with the following in named.conf, adjusting the allow list as needed:# key "rndc-key" &#123;# algorithm hmac-md5;# secret "g7vCooMXxxyLTD92+C5bOg==";# &#125;;# # controls &#123;# inet 127.0.0.1 port 953# allow &#123; 127.0.0.1; &#125; keys &#123; "rndc-key"; &#125;;# &#125;;# End of named.conf 将开头的 key 覆盖到 /etc/rndc.conf 1awk '/# Start of rndc.conf/,/# End of rndc.conf/' /etc/rndc &gt; /etc/rndc.conf 修改 server IP 123456789101112# Start of rndc.confkey "rndc-key" &#123; algorithm hmac-md5; secret "g7vCooMXxxyLTD92+C5bOg==";&#125;;options &#123; default-key "rndc-key"; default-server 192.168.127.123; default-port 953;&#125;;# End of rndc.conf 将 # 开头的行写到 /etc/named.conf 文件中，并去掉部分注释。修改被控制机IP地址，以及allow，允许哪些IP来控制本机 1234567891011# Use with the following in named.conf, adjusting the allow list as needed:key "rndc-key" &#123; algorithm hmac-md5; secret "je+uT0BxuoBgYVic//p6Rg==";&#125;;controls &#123; inet 192.168.127.123 port 953 allow &#123; any; &#125; keys &#123; "rndc-key"; &#125;;&#125;;# End of named.conf 使用 rndc -c /etc/rndc.conf status 命令查看状态 12345678910111213version: 9.9.4-RedHat-9.9.4-73.el7_6 &lt;id:8f9657aa&gt;CPUs found: 1worker threads: 1UDP listeners per interface: 1number of zones: 103debug level: 0xfers running: 0xfers deferred: 0soa queries in progress: 0query logging is OFFrecursive clients: 0/0/1000tcp clients: 0/100server is up and running 其他命令 123rndc -c /etc/rndc.conf notify study.info # 手动通知区域rndc -c /etc/rndc.conf flush # 清空缓存rndc -c /etc/rndc.conf stop # 停止 dns 服务 上面只是实现了本机 IP 控制本机，如果要使用其他主机来控制，需要拷贝 rndc 到控制机 12scp -P 22 192.168.127.123:/etc/rndc.conf /root/rndc -c /root/rndc.conf status 子域授权子域授权，在原有的域上再划分出一个小的区域并指定新 DNS 服务器。在这个小的区域中如果有客户端请求解析，则只需要找新的子 DNS 服务器。这样的做的好处可以减轻主 DNS 的压力，也有利于管理。这里只做正向区域的子域授权。 以子域 m.study.co. 为例，主 DNS 服务器IP还是之前的 192.168.127.123，子域DNS服务器地址是 192.168.127.130 主 DNS 服务器的配置，要在 /var/named/zone.study.co 添加子域资源记录并修改序列号，重新加载进程完成主从同步 12m IN NS ns1.m.study.co.ns1.m IN A 192.168.127.130 子域服务器的配置，需要在子域 m.netpas.co. 服务器进行相关配置，启动服务 123yum -y install bind bind-utilscp /etc/named.conf&#123;,.bak&#125;scp -P 22 192.168.127.123:/etc/named.conf /etc/named.conf 修改 /etc/named.conf 并查看文件内容 12345678910111213141516171819202122232425262728options &#123; listen-on port 53 &#123; 192.168.127.130; &#125;; recursion yes; max-cache-ttl 900; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; recursing-file "/var/named/data/named.recursing"; secroots-file "/var/named/data/named.secroots"; allow-query &#123; "any"; &#125;; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;zone "m.study.co" IN &#123; type master; file "zone.m.study.co";&#125;; 创建区域文件 /var/named/zone.m.study.co 123touch /var/named/zone.m.study.cochown /var/named/zone.m.study.co --reference /etc/named.confchmod /var/named/zone.m.study.co --reference /etc/named.conf 写入内容 1234567891011$TTL 600@ IN SOA @ memory.study.co. ( 2006103001; Serial at current time 1D ; Refresh after 1 day 1H ; Retry after 1 houre 1M ; Expire after 1 month 1W) ; Minimum TTL of 1 week@ IN NS ns1ns1 IN A 192.168.127.130www IN A 192.168.127.130 启动服务 1systemctl enable --now named 主 DNS 服务器测试 12dig -t ns @192.168.127.123 m.study.codig @192.168.127.123 www.m.study.co 从 DNS 服务器测试 12dig @192.168.127.124 -t ns m.study.codig @192.168.127.124 www.m.study.co 子域DNS测试 12dig @192.168.127.130 www.study.co# 无法获取正常结果，需要向父域转发DNS请求 转发器在DNS服务器的配置中，如果采用默认的配置，其实效率是较低的，因为默认情况下，我们所有的非权威解析都会被发送到根服务器进行迭代查询。如果采用转发，如将我们的DNS解析请求转发到一些公共DNS服务器上，由于公共DNS服务器上缓存了大量的解析，因此比原始的迭代查询快。全局转发能够实现对非权威解析（已缓存的除外）都转发到特定DNS服务器。 需要用到 forward 配置参数 123forward &#123; only | first &#125; # only 先转发到转发器，如果得不到答案自己不会尝试解析 # first 先转发到转发器，如果得不到答案则向根发起请求 上面子域DNS服务器解析主域的域名无法获取正常结果，需做转发配置。在子域DNS服务器 /etc/named.conf 的全局配置 options 字段加入以下两行 12forward only;forwarders &#123; 192.168.247.123;192.168.127.124; &#125;; 如果仅设置 forwarders，则在无法联系转发器时，就会尝试自己解析，即转发到根服务器迭代查询实现解析（如果配置有根zone）。 如果想服务器在联系不到转发器时不进行多余操作，则可以加上 forward only;；这样如果联系不上转发器时，服务器将只查询权威解析和本地缓存的解析。 区域转发：从BIND9.1开始，引入一个新特新：转发区（forward zone ），及允许查询特定区域时，将其转发到指定DNS服务器上。 子域DNS服务器在修改配置后重启服务，并测试验证 1dig @192.168.127.130 www.study.co DNS视图ACL的应用与配置 在 /etc/named.conf 的全局配置中，有 allow-query { 192.168.8.0/24; }; 这样的一行定义允许为哪些些客户端进行递归查询。这里只允许了这一个IP段，如果是大型企业或者公网我们需要允许的客户端有上百个IP段时，这里会写很长而且如果在多个地方需要用到，则需写多次，配置麻烦且影响查看。因此引入ACL，可以实现集中定义，所有位置均可引用。ACL类似程序开发中的函数。例如: 12345678910acl trust &#123; 172.16.100.0/24； 10.35.0.0/24； 192.168.0.0/24； 127.0.0.1；&#125;;options &#123; allow-query &#123; trust; &#125;; // 引用上面定义的ACL ……其他配置省略……&#125;;` 视图 viewview 将不同IP地址段发来的查询响应到不同的DNS解析。例如需要对多个不同IP地址段进行配置，就需要明确这些IP地址段，这样View功能才会有效。注意一旦使用view，所有域都必须定义在 view。 智能DNS 智能DNS是域名服务在业界首创的智能解析服务。能自动判断访问者的IP地址并解析出对应的IP地址，使网通用户会访问到网通服务器，电信用户会访问到电信服务器。在 Bind 中可以使用 acl 和 view 实现智能DNS 创建 tel_ip、cnc_ip、cm_ip、crc_ip、edu、other 6个访问控制列表表示不同来源(电信，联通，移动，铁通，教育，其他，默认)，以区域 study.co 为例，实现智能DNS 由于IP地址段数量较大，因此在 /var/named/ 目录下创建目录 acl 存放不同来源的IP段。 123456mkdir -pv /var/named/aclchown /var/named/acl/ --reference /var/named/chmod /var/named/acl/ --reference /var/named/touch /var/named/&#123;tel,cnc,cm,crc,edu,other&#125;_ip.aclchown -R /var/named/acl/* --reference=/etc/named.confchmod -R /var/named/acl/* --reference=/etc/named.conf 在 /var/named/acl/tel_ip.acl 创建针对电信IP的 acl 12345acl tel_ip&#123; 1.0.1.0/24; 1.0.2.0/23; 1.0.8.0/21;&#125;; 在 /var/named/acl/cnc_ip.acl 创建针对网通IP的 acl 12345acl cnc_ip&#123; 1.24.0.0/13; 1.56.0.0/13; 1.188.0.0/14;&#125;; 由于IP量比较大，上面只写了几个地址段仅供参考。实际情况需要写上百条，每个地址段占用一行，以分号结尾 针对这种数量比较大的情况，我们可以在 /etc/named.conf 使用 include 来处理，并添加与之对应的视图配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576options &#123; listen-on port 53 &#123; 192.168.127.123; &#125;; allow-transfer &#123;192.168.127.124; &#125;; // 允许区域传送的IP地址 recursion yes; notify yes; // 启用通知从服务器同步功能 max-cache-ttl 900; directory "/var/named"; dump-file "/var/named/data/cache_dump.db"; statistics-file "/var/named/data/named_stats.txt"; memstatistics-file "/var/named/data/named_mem_stats.txt"; recursing-file "/var/named/data/named.recursing"; secroots-file "/var/named/data/named.secroots"; allow-query &#123; "any"; &#125;; dnssec-enable yes; dnssec-validation yes; /* Path to ISC DLV key */ bindkeys-file "/etc/named.iscdlv.key"; managed-keys-directory "/var/named/dynamic"; pid-file "/run/named/named.pid"; session-keyfile "/run/named/session.key";&#125;;view "tel" &#123; match-clients &#123; tel_ip;&#125;; zone "study.info" IN &#123; type master; file "zone.study.info"; &#125;; zone "study.co" IN &#123; type master; file "zone.study.co"; &#125;; zone "127.168.192.in-addr.arpa" IN &#123; type master; file "zone.192.168.127"; &#125;;&#125;;view "cnc" &#123; match-clients &#123; cnc_ip;&#125;; zone "study.info" IN &#123; type master; file "zone.study.info"; &#125;; zone "study.co" IN &#123; type master; file "zone.study.co"; &#125;; zone "127.168.192.in-addr.arpa" IN &#123; type master; file "zone.192.168.127"; &#125;;&#125;;# Use with the following in named.conf, adjusting the allow list as needed:key "rndc-key" &#123; algorithm hmac-md5; secret "je+uT0BxuoBgYVic//p6Rg==";&#125;;controls &#123; inet 192.168.127.123 port 953 allow &#123; any; &#125; keys &#123; "rndc-key"; &#125;;&#125;;# End of named.confinclude "/var/named/acl/tel_ip.acl";include "/var/named/acl/cnc_ip.acl";include "/var/named/acl/cm_ip.acl";include "/var/named/acl/crc_ip.acl";include "/var/named/acl/edu_ip.acl";include "/var/named/acl/other_ip.acl"; 在 /var/named 下分别创建对应的区域文件(可拷贝)，并将相关记录改成对应运营商的IP就完成了智能解析。 修改好配置重启服务后，使用 dig 命令在不同环境下进行测试，来验证效果。 当然，如果你的 zone 比较多的话，也可以像 acl 的处理方法一样分类并单独写一个文件，最后使用 include 配置在 /etc/named.conf 中即可 日志Logging bind中我们可以通过配置logging来记录日志信息，以便以后对服务器的分析及问题的跟踪。logging语句为域名服务器设定了一个多样性的logging选项。它的channel短语对应于输出方式、格式选项和分类级别，它的名称可以与category短语一起定义多样的日志信息。如果打开日志功能可能会降低dns的性能，因此不建议开启日志功能。 开启日志功能 只需要在option里面加入一个选项即可。man named.conf 12345options &#123; directory "/var/named"; querylog yes;&#125;; 之后查看 /var/log/messages 就能看到日志信息；这样会浪费大量的空间。可以使用 catagory 日志系统，帮我们定制需要对哪些行为进行日志检测。 日志系统 bind的日志系统，提供了两个子系统，一个叫做channel，一个叫做category。 123456789catagory: 日志源（指的是产生日志的日志源，比如说有的是跟查询有关的，有的是跟区域传送相关的。）所以catagory可以让我们定义日志来源。 查询 区域传送； 可以通过catagory自定义日志来源；一个catagory，可以存放到多个位置；一个channel只能存放一个catagory。channel: 定义日志的日志保存位置； syslog：系统日志；使用日志级别的概念。/var/log/messages. file: 自定义保存日志信息的文件。 默认channel，下面是named 提前定义的四个通道，用于指定缺省的日志。 123456789101112131415channel "default_syslog" &#123; syslog daemon; # 发送给syslog 的daemon facility severity info; # 只发送此优先级和更高优先级的信息&#125;;channel "default_debug" &#123; file "named.run"; # 写入工作目录下的named.run 文件。注意：如果服务器用-f 参数启动，则"named.run"会被stderr 所替换。 severity dynamic; # 按照服务器当前的debug 级别记录日志&#125;;channel "default_stderr"&#123; stderr; # 写到stderr severity info; # 只发送此优先级和更高优先级的信息&#125;;channel "null" &#123; null; # 丢弃所有发到此通道的信息&#125;; default_debug 通道有特殊的性质：只有当服务器的debug级别非0的时候，它才产生输出。一般来说，它会在服务器的工作目录中写入 named.run 文件。因为安全原因，当在命令行选项中使用了 -u 参数后，只有当 named 使用了新的UID后，named.run 文件才会产生，以 root 身份启动和运行的 named 所产生的 debug 信息将会被丢弃。如果用户需要得到这些输出，则必须使用 -g 参数运行服务器，并重新将标准错误定向到一个文件中去。一旦定义好一个通道，它就不能被重新定义。这样就不能修改内置的通道，但是可以通过把分类指向你已经定义的通道，来修改默认的日志记录。 示例 1234567891011logging &#123; file "log.msgs" version 3 size 10k; # 一旦达到10k，就开始滚动，日志是可以滚动的； severity dynamic; # 定义日志级别； &#125;; channel my_syslog &#123; syslog local0; # 定义syslog里面local0的信息存放到哪里去； severity info; # 定义local0里面的普通信息放到固定位置去。 &#125;; category xfer-in &#123; my_file; &#125;; # 传入 #将传入日志保存到my_file里面去； category update &#123; my_syslog; &#125;; # 更新信息 &#125;; 日志的设置和定义 12345678910channel通道：作用主要定义日志输出的方式；在定义通道的语句里有哪些子语句： 通道的名称，即自定义通道的名称，即是什么类别。 输出方式和路径； 输出日志的轮转；即日志1，日志2，日志3...; 输出日志的大小限制； 输出到syslog 定义消息的级别：severity critical |err |warning |notice |info |debug |dynamic 定义类别的输出：print-category yes or no 定义等级的输出：print-severity yes or no 定义时间的输出：print-time yes or no 1234567891011category类别：定义了那些数据需要记录，即在日志里输出那些日志内容。哪一类的类别使用哪个或哪几个已经定义好的通道 类别的种类： default，没有配置的分类使用default的分类日志配置。 general，许多没有分类的内容都在此分类； database，named使用的，用来存储和缓存的内部数据库信息； security，接受和拒绝的请求 config配置文件分析和处理 resolver DNA解析； xfer-in：服务器收到的域传输； xfer-out：服务器发送的域传输。 queries 请求。]]></content>
      <tags>
        <tag>Service</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenSSH]]></title>
    <url>%2F2016%2F03%2F21%2F190139-OpenSSH%2F</url>
    <content type="text"><![CDATA[SSHSSH (Secure Shell Protocol)，由 IETF 网络工作小组（Network working Group）指定；在进行数据传输之前，SSH先对联机数据包通过加密技术进行加密处理，加密后在进行数据传输。确保了传递的数据安全。 SSH 是专为远程登录会话和其他网络服务提供的安全性协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题，在当前的生产环境运维工作中，绝大多数企业普遍采用 SSH 协议服务来代替传统的不安全的远程联机服务软件，如telnet（23/tcp，非加密）。 默认状态下，SSH 服务监听在应用层协议的 TCP 协议的 22 号端口，建立在应用层和传输层基础上。主要提供了两个服务功能，一个是提供类似 Telnet 远程联机服务器的服务，即 SSH 服务；另一个是类似 FTP 服务的 sftp-server，借助 SSH 协议来传输数据，提供更安全的 SFTP 服务（vsftp，proftp）。 SSH 版本目前有 1.x 和 2.x ，由于 1.x 的漏洞原因，目前使用安全协议 SSH2。SSH 客户端包含 ssh 远程连接命令，以及远程拷贝 scp 命令。 SSH 服务是一个守护进程（daemon），他在后台运行并响应来自客户端的连接请求，SSH 服务端的进程名为 sshd，负责实时监听远程 SSH 客户端的连接请求并进行处理，一般包括公共密钥认证、密钥交换、对称密钥加密和非安全连接等。 认证过程只要知道用户名和密码，就可以登录到远程主机。所有传输的数据都会被加密，但是不能保证正在连接的服务器就是想连接的服务器。可能会有别的服务器在冒充真正的服务器，也就是受到“中间人”这种方式的攻击。 SSH 通道（channel）的建立Server 运行对应的服务 sshd 12345678910[user1@study ~]$ systemctl status sshd● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2016-03-13 09:57:01 CST; 7h ago Docs: man:sshd(8) man:sshd_config(5) Main PID: 796 (sshd) CGroup: /system.slice/sshd.service └─796 /usr/sbin/sshd -D[user1@study ~]$ 在 /etc/ssh/ 下生成密钥对，私钥是 ssh_host_*_key，公钥是 ssh_host_*_key.pub 123[user1@study ~]$ ls /etc/ssh/moduli ssh_config sshd_config ssh_host_ecdsa_key ssh_host_ecdsa_key.pub ssh_host_ed25519_key ssh_host_ed25519_key.pub ssh_host_rsa_key ssh_host_rsa_key.pub[user1@study ~]$ Client 向 Server 发起连接请求，Server 接收到请求后将自己对应算法的公钥发送给 Client，当 Client 收到提示信息后输入 yes，验证并接受 Server 的主机公钥，并且 Client 也生成自己的密钥对，用 Server 的公钥加密自己的公钥发送给 Server。接着，安全的 SSH 通道建立 12345[root@study ~]$ ssh localhostThe authenticity of host 'localhost (::1)' can't be established.ECDSA key fingerprint is SHA256:Yn5m2m9aqBfL7PTDMrS0Xh3UGn75PZdAqgYxF0tuRa0.ECDSA key fingerprint is MD5:e6:49:44:f7:f5:18:04:77:01:e5:ab:48:93:03:0e:86.Are you sure you want to continue connecting (yes/no)? yes 基于口令的认证Client 使用 Server 的公钥加密自己的用户名发送给Server Server 收到信息后使用自己的私钥解密数据得到用户名，确定有此用户则发信息给 Client 要求发送对应用户的密码 1user1@localhost's password: Client 用 Server 的公钥加密对应用户的密码发送给 Server 发送给 Server。Server 使用自己的私钥解密并验证登录口令 基于密钥的认证采用数字签名的方法来认证客户端，在 Linux 设备上可以利用 RSA 和 DSA 两种公共密钥算法实现数字签名 认证过程分为两个步骤：会话密钥生成和用户认证，具体实现过程比较复杂，涉及到一些数学运算，故不再详细阐述 认证流程图下面是一张基本的通信过程流程图 SSH 服务的常用配置和命令常用配置SSH 服务在服务器上以 sshd 运行，对应的配置文件为 /etc/ssh/sshd_config 默认情况下服务器端监听的端口是 22 ，为了提高安全性，建议修改成自定义的端口 1Port 52113 在对于一些安全要求比较高的情况下，可能不允许 root 直接远程登录，而且不允许空密码登录，这时就需要修改下面的参数 12PermitRootLogin no # 禁止root远程登录PermitEmptyPasswords no # 禁止空密码的用户登录 默认情况下客户端试图登录 SSH 服务器时，服务器端会先根据客户端的 IP 地址进行 DNS 的 PTR 反向查询，尝试找出客户端的主机名，然后根据查询出的客户端主机名进行 DNS 的正向 A 记录查询，验证与其原始登录的 IP 地址是否一致，这是防止客户端欺骗的一种措施，但一般我们用到的是动态 IP 不会有 PTR 记录，这就会导致登录过程很慢。因此关闭这个功能是很常用的。 1UseDNS no # 从 yes 改为 no 常用命令ssh远程登录命令，常用选项： 1234 -b 指定源地址，也可使用 -oBindAddress= -p 指定端口号，也可使用 -oPort=-v 显示详细信息-o StrictHostKeyChecking=no 跳过证书验证，很多情况下都需要输入yes，在一些自动登录的情况下比较多用 命令格式 1234# 登录：ssh -l user host # 或 ssh user@host # 或ssh user@host 'command' ssh-keygen用来生成公钥和私钥密钥对的工具 常用选项 1234 -t rsa|dsa 加密类型 -f 指定密钥保存文件的路径，一般是 ~/.ssh/id_rsa -N '' 指定私钥的密码-P '' 指定私钥的密码 ssh-copy-id这个命令可以将生成的公钥传输至远程服务器，使用 -i 选项指定公钥的路径，如果远程主机监听 sshd 服务端口不是 22，就需要使用 -p 来指定对应的端口号 ssh-copy-id 是基于 shell 编写的开源脚本，有兴趣的话可以看看源码学习一下 scp跨主机文件安全复制工具 常用选项 123-r 递归拷贝，如果拷贝的是一个目录就需要这个选项-P 指定端口号-p 在拷贝前后保持文件或目录属性 命令格式 12scp USERNAME@HOST:/path/to/somefile /path/to/localscp /path/to/local USERNAME@HOST:/path/to/somewhere sftpssh服务附带的 sftp 功能命令，用于文件传输 123sftp -oPort=52113 root@192.168.247.164sftp&gt; cd /rootsftp&gt; ? 命令一台主机为客户端（基于某个用户实现） 12345# 1、生成一对密钥ssh-keygen -t rsa -f a.key -N '' -C"root@zhangsan"# 2、将公钥传输至服务器端某用户的家目录下的.ssh/authorized_keys文件中ssh-copy-id -i /root/a.key.pub root@192.168.2.2# 3、测试登录 ssh 免密登录配置本机生成密钥 12345678910111213141516171819202122[root@study ~]# ssh-keygen Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:+gGa1NFQrFzQXjWOPrTAp37/HUKglCOWET5MJptwAvU root@studyThe key&apos;s randomart image is:+---[RSA 2048]----+| .o+ ooXo .o || = O+* oo . || E.@+=+.. || .+.=*o.. || . o S.+ . || . o + .. || o . o . . . || . o . ...|| . ... .|+----[SHA256]-----+[root@study ~]# 如果你觉着这样被询问比较麻烦，可以这样做： 123456789101112131415161718[root@study ~]# ssh-keygen -f /root/.ssh/id_rsa -N '' -f 指定私钥保存路径，-N '' 指定私钥密码为空，用 -P 亦可Generating public/private rsa key pair.Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:mLmYT0wzcCXnehcoDawFWxU+oli63iFyM5Pab9MBTvo root@studyThe key's randomart image is:+---[RSA 2048]----+| .o+.=. || ooO . || +o+ * . || +++ B . . || o+..O S . || .o.=.= . ||. O.+.+. || * *E+. ||. ooo.. |+----[SHA256]-----+ 上传公钥到远端主机（待信主机） 123456789101112[root@study ~]# ssh-copy-id -p 22 192.168.127.159/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keysroot@192.168.127.159's password: Number of key(s) added: 1Now try logging into the machine, with: "ssh -p '22' '192.168.127.159'"and check to make sure that only the key(s) you wanted were added.[root@study ~]# 登录测试 1[root@study ~]# ssh -p 22 192.168.127.159]]></content>
      <tags>
        <tag>Service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是数字签名]]></title>
    <url>%2F2016%2F03%2F17%2F110123-%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%2F</url>
    <content type="text"><![CDATA[什么是数字签名有时候我们在访问网页时，浏览器会提示 “此网站的数字证书不可靠” 等类似的信息，究竟什么是数字签名和数字证书呢？ 鲍勃有两把钥匙，一把是公钥，另一把是私钥。公钥是公之于众的，所有需要的人都可以获得公钥，但是他的私钥是自己私有的。如果用公钥对数据进行加密，只有用对应的私钥才能解密；如果用私钥对数据进行加密，那么只有用对应的公钥才能解密。 鲍勃把公钥送给他的朋友：帕蒂、道格、苏珊，每人各自一把 苏珊想要给鲍勃写一封保密信。她写完后用鲍勃的公钥加密，就可以达到保密的效果。 鲍勃收信后，用私钥解密，就看到了信件内容。这里要强调的是，只要鲍勃的私钥不泄露，这封信就是安全的，即使落在别人手里，也无法解密。 鲍勃给苏珊回信，决定采用”数字签名”。他写完后先用 Hash 函数，生成信件的摘要信息（digest）。 然后鲍勃使用私钥，对这个摘要加密，生成 “数字签名”（signature）。 鲍勃将这个签名，附在信件下面，一起发给苏珊。 苏珊收信后，取下数字签名，用鲍勃的公钥如果能成功解密，得到信件的摘要，就说明这封信确实是鲍勃发出的。 苏珊再对信件本身使用 Hash 函数，将得到的结果，与上一步得到的摘要进行对比。如果两者一致，就证明这封信未被修改过。 复杂的情况出现了。道格想欺骗苏珊，他偷偷使用了苏珊的电脑，用自己的公钥换走了鲍勃的公钥。此时，苏珊实际拥有的是道格的公钥，但是还以为这是鲍勃的公钥。因此，道格就可以冒充鲍勃，用自己的私钥做成 “数字签名”，写信给苏珊，让苏珊用假的鲍勃公钥进行解密。 后来，苏珊感觉不对劲，发现自己无法确定公钥是否真的属于鲍勃。她想到了一个办法，要求鲍勃去找 “证书中心” （certificate authority，简称 CA），为公钥做认证。证书中心用自己的私钥，对鲍勃的公钥和一些相关信息一起加密，生成 “数字证书”（Digital Certificate）。 鲍勃拿到数字证书以后，就可以放心了。以后再给苏珊写信，只要在签名的同时，再附上数字证书就行了。 苏珊收信后，用CA的公钥解开数字证书，就可以拿到鲍勃真实的公钥了，然后就能证明”数字签名”是否真的是鲍勃签的。 数字签名的应用 下面，我们看一个应用”数字证书”的实例：https协议。这个协议主要用于网页加密。 首先，客户端向服务器发出加密请求。 服务器用自己的私钥加密网页以后，连同本身的数字证书，一起发送给客户端。 客户端（浏览器）的”证书管理器”，有”受信任的根证书颁发机构”列表。客户端会根据这张列表，查看解开数字证书的公钥是否在列表之内。 如果数字证书记载的网址，与你正在浏览的网址不一致，就说明这张证书可能被冒用，浏览器会发出警告。 如果这张数字证书不是由受信任的机构颁发的，浏览器会发出另一种警告。 如果数字证书是可靠的，客户端就可以使用证书中的服务器公钥，对信息进行加密，然后与服务器交换加密信息。 总结数字签名的用途 数字签名是用来验证服务端与客户端之间发送的报文信息是否被篡改了 数字签名的原理 server 对 client 发送一个报文，client 先用 Hash 算法对报文进行计算得到的值我们叫做信息摘要，接着用 server 的私钥对信息摘要进行加密得到密文我们叫做数字签名，server 就把报文+数字签名一起发送给客户端，client 用 server 的公钥先对数字签名进行解密，得到信息摘要，在对报文进行 Hash 计算，用计算得到的值和信息摘要进行对比，两者相同就证明报文没有被修改 为什么要用 Hash 算法 Hash 算法是一种不可逆的单向加密算法，一旦修改变原文一处内容，计算的 hash 值会发生巨大变化。而非对称加密的计算需要消耗大量的计算机资源，相比较而言效率非常低，所以采用 Hash 算法 原文： http://www.youdzone.com/signature.html翻译： http://www.ruanyifeng.com/blog/2011/08/what_is_a_digital_signature.html参考： https://www.jianshu.com/p/80aa37311151]]></content>
      <tags>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[私有CA及https]]></title>
    <url>%2F2016%2F03%2F13%2F194143-%E7%A7%81%E6%9C%89CA%E5%8F%8Ahttps%2F</url>
    <content type="text"><![CDATA[说明x509.3证书格式 证书格式的版本号 证书序列号 证书签名算法 证书颁发者 有效期 持有者的名称 持有者的公钥 CA的ID 持有者的ID 其他扩展信息 基本约束 证书策略 密钥的使用限制 CA签名 SSL握手要完成的工作 SSL会话基于 IP 地址进行，不支持在基于主机名的虚拟主机上实现 交换协议版本号 选择一个双方都支持的加密方式 对两端实现身份验证 密钥交换 客户端验证服务器端证书 日期检查：证书是否在有效期内 证书颁发者的可信度 证书的签名检测 持有者的身份检测 配置私有CA服务器修改ca默认项配置 1vim /etc/pki/tls/openssl.cnf 12345678910111213141516171819202122232425[ req_distinguished_name ]countryName = Country Name (2 letter code)countryName_default = CN # 默认国家设置为CNcountryName_min = 2countryName_max = 2stateOrProvinceName = State or Province Name (full name)#stateOrProvinceName_default = Default ProvincestateOrProvinceName_default = BEIJING # 默认省、州设置为BEIJINGlocalityName = Locality Name (eg, city)localityName_default = chaoyang # 默认城市设置为朝阳0.organizationName = Organization Name (eg, company)0.organizationName_default = Nettest # 默认公司名称organizationalUnitName = Organizational Unit Name (eg, section)organizationalUnitName_default = NetworkOpertion # 默认部门名称设为网络运维部#organizationalUnitName_default =commonName = Common Name (eg, your name or your server\'s hostname) # 申请证书的主服务器名称commonName_max = 64emailAddress = Email Address # 证书管理员邮箱地址 创建私有 CA 123456789101112131415cd /etc/pki/CA/(umask 077;openssl genrsa -out private/cakey.pem 2048)# 生成CA的私钥openssl req -new -x509 -key private/cakey.pem -out cacert.pem -days 3655# 创建 CA 自签署证书mkdir -pv /etc/pki/CA/&#123;certs,crl,newcerts&#125;# 创建所需目录touch index.txt serial# 创建所需文件echo 01 &gt; serial # 写入序列号 https 的实现安装 mod_ssl 模块，httpd 基于 mod_ssl 模块实现对 ssl 的支持 1yum -y install mod_ssl 创建目录，存放密钥文件和证书请求文件、证书 1mkdir -pv /etc/httpd/conf/ssl 生成私钥 12cd /etc/httpd/conf/ssl(umask 077; openssl genrsa -out httpd.key 1024) web server 生成证书申请 123cd /etc/httpd/conf/sslopenssl req -new -key httpd.key -out httpd.csr # 生成一个证书颁发请求并填写相关信息 CA证书签署 1234openssl ca -in httpd.csr -out httpd.crt -days 3655# 将web服务器的申请证书发送给私有CA服务器# 私有CA服务器盖章，并发送给web服务器# 这里CA服务器和web服务器为同一台 修改httpd的ssl配置 1vim /etc/httpd/conf.d/ssl.conf 1234DocumentRoot "/var/www/html"ServerName www.test.com:443SSLCertificateFile /etc/httpd/conf/ssl/httpd.crtSSLCertificateKeyFile /etc/httpd/conf/ssl/httpd.key 配置检查并重启服务 12httpd -tsystemctl restart httpd 导入 CA 证书测试，证书路径：/etc/pki/CA/cacert.pem Windows 测试：拷贝证书至 Windows 环境，后缀名改为 crt 导入即可 Linux 测试： openssl s_client -connet：验证的地址：端口 -CAfile:CA证书的路径 1openssl s_client -connect www.test.com:443 -CAfile /etc/pki/CA/cacert.pem]]></content>
      <tags>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[是时候理解下HTTPS及背后的加密原理了]]></title>
    <url>%2F2016%2F03%2F09%2F212119-%E6%98%AF%E6%97%B6%E5%80%99%E7%90%86%E8%A7%A3%E4%B8%8BHTTPS%E5%8F%8A%E8%83%8C%E5%90%8E%E7%9A%84%E5%8A%A0%E5%AF%86%E5%8E%9F%E7%90%86%E4%BA%86%2F</url>
    <content type="text"><![CDATA[出处：转载自微信公众号：Hollis（ID：hollischuang） HTTPS（Hypertext Transfer Protocol Secure，超文本传输安全协议），是以安全为目标的 HTTP 通道，简单讲是 HTTP 的安全版。本文，就来深入介绍下其原理。 为什么需要 HTTPS使用 HTPPS 的原因其实很简单，就是因为 HTTP 的不安全。 当我们往服务器发送比较隐私的数据（比如说你的银行卡，身份证）时，如果使用 HTTP 进行通信。那么安全性将得不到保障。 首先数据在传输的过程中，数据可能被中间人抓包拿到，那么数据就会被中间人窃取。 其次数据被中间人拿到后，中间人可能对数据进行修改或者替换，然后发往服务器。 最后服务器收到数据后，也无法确定数据有没有被修改或替换，当然，如果服务器也无法判断数据就真的是来源于客户端。 总结下来，HTTP 存在三个弊端： 无法保证消息的保密性 无法保证消息的完整性和准确性 无法保证消息来源的可靠性 HTTPS 就是为了解决上述问题应运而生的。 HTTPS 基本概念为了解决 HTTP 中存在的问题，HTTPS 采用了一些加解密，数字证书，数字签名的技术来实现。下面先介绍一下这些技术的基本概念。 对称加密与非对称加密为了保证消息的保密性，就需要用到加密和解密。加解密算法目前主流的分为对称加密和非对称加密。 ①对称加密（共享密匙加密）：客户端和服务器公用一个密匙用来对消息加解密，这种方式称为对称加密。 客户端和服务器约定好一个加密的密匙。客户端在发消息前用该密匙对消息加密，发送给服务器后，服务器再用该密匙进行解密拿到消息。 对称加密的优点：对称加密解决了 HTTP 中消息保密性的问题。 对称加密的缺点：对称加密虽然保证了消息保密性，但是因为客户端和服务器共享一个密匙，这样就使得密匙特别容易泄露。因为密匙泄露风险较高，所以很难保证消息来源的可靠性、消息的完整性和准确性。 ②非对称加密（公有密匙加密）：既然对称加密中，密匙那么容易泄露，那么我们可以采用一种非对称加密的方式来解决。 采用非对称加密时，客户端和服务端均拥有一个公有密匙和一个私有密匙。公有密匙可以对外暴露，而私有密匙只有自己可见。 使用公有密匙加密的消息，只有对应的私有密匙才能解开。反过来，使用私有密匙加密的消息，只有公有密匙才能解开。 这样客户端在发送消息前，先用服务器的公匙对消息进行加密，服务器收到后再用自己的私匙进行解密。 非对称加密的优点： 非对称加密采用公有密匙和私有密匙的方式，解决了 HTTP 中消息保密性问题，而且使得私有密匙泄露的风险降低。 因为公匙加密的消息只有对应的私匙才能解开，所以较大程度上保证了消息的来源性以及消息的准确性和完整性。 非对称加密的缺点： 非对称加密时需要使用到接收方的公匙对消息进行加密，但是公匙不是保密的，任何人都可以拿到，中间人也可以。那么中间人可以做两件事，第一件是中间人可以在客户端与服务器交换公匙的时候，将客户端的公匙替换成自己的。这样服务器拿到的公匙将不是客户端的，而是服务器的。服务器也无法判断公匙来源的正确性。第二件是中间人可以不替换公匙，但是他可以截获客户端发来的消息，然后篡改，然后用服务器的公匙加密再发往服务器，服务器将收到错误的消息。 非对称加密的性能相对对称加密来说会慢上几倍甚至几百倍，比较消耗系统资源。正是因为如此，HTTPS 将两种加密结合了起来。 数字证书与数字签名为了解决非对称加密中公匙来源的不安全性。我们可以使用数字证书和数字签名来解决。 ①数字证书的申请 在现实中，有一些专门的权威机构用来颁发数字证书，我们称这些机构为认证中心（CA，Certificate Authority）。 我们（服务器）可以向这些 CA 来申请数字证书。申请的过程大致是：自己本地先生成一对密匙，然后拿着自己的公匙以及其他信息（比如说企业名称啊什么的）去 CA 申请数字证书。 CA 在拿到这些信息后，会选择一种单向 Hash 算法（比如说常见的 MD5）对这些信息进行加密，加密之后的东西我们称之为摘要。 单向 Hash 算法有一种特点就是单向不可逆的，只要原始内容有一点变化，加密后的数据都将会是千差万别（当然也有很小的可能性会重复，有兴趣的小伙伴了解一下鸽巢原理），这样就防止了信息被篡改。 生成摘要后还不算完，CA 还会用自己的私匙对摘要进行加密，摘要加密后的数据我们称之为数字签名。 最后，CA 将会把我们的申请信息（包含服务器的公匙）和数字签名整合在一起，由此而生成数字证书。然后 CA 将数字证书传递给我们。 ②数字证书怎么起作用 服务器在获取到数字证书后，服务器会将数字证书发送给客户端，客户端就需要用 CA 的公匙解密数字证书并验证数字证书的合法性。 那我们如何能拿到 CA 的公匙呢？我们的电脑和浏览器中已经内置了一部分权威机构的根证书，这些根证书中包含了 CA 的公匙。 之所以是根证书，是因为现实生活中，认证中心是分层级的，也就是说有顶级认证中心，也有下面的各个子级的认证中心，是一个树状结构，计算机中内置的是最顶级机构的根证书，不过不用担心，根证书的公匙在子级也是适用的。 客户端用 CA 的公匙解密数字证书，如果解密成功则说明证书来源于合法的认证机构。解密成功后，客户端就拿到了摘要。 此时，客户端会按照和 CA 一样的 Hash 算法将申请信息生成一份摘要，并和解密出来的那份做对比，如果相同则说明内容完整，没有被篡改。 最后，客户端安全的从证书中拿到服务器的公匙就可以和服务器进行安全的非对称加密通信了。服务器想获得客户端的公匙也可以通过相同方式。 下图用图解的方式说明一般的证书申请及其使用过程： HTTPS 原理通过上面的学习，我们了解了对称加密与非对称加密的特点和优缺点，以及数字证书的作用。 HTTPS 没有采用单一的技术去实现，而是根据他们的特点，充分的将这些技术整合进去，以达到性能与安全最大化。 这套整合的技术我们称之为 SSL（Secure Scoket Layer，安全套接层）。所以 HTTPS 并非是一项新的协议，它只是在 HTTP 上披了一层加密的外壳。 HTTPS 的建立，先看一下流程图： 这里把 HTTPS 建立到断开分为 6 个阶段，12 个过程。下面将对 12 个过程一 一做解释： 客户端通过发送 Client Hello 报文开始 SSL 通信。报文中包含客户端支持的 SSL 的指定版本、加密组件（Cipher Suite）列表（所使用的加密算法及密匙长度等）。 服务器可进行 SSL 通信时，会以 Server Hello 报文作为应答。和客户端一样，在报文中包含 SSL 版本以及加密组件。服务器的加密组件内容是从接收到的客户端加密组件内筛选出来的。 服务器发送证书报文。报文中包含公开密匙证书。 最后服务器发送 Server Hello Done 报文通知客户端，最初阶段的 SSL 握手协商部分结束。 SSL 第一次握手结束之后，客户端以 Client Key Exchange 报文作为回应。报文包含通信加密中使用的一种被称为 Pre-master secret 的随机密码串。该报文已用步骤 3 中的公开密匙进行加密。 接着客户端继续发送 Change Cipher Spec 报文。该报文会提示服务器，在此报文之后的通信会采用 Pre-master secret 密匙加密。 客户端发送 Finished 报文。该报文包含连接至今全部报文的整体校验值。这次握手协商是否能够成功，要以服务器是否能够正确解密该报文作为判定标准。 服务器同样发送 Change Cipher Spec 报文。 服务器同样发送 Finished 报文。 服务器和客户端的 Finished 报文交换完毕之后，SSL 连接就算建立完成。当然，通信会受到 SSL 的保护。从此处开始进行应用层协议的通信，即发送 HTTP 请求。 应用层协议通信，即发送 HTTP 响应。 最后由客户端断开连接。断开连接时，发送 close_notify 报文。上图做了一些省略，这步之后再发送 TCP FIN 报文来关闭与 TCP 的通信。 另外，在以上流程图中，应用层发送数据时会附加一种叫做 MAC（Message Authentication Code）的报文摘要。MAC 能够查知报文是否遭到篡改，从而保证报文的完整性。 下面再用图解来形象的说明一下，此图比上面数字证书的图更加的详细一些（图片来源于《图解 HTTP》）： 经过上面的介绍，我们可以看出 HTTPS 先是利用数字证书保证服务器端的公匙可以安全无误的到达客户端。 然后再用非对称加密安全的传递共享密匙，最后用共享密匙安全的交换数据。 HTTPS 的使用HTTPS 那么的安全，是不是我们在什么场景下都要去使用 HTTPS 进行通信呢？答案是否定的。 ①HTTPS 虽然提供了消息安全传输的通道，但是每次消息的加解密十分耗时，消耗系统资源。 所以，除非在一些对安全性比较高的场景下，比如银行系统，购物系统中我们必须要使用 HTTPS 进行通信，其他一些对安全性要求不高的场景，我们其实没必要使用 HTTPS。 ②使用 HTTPS 需要使用到数字证书，但是一般权威机构颁发的数字证书都是收费的，而且价格也是不菲的。 所以对于一些个人网站来讲，如果对安全性要求不高，也没必要使用 HTTPS。 作者：安静的boy编辑：陶家龙、孙淑娟出处：转载自微信公众号：Hollis（ID：hollischuang）]]></content>
      <tags>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenSSL]]></title>
    <url>%2F2016%2F03%2F05%2F170135-OpenSSL%2F</url>
    <content type="text"><![CDATA[SSLSecure Sockets Layer 安全套接层，及其继任者传输层安全（Transport Layer Security，TLS）是为网络通信提供安全及数据完整性的一种安全协议。TLS与SSL在传输层对网络连接进行加密 服务功能 认证用户和服务器，确保数据发送到正确的客户机和服务器 保证数据的机密性，防止数据中途被窃取 维护数据的完整性，确保数据在传输过程中不被篡改 服务器类型 Tomcat 5.x Nginx IIS Apache 2.x IBM HTTP SERVER 6.0[1] 工作流程服务器认证阶段 客户端向服务器发送一个开始信息“Hello”以便开始一个新的会话连接 服务器根据客户的信息确定是否需要生成新的主密钥，如需要则服务器在响应客户的“Hello”信息时将包含生成主密钥所需的信息 客户根据收到的服务器响应信息，产生一个主密钥，并用服务器的公开密钥加密后传给服务器 服务器回复该主密钥，并返回给客户一个用主密钥认证的信息，以此让客户认证服务器 用户认证阶段 在此之前，服务器已经通过了客户认证 经认证的服务器发送一个提问给客户，客户则返回（数字）签名后的提问和其公开密钥，从而向服务器提供认证 OpenSSLOpenSSL 是一个安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及 SSL 协议，并提供丰富的应用程序供测试或其它目的使用。他是SSL的开源实现 库文件 libcrypto：通用加密库 libssl：TLS/SSL的实现，基于回话的实现了身份认证，数据机密性和回话完整性的库文件 命令和选项openssl 是 Linux 下一个多功能命令行工具，可以实现私有证书颁发机构 常用选项 12345-a # 对加密后的数据进行base64编码，或解密前先对数据进行base64解码-des3 # 加密算法，自己根据需要来指定-salt # 加盐，加盐后相同的明文可以得到不同的密文-in # 要读取的文件-out # 要输出的文件 常用子命令 12345678910111213141516171819202122232425262728openssl ? # 获得子命令openssl version # 获得版本号openssl speed # 测试所有算法在本机的加密速度openssl speed des # 测试des加密在本机的性能openssl enc -des3 -salt -a -in install.log -out install.des3# 使用des3加密文件openssl enc -des3 -salt -d -in a.des3 -out a.t# 使用des3解密文件openssl dgst -sha1 a.t# 计算文件的校验码md5sum a.t # 计算文件的校验码sha1sum a.t # 计算文件的校验码openssl passwd -1 -salt QAZXsw2 # 为用户生成密码串openssl rand -base64 100# 生成随机字符openssl genrsa# 生成一个私钥，默认为512位openssl genrsa 2048# 生成一个2048位的私钥]]></content>
      <tags>
        <tag>Security</tag>
        <tag>OpenSSL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加密技术和算法]]></title>
    <url>%2F2016%2F03%2F01%2F112123-%E5%8A%A0%E5%AF%86%E6%8A%80%E6%9C%AF%E5%92%8C%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[TCP/IP 安全因素 数据机密性 保证数据密文传输，不能被中间人破解数据读取到真实内容 常见的不机密通信：ftp、http、smtp、telnet。这些协议的通信过程中都是明文传输，无法保证数据的机密性。 数据完整性 数据是否被篡改：不能让入侵者使用假数据代替合法数据，否则数据将丧失完整性。 身份验证 验证身份的真实性，防止非法者冒充。 加密技术及算法对称加密加密（encryption）与解密（decryption）使用的是同样的密钥（secret key），密码学中叫对称加密算法。这种加密算法可以保证数据的机密性，如果想要解密，必须事先知道加密密钥，否则无法解密 算法 常用的算法有：DES、3DES、TDEA、Blowfish、RC2、RC4、RC5、IDEA、SKIPJACK、AES等。 优势 算法公开、计算量小、加密速度快、加密效率高 缺点 在数据传送前，发送方和接收方必须商定好密钥，然后使双方都必须能保存好密钥 双方使用同样的密钥，安全性无法得到保证。若一方的密钥被泄露，那么加密信息就不安全 每对用户每次使用对称加密算法时，都需要使用其他人不知道的唯一密钥，这使得收、发双方所拥有的钥匙数量巨大，密钥管理成为双方的负担 单向加密单向加密是一种不可逆的加密，在加密过程中不使用密钥，明文数据由系统加密算法处理成密文，并且密文无法解密。单向加密主要是提取数据的指纹及特征码，用于校验数据是否被修改，以此来保证数据的完整性 特征 输入一样，输出必然一样 雪崩效应：输入的一点改变，将引起结果的巨大改变，常用于防暴力破解 定长输出：无论输入的长度多长，输出的结果都一样长 不可逆：无法根据特征码还原出数据 无法进行身份验证和保证数据的机密性 算法 MD4 信息摘要算法，由于有漏洞被淘汰 MD5 message-digest algorithm 5（信息-摘要算法），输出结果固定长度128bit SHA1：secure hash algorithm（安全散列算法）, 输出结果固定长度160bit SHA192，SHA256，SHA384 CRC-32 不加密，只提供校验功能 基本实现过程 发送方为 Tom， 接收方为 Jerry Tom 为了防止明文数据 Data 被其他人篡改，对数据使用单向加密算法，计算得到数据的特征码 A Tom 将数据 Data 和特征码 A 一起发送给 Jerry Jerry 收到数据 Data 和特征码 A ，对数据 Data 使用相同的单向加密算法计算出一个特征码 B 如果特征码 A 和 B 相同，则说明数据没有被修改，是完整的；否则数据被篡改，丧失了完整性 遗留的安全问题 如果 Tom 在传递数据 Data 给 Jerry 的过程中时，遭到中间人攻击，导致数据都被中间人截获 中间人冒充 Tom，对数据 Data 也进行单向加密算法，计算出特征码 C，再将 Data 和特征码 C 一起发送给 Jerry Jerry 收到数据后对其进行单向加密算法，此时计算出的特征码和 C 一样。虽然特征码是相同的，但这并不是真实的 Tom 发来的数据 接收方最终无法判断数据的来源，陷入身份验证的困境，因此引入了密钥交换 密钥交换 互联网密钥交换：Internet Key Exchange，简称IKE，基于Diffie-Hellman协议协商生成密码。 实现双方使眼色交换密钥，而且密钥本身不在互联网上传播 IKE大致实现原理 Tom 和 Jerry 协商选择两个数字：P，g（大素数，生成器数） Tom 在本机随机选择一个数字 x， Jerry 在本机随机选择一个数字 y x 只有 Tom 知道，y 只有 Jerry 知道，且 x 和 y 不在互联网传输 Tom 将 g^x%P 计算结果 R-tom 发送给 Jerry Jerry 将 g^y%P 计算结果 R-jerry 发送给 Tom 互联网中的用户能看到的数字有四个：P，g，R-tom，R-jerry 由于离散对数的原理，根据暴露的4个数字几乎不可能推算出 x 和 y 的值 Tom 对 R-jerry 取x次方：(g^y%P)^x=g^yx%P Jerry 对 R-tom 取y次方：(g^x%P)^y=g^xy%P 二者结果相同进而生成密钥，密钥交换问题解决 身份验证的安全隐患 Tom 和 Jerry 已经事先约定好数字后传输不需再次事先商定数字 P 和 g ，每次发送数据只需都进行一次计算，进行一次密钥交换即可，因此保证了身份验证。但是，如果 Tom 和 Jerry 从未见过面，第一次进行传输时，在商定数字的过程中遭到中间人攻击，则来源身份就可能被冒充，Jerry 又再次陷入身份验证的僵局。要完成用户的身份验证，就需要使用非对称加密 非对称加密非对称加密也叫公钥加密。公钥与私钥是一对，如果用公钥对数据进行加密，只有用对应的私钥才能解密；如果用私钥对数据进行加密，那么只有用对应的公钥才能解密。因为加密和解密使用的是两个不同的密钥，所以叫作非对称加密，也可以叫双钥加密。 密钥对 私钥：private key，只能用与之对应的公钥解密，不公开 公钥：public key，从私钥中抽出的一段特征，只能用与之对应的私钥解密，公开，所有人都能看到 Tom 用 Jerry 的公钥加密数据，传输后的数据只有 Jerry 用自己的私钥才能解开，以此保证了数据的机密性 Tom 用自己的私钥加密数据，私钥只有 Tom 自己知道，只要 Jerry 用 Tom 的公钥能解密数据就说明是由 Tom 加密的，以此保证了身份验证 密钥对的原则 一个公钥对应一个私钥 让大家都知道的是公钥，不告诉大家只有自己知道的是私钥 如果用其中一个密钥加密数据，则只有对应的那个密钥才可以解密 如果用其中一个密钥可以进行解密数据，则该数据必然是对应的那个密钥进行的加密 非对称密钥的主要应用就是公钥加密和公钥认证，而公钥加密的过程和公钥认证的过程是不一样的 基本工作原理 A 给 B 发送数据在通信前，双方事先产生一对用于自己加密和解密的公钥和私钥。A的私钥保密，公钥公开；B 的私钥保密，公钥发送给 A 为了保证数据完整性，使用单向加密算法计算出数据的特征码。将特征码附着在数据后发送给 B 中间人 C 获取数据后，使用 A 的公钥解密得到了特征码 对数据进行篡改后，使用单向加密算法算出来的特征码无法还原成 A 计算出的特征码 为了保证身份验证，防止特征码被中间人冒充，A 使用自己的私钥对特征码进行加密 中间人 C 截获数据后(即便无任何修改)，使用自己的私钥对 A 计算的特征码加密，冒充 A 将截获的数据及自己私钥加密后的特征码发送给 B B 收到 C（冒充A）发来的数据，此时仍然认为发送方是 A 接着 B 使用 A 的公钥却无法解密冒充者 C 私钥加密的特征码，此时 B 就已经知道数据并不是 A 发的那一份，而是假的 为了保证数据的机密性，A 使用 B 的公钥对所有数据加密 B 在收到数据后，使用自己的私钥解密所有数据 使用 A 的公钥成功解密得到了特征码，则验证了 A 的身份 只有 A 私钥加密的数据发过来才能用 A 的公钥解密。因为 A 的私钥只有 A 一个人有 使用单向加密算法计算数据的特征码，与发送过来解密后的特征码作比较，如果相同则说明数据完好无损 用自己的私钥解密 A 使用 B 的公钥加密后发送过来的数据。其他人都无法解密，因为只有 B 才有自己的私钥，这就保证了数据的机密性 加密算法 RSA：可进行数据加密、解密、签名 1234567891011openssl genrsa -out private.key 1024# 生成一个私钥，输出到文件 private.key 中，密钥长度为1024bitopenssl rsa -in private.key -pubout -out pub.key# 通过密钥文件 private.key 提取公钥，输出到文件 pub.key echo -n "123456" | openssl rsautl -encrypt -inkey pub.key -pubin &gt; encode.result# 使用公钥加密信息 cat encode.result | openssl rsautl -decrypt -inkey private.key # 使用私钥解密信息 DSA：只能用于数字签名及其认证。在 DSA 数字签名和认证中，发送者使用自己的私钥对文件或消息进行签名，接受者收到消息后使用发送者的公钥来验证签名的真实性。DSA 算法和 RSA 不同之处在于它不能用作加密和解密，也不能进行密钥交换，只用于签名，因此速度比 RSA 要快很多 12345678910111213openssl dsaparam -out dsaparam.pem 1024openssl gendsa -out privkey.pem dsaparam.pem# 生成一个密钥(私钥)openssl dsa -in privkey.pem -out pubkey.pem -puboutrm -fr dsaparam.pem # 生成公钥 echo -n "123456" | openssl dgst -dss1 -sign privkey.pem &gt; sign.result# 使用私钥签名echo -n "123456" | openssl dgst -dss1 -verify pubkey.pem -signature sign.result# 使用公钥验证 特点 非对称加密速度慢，比对称加密慢3个数量级1000倍（一个数量级：10倍） 一般不用于加密大量数据，主要用于实现用户认证和帐号信息加密 下面是在 ssh 一个之前从未 ssh 过的主机时的提示信息，其中就有 RSA 相关的指纹信息提示： 12345[root@study ~]$ ssh 10.131.235.14The authenticity of host '[10.131.235.14]:22 ([10.131.235.14]:22)' can't be established.RSA key fingerprint is SHA256:+QKvM9/2/CtcpyCh4krEUVnO3pSzRs3PEHjp13+zlVc.RSA key fingerprint is MD5:a6:29:fa:84:22:8e:17:8c:8a:53:af:4d:11:2a:59:3c.Are you sure you want to continue connecting (yes/no)? 公钥验证在非对称加密体系中，公钥用来加密信息，私钥用来数字签名 在互联网任何人都可以生成自己的（公钥，私钥）对，所以为了防止有人散布伪造的公钥骗取信任，就需要一个可靠的第三方机构来生成经过认证的（公钥，私钥）对。双方在通信时都出示证件，这个证件由某个权威机构发放，只要验证证件内的有效信息就可以验证对方的身份。 目前，世界上最主要的数字服务认证商是位于美国加州的 Verisign 公司，它的主要业务就是分发 RSA 数字证书。为了防止在发证的时候出现中间人现欺骗，一些操作系统在安装时就已经将一些权威的发证机构的证书放在系统里了 数字证书认证 CA(Certficate Authority)，数字证书认证中心，是整个网上电子交易安全的关键环节。它主要负责产生、分配并管理所有参与网上交易的实体所需的身份认证数字证书 PKI：Public Key Infrastructure（公钥基础设施）。提供公钥加密和数字签名服务的系统或平台，目的是为了管理密钥和证书 为了验证公钥发送方的合法性，因此有了证书颁发机构（要自己事先为自己颁发一个证书） 证书的格式：X509，PKCS 证书吊销列表：CRL(Certificate Revocation List) 基本的三重验证假设 A 和 B 彼此间是可靠的彼此认证的通信。即 A 和 B 通过 CA 机构颁发的证书彼此认可对方的公钥。 A 给 B 发送数据在通信前，双方事先产生一对用于自己加密和解密的公钥和私钥。A的私钥保密，公钥公开；B 的私钥保密，公钥发送给 A A 和 B 基于 DH 协议，互相协商后生成两个数字（P，g） 为了保证数据的完整性，使用单向加密算法得到数据的特征码，将特征码附着在数据后 为了保证身份验证，防止特征码被中间人冒充，A 使用自己的私钥对特征码进行加密 为了保证数据的机密性，A 在本机生成一段随机数字(x)当作解开所有数据的对称密码，对数据加密，这个密码发送前只有 A 知道 A 使用 B 的公钥将对称密码加密，将加密的数据、对称密码发送给 B B收到数据后 使用自己的私钥解密数据，得到了 A 的对称密码和对称密码加密的数据。使用 A 的对称密码解密数据。保证了数据机密性。中间人即便获得数据也无法解开对称密码，因为对称密码使用的是B的公钥加密，只有 B 的私钥才能解开，对称密码加密后的数据及特征码也无从得知 接着 B 使用 A 的公钥解密得到（A 私钥加密的）特征码。如果能解密成功，则 A 的身份得到验证 使用单向加密算法计算数据的特征码与解密得到的特征码作比较，如果相同则说明数据完好无损]]></content>
      <tags>
        <tag>Security</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux生成随机数的多种方法]]></title>
    <url>%2F2015%2F11%2F27%2F110119-Linux%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E6%95%B0%E7%9A%84%E5%A4%9A%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[通过内部系统变量 $RANDOM 123[user1@study ~]$ echo $RANDOM12489[user1@study ~]$ 如果超过 5 位可以加个固定 10 位整数，然后进行求余。生成 400000~500000 的随机数： 12345678910111213141516#!/bin/bash function rand()&#123; min=$1 max=$(($2-$min+1)) # 生成0-32767之间的整数随机数 # num=$(echo $RANDOM) # 若要生成5位数以上的随机数，则需要加个固定10位整数，然后进行求余，如下： num=$(($RANDOM+1000000000)) #增加一个10位的数再求余 echo $(($num%$max+$min)) &#125; rnd=$(rand 300000 600000) echo $rnd exit 0 使用 awk 命令的随机函数 123[user1@study ~]$ awk 'BEGIN&#123;srand();print rand()*1000000&#125;' 779019[user1@study ~]$ 1awk 'function irand(min, max)&#123;max= max - min + 1;num= rand() * 1000000000;return int(num % max + min);&#125;!a[$1]++&#123;print $1,irand(1,30) &#125;' filename 使用 openssl 命令产生随机数 openssl rand 用于产生指定长度个bytes的随机字符。-base64或-hex对随机字符串进行base64编码或用hex格式显示。 123456[user1@study ~]$ openssl rand -base64 8 | md5sum | cut -c1-8 # 八位字母和数字的组合5f8aa9c1[user1@study ~]$ [user1@study ~]$ openssl rand -base64 8 | cksum | cut -c1-8 # 八位数字25627052[user1@study ~]$ 通过 date 从时间获得随机数 12345678[user1@study ~]$ date +%s%N # 生成19位数字1437297460176572314[user1@study ~]$ [user1@study ~]$ date +%s%N | cut -c6-13 # 取八位数字97471199[user1@study ~]$ [user1@study ~]$ date +%s%N | md5sum | head -c 8 # 八位字母和数字的组合68b50c31[user1@study ~]$ 生成 1~50 的随机数 12345678910111213#!/bin/bash function rand()&#123; min=$1 max=$(($2-$min+1)) num=$(date +%s%N) echo $(($num%$max+$min)) &#125; rnd=$(rand 1 50) echo $rnd exit 0 通过系统内唯一数据生成随机数 /dev/random 存储系统当前运行的环境的实时数据，可以看作系统某时候的唯一值数据，提供优质随机数。 /dev/urandom 是非阻塞的随机数产生器，读取时不会产生阻塞，速度更快、安全性较差的随机数发生器。 123[user1@study ~]$ head -n 10 /dev/urandom | md5sum | head -c 1096fac9b325[user1@study ~]$ [user1@study ~]$ 生成全字符的随机字符串 123[user1@study ~]$ strings -n 8 /dev/urandom | head -n 1ayU!iwR?[user1@study ~]$ 生成数字加字母的随机字符串，其中 strings -n 设置字符串的字符数，head -n 设置输出的行数。 123[user1@study ~]$ sed -e 's/[^a-zA-Z0-9]//g' /dev/urandom | strings -n 8 | head -n 1DwNJNIp4Ff[user1@study ~]$ urandom 的数据很多使用 cat 会比较慢，可以使用 head 读200行，再用 cksum 将读取文件内容生成唯一的表示整型数据，cut 以 &quot; &quot; 分割然后得到分割的第一个字段数据 1234[user1@study ~]$ head -200 /dev/urandom| cksum |cut -d" " -f1 2185818[user1@study ~]$ 读取 Linux的 uuid UUID码全称是通用唯一识别码 (Universally Unique Identifier, UUID)。它格式是：包含32个16进制数字，以“-”连接号分为五段，形式为8-4-4-4-12的32个字符。 Linux的UUID码也是由内核提供的，在 /proc/sys/kernel/random/uuid 这个文件内。每次查看此文件结果都会不同。 123[user1@study ~]$ cat /proc/sys/kernel/random/uuid bd777e6e-820e-443b-83d9-b8fc8ba65de8[user1@study ~]$ 获取不同的随机整数 123[user1@study ~]$ cat /proc/sys/kernel/random/uuid| cksum | cut -f1 -d" " 428476922[user1@study ~]$ 使用 uuid 生成 100~500 随机数 12345678910111213#!/bin/bash function rand()&#123; min=$1 max=$(($2-$min+1)) num=$(cat /proc/sys/kernel/random/uuid | cksum | awk -F ' ' '&#123;print $1&#125;') echo $(($num%$max+$min)) &#125; rnd=$(rand 100 500) echo $rnd exit 0 从元素池中随机抽取取 123pool=(a b c d e f g h i j k l m n o p q r s t 1 2 3 4 5 6 7 8 9 10)num=$&#123;#pool[*]&#125;result=$&#123;pool[$((RANDOM%num))]&#125; 用于生成一段特定长度的有数字和字母组成的字符串，字符串中元素来自自定义的池子。 12345678910111213141516171819#!/bin/bash length=8 i=1 seq=(0 1 2 3 4 5 6 7 8 9 a b c d e f g h i j k l m n o p q r s t u v w x y z A B C D E F G H I J K L M N O P Q R S T U V W X Y Z) num_seq=$&#123;#seq[@]&#125; while [ "$i" -le "$length" ];do seqrand[$i]=$&#123;seq[$((RANDOM%num_seq))]&#125; let "i=i+1" done echo "The random string is: " for j in $&#123;seqrand[@]&#125;;do echo -n $j done echo 使用 mkpasswd 命令 需要安装 expect 123[user1@study ~]$ mkpasswd #FldwzX55[user1@study ~]$ 生成 13 位的密码 123[user1@study ~]$ mkpasswd -l 13 3E&quot;pmkxnm3itP[user1@study ~]$]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Miscellaneous</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux查看操作系统位数的几种方法]]></title>
    <url>%2F2015%2F11%2F26%2F210111-Linux%E6%9F%A5%E7%9C%8B%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%BD%8D%E6%95%B0%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[getconf 命令 123[user1@study ~]$ getconf LONG_BIT64[user1@study ~]$ 内置系统环境变量 HOSTTYPE 123[user1@study ~]$ echo $&#123;HOSTTYPE&#125; x86_64[user1@study ~]$ x86_64 表示 64 位系统， i686 、i386 表示 32 位系统，i686 只是 i386 的一个子集，支持的 CPU 从 Pentium 2 (686)开始，之前的型号不支持。 123[user1@study ~]$ uname -mx86_64[user1@study ~]$ arch 命令 123[user1@study ~]$ arch x86_64[user1@study ~]$ file 命令 123[user1@study ~]$ file /bin/ls/bin/ls: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.32, BuildID[sha1]=c5ad78cfc1de12b9bb6829207cececb990b3e987, stripped[user1@study ~]$ 查看CPU信息可确定是否支持64bit计算，lm ： long mode，如果能搜索到则说明支持，否则不支持 1[user1@study ~]$ egrep '^flags.*\&lt;lm\&gt;' /proc/cpuinfo]]></content>
      <tags>
        <tag>Miscellaneous</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用safe-rm避免rm命令误删文件]]></title>
    <url>%2F2015%2F11%2F25%2F172103-%E4%BD%BF%E7%94%A8safe-rm%E9%81%BF%E5%85%8Drm%E5%91%BD%E4%BB%A4%E8%AF%AF%E5%88%A0%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[前言在Linux系统下，超级用户如果使用 rm -rf / ，那就相当于系统自杀，会造成业务灾难。 根据最新的POSIX.1-2008标准，rm -fr / 命令是不会被执行的，而是应该打印错误信息。但是老的POSIX.1-2004标准则无此定义，那么这个有什么意义呢？在Linux中，我们所使用的 rm、touch、mkdir、cp、mv 等命令都是由 coreutils 这个核心工具提供的，coreutils 5.2 稳定版于2004年2月19日发布，而现在 coreutils 工具在 CentOS6 上都已经是8.22版本了（CentOS7 是8.4版本，Debian8 是8.23版本）。只有你的 coreutils的版本足够高（5.2版本以上），才可以”安全地”使用 rm -fr / 这个指令，老版本的rm还是存在此问题的。 以下是针对CentOS6和CentOS7的验证 123456789[root@CentOS-6.8 ~]# uname -r2.6.32-642.el6.x86_64[root@CentOS-6.8 ~]# rpm -qi coreutils | grep -i versionVersion : 8.4 Vendor: CentOS[root@CentOS-6.8 ~]# [root@CentOS-6.8 ~]# rm -fr /rm: it is dangerous to operate recursively on `/'rm: use --no-preserve-root to override this failsafe 1234567[root@CentOS7 ~]# uname -r4.14.14-1.el7.elrepo.x86_64[root@CentOS7 ~]# rpm -qi coreutils | grep -i versionVersion : 8.22[root@CentOS7 ~]# rm -fr /rm: it is dangerous to operate recursively on ‘/’rm: use --no-preserve-root to override this failsafe 提示的意思是 12rm: 在"/" 进行递归操作十分危险rm: 使用 --no-preserve-root 选项跳过安全模式 即便是这样，也无法避免重要文件被误删的情况，因为 root 用户是有绝对权限的。很多系统正常运行要依赖各种各样的文件，一旦其中任意一个文件被误删将会造成严重的影响，最明显的表现是各种命令无法正常使用，系统服务无法正常运行 为了避免种误删除操作，我们可以尝试很多办法，回收站机制、给重要目录设置权限、替换 rm 命令等；再做过这些尝试后，个人认为替换 rm 命令比较简单直接，用safe-rm 来替换 rm 便可以满足大部分需求 safe-rm及安装safe-rm 是一个开源软件用来替代不太安全的rm，可以在/etc/safe-rm.conf中配置路径黑名单，定义哪些不能被safe-rm删除。将safe-rm 更名为 rm 并放在 $PATH 中比 原rm 程序靠前的位置。一些脚本中使用完全路径/bin/rm则不会受此影响。 safe-rm 的主页：https://launchpad.net/safe-rm 下载Safe-rm 软件包，解压后会得到一个 safe-rm 可执行文件，将这个文件拷贝到系统的二进制可执行程序目录下，但是要保证这个路径在rm命令路径前面 1234567891011121314[root@CentOS7 ~]# wget https://launchpad.net/safe-rm/trunk/0.12/+download/safe-rm-0.12.tar.gz[root@CentOS7 ~]# ar xf safe-rm-0.12.tar.gz cd safe-rm-0.12[root@CentOS7 safe-rm-0.12] # echo $PATH/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/netpas/bin[root@CentOS7 safe-rm-0.12] # [root@CentOS7 safe-rm-0.12] # which rmalias rm='rm -i' /usr/bin/rm[root@CentOS7 safe-rm-0.12] # cp -a safe-rm /usr/local/sbin/ [root@CentOS7 safe-rm-0.12] # ln -sv /usr/local/sbin/safe-rm /usr/local/sbin/rm‘/usr/local/sbin/rm’ -&gt; ‘/usr/local/sbin/safe-rm’[root@CentOS7 safe-rm-0.12] # safe-rm的配置safe-rm 命令使用两个配置文件，全局配置 /etc/safe-rm.conf 和用户配置 ~/.safe-rm。配置的时候只需要将重要文件或者目录的完整路径输入进去就可以了，每条以回车分隔。例如： 1/test 注意： 这样写可以避免 test 目录被删除，但无法避免 test 目录下的文件被删除 12/test/test/* 注意： 这样写可以避免 test 目录和 test 目录下的普通文件被删除，但无法避免 test 目录下链接文件被删除。所以像 /lib 或 /lib64 这种目录，下面会有很多对库文件的链接文件，使用safe-rm并不能保护文件。 建议： 作为运维人员，应当严格要求自己，养成良好的维护、操作、及时备份的习惯]]></content>
      <tags>
        <tag>Miscellaneous</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下socks5搭建和应用]]></title>
    <url>%2F2015%2F11%2F24%2F210143-Linux%E4%B8%8Bsocks5%E6%90%AD%E5%BB%BA%E5%92%8C%E5%BA%94%E7%94%A8%2F</url>
    <content type="text"><![CDATA[socks介绍 SOCKS：防火墙安全会话转换协议 （Socks: Protocol for sessions traversal across firewall securely） SOCKS 协议提供一个框架，为在 TCP 和 UDP 域中的客户机/服务器应用程序能更方便安全地使用网络防火墙所提供的服务。 这个协议从概念上来讲是介于应用层和传输层之间的 “中介层（shim-layer）”，因而不提供如传递 ICMP 信息之类的网络层网关服务。 SOCKS5 是一个代理协议，它在使用TCP/IP协议通讯的前端机器和服务器机器之间扮演一个中介角色，使得内部网中的前端机器变得能够访问Internet网中的服务器，或者使通讯更加安全。 SOCKS5 服务器通过将前端发来的请求转发给真正的目标服务器， 模拟了一个前端的行为。在这里，前端和SOCKS5之间也是通过TCP/IP协议进行通讯，前端将原本要发送给真正服务器的请求发送给SOCKS5服务器，然后SOCKS5服务器将请求转发给真正的服务器。 安装socks5 解决依赖关系 1yum -y install pam-devel openldap-devel openssl-devel 编译安装 12345wget https://nchc.dl.sourceforge.net/project/ss5/ss5/3.8.9-8/ss5-3.8.9-8.tar.gztar xf ss5-3.8.9-8.tar.gz cd ss5-3.8.9/./configuremake &amp;&amp; make install 配置 配置备份 1mv /etc/opt/ss5/ss5.conf&#123;,.bak&#125; 修改认证方式/etc/opt/ss5/ss5.conf默认是无用户认证，需要使用-u 12auth 0.0.0.0/0 - upermit - 0.0.0.0/0 - 0.0.0.0/0 - - - - - 添加用户名密码/etc/opt/ss5/ss5.passwd每行一个 用户 密码，使用空格分隔 12test1 12345test2 56789 修改ss5启动的参数，自定义代理端口 /etc/sysconfig/ss5（如果不设置，默认是1080）此文件ss5启动时会主动加载 12# Add startup option hereSS5_OPTS=" -u root -b 0.0.0.0:10080" 创建服务控制脚本/usr/sbin/ss5_ctl.sh 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#!/bin/bash## chkconfig: 345 20 80# description: This script takes care of starting \# and stopping ss5#OS=`uname -s`if [ $OS = "Linux" ] || [ $OS = "SunOS" ]; then # Source function library. . /etc/rc.d/init.d/functions# Source networking configuration. . /etc/sysconfig/network# Check that networking is up. [ "$&#123;NETWORKING&#125;" = "no" ] &amp;&amp; exit 0 [ -f /usr/sbin/ss5 ] || exit 0fi# Test custom variablestest -f /etc/sysconfig/ss5 &amp;&amp; . /etc/sysconfig/ss5# See how we were called.case "$1" in start) # Start daemon. echo -n "Starting ss5... " if [ $OS = "Linux" ]; then daemon /usr/sbin/ss5 -t $SS5_OPTS touch /var/lock/subsys/ss5 else if [ $OS = "SunOS" ]; then /usr/sbin/ss5 -t touch /var/lock/subsys/ss5 else /usr/local/sbin/ss5 -t fi fi echo "done" ;; stop) # Stop daemon. echo "Shutting down ss5... " if [ $OS = "Linux" ] || [ $OS = "SunOS" ]; then killproc ss5 rm -f /var/lock/subsys/ss5 else killall ss5 fi rm -f /var/run/ss5/ss5.pid echo "done" ;; reload) # Reload configuration if [ $OS = "Linux" ] || [ $OS = "SunOS" ]; then echo -n "Reloading ss5... " killproc ss5 -1 else pkill -HUP ss5 fi echo "done reload" ;; restart) # Restart daemon echo -n "Restarting ss5... " $0 stop $0 start ;; status) if [ $OS = "Linux" ] || [ $OS = "SunOS" ]; then status ss5 fi ;; *) echo "Usage: ss5 &#123; start | stop | status | restart | reload &#125;" exit 1 ;;esacexit 0 服务控制 12ss5_ctl.sh start netstat -tunlp | grep ss5 应用应用场景：办公室使用的是电信网络，运维工程师需要在办公室使用SecureCRT来远程一台配置了移动IP的服务器。由于电信到移动跨运营商导致无法使用SecureCRT直接ssh远程。因此可以使用一台配置了ss5的服务器来做代理。前面已经说明了怎么配置，接下来补充一下SecureCRT如何使用ss5。 添加firewall打开SecureCRT，打开 Options =&gt; Global Options... 对应的session使用firewall，选择要ssh远程的的session，右键单击属性，选择防火墙]]></content>
      <tags>
        <tag>Miscellaneous</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iftop流量监控工具]]></title>
    <url>%2F2015%2F11%2F15%2F210510-iftop%E6%B5%81%E9%87%8F%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[简介iftop 是一款类似于 top 命令的实时流量监控工具，监控 TCP/IP 连接等，缺点就是无报表功能。可以用来监控网卡的实时流量（可以指定网段）、反向解析IP、显示端口信息等。必须以 root 身份才能运行。 安装方法源码包编译安装下载最新的源码包。建议使用网络 yum 源(最好是自带的)，准备编译所需的环境，make、gcc、autoconf 等。安装libpcap 和 libcurses 依赖包 12345678910111213# 安装所需依赖包：yum -y install flex byacc libpcap ncurses ncurses-devel libpcap-devel# 下载源码包wget http://www.ex-parrot.com/~pdw/iftop/download/iftop-0.17.tar.gz# 解压tar zxvf iftop-0.17.tar.gz# 编译安装cd iftop-0.17./configure --prefix=/opt/iftop/make &amp;&amp; make install rpm包安装12345678# 安装所需依赖包yum -y install flex byacc libpcap ncurses ncurses-devel# 下载rpm包wget ftp://fr2.rpmfind.net/linux/dag/redhat/el5/en/i386/dag/RPMS/iftop-0.17-1.el5.rf.i386.rpm# 安装rpm包rpm -ivh iftop-0.17-1.el5.rf.i386.rpm 界面说明 &lt;= 和 =&gt; 是流量的方向 TX：发送流量 RX：接收流量 TOTAL：总流量 Cumm：运行iftop到目前时间的总流量 peak：流量峰值 rates：分别表示过去 2s 10s 40s 的平均流量 参数说明 -i 设定监测的网卡，如：iftop -i eth1 -B 以bytes为单位显示流量(默认是bits) -n 使host信息默认直接都显示IP，如：iftop -n -N 使端口信息默认直接都显示端口号，如: iftop -N -F 显示特定网段的进出流量，如 iftop -F 10.10.1.0/24 或 iftop -F 10.10.1.0/255.255.255.0 -h display this message，帮助，显示参数信息 -p 使用这个参数后，中间的列表显示的本地主机信息，出现了本机以外的IP信息; -b 使流量图形条默认就显示; -f 过滤计算包; -P 使host信息及端口信息默认就都显示; -m 设置界面最上边的刻度的最大值，刻度分五个大段显示，例：iftop -m 100M 操作命令进入 iftop 画面后的操作命令: 按 h 切换是否显示帮助; 按 n 切换显示本机的IP或主机名; 按 s 切换是否显示本机的host信息; 按 d 切换是否显示远端目标主机的host信息; 按 t 切换显示格式为2行/1行/只显示发送流量/只显示接收流量; 按 N 切换显示端口号或端口服务名称; 按 S 切换是否显示本机的端口信息; 按 D 切换是否显示远端目标主机的端口信息; 按 p 切换是否显示端口信息; 按 P 切换暂停/继续显示; 按 b 切换是否显示平均流量图形条; 按 B 切换计算2秒或10秒或40秒内的平均流量; 按 T 切换是否显示每个连接的总流量; 按 l 打开屏幕过滤功能，输入要过滤的字符，比如ip,按回车后，屏幕就只显示这个IP相关的流量信息; 按 L 切换显示画面上边的刻度;刻度不同，流量图形条会有变化; 按 j 或按 k 可以向上或向下滚动屏幕显示的连接记录; 按 1 或 2 或 3 可以根据右侧显示的三列流量数据进行排序; 按 &lt; 根据左边的本机名或IP排序; 按&gt; 根据远端目标主机的主机名或IP排序; 按 o 切换是否固定只显示当前的连接; 按 f 可以编辑过滤代码 按 ! 可以使用shell命令 按 q 退出监控。]]></content>
      <tags>
        <tag>Miscellaneous</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用lrzsz进行Windows与Linux间文件的上传/下载]]></title>
    <url>%2F2015%2F11%2F09%2F090135-%E4%BD%BF%E7%94%A8lrzsz%E8%BF%9B%E8%A1%8CWindows%E4%B8%8ELinux%E9%97%B4%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%8A%E4%BC%A0-%E4%B8%8B%E8%BD%BD%2F</url>
    <content type="text"><![CDATA[简述lrzsz 是一款在 linux 里可代替 ftp 上传和下载的程序，它是一种 unix 通信套件提供的X，Y，和 ZModem 文件传输协议。之前我们基本上都用的 FTP 或 SFTP 来进行 Windows 和 Linux 之间的文件传输，在 Linux 上安装 lrzsz 之后结合 SecureCRT 或 XShell 进行文件传输显得更为方便 安装检查当前系统是否安装 1rpm -q lrzsz 使用 yum 安装 lrzsz 1yum -y install lrzsz 使用文件上传 12rz# 这个命令是 Receive ZMODEM 的简写 文件下载，需要对SecureCRT进行Windows接受文件路径的设置 Options ==&gt; Global Options ==&gt; General ==&gt; Default Session ==&gt; Edit Default Settings... ==&gt; Connection ==&gt; SSH2 ==&gt; SFTP Session ==&gt; Local directory 设置好之后即可执行命令 12sz /path/to/filename# sends one or more files with ZMODEM protocol]]></content>
      <tags>
        <tag>Miscellaneous</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7网卡名称的修改]]></title>
    <url>%2F2015%2F11%2F04%2F094127-CentOS7%E7%BD%91%E5%8D%A1%E5%90%8D%E7%A7%B0%E7%9A%84%E4%BF%AE%E6%94%B9%2F</url>
    <content type="text"><![CDATA[修改udev的rules文件生产环境中，托管于机房的服务器经常会进行割接操作，为了能让网卡更容易让运维人员和机房识别，避免因为弄错网线或找错网卡导致业务中断，在服务器上架前就应该对所有网卡按照 eth0、eth1 的方式来命名，并按照网卡的物理位置贴上标签。在 CentOS7 系统中，默认的网卡命名方式已经不再是 eth0、eth1 的格式了。 一般情况下，板载网卡（目前多数服务器为板载双网卡）的 MAC 地址相差 1，其余网卡则为外接网卡。 使用 ip addr show 命令可以查看一台机器上所有的网卡信息。 123456789101112131415161718[root@m2 ~]# ip addr show 1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN qlen 1 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo inet6 ::1/128 scope host 2: ens32: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:50:56:39:b5:c6 brd ff:ff:ff:ff:ff:ff inet6 fe80::e349:3059:2d58:c589/64 scope link 3: ens33: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:50:56:39:b5:c7 brd ff:ff:ff:ff:ff:ff inet 172.20.35.2/22 brd 172.20.35.255 scope global dynamic ens33 inet6 fe80::d9b6:fc5b:da94:a526/64 scope link 4: ens34: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:50:56:3f:ef:47 brd ff:ff:ff:ff:ff:ff inet6 fe80::5043:4dc:eec2:582d/64 scope link 5: ens35: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000 link/ether 00:0c:29:87:80:67 brd ff:ff:ff:ff:ff:ff inet6 fe80::c308:1eca:83e4:11c/64 scope link 其中 00:50:56:39:b5:c6 和 00:50:56:39:b5:c7 这两个 MAC 地址相差为 1，因此可以大致断定网卡 ens32 和 ens33 为板载网卡，网卡名顺序应该改为 eth0 和 eth1，剩下两块网卡为外接网卡，命名为 eth2 和 eth3 。 要修改默认的网卡命名方式，我们可以创建一个自定义 udev 的 rules 文件，如：/etc/udev/rules.d/70-mynet.rules，然后按照顺序将 MAC 地址与网卡名称绑定。 1234SUBSYSTEM=="net", ACTION="add", DRIVERS=="?*", ATTR&#123;address&#125;=="00:50:56:39:b5:c6", ATTR&#123;dev_id&#125;=="0x0", ATTR&#123;type&#125;=="1", KERNEL=="eth*", NAME="eth0"SUBSYSTEM=="net", ACTION="add", DRIVERS=="?*", ATTR&#123;address&#125;=="00:50:56:39:b5:c7", ATTR&#123;dev_id&#125;=="0x0", ATTR&#123;type&#125;=="1", KERNEL=="eth*", NAME="eth1"SUBSYSTEM=="net", ACTION="add", DRIVERS=="?*", ATTR&#123;address&#125;=="00:50:56:3f:ef:47", ATTR&#123;dev_id&#125;=="0x0", ATTR&#123;type&#125;=="1", KERNEL=="eth*", NAME="eth2"SUBSYSTEM=="net", ACTION="add", DRIVERS=="?*", ATTR&#123;address&#125;=="00:0c:29:87:80:67", ATTR&#123;dev_id&#125;=="0x0", ATTR&#123;type&#125;=="1", KERNEL=="eth*", NAME="eth3" 除此之外，还需要更改网卡配置文件，配置 DEVICE 、NAME 以及 HWADDR 参数。在 ifcfg 文件中使用 HWADDR 参数设定 MAC 地址，这样就可由 udev 识别，然后从 DEVICE 参数提供的字符串中提取网卡名称。 /etc/sysconfig/network-scripts/ifcfg-eth0 的配置： 1234567891011121314151617181920TYPE=EthernetBOOTPROTO=noneDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyUUID=a805585c-c69a-4885-8f83-16d67754dccb# ----------------------------------NAME=eth0DEVICE=eth0ONBOOT=yesHWADDR=00:50:56:39:b5:c6# ---------------------------------- /etc/sysconfig/network-scripts/ifcfg-eth1 的配置： 12345678910111213141516171819202122232425TYPE=EthernetBOOTPROTO=noneDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyUUID=6d524d10-ee00-460e-af9c-61e57c833e75# ----------------------------------NAME=eth1DEVICE=eth1ONBOOT=yesHWADDR=00:50:56:39:b5:c7# ----------------------------------IPADDR=172.20.35.2NETMASK=255.255.252.0BROADCAST=172.20.35.255NETWORK=172.20.32.0GATEWAY=172.20.32.7 /etc/sysconfig/network-scripts/ifcfg-eth2 的配置： 1234567891011121314151617181920TYPE=EthernetBOOTPROTO=noneDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyUUID=cfefc668-986c-4c4f-b673-66d4463a56e5# ----------------------------------NAME=eth2DEVICE=eth2ONBOOT=yesHWADDR=00:50:56:3f:ef:47# ---------------------------------- /etc/sysconfig/network-scripts/ifcfg-eth3 的配置： 1234567891011121314151617181920TYPE=EthernetBOOTPROTO=noneDEFROUTE=yesPEERDNS=yesPEERROUTES=yesIPV4_FAILURE_FATAL=noIPV6INIT=yesIPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=noIPV6_ADDR_GEN_MODE=stable-privacyUUID=1aa05d79-80f3-4550-bc57-9dc64a4c8ebf# ----------------------------------NAME=eth3DEVICE=eth3ONBOOT=yesHWADDR=00:0c:29:87:80:67# ---------------------------------- 重启完成后验证 修改Grub2配置如果你并不关心网卡的物理位置，比如用的是云主机，只想将网卡命名方式改为 eth0、eth1 的格式，除了按照上面的方法，还可以修改 GRUB 菜单的内核启动命令行的参数。 修改 /etc/default/grub 文件，在 GRUB_CMDLINE_LINUX= 参数中补充 net.ifnames=0 biosdevname=0 123456789[root@bogon ~]# cat /etc/default/grubGRUB_TIMEOUT=5GRUB_DISTRIBUTOR=&quot;$(sed &apos;s, release .*$,,g&apos; /etc/system-release)&quot;GRUB_DEFAULT=savedGRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=&quot;console&quot;GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rhgb quiet net.ifnames=0 biosdevname=0&quot;GRUB_DISABLE_RECOVERY=&quot;true&quot;[root@bogon ~]# 修改完配置后，还需要通过 grub2-mkconfig 命令重新生成配置。123456789[root@bogon ~]# cp /boot/grub2/grub.cfg&#123;,.old&#125;; [root@bogon ~]# grub2-mkconfig -o /boot/grub2/grub.cfgGenerating grub configuration file ...Found linux image: /boot/vmlinuz-3.10.0-957.el7.x86_64Found initrd image: /boot/initramfs-3.10.0-957.el7.x86_64.imgFound linux image: /boot/vmlinuz-0-rescue-17fcd15f39ac46b6906c263179a1a3b9Found initrd image: /boot/initramfs-0-rescue-17fcd15f39ac46b6906c263179a1a3b9.imgdone[root@bogon ~]# 在CentOS7 中提供了 grubby 命令，可以用来查看 /boot/grub2/grub.cfg 中的 grub 策略。 1234[root@bogon ~]# grubby --info=ALL | grep argsargs=&quot;ro crashkernel=auto rhgb quiet net.ifnames=0 biosdevname=0 &quot;args=&quot;ro crashkernel=auto rhgb quiet net.ifnames=0 biosdevname=0 &quot;[root@bogon ~]# 使用 grubby 命令也可以直接修改 /boot/grub2/grub.cfg 中的 grub 策略。 123456[root@bogon ~]# cp /boot/grub2/grub.cfg&#123;,.bak&#125;;[root@bogon ~]# grubby --update-kernel=ALL --args=&quot;net.ifnames=1 biosdevname=1&quot;[root@bogon ~]# grubby --info=ALL | grep args args=&quot;ro crashkernel=auto rhgb quiet net.ifnames=1 biosdevname=1&quot;args=&quot;ro crashkernel=auto rhgb quiet net.ifnames=1 biosdevname=1&quot;[root@bogon ~]# 但是这并不会更新 /etc/default/grub ，所以最稳妥的办法还是手动修改 /etc/default/grub 然后重新生成配置。]]></content>
      <tags>
        <tag>Network</tag>
        <tag>grub2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS7网卡一致性命名规则]]></title>
    <url>%2F2015%2F11%2F03%2F105011-CentOS7%E7%BD%91%E5%8D%A1%E4%B8%80%E8%87%B4%E6%80%A7%E5%91%BD%E5%90%8D%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[一致性网络设备命名，即 Consistent Network Device Naming 。 服务器通常有多块网卡，有板载集成（集成网卡主板（Lan-on-Motherboard），或 LOM）的，同时也有插在 PCIe 插槽的。Linux 系统的命名原来是 eth0，eth1 这样的形式，但是这个编号往往不一定准确对应网卡接口的物理顺序。为解决这类问题，Dell 开发了 biosdevname 方案。systemd v197 版本中将 Dell 的方案作了进一步的一般化拓展。目前的 CentOS 7 既支持 Dell 的 biosdevname，也支持 systemd 的方案。 在 CentOS 7 中，udev 支持大量不同的命名方案。默认是根据固件、拓扑及位置信息分配固定名称。这样做的优点是命名可完全自动进行，并可预期，即使添加或删除硬件后也会保留其名称（不会出现重复枚举的情况），同时可顺利更换损坏的硬件。不足之处是，相比传统的名称，比如 eth0 或 wlan0，这些名称有时会比较难理解。例如：enp5s0 。 命名方案层级结构默认情况下，systemd 会使用以下策略，采用支持的命名方案为接口命名： 方案 1：如果固件或 BIOS 信息适用且可用，则使用整合了为板载设备提供索引号的固件或 BIOS 的名称（例如：eno1），否则请使用方案 2。 方案 2：如果固件或 BIOS 信息适用且可用，则使用整合了为 PCI 快速热插拔插槽提供索引号的固件或 BIOS 名称（例如 ens1），否则请使用方案 3。 方案 3：如果硬件连接器物理位置信息可用，则使用整合了该信息的名称（例如：enp2s0），否则请使用方案 5。 方案 4： 默认不使用整合接口 MAC 地址的名称（例如：enx78e7d1ea46da），但用户可选择使用此方案。 方案 5：传统的不可预测的内核命名方案，在其他方法均失败后使用（例如： eth0）。 这个策略（如上所述）是默认策略。如果该系统已启用 biosdevname，则会使用该方案。注：启用 biosdevname 需要添加 biosdevname=1 作为内核命令行参数（Dell 系统除外），此时只要安装 biosdevname，就会默认使用该方案。如果用户已添加 udev 规则，该规则会更改内核设备名称，则会优先使用这些规则。 了解设备重命名过程设备命名过程如下： 1、/usr/lib/udev/rules.d/60-net.rules 文件中的规则会让 udev 帮助工具 /lib/udev/rename_device 查看所有 /etc/sysconfig/network-scripts/ifcfg-suffix 文件。如果发现包含 HWADDR 条目的 ifcfg 文件与某个接口的 MAC 地址匹配，它会将该接口重命名为 ifcfg 文件中由 DEVICE 指令给出的名称。 2、/usr/lib/udev/rules.d/71-biosdevname.rules 中的规则让 biosdevname 根据其命名策略重命名该接口，即在上一步中没有重命名该接口、已安装 biosdevname、且在 boot 命令行中将 biosdevname=0 作为内核命令给出。 3、 /lib/udev/rules.d/75-net-description.rules 中的规则让 udev 通过检查网络接口设备，填写内部 udev 设备属性值 ID_NET_NAME_ONBOARD、ID_NET_NAME_SLOT、ID_NET_NAME_PATH。注：有些设备属性可能处于未定义状态。 4、 /usr/lib/udev/rules.d/80-net-name-slot.rules 中的规则让 udev 重命名该接口，优先顺序如下：ID_NET_NAME_ONBOARD、ID_NET_NAME_SLOT、ID_NET_NAME_PATH。并提供如下信息：没有在步骤 1 或 2 中重命名该接口，同时未给出内核参数 net.ifnames=0。如果一个参数未设定，则会按列表的顺序设定下一个。如果没有设定任何参数，则不会重命名该接口。 第 3 步和第4 步采用命名规则 1、2、3，可自选方案 4 。 了解可预期网络接口设备名称根据接口类型以两个字母开头：1、en 代表以太网，2、wl 代表无线局域网（WLAN），3、ww 代表无线广域网（WWAN）。 名称有以下类型： 设备名称类型 所有多功能 PCI 设备都在其设备名称中包含 [f&lt;function&gt;] 号，其中包括 function 0 设备。 在 USB 设备中会组成集线器端口号完整链。如果该名称超过 15 个字符上限，则无法导出该名称。 已取消 USB configuration descriptors == 1 和 USB interface descriptors == 0（如果只有一个 USB 配置或接口存在，则默认值为 configuration == 1 及 interface == 0）。 使用 BIOSDVNAME 保持网络设备命名一致通过 biosdevname udev 帮助程序实施此功能，可将所有内嵌网络接口名称、PCI 卡网络接口名称、以及现有eth[0123…] 的虚拟功能网络接口名称改为新的命名规范。 注：除非使用 Dell 系统，或特别明确说明启用 biosdevname，否则会优先使用 systemd 命名惯例。 biosdevname 命名惯例 系统要求biosdevname 程序使用来自系统BIOS 的信息，特别是 SMBIOS 中包含。type 9（系统插槽）和 type 41（板载设备扩展信息）字段。如果系统的 BIOS 没有 SMBIOS 版本 2.6 或更高版本和这个数据，则不会使用新的命名规则。大多数老硬件不支持这个功能，因为缺少有正确 SMBIOS 版本的 BIOS 和字段信息。 必须安装 biosdevname 软件包方可或使用这个功能。要安装这个软件包，请作为 root 用户运行以下命令： 1~]# yum install biosdevname 启用和禁用该功能要禁用这个功能，请在安装过程中及安装后，在 boot 命令行中使用以下选项： 1biosdevname=0 要启用这个功能，请在安装过程中及安装后，在 boot 命令行中使用以下选项： 1biosdevname=1 除非系统达到最低要求，否则会忽略这个选项，同时系统会使用 systemd 命名方案。 如果指定 biosdevname 安装选项，那么它就必须在该系统的声明周期内作为其引导选项使用。 控制网络设备名称选择可以如下方式控制设备命名： 根据网络接口设备识别 在 ifcfg 文件中使用 HWADDR 指令设定 MAC 地址，这样就可由 udev 识别。会从 DEVICE 指令提供的字符串中提取该名称，根据惯例，该名称应使用与 ifcfg 相同的后缀。例如：ifcfg-eth0。 通过打开或关闭 biosdevname 可使用由 biosdevname 提供的名称（如果 biosdevname 可确定）。 通过打开或关闭 systemd-udev 的命名方案 可使用由 systemd-udev 提供的名称（如果 systemd-udev 可确定）。 禁用一致网络设备命名请选择以下方法之一禁用一致网络设备命名： 通过屏蔽默认策略中的 udev 规则文件，禁止分配固定名称，以便重新使用不可预期的内核名称。可为 /dev/null 生成一个符号链接完成“屏蔽”。请作为 root 用户运行以下命令： 1ln -s /dev/null /etc/udev/rules.d/80-net-name-slot.rules 创建自己的手动命名方案。例如：将接口命名为 “internet0”、“dmz0” 或 “lan0”。要创建自己的 udev 规则文件，并为那些设备设置 NAME 属性。确定在使用默认策略文件前使用该文件。例如：将其命名为 /etc/udev/rules.d/70-my-net-names.rules。 修改策略文件，使其选择不同的命名方案后。例如：默认根据接口的 MAC 地址命名所有接口。作为 root 复制默认策略文件，如下： 1cp /usr/lib/udev/rules.d/80-net-name-slot.rules /etc/udev/rules.d/80-net-name-slot.rules 在 /etc/udev/rules.d/ 目录中编辑文件，并根据需要修改。 在 GRUB 2 菜单的内核命令行中添加以下指令： 1net.ifnames=0 更新所有 GRUB 2 内核菜单条目，作为 root 用户输入以下命令： 1~]# grubby --update-kernel=ALL --args=net.ifnames=0 原文链接： https://access.redhat.com/documentation/zh-cn/red_hat_enterprise_linux/7/html/networking_guide/ch-consistent_network_device_naming]]></content>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS网卡配置文件说明]]></title>
    <url>%2F2015%2F11%2F02%2F0154138-CentOS%E7%BD%91%E5%8D%A1%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[Redhat Linux 的网络配置，基本上是通过修改几个配置文件来实现的，虽然也可以用 ifconfig 来设置 IP，用 route 来配置默认网关，用 hostname 来配置主机名，但是重启后会丢失。 在 RedHat 中，系统网络设备的配置文件保存在 /etc/sysconfig/network-scripts 目录下，ifcfg-eth0 包含第一块网卡的配置信息，ifcfg-eth1 包含第二块网卡的配置信息。在启动时系统通过读取这个配置文件决定某个网卡是否启动和如何配置。 下面是 /etc/sysconfig/network-scripts/ifcfg-eth0 文件中可以配置的选项及对应说明 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081TYPE=Ethernet# 网络类型,Ethernet(以太网)BOOTPROTO=static# 引导协议;# BOOTPROTO=&#123;static|none|dhcp|bootp&#125;# 指定静态地址使用static或none;# 从DHCP服务器获取地址使用dhcp;# 从中心服务器上获得IP地址使用bootp(DHCP前身)DEFROUTE=yes# default route，是否将此设备设为默认路由PEERDNS=yes# 是否在BOOTPROTO为dhcp时接受由DHCP服务器指定的DNS地址覆盖本地(/etc/resolv.conf)的DNS;# 不会立即生效,但重启网络服务或主机都会生效；PEERROUTES=yesIPV4_FAILURE_FATAL=no# 如果ipv4配置失败是否禁用该设备IPV6INIT=no# 是否启用IPv6的接口IPV6_AUTOCONF=yesIPV6_DEFROUTE=yesIPV6_PEERDNS=yesIPV6_PEERROUTES=yesIPV6_FAILURE_FATAL=no# 如果ipv6配置失败是否禁用该设备IPV6_ADDR_GEN_MODE=stable-privacyNM_CONTROLLED=no # 是否由Network Manager服务托管USERCTL=no# 是否允许普通用户控制此接口ARPCHECK=yes# 是否检查ARPNAME=eth0# 网络连接的名字UUID=7aa5daf3-244d-4e83-9fd8-27a4df21289a# 用来标识网卡的唯一识别码，MTU=1500# 最大传输单元DEVICE=eth0# 设备名称HWADDR=0c:c4:7a:91:fe:16# 硬件地址/MAC地址ONBOOT=yes# 是否在网络服务启动时启动网卡IPADDR=183.60.153.176# IP地址NETMASK=255.255.255.128# 子网掩码PREFIX=25# 子网掩码NETWORK=183.60.153.128# 网络地址BROADCAST=183.60.153.255# 广播地址GATEWAY=183.60.153.129# 网关(默认路由)DNS1=8.8.8.8# 首选DNSDNS2=114.114.114.114# 备用DNS]]></content>
      <tags>
        <tag>Network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux配置ADSL拨号上网]]></title>
    <url>%2F2015%2F11%2F01%2F130119-Linux%E9%85%8D%E7%BD%AEADSL%E6%8B%A8%E5%8F%B7%E4%B8%8A%E7%BD%91%2F</url>
    <content type="text"><![CDATA[安装1yum install rp-pppoe.x86_64 配置PPPOE客户端软件安装完软件包后，必须配置pppoe的配置文件/etc/ppp/pppoe.conf，从而让ADSL拨号时使用配置文件中的用户名、密码等参数。使用adsl-setup进行配置： 123456789101112131415161718/usr/sbin/adsl-setup&gt;&gt;&gt; Enter your PPPoE user name :# 输入ADSL帐号的用户名&gt;&gt;&gt; Enter the Ethernet interface connected to the ADSL modemFor Solaris, this is likely to be something like /dev/hme0.For Linux, it will be ethn, where ‘n’ is a number.(default eth0):# 输入 eth0 ，这是ADSL相连的网卡的名字。&gt;&gt;&gt; Enter the demand value (default no):# 输入 no&gt;&gt;&gt; Enter the DNS information here:# 输入 server，这表示使用ADSL拨号自动获得的DNS服务器IP地址&gt;&gt;&gt; Please enter your PPPoE password:# 输入ADSL帐号的密码&gt;&gt;&gt; Choose a type of firewall (0-2):# 输入 0 ，不使用防火墙&gt;&gt;&gt; Accept these settings and adjust configuration files (y/n)?# 如果输入的信息正确，输入 y ,完成配置，否则，输入 n 重新输入。 启动PPPOE客户端软件123456789101112/usr/sbin/adsl-start# 启动PPPOE客户端软件,进行连接# 如果成功，将出现Connected；如果不成功，请检查网线、ADSL MODEM等物理设备，并查看 /var/log/messages中的信息/usr/sbin/adsl-stop# 关闭和ISP的连接/usr/sbin/adsl-status# 查看当前连接的状态chkconfig --add adsl# 将在当前的运行级下加入ADSL的自启动脚本。 测试1234567ifconfig -a# 在输出中应该含有关于 ppp0 的一堆信息，其中还绑定了 IP 地址,说明已经从拨号中获得了IP地址。netstat -nr# 查看路由表信息，这时的默认路由应该是上面获得的IP地址。# 如果没有默认路由，我们可以手动增加：route add default gw 上面获得的IP地址 维护添加计划任务定时拨号 16 7 * * * root /usr/sbin/adsl-stop /etc/ppp/pppoe-eth1.conf;/usr/sbin/adsl-start /etc/ppp/pppoe-eth1.conf &gt; /dev/null 2&gt;&amp;1]]></content>
      <tags>
        <tag>Miscellaneous</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell相关的面试题]]></title>
    <url>%2F2015%2F10%2F17%2F174103-shell%E7%9B%B8%E5%85%B3%E7%9A%84%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[CentOS Linux系统默认的shell是（） 解答：bash查看方法：12345&gt; [root@centos-7.3 ~]# echo $SHELL&gt; /bin/bash&gt; [root@centos-7.3 ~]# awk -F &apos;:&apos; &apos;/^root/&#123;print $NF&#125;&apos; /etc/passwd&gt; /bin/bash&gt; 已知如下命令及返回结果，请问echo $user的返回结果是（） 12345678&gt; [root@test ~]# cat test.sh &gt; #!/bin/bash&gt; user=`whoami`&gt; [root@test ~]# sh test.sh &gt; &gt; [root@test ~]# echo $user&gt; ？？？&gt;]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的学习建议]]></title>
    <url>%2F2015%2F10%2F06%2F114107-shell%E7%9A%84%E5%AD%A6%E4%B9%A0%E5%BB%BA%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[在做 Linux 系统相关的运维工作中，经常会编写shell脚本来完成服务的一键配置，定时维护等任务。shell 脚本严格意义上讲并不是编程语言。很多人在写脚本的时候，想到哪里就写到哪里，多人协作的时候代码很难得到规范和统一。为了更高效地写 shell 脚本，结合自己的经验，查阅了一些资料，罗列了一些建议。 规范自己的代码风格根据自己的使用习惯，写脚本时遵循一致的代码风格。最简单的一个就是缩进如果习惯了是4个空格那就一直保持，最好不要是今天写的时候缩进是4个空格，明天写的时候成了两个空格或一个制表符。 开头的解释器 shebang 其实就是在很多脚本的第一行出现的以#!开头的注释，指明了当我们没有指定解释器的时候默认的解释器，一般是下面这样： 1#!/bin/bash 直接使用./a.sh 来执行这个脚本的时候，如果没有 shebang，那么它就会默认用 $SHELL 指定的解释器，否则就会用 shebang 指定的解释器 上面的写法可能不太具备适应性，一般我们会用下面的方式来指定，而且这也是比较推荐的使用方式 1#!/usr/bin/env bash 解释器分很多种，可以用下面的命令查看本机支持的解释器： 1234567[user1@test ~]$ cat /etc/shells /bin/sh/bin/bash/sbin/nologin/bin/tcsh/bin/csh/bin/ksh 内容做到注释 不管是其他开发语言也好，shell这种脚本语言也要，在写代码的过程中养成良好的注释习惯。没有注释的情况下，在三四个月之后你可能回头看自己的代码时不知道当初的自己是如何想的，以及不知道代码实现了什么功能；另一方面注释可以提高可读性，和别人协作的时候，别人看了也不至于头大。 注释一般包括以下几个方面： shebang 脚本的参数 脚本的用途 脚本的注意事项 脚本的写作时间，作者，版权等 各个函数前的说明注释 一些较复杂的单行命令注释 参数要规范当我们的脚本需要接受参数的时候，一定要先判断参数是否合乎规范，并给出合适的回显，方便使用者了解参数的使用。至少需要判断下参数的个数： 12345678910if test $# -le 1;then echo "Usage : $(basename $0) srcip &lt; destip | dest domainname &gt;" exit 0else echo "....." fi 环境变量的定义一般情况下我们会将一些重要的环境变量定义在开头，确保这些变量的存在。最典型的应用就是，当我们本地安装了很多 java 版本时，我们可能需要指定一个 java 来用。那么这时我们就会在脚本开头重新定义 JAVA_HOME 以及 PATH 变量来进行控制。 1234567# load profilesource /etc/profile# Set up a default search path.PATH="/sbin:/usr/sbin:/bin:/usr/bin:/usr/local/sbin:/usr/local/bin:/root/bin"export PATH 缩进要规矩 正确的缩进是很重要的，尤其是在写函数的时候，否则我们在阅读的时候很容易把函数体跟直接执行的命令搞混。 对于 shell 脚本，因为很多需要缩进的地方 (比如 if，for 语句) 都不长，很多人因此都懒得去缩进，而且很多人不习惯用函数，导致缩进功能被弱化。 常见的缩进方法主要有”soft tab” 和”hard tab” 两种 soft tab：就是使用 n 个空格进行缩进 (n 通常是 2 或 4) hard tab： 指的就是制表符\t 根据自己的使用习惯选择适合自己的缩进方式，并一直保持下去 对于 if 和 for 语句之类的，我们最好不要把 then，do 这些关键字单独写一行，这样看上去比较丑。下面是示例 123for i in &#123;1..10&#125;;do echo $&#123;i&#125;done 12345678# Check networkdstname="mirrors.163.com"if (ping $&#123;dstname&#125; -c 3 -i 0.01 -w 2 -q 1&gt;/dev/null 2&gt;&amp;1)then echo "Network is OK "else echo "Network is unreachable " exit 2fi 脚本和变量命名要标准遵循合理的规范： 文件名规范：以. sh 结尾，方便识别 变量名规范： 最好见名知意 统一命名风格， 一般用小写字母加下划线（file_path），或使用驼峰语法（filePath） 编码要统一 在写脚本的时候尽量使用 UTF-8 编码，能够支持中文等一些奇奇怪怪的字符。虽然能写中文，但是在写注释以及打 log 的时候还是尽量英文，因为很多机器还是没有直接支持中文的，打出来可能会有乱码。 尤其需要注意一点，当我们是在 windows 下用 utf-8 编码来写 shell 脚本的时候，一定要注意这个 utf-8 是否是有 BOM 的。默认情况下 windows 判断 utf-8 格式是通过在文件开头加上三个 EF BB BF 字节来判断的，但是在 Linux 中默认是无 BOM 的。因此如果我们是在 windows 下写脚本的时候，一定要注意将编码改成 Utf-8 无 BOM，一般用 notepad++ 之类的编辑器都能改。否则，在 Linux 下运行的时候就会识别到开头的三个字符，从而报一些无法识别命令的错。 使用统一的执行方式执行shell脚本的方式大致有如下几种 1bash /tmp/test.sh 1/tmp/test.sh 1./test.sh 其中后面两种是需要脚本有执行权限的，这也是建议的执行方式。不加执行权限导致无法直接执行。 日志回显 日志的重要性不必多说，能够方便我们回头纠错，在大型的项目里是非常重要的。 如果这个脚本是供用户直接在命令行使用的，那么我们最好还要能够在执行时实时回显执行过程，方便用户掌控。 为了提高用户体验，我们可以在回显中添加一些特效，比如颜色、闪烁等 不在脚本中使用密码安全很重要，不要把密码硬编码在脚本里，尤其是当脚本托管在类似 Github 这类平台中时，明文密码就暴露在互联网中了。 代码太长要分行在源码包编译安装软件时，参数可能会很长，为了保证较好的阅读体验，我们可以用反斜杠来分行： 1234./configure \ –prefix=/usr \ –sbin-path=/usr/sbin/nginx \ –conf-path=/etc/nginx/nginx.conf \ 注意: 在\前要有个空格 编码的细节和规范使用新的语法这里的新语法不是指有多厉害，而是指我们可能更希望使用较新引入的一些语法，更多是偏向代码风格的，比如 尽量使用 func(){}来定义函数，而不是func{} 尽量使用[[]]来代替[] 尽量使用$()将命令的结果赋给变量，而不是反引号 在复杂的场景下尽量使用 printf代替 echo进行回显 事实上，这些新写法很多功能都比旧的写法要强大，用的时候就知道了。 让自己的代码更简短这里的简短不单单是指代码长度，而是用到的命令个数。这不仅牵涉到代码的可读性，而且也关乎代码的执行效率。 原则上应该做到： 能一条命令解决的问题绝不用两条命令解决 能直接读取文件就不要用管道 命令能少尽可能少，管道并不是越多越好 题外话：你用的管道太多会让别人感觉你很low 示例 12cat /etc/passwd | grep root grep root /etc/passwd 其实代码简短在还能某种程度上能保证效率的提升，比如下面的例子： 12345#method1 find . -name '*.txt' |xargs sed -i s/233/666/g find . -name '*.txt' |xargs sed -i s/235/626/g find . -name '*.txt' |xargs sed -i s/333/616/g find . -name '*.txt' |xargs sed -i s/233/664/g 12#method1 find . -name '*.txt' |xargs sed -i "s/233/666/g;s/235/626/g;s/333/616/g;s/233/664/g" 这两种方法做的事情都一样，就是查找所有的. txt后缀的文件并做一系列替换。前者是多次执行find，后者是执行一次 find，但是增加了sed的模式串。第一种可读性更好一点，但是当替换的量变大的时候，第二种的速度就会比第一种快很多。这里效率提升的原因，就是第二种只要执行一次命令，而第一种要执行多次。 让自己的代码更有效率在使用命令的时候要了解命令的具体做法，尤其当数据处理量大的时候，要时刻考虑该命令是否会影响效率。比如下面的两个 sed 命令： 123456sed -n '1p' filesed -n '1p;1q' file# 他们的作用一样，都是获取文件的第一行# 但是第一条命令会读取整个文件，而第二条命令只读取第一行。# 当文件很大的时候，仅仅是这样一条命令不一样就会造成巨大的效率差异。 在敏感操作时变量引用要严谨对一个值为路径的变量进行删除、移动操作时，一定要先判断该变量是否为空 示例 123path=/server/backupfind $path -name "*.tar.gz" -type f | xargs rm -f # 一旦变量为空，则会删除当前目录 避免方法 删除操作之前，切换到一个临时目录 使用变量展开，若变量未定义或者为空则赋一个值给这个变量， 示例 1[ $RETVAL = 0 ] &amp;&amp; rm -f $&#123;pidfile:=/tmp/test&#125; /var/lock/subsys/$&#123;prog:=/tmp/test&#125; 勤用双引号 示例1 12345#!/bin/bash # 已知当前文件夹有一个a.sh的文件 var="*.sh" echo $var echo "$var" 运行结果如下： 12a.sh*.sh 这是因为shell对*进行了解释，变成了下面这样 12echo *.shecho "*.sh" 示例2 123#!/bin/basharg1=$1[ $&#123;arg1&#125; == "0" ] &amp;&amp; echo "0" || echo 1 直接执行bash test.sh，不加参数的情况下就会报错，因此需要使用双引号： 123#!/bin/basharg1=$1[ "$&#123;arg1&#125;" == "0" ] &amp;&amp; echo "0" || echo 1 在很多情况下，在将变量作为参数的时候，一定要注意双引号的使用，实际应用的时候由于这个细节导致的问题实在是太多了 使用main函数像 java，C 这样的编译型语言都会有一个函数入口，这种结构使得代码可读性很强，我们知道哪些直接执行，哪些是函数。但是脚本不一样，脚本属于解释性语言，从第一行直接执行到最后一行，如果在这当中命令与函数糅杂在一起，那就非常难读了。 用 python 的朋友都知道，一个合乎标准的 python 脚本大体上至少是这样的： 12345678#!/usr/bin/env python def func1(): pass def func2(): pass if __name__=='__main__': func1() func2() 他用一个很巧妙的方法实现了我们习惯的 main 函数，使得代码可读性更强 在 shell 中，我们也有类似的小技巧: 123456789101112#!/usr/bin/env bash func1()&#123; #do sth &#125; func2()&#123; #do sth &#125; main()&#123; func1 func2 &#125; main "$@" 我们可以采用这种写法，同样实现类似的 main 函数，使得脚本的结构化程度更好。 理清作用域shell 中默认的变量作用域都是全局的，比如下面的脚本： 1234567#!/usr/bin/env bash var=1func()&#123; var=2 &#125; func echo $var 他的输出结果就是 2 而不是 1，这样显然不符合我们的编码习惯，很容易造成一些问题。 因此，相比直接使用全局变量，我们最好使用 local readonly 这类的命令，其次我们可以使用 declare 来声明变量。这些方式都比使用全局方式定义要好。 下面是做了修整的示例 1234567#!/usr/bin/env bash var=1func()&#123; local var=2 &#125; func echo $var 注意事项 路径尽量保持绝对路径，绝多路径不容易出错，如果非要用相对路径，最好用./修饰 优先使用 bash 的变量替换代替 awk sed，这样更加简短，比如 123a=131341echo $&#123;a/3/h&#125;echo $&#123;a//3/h&#125; 简单的if尽量使用 &amp;&amp; ||，写成单行。比如 1[[ x -gt 2]] &amp;&amp; echo x 当 export 变量时，尽量加上子脚本的 namespace，保证变量不冲突 会使用 trap 捕获信号，并在接受到终止信号时执行一些收尾工作 使用 mktemp 生成临时文件或文件夹来避免和他人冲突 利用 / dev/null 结合输入输出重定向来过滤不友好的输出信息 利用命令的返回值判断命令的执行情况 使用文件前要判断文件是否存在，否则做好异常处理 不要处理 ls 后的数据 (比如ls -l | awk &#39;{ print $8}&#39;)，ls 的结果非常不确定，并且和平台有关 读取文件时不要使用 for loop 而要使用 while read 写脚本一定先测试再到生产环境]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用dialog创建交互式shell对话框]]></title>
    <url>%2F2015%2F10%2F03%2F184310-%E4%BD%BF%E7%94%A8dialog%E5%88%9B%E5%BB%BA%E4%BA%A4%E4%BA%92%E5%BC%8Fshell%E5%AF%B9%E8%AF%9D%E6%A1%86%2F</url>
    <content type="text"><![CDATA[dialog是一个可以创建对话框的工具，需要手动安装，yum源安装即可。 系统默认自带whiptail也可实现对话框的创建 每个对话框提供的输出有两种形式： 将所有输出到stderr，不显示到屏幕； 使用退出状态码，OK为0，NO为1，ESC为255。 语法说明1Usage: dialog --common-options --boxType "Text" Height Width --box-specific-option --common-options 通用选项 --boxType 窗体类型 &quot;Text&quot;窗体的标题 Height 窗体的高度（字符个数） Width 窗体宽度（字符个数） 选项通用选项这个选项用来设置dialog box的背景、颜色和标题等。 --title &lt;title&gt;：窗体的标题 --backtitle &lt;backtitle&gt;：窗体的背景标题 --colors：使用颜色 \Z表示开始，\Zn表示结束。解读嵌入式\Z的对话框中的特殊文本序列，序列由下面的字符0-7, b，B, u, U等组成，恢复正常的设置使用\Zn。 --no-shadow：禁用窗体的阴影效果 --shadow：启用窗体的阴影效果 --insecure：输入部件的密码时，使用星号来代表每个字符。 --no-cancel：设置在输入框、菜单和复选框中不显cancel项。 --nook 没有ok键 --clear：完成清屏操作，在框体显示结束后，清除框体，这个参数只能单独使用，不能和别的参数联合使用。 --ok-label &lt;str&gt;：覆盖使用OK按钮标签，换做其它字符。 --cancel-label &lt;str&gt;：功能同上。 --begin &lt;y&gt; &lt;x&gt;：指定对话框左上角在屏幕上的坐标。 --timeout &lt;secs&gt;：超时（返回的错误代码），如果用户在指定的时间内没有给出相应动作，就按超时处理。 --defaultno：设定光标在yesno对话框的默认位置为no --default-item string ：设定在复选框中的默认值 --sleep &lt;secs&gt;：窗体的超时时间，如果用户没有在超时时间内进行选择，将会退出并返回一个错误码 --stderr：以标准错误方式输出。 --stdout：以标准方式输出。 --default-item &lt;str&gt;：设置在一份清单、表格或菜单中的默认项目，通常在框中的第一项是默认的。 窗体类型选项常见的对话框控件选项如下所示： --calendar：提供了一个日历，让你可以选择日期。 --checklist：允许你显示一个选项列表，每个选项都可以被单独的选择(复选框)。 --from：允许建立一个带标签的文本字段，并要求填写。 --fselect：提供一个路径，让你选择浏览的文件。 --gauge：显示一个表，呈现出完成的百分比，就是显示出进度。 --infobox：显示消息后，（没有等待响应）对话框立刻返回，但不清除屏幕(信息框)。 --inputbox：让用户输入文本(输入框)。 --inputmenu：提供一个可供用户编辑的菜单（可编辑的菜单框）。 --menu：显示一个列表供用户选择(菜单框)。 --msgbox：显示一条消息，并要求用户选择一个确定按钮(消息框)。 --pause：显示一个表格用来显示一个指定的暂停期的状态。 --passwordbox：显示一个输入框，它隐藏文本。 --passwordfrom：显示一个来源于标签并且隐藏的文本字段。 --radiolist：提供一个菜单项目组，只有一个项目，可以选择(单选框)。 --tailbox：在一个滚动窗口文件中使用tail命令来显示文本。 --tailboxbg：跟tailbox类似，但是在background模式下操作。 --textbox：在带有滚动条的文本框中显示文件的内容(文本框)。 --timebox：提供一个窗口，选择小时、分钟、秒。 --yesno：提供一个带有yes和no按钮的简单信息框(是/否框)。 使用示例创建消息框 语法 1dialog --title "&lt;message box title&gt;" --msgbox "&lt;text to show&gt;" &lt;height&gt; &lt;width&gt; 实例 1dialog --backtitle "Test the first message box" --title "Test Message Box" --colors --ok-label "YES" --msgbox "Create a message box with dialog. Choose \Z1YES\Zn to continue." 10 60 效果 创建输入框 格式 1dialog --inputbox text height width 示例 123#!/bin/bashuserName=$(dialog --backtitle "Add a user" --title "Username" --inputbox "Please input a username" 10 30 --stdout)echo "Username is:" $userName 效果 创建文本信息框 格式 1dialog --textbox file height width 示例 1dialog --textbox /etc/fstab 20 80 效果 创建yesno对话框 格式 1dialog --yesno text height width 示例 1dialog --title "yes/no" --no-shadow --yesno "Delete the file /tmp/test.txt?" 10 30 效果 创建一个菜单栏 格式 1dialog --menu text height width menu-height tag1 item1 tag2 item2 … 示例 12dialog --title "Pick a choice" --menu "Choose one" 12 35 5 A "Display the disk usage" B "Display the meminfo" C "Quit"# 进入菜单后按A、B、C可定位到某一个条目上，标准输出是tag 效果 创建文件选框 格式 1dialog --fselect filepath height width 示例 1dialog --title "Pick one file" --fselect /root/ 7 40 效果 创建复选框 格式 1dialog --checklist "Test" height width menu-height tag1 item1 tag2 item2 … 示例 1dialog --backtitle "Checklist" --checklist "Test" 20 50 10 Memory Memory_Size 1 Dsik Disk_Size 2 效果 创建密码框 格式 1dialog --passwordbox text height width [init] 示例 1dialog --title "Password" --passwordbox "Please give a password for the new user:" 10 35 密码暴露出来不安全，所以通常我们会加上一个安全选项--insecure，将每个字符用*来显示。 1dialog --title "Password" --insecure --passwordbox "Please give a password for the new user:" 10 30 效果 创建一个日历框 格式 1dialog --calendar "Date" height width day month year 示例 显示当前日期 1dialog --title "Calendar" --calendar "Date" 5 50 显示指定日期 1dialog --title "Calendar" --calendar "Date" 5 50 1 2 2013 效果 创建一个进度框 格式 1dialog --gauge text height width [&lt;percent&gt;] 示例 固定进度显示 1dialog --title "installation pro" --gauge "installation" 10 30 10 实时显示 1for i in &#123;1..100&#125; ;do echo $i;done | dialog --title "installation pro" --gauge "installation" 10 30 拷贝100个文件 1234567891011121314151617181920#!/bin/bashdeclare -i percent=0install -cd /tmp/test(for file in /etc/*;do if [ $&#123;percent&#125; -le 100 ];then cp -r $&#123;file&#125; /tmp/test/ 2&gt;/dev/null echo XXX # 两个XXX之间的内容替换标题 echo "Copy the file $&#123;file&#125; ... " echo XXX echo $&#123;percent&#125; fi ((percent=percent+1)) sleep 0.1done ) | dialog --title "Coping..." --gauge "Starting to copy files ... " 6 50 0 效果 创建表单 格式 1dialog --form text height width formheight [ label y x item y x flen ilen ] ... 其中：flen表示field length，定义了选定字段中显示的长度；ilen表示input-length, 定义了在外地输入的数据允许的长度。使用up/down（或ctrl/ N，ctrl/ P）在使用领域之间移动，使用tab键在窗口之间切换。 示例 12345dialog --title "Add a user" --form "Please input the infomation of new user:" 12 40 4 \ "Username:" 1 1 "" 1 15 15 0 \ "Full name:" 2 1 "" 2 15 15 0 \ "Home Dir:" 3 1 "" 3 15 15 0 \ "Shell:" 4 1 "" 4 15 15 0 效果 综合应用示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283#! /bin/bashyesno() &#123; dialog --title "First screen" --backtitle "Test Program" --clear --yesno \ "Start this test program or not ? \nThis decesion have to make by you." 16 51 # yes is 0, no is 1 , esc is 255 result=$? if [ $result -eq 1 ] ; then exit 1; elif [ $result -eq 255 ]; then exit 255; fi username;&#125;username() &#123; cat /dev/null &gt;/tmp/test.username dialog --title "Second screen" --backtitle "Test Program" --clear --inputbox \ "Please input your username (default: hello) " 16 51 "hello" 2&gt;/tmp/test.username result=$? if [ $result -eq 1 ] ; then yesno; elif [ $result -eq 255 ]; then exit 255; fi password;&#125;password() &#123; cat /dev/null &gt;/tmp/test.password dialog --insecure --title "Third screen" --backtitle "Test Program" --clear --passwordbox \ "Please input your password (default: 123456) " 16 51 "123456" 2&gt;/tmp/test.password result=$? if [ $result -eq 1 ] ; then username; elif [ $result -eq 255 ]; then exit 255; fi occupation;&#125;occupation() &#123; cat /dev/null &gt;/tmp/test.occupation dialog --title "Forth screen" --backtitle "Test Program" --clear --menu \ "Please choose your occupation: (default: IT)" 16 51 3 \ IT "The worst occupation" \ CEO "The best occupation" \ Teacher "Not the best or worst" 2&gt;/tmp/test.occupation result=$? if [ $result -eq 1 ] ; then password; elif [ $result -eq 255 ]; then exit 255; fi finish;&#125;finish() &#123; dialog --title "Fifth screen" --backtitle "Test Program" --clear --msgbox \ "Congratulations! The test program has finished!\n Username: $(cat /tmp/test.username)\n Password: $(cat /tmp/test.password)\n Occupation: $(cat /tmp/test.occupation)" 16 51 result=$? if [ $result -eq 1 ] ; then occupation elif [ $result -eq 255 ]; then exit 255; fi&#125;yesno;]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用whiptail创建交互式shell对话框]]></title>
    <url>%2F2015%2F10%2F01%2F172135-%E4%BD%BF%E7%94%A8whiptail%E5%88%9B%E5%BB%BA%E4%BA%A4%E4%BA%92%E5%BC%8Fshell%E5%AF%B9%E8%AF%9D%E6%A1%86%2F</url>
    <content type="text"><![CDATA[在终端环境下安装新的软件时，经常会看到信息对话框弹出，需要你的输入。对话框的类型有密码箱，检查表，菜单，等等。他们可以引导你以一种直观的方式输入必要的信息，使用这样的用户友好的对话框的好处是显而易见的。如下图所示： 当你想要写一个交互式shell脚本时，你可以使用这样的对话框来接受用户的输入。whiptail可以在shell脚本中创建基于终端的对话框，消息框的过程，类似于Zenity或xdialog GUI脚本代码。预先安装在所有的Linux发布版本中。 相关链接: https://en.wikibooks.org/wiki/Bash_Shell_Scripting/Whiptail 创建消息框 语法 1whiptail --title "&lt;message box title&gt;" --msgbox "&lt;text to show&gt;" &lt;height&gt; &lt;width&gt; 实例 12#!/bin/bashwhiptail --title "Test Message Box" --msgbox "Create a message box with whiptail. Choose Ok to continue." 10 60 效果 创建yes/no对话框 语法 1whiptail --title "&lt;dialog box title&gt;" --yesno "&lt;text to show&gt;" &lt;height&gt; &lt;width&gt; 实例 12345if (whiptail --title "Test Yes/No Box" --yesno "Choose between Yes and No." 10 60) then echo "You chose Yes. Exit status was $?."else echo "You chose No. Exit status was $?."fi 效果 或者可以是“–yes-button” , “–no-button”选项。 123456#!/bin/bashif (whiptail --title "Test Yes/No Box" --yes-button "Skittles" --no-button "M&amp;M's" --yesno "Which do you like better?" 10 60) then echo "You chose Skittles Exit status was $?."else echo "You chose M&amp;M's. Exit status was $?."fi 创建一个表单输入框如果你想用户输入任意的文本，您可以使用一个输入框。 语法 1whiptail --title "&lt;input box title&gt;" --inputbox "&lt;text to show&gt;" &lt;height&gt; &lt;width&gt; &lt;default-text&gt; 实例 12345678#!/bin/bashPET=$(whiptail --title "Test Free-form Input Box" --inputbox "What is your pet's name?" 10 60 Wigglebutt 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3)exitstatus=$?if [ $exitstatus = 0 ]; then echo "Your pet name is:" $PETelse echo "You chose Cancel."fi 效果 创建一个密码框当用户需要输入敏感信息时密码框是有用的。 语法 1whiptail --title "&lt;password box title&gt;" --passwordbox "&lt;text to show&gt;" &lt;height&gt; &lt;width&gt; 实例 12345678#!/bin/bashPASSWORD=$(whiptail --title "Test Password Box" --passwordbox "Enter your password and choose Ok to continue." 10 60 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3)exitstatus=$?if [ $exitstatus = 0 ]; then echo "Your password is:" $PASSWORDelse echo "You chose Cancel."fi 效果 创建一个菜单栏当你想让用户选择一个任意数量的选择中，你可以使用菜单框。 语法 1whiptail --title "&lt;menu title&gt;" --menu "&lt;text to show&gt;" &lt;height&gt; &lt;width&gt; &lt;menu height&gt; [ &lt;tag&gt; &lt;item&gt; ] . . . 实例 123456789101112#!/bin/bashOPTION=$(whiptail --title "Test Menu Dialog" --menu "Choose your option" 15 60 4 \"1" "Grilled Spicy Sausage" \"2" "Grilled Halloumi Cheese" \"3" "Charcoaled Chicken Wings" \"4" "Fried Aubergine" 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3)exitstatus=$?if [ $exitstatus = 0 ]; then echo "Your chosen option:" $OPTIONelse echo "You chose Cancel."fi 效果 创建radiolist单选对话框 语法 1whiptail --title "&lt;radiolist title&gt;" --radiolist "&lt;text to show&gt;" &lt;height&gt; &lt;width&gt; &lt;list height&gt; [ &lt;tag&gt; &lt;item&gt; &lt;status&gt; ] . . . 实例 12345678910111213#!/bin/bashDISTROS=$(whiptail --title "Test Checklist Dialog" --radiolist \"What is the Linux distro of your choice?" 15 60 4 \"debian" "Venerable Debian" ON \"ubuntu" "Popular Ubuntu" OFF \"centos" "Stable CentOS" OFF \"mint" "Rising Star Mint" OFF 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3)exitstatus=$?if [ $exitstatus = 0 ]; then echo "The chosen distro is:" $DISTROSelse echo "You chose Cancel."fi 效果 创建一个表对话框当你想让用户选择一个列表中选择多个选项的清单对话框是有用的，radiolist对话框，只允许选择一个。 语法 1whiptail --title "&lt;checklist title&gt;" --checklist "&lt;text to show&gt;" &lt;height&gt; &lt;width&gt; &lt;list height&gt; [ &lt;tag&gt; &lt;item&gt; &lt;status&gt; ] . . . 实例 12345678910111213#!/bin/bashDISTROS=$(whiptail --title "Test Checklist Dialog" --checklist \"Choose preferred Linux distros" 15 60 4 \"debian" "Venerable Debian" ON \"ubuntu" "Popular Ubuntu" OFF \"centos" "Stable CentOS" ON \"mint" "Rising Star Mint" OFF 3&gt;&amp;1 1&gt;&amp;2 2&gt;&amp;3)exitstatus=$?if [ $exitstatus = 0 ]; then echo "Your favorite distros are:" $DISTROSelse echo "You chose Cancel."fi 效果 创建一个进度条进度条是一个用户友好的对话框。whiptail从标准输入读取一个百分数（0～100），显示一个表内相应的计数。 语法 1whiptail --gauge "&lt;test to show&gt;" &lt;height&gt; &lt;width&gt; &lt;inital percent&gt; 实例 1234567#!/bin/bash&#123; for ((i = 0 ; i &lt;= 100 ; i+=20)); do sleep 1 echo $i done&#125; | whiptail --gauge "Please wait while installing" 6 60 0 效果]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell用法整理]]></title>
    <url>%2F2015%2F09%2F21%2F094119-shell%E7%94%A8%E6%B3%95%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[使用 set 和 eval 取当前的运行级别源码出自 CentOS6.X系统 sshd 服务脚本：/etc/init.d/sshd 1234[user1@study ~]$ runlevel=$(set -- $(runlevel); eval "echo \$$#" )[user1@study ~]$ echo $&#123;runlevel&#125; 3[user1@study ~]$ 分析： 将 runlevel 命令执行结果通过 set -- 根据分隔符IFS，把值依次赋给位置参数 ($1,$2,$3…) 12345678910[user1@study ~]$ runlevelN 3[user1@study ~]$ set -- $(runlevel)[user1@study ~]$ echo $1N[user1@study ~]$ echo $23[user1@study ~]$ echo $1 $2N 3[user1@study ~]$ $#取得位置参数的个数为两个 123[user1@study ~]$ echo $#2[user1@study ~]$ 要取的数值为第二个参数即最后一个，使用 $2 即可取得第二个位置参数，这里的 2 使用 $# 来代替。由于 $$ 代表当前命令的PID，因此需要转义 $ 即 \$$#。 要用 eval 做二次扫描，把 echo 的字符串当做命令解析，第二次解析 $2 的值为 3 。不进行解析的话 $2 只能当做纯字符串输出 12345678910[user1@study ~]$ echo $$# 1343## 这里$$输出了进程pid，然后输出#[user1@study ~]$ echo \$$#$2# 等同于 echo $2[user1@study ~]$ eval "echo \$$#"3 判断变量是否为整数方法一：使用expr做计算，判断命令执行返回值 12expr $1 + 1 &amp;&gt;/dev/null[ $? -eq 0 ] &amp;&amp; echo "int" || echo "not int" 方法二：使用变量字符串替换的结果做条件判断 1234num=2[ -n $&#123;num&#125; -a "$&#123;num&#125;" = "$&#123;num//[^0-9]/&#125;" ] &amp;&amp; echo "int" || echo "not int"# 或[ -n $&#123;num&#125; -a -z "$&#123;num//[0-9]/&#125;" ] &amp;&amp; echo "int" || echo "not int" 方法三：使用shell正则做条件判断 12345678check_int()&#123; local char=$1 if [[ $char =~ ^[1-9][0-9]*$ ]];then return 0 else return 1 fi&#125; 匹配指定格式的文件名源码出自CentOS6.X系统的命令脚本：/usr/bin/ssh-copy-id，用到了expr的表达式 expr STRING : REGEXP，还需要注意 expr 命令最好使用绝对路径 123456L_ID_FILE="~/.ssh/test.pub" if expr "$L_ID_FILE" : ".*\.pub$" &gt;/dev/null ; then PUB_ID_FILE="$L_ID_FILE"else PUB_ID_FILE="$L_ID_FILE.pub"fi 字串 STRING 中一旦被正则表达式 REGEXP 匹配到，就返回匹配到的字符串的长度，否则返回 0 123456[user1@study ~]$ a=test.txt[user1@study ~]$ expr $a : ".*\.txt$"8[user1@study ~]$ expr $a : ".*\.txta$"0[user1@study ~]$ 判断字符串是否不为空test &quot;string&quot; 等同于 [ &quot;string&quot; ] 等同于 [ -n &quot;string&quot; ] 1234567891011[user1@study ~]$ test "fdsa" &amp;&amp; echo not null || echo 0not null[user1@study ~]$ test "" &amp;&amp; echo not null || echo 00[user1@study ~]$ test " " &amp;&amp; echo not null || echo 0not null[user1@study ~]$ [ -n "" ] &amp;&amp; echo not null || echo 0 0[user1@study ~]$ [ -n " " ] &amp;&amp; echo not null || echo 0not null[user1@study ~]$ 使用rename实现批量改文件名将后缀名 .conf 的文件批量改为 .conf.bak 12345678910[user1@study ~]$ ls *.confnamed10.conf named12.conf named14.conf named16.conf named2.conf named4.conf named6.conf named8.confnamed11.conf named13.conf named15.conf named1.conf named3.conf named5.conf named7.conf named9.conf[user1@study ~]$ rename .conf&#123;,.bak&#125; *.conf [user1@study ~]$ ls *.confls: cannot access *.conf: No such file or directory[user1@study ~]$ ls *.conf.baknamed10.conf.bak named12.conf.bak named14.conf.bak named16.conf.bak named2.conf.bak named4.conf.bak named6.conf.bak named8.conf.baknamed11.conf.bak named13.conf.bak named15.conf.bak named1.conf.bak named3.conf.bak named5.conf.bak named7.conf.bak named9.conf.bak[user1@study ~]$ 将后缀名 .conf.bak 的文件改为 .conf 12345678910[user1@study ~]$ ls *.conf.baknamed10.conf.bak named12.conf.bak named14.conf.bak named16.conf.bak named2.conf.bak named4.conf.bak named6.conf.bak named8.conf.baknamed11.conf.bak named13.conf.bak named15.conf.bak named1.conf.bak named3.conf.bak named5.conf.bak named7.conf.bak named9.conf.bak[user1@study ~]$ rename .conf.bak .conf *.conf.bak [user1@study ~]$ ls *.conf.bakls: cannot access *.conf.bak: No such file or directory[user1@study ~]$ ls *.confnamed10.conf named12.conf named14.conf named16.conf named2.conf named4.conf named6.conf named8.confnamed11.conf named13.conf named15.conf named1.conf named3.conf named5.conf named7.conf named9.conf[user1@study ~]$ 使用内置命令type取命令的路径12345[user1@study ~]$ type -path ssh/bin/ssh[user1@study ~]$ which ssh/bin/ssh[user1@study ~]$ 检查域名是否被干扰向根请求解析指定的域名，正常情况下根不会返回任何A记录，只会返回它所属下一级域的NS记录。如果 dig +short 返回的值为空则说明域名未被干扰，如果返回一个A记录的IP地址，说明域名在请求解析的途中被拦截或干扰。 1234567[user1@study ~]$ source_ip=192.168.127.123[user1@study ~]$ query_answer=$(dig +short -b $&#123;source_ip&#125; @a.root-servers.net. www.baidu.com &gt;/dev/null 2&gt;&amp;1)[user1@study ~]$ echo $&#123;query_answer&#125; [user1@study ~]$ test -z "$&#123;query_answer&#125;" &amp;&amp; echo ok || echo not okok[user1@study ~]$]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell实现netmask掩码和cidr掩码位转换]]></title>
    <url>%2F2015%2F09%2F20%2F114131-shell%E5%AE%9E%E7%8E%B0netmask%E6%8E%A9%E7%A0%81%E5%92%8Ccidr%E6%8E%A9%E7%A0%81%E4%BD%8D%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[口算法netmask转CIDR例如：255.255.192.0 255.0.0.0、255.255.0.0、255.255.255.0、255.255.255.255 这四种分别对应 8、16、24、32 去掉所有255.的字符和.及其后面的字符，得到了 192。用 256 减去 192，得到了 64，也就是 2 的 6 次方 XXX.XXX.192.XXX 24-6=18 192在第一段，用8减 192在第二段，用16减 192在第三段，用24减 192在第四段，用32减 CIDR转netmask例如：20==&gt;255.255.240.0 根据上面的进行反推，8、16、24、32 可直接转换 24-20=4 小于8则用8减 大于8小于16则用16减 大于16小于24则用24减 大于24小于32则用32减 求得2的N次幂，即：2的4次方得到16，256-16=240 255.255.XXX.0，这里的XXX是240 小于8则是XXX.0.0.0 大于8小于16则255.XXX.0.0 大于16小于24则255.255.XXX.0 大于24小于32则255.255.255.XXX 使用自带命令ipcalc常用选项 12345-b, --broadcast Display calculated broadcast address-h, --hostname Show hostname determined via DNS-m, --netmask Display default netmask for IP (class A, B, or C)-n, --network Display network address-p, --prefix Display network prefix 使用示例 123456[user1@study ~]$ ipcalc -pmnb 222.58.15.18/29NETMASK=255.255.255.248PREFIX=29BROADCAST=222.58.15.23NETWORK=222.58.15.16[user1@study ~]$ perl开发的ipcalc官网：http://jodies.de/ipcalc 1234567891011$ ipcalc 192.168.0.1/24 Address: 192.168.0.1 11000000.10101000.00000000. 00000001Netmask: 255.255.255.0 = 24 11111111.11111111.11111111. 00000000Wildcard: 0.0.0.255 00000000.00000000.00000000. 11111111=&gt;Network: 192.168.0.0/24 11000000.10101000.00000000. 00000000HostMin: 192.168.0.1 11000000.10101000.00000000. 00000001HostMax: 192.168.0.254 11000000.10101000.00000000. 11111110Broadcast: 192.168.0.255 11000000.10101000.00000000. 11111111Hosts/Net: 254 Class C, Private Internet 来自openwrt的shell脚本 内容来源于：openwrt 1234567891011121314151617181920#!/bin/bashmask2cdr ()&#123; # Assumes there's no "255." after a non-255 byte in the mask local x=$&#123;1##*255.&#125; set -- 0^^^128^192^224^240^248^252^254^ $(( ($&#123;#1&#125; - $&#123;#x&#125;)*2 )) $&#123;x%%.*&#125; x=$&#123;1%%$3*&#125; echo $(( $2 + ($&#123;#x&#125;/4) ))&#125;cdr2mask ()&#123; # Number of args to shift, 255..255, first non-255 byte, zeroes set -- $(( 5 - ($1 / 8) )) 255 255 255 255 $(( (255 &lt;&lt; (8 - ($1 % 8))) &amp; 255 )) 0 0 0 [ $1 -gt 1 ] &amp;&amp; shift $1 || shift echo $&#123;1-0&#125;.$&#123;2-0&#125;.$&#123;3-0&#125;.$&#123;4-0&#125;&#125;# examples:mask2cdr 255.255.255.0cdr2mask 24 思路说明mask2cdr()To get the CIDR prefix from a dot-decimal netmask like this one:要从像下面这样的点分十进制掩码获得CIDR子网掩码 1255.255.192.0 you first have to convert the four octets to binary and then count the most significant bits (i.e. the number of leading ones):首先你必须转换成四个八位二进制，而且算出占了1的位数 111111111.11111111.11000000.00000000 # 18 ones = /18 in CIDR This function does that rather creatively. First, we strip off all of the leading 255 octets (i.e. the octets that are all ones in binary) and store the results in variable x:这个函数确实极具创造性。首先，我们将传入函数的的第一个位置参数（即点分十进制子网掩码）去掉所有开头的255，然后复制给变量x 1local x=$&#123;1##*255.&#125; This step uses parameter expansion, which the entire script relies on pretty heavily. If we continue with our example netmask of 255.255.192.0, we now have the following values:这一步我们使用参数扩展，整个脚本对此有很强的依赖性。如果我们根据刚刚的例子继续看，会得到如下值 12$1: 255.255.192.0 $x: 192.0 Next we set three variables: $1, $2, and $3. These are called positional parameters; they are much like ordinary named variables but are typically set when you pass arguments to a script or function. We can set the values directly using set –, for example:接下来我们设置了三个变量：$1，$2和$3，他们都是位置参数，和普通变量大同小异，但是当你将参数传给一个脚本或者函数时他们是很典型的设置。我们可以直接使用set --来设定变量的值，列如： 1set -- foo bar # $1 = foo, $2 = bar I prefer using named variables over positional parameters since it makes scripts easier to read and debug, but the end result is the same. We set $1 to:相比较位置参数，我更喜欢使用定义好的变量，因为这样使得脚本更容易阅读和调试bug，但是最终的结果都是相同的，我们把位置参数$1设置为： 10^^^128^192^224^240^248^252^254^ This is really just a table to convert certain decimal values to binary and count the number of 1 bits. We’ll come back to this later.这其实只是一个用来转换十进制到二进制，统计1bits数量的一个表。我们稍后将会回顾这里 We set $2 to我们将位置参数$2设置为： 1$(( ($&#123;#1&#125; - $&#123;#x&#125;)*2 )) This looks complex, but it is really just counting the number of 1 bits we stripped off in the first command. It breaks down to this:这个看起来有些复杂，但是其实只是计算我们从第一个命令中去掉（二进制数中八个位都占了1的位）的数量。它划分成了这样： 12(number of chars in $1 - number of chars in $x) * 2# 如果传递给函数的子网掩码是255.255.255.192的话，那么其实就是（15-3）*2=24 which in our case works out to在我们的情况下，其实就是这样： 1(13 - 5) * 2 = 16 We stripped off two octets so we get 16. Makes sense.我们去除了两个（在二进制都占了1的位数=8）8位因此得到了16 We set $3 to:我们将位置参数$3设置为： 1$&#123;x%%.*&#125; which is the value of $x with everything after the first . stripped off. In our case, this is 192.从刚开始到现在$x的值，在我们的情况下已经赋值为192 We need to convert this number to binary and count the number of 1 bits in it, so let’s go back to our “conversion table.” We can divide the table into equal chunks of four characters each:我们需要将这个数字转换为二进制并计算占了1的位的数量，让我们回到我们的“转换表”。我们可以把表分成每个块的字符数等于四的块： 10^^^ 128^ 192^ 224^ 240^ 248^ 252^ 254^ In binary, the above numbers are:转换为二进制就是 1200000000 10000000 11000000 11100000 11110000 11111000 11111100 11111110# 0 ones 1 one 2 ones 3 ones ... If we count from the left, each four-character block in the table corresponds to an additional 1 bit in binary. We’re trying to convert 192, so let’s first lop off the rightmost part of the table, from 192 on, and store it in x:如果我们从左边数，表中的每个四字符的块对应一个额外 占了1的位 的二进制数。我们正试图转换 192 ，所以让我们先剔除掉从192开头的了最右边的表，并赋值给x ： 1x=$&#123;1%%$3*&#125; The value of $x is now$x的值现在就是 10^^^128^ which contains two four-character blocks, or two 1 bits in binary.包含了两个4字符的块或者说是两个占了1位的二进制 Now we just need to add up the 1 bits from our leading 255 octets (16 total, stored in variable $2) and the 1 bits from the previous step (2 total):现在我们只需要把之前算的两个（二进制下都为1的）八位组，（16个，赋值给位变量 $ 2 ），加上从第二步的表中算出$x在二进制中占了1的位的数2 1echo $(( $2 + ($&#123;#x&#125;/4) )) where其中 1$&#123;#x&#125;/4 is the number of characters in $x divided by four, i.e. the number of four-character blocks in $x.是$x的字符数除以四（每四个字符是一个块） Output:输出结果 118 cdr2mask()Let’s keep running with our previous example, which had a CIDR prefix of 18. We use set – to set positional parameters $1 through $9: 123456789$1: $(( 5 - ($1 / 8) )) # 5 - (18 / 8) = 3 [integer math]$2: 255$3: 255$4: 255$5: 255$6: $(( (255 &lt;&lt; (8 - ($1 % 8))) &amp; 255 )) # (255 &lt;&lt; (8 - (18 % 8))) &amp; 255 = 192$7: 0$8: 0$9: 0 Let’s examine the formulas used to set $1 and $6 a little closer. $1 is set to: 1$(( 5 - ($1 / 8) )) The maximum and minimum possible values for a CIDR prefix are 32 for netmask 111111111.11111111.11111111.11111111 and 0 for netmask 100000000.00000000.00000000.00000000 The above formula uses integer division, so the possible results range from 1 to 5: 125 - (32 / 8) = 15 - ( 0 / 8) = 5 $6 is set to: 1$(( (255 &lt;&lt; (8 - ($1 % 8))) &amp; 255 )) Let’s break this down for our example CIDR prefix of 18. First we take the modulus and do some subtraction: 18 - (18 % 8) = 6 Next we bitwise shift 255 by this value: 1255 &lt;&lt; 6 This is the same as pushing six 0 bits onto the end of 255 in binary: 111111111000000 Finally, we bitwise AND this value with 255: 1211111111000000 &amp;00000011111111 # 255 which gives 100000011000000 or simply 111000000 Look familiar? This is the third octet in our netmask in binary: 1211111111.11111111.11000000.00000000 ^------^ In decimal, the value is 192. Next we shift the positional parameters based on the value of $1: 1[ $1 -gt 1 ] &amp;&amp; shift $1 || shift In our case, the value of $1 is 3, so we shift the positional parameters 3 to the left. The previous value of $4 becomes the new value of $1, the previous value of $5 becomes the value of $2, and so on: 123456$1: 255$2: 255$3: 192$4: 0$5: 0$6: 0 These values should look familiar: they are the decimal octets from our netmask (with a couple of extra zeros tacked on at the end). To get the netmask, we simply print out the first four with dots in between them: 1echo $&#123;1-0&#125;.$&#123;2-0&#125;.$&#123;3-0&#125;.$&#123;4-0&#125; The -0 after each parameter says to use 0 as the default value if the parameter is not set. Output: 1255.255.192.0]]></content>
      <tags>
        <tag>Network</tag>
        <tag>ShellScripts</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过受限bash创建只读用户]]></title>
    <url>%2F2015%2F09%2F16%2F114147-%E9%80%9A%E8%BF%87%E5%8F%97%E9%99%90bash%E5%88%9B%E5%BB%BA%E5%8F%AA%E8%AF%BB%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[受限bash bash本身也有一定的限制功能，就是通过其(受限shell) restricted shell 功能。 如果bash是以rbash为名启动，或者使用-r选项运行，它就称为受限shell。 受限bash所做的限制包括： 阻止用户改变目录和环境变量 重定向输出 使用绝对路径运行命令 使用exec命令和其它一些操作 限制的操作受限shell能够使系统环境更好控制。如果启动受限shell，以下操作将被禁止： 使用cd命令切换目录； 设置或者取消SHELL、PATH、ENV或者BASH_ENV环境变量; 以绝对路径运行命令(即命令名中不能包含目录分隔符“/”); 以绝对路径指定的文件名作为内置命令”.”的参数; 在启动时通过 shell 环境导入函数定义; 在启动时通过 shell 环境解析 SHELLOPTS 的值; 使用&gt;、&gt;|、&gt;&amp;、&amp;&gt;和&gt;&gt;等重定向操作重定向输出； 使用exec命令使其它的命令代替当前shell; 通过enable内置命令的 -f 和 -d 选项增加或删除内置命令; 执行内置命令command时加上 -p 选项; 通过 set +r 或 set +o restricted 关闭受限模式; 配置步骤123456789101112131415161718192021222324ln -sv /bin/bash /bin/rbash# 为限制用户创建rbashinstall -cdv /work/ # 创建主工作目录useradd -d /work/ -s /bin/rbash loveyou# 创建限制用户，指定家目录为/work，跳过skel文件复制，指定shell为/bin/rbashpasswd loveyou# 为限制用户创建密码mkdir -pv /work/subin# 为限制用户创建允许使用的命令目录test `/usr/bin/id -g` -eq 500 &amp;&amp; export PATH=/work/subin# 修改环境变量/etc/profile，判断组ID，使可用命令为家目录下的subin目录ln -sv /bin/su /work/subin/suln -sv /bin/cat /work/subin/cat# 创建允许使用的命令alias su='su -l'# 在/etc/profile前面定义别名]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell中脚本路径的获取]]></title>
    <url>%2F2015%2F09%2F08%2F214103-shell%E4%B8%AD%E8%84%9A%E6%9C%AC%E8%B7%AF%E5%BE%84%E7%9A%84%E8%8E%B7%E5%8F%96%2F</url>
    <content type="text"><![CDATA[很多情况下，我们会先获取当前脚本的路径，然后一这个路径为基准，去找其他的路径。通常我们是直接用 pwd 以期获得脚本的路径。实际上这样是不严谨的，pwd 获得的是当前 shell 的执行路径，而不是当前脚本的执行路径。 使用 dirname 命令再结合 pwd 可以准确地得到脚本的实际路径 12345678910111213141516[user1@study ~]$ cat test.sh #!/bin/bashecho $(pwd)script_dir=$(cd $(dirname $0) &amp;&amp; pwd)echo $&#123;script_dir&#125;[user1@study ~]$ bash test.sh/home/user1/home/user1[user1@study ~]$ cd /tmp/[user1@study tmp]$ bash ~/test.sh /tmp/home/user1[user1@study tmp]$ 结合使用 readlink -f 可以实现同样的效果 12345678910111213141516[user1@study ~]$ cat test.sh #!/bin/bashecho $0script_dir=$(dirname $(readlink -f $0))echo $&#123;script_dir&#125;[user1@study ~]$ bash test.shtest.sh/home/user1[user1@study ~]$ cd /tmp/[user1@study tmp]$ bash ~/test.sh /home/user1/test.sh/home/user1[user1@study tmp]$ 在脚本中使用 basename 命令即可获得脚本文件的基名 12345678910111213[user1@study ~]$ cat test.sh #!/bin/bashecho $0echo $(basename $0)[user1@study ~]$ bash test.sh test.shtest.sh[user1@study ~]$ bash /home/user1/test.sh /home/user1/test.shtest.sh[user1@study ~]$]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell使用mktemp命令创建临时文件]]></title>
    <url>%2F2015%2F09%2F03%2F132123-shell%E4%BD%BF%E7%94%A8mktemp%E5%91%BD%E4%BB%A4%E5%88%9B%E5%BB%BA%E4%B8%B4%E6%97%B6%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在生产环境中，很多情况下在脚本中会使用一些临时的普通文件，比如 1.txt，test.txt。为了简单，可能 A 员工在维护时脚本中使用了一个 1.txt，B员工在维护的时候也使用了 1.txt，这时候就造成了文件使用上的冲突。为了尽可能的避免这类情况的发生，我们就可以使用 mktemp 命令创建属于自己的临时文件，当然也可以创建临时的目录。 用法格式 1mktemp [OPTION]... [TEMPLATE] 其中 TEMPLATE 必须以一个或多个 X 结尾 1234[user1@study ~]$ mktemp test.XXXtest.xW0[user1@study ~]$ lstest.xW0 命令选项 -q：静默模式，执行时若发生错误，不会显示任何信息 -d：创建一个临时目录 -u：暂存文件会在 mktemp 结束前先行删除 -p：指定要把临时文件创建在哪个目录下，必须指定绝对路径 脚本中用到的临时文件我们可以使用命令替换的方式，将临时文件名赋值给变量，在操作完成后删除这个变量即可 1234567891011[user1@study ~]$ cat test.sh#!/bin/bashFILE=$(mktemp /tmp/ipinfo.XXXX)echo "hello" &gt;&gt; $&#123;FILE&#125;ls $&#123;FILE&#125;cat $&#123;FILE&#125;[user1@study ~]$ bash test.sh/tmp/ipinfo.cHrwhello[user1@study ~]$ mktemp -p /tmp//tmp/tmp.PDDDcAuBzk]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的进程替换]]></title>
    <url>%2F2015%2F08%2F30%2F134135-shell%E7%9A%84%E8%BF%9B%E7%A8%8B%E6%9B%BF%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[进程替换与命令替换很相似，命令替换把一个命令的结果赋给一个变量，例如 dir_contents=$(ls -al) 。进程替换则是把一个进程的输出回馈给另一个进程 (换句话说，它把一个命令的结果发送给另一个命令)。 命令替换的形式是由圆括号括起的命令 12&gt;(command)&lt;(command) 启动进程替换：它是用 /dev/fd/&lt;n&gt; 文件把在圆括号内的进程的处理结果发送给另外一个进程，在 &lt; 或 &gt; 与圆括号之间是没有空格的. 如果加了空格将会引起错误信息。如果系统的 /dev/fd/&lt;n&gt; 文件不够时，Bash 会使用临时文件。 12cat &lt;(ls -l)# 等同于 ls -l | cat 列出系统中3个主要的 bin 目录的所有文件，并且按文件名排序 12sort -k 9 &lt;(ls -l /bin) &lt;(ls -l /usr/bin) &lt;(ls -l /usr/X11R6/bin)# 注意是三个明显不同的命令输出回馈给'sort'. 给出两个命令输出的不同之处 1diff &lt;(command1) &lt;(command2)]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的语法调试]]></title>
    <url>%2F2015%2F08%2F27%2F134119-shell%E7%9A%84%E8%AF%AD%E6%B3%95%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[使用bash选项-n 检查脚本语法格式是否有错 1bash -n script.sh -v 选项将跟踪脚本中每个命令的执行 1bash -v script.sh -x 选项会使脚本单步执行，将整个脚本每一步解释和执行过程显示出来 1234567891011121314151617181920[user1@study ~]$ cat script.sh #!/bin/bashif [[ '2' = '3' ]];then echo yeselse echo nofiecho "123" | grep 2 &amp;&amp; echo yes || echo no[user1@study ~]$ bash -x script.sh+ [[ 2 = \3 ]]+ echo nono+ echo 123+ grep 2123+ echo yesyes[user1@study ~]$ 使用set命令1234set -x # 在执行时候显示参数和命令。set +x # 禁止调式。set -v # 当命令进入读取时候显示输入。set +v # 禁止打印输入 仅在 -x 和 +x 区域显示调试信息 12345678910111213141516171819202122232425[user1@study ~]$ cat test.sh #!/bin/bashfor i in &#123;1..5&#125; ; do set -x echo $i set +xdone[user1@study ~]$ bash test.sh+ echo 11+ set +x+ echo 22+ set +x+ echo 33+ set +x+ echo 44+ set +x+ echo 55+ set +x[user1@study ~]$ 使用 _DEBUG 环境变量若需要自定义格式显示调式信息可通过 _DEBUG 环境变量来建立。将需要调式的行前加上 DEBUG，运行脚本前没有加 _DEBUG=on 就不会显示任何信息，脚本中 : 告诉shell不进行任何操作。 12345678910#!/bin/bashDEBUG () &#123; [ "$_DEBUG" = "on" ] &amp;&amp; $@ || :&#125;for i in &#123;1..5&#125; ; do DEBUG echo $idone[user1@study ~]$ bash test.sh[user1@study ~]$ 将调试功能设置为“on”来运行脚本： 1234567[user1@study ~]$ _DEBUG=on bash test.sh 12345[user1@study ~]$ 使用shellbang把 shebang 从 #!/bin/bash 修改成 #!/bin/bash -xv 即可 静态检查工具 shellcheck为了从制度上保证脚本的质量，我们最简单的想法大概就是搞一个静态检查工具，通过引入工具来弥补开发者可能存在的知识盲点。 shellcheck这个工具的对不同平台的支持力度都很大，他至少支持 Debian，Arch，Gentoo，EPEL，Fedora，OS X,，openSUSE 等等各种的平台的主流包管理工具。 使用 epel 的 yum 源即可安装。它的 Github 地址为 https://github.com/koalaman/shellcheck 12yum -y install epel-releaseyum install ShellCheck shellcheck 提供了一个非常非常强大的 wiki。在这个 wiki 里，我们可以找到这个工具所有判断的依据，每一个检测到的问题都可以在 wiki 里找到对应的问题单号，他不仅告诉我们” 这样写不好”，而且告诉我们” 为什么这样写不好”，” 我们应当怎么写才好”，非常适合刨根问底党进一步研究。]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell中信号捕捉]]></title>
    <url>%2F2015%2F08%2F24%2F174111-shell%E4%B8%AD%E4%BF%A1%E5%8F%B7%E6%8D%95%E6%8D%89%2F</url>
    <content type="text"><![CDATA[信号捕捉信号是一种进程间的通信机制，它给应用程序提供一种异步的软件中断，使应用程序有机会接受其他程序活终端发送的命令(即信号)。 应用程序收到信号后，有三种处理方式：忽略，默认，捕捉。进程收到一个信号后，会检查对该信号的处理机制。如果是 SIG_IGN，就忽略该信号；如果是 SIG_DFT，则会采用系统默认的处理动作，通常是终止进程或忽略该信号；如果给该信号指定了一个处理函数(捕捉)，则会中断当前进程正在执行的任务，转而去执行该信号的处理函数，返回后再继续执行被中断的任务。 常见信号kill -l 和 trap -l 可列出系统的信号 1234567891011121314151617181920212223242526272829[user1@study ~]$ kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX[user1@study ~]$ trap -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR111) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+338) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+843) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+1348) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-1253) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-758) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-263) SIGRTMAX-1 64) SIGRTMAX[user1@study ~]$ stty -a 可列出中断信号与键盘的对应 1234567891011[user1@study ~]$ stty -aspeed 38400 baud; rows 25; columns 100; line = 0;intr = ^C; quit = ^\; erase = ^?; kill = ^U; eof = ^D; eol = &lt;undef&gt;; eol2 = &lt;undef&gt;;swtch = &lt;undef&gt;; start = ^Q; stop = ^S; susp = ^Z; rprnt = ^R; werase = ^W; lnext = ^V; flush = ^O;min = 1; time = 0;-parenb -parodd -cmspar cs8 -hupcl -cstopb cread -clocal -crtscts-ignbrk -brkint -ignpar -parmrk -inpck -istrip -inlcr -igncr icrnl ixon -ixoff -iuclc -ixany -imaxbel-iutf8opost -olcuc -ocrnl onlcr -onocr -onlret -ofill -ofdel nl0 cr0 tab0 bs0 vt0 ff0isig icanon iexten echo echoe echok -echonl -noflsh -xcase -tostop -echoprt echoctl echoke[user1@study ~]$ 常见的信号及其描述 信号 Num 描述 SIGHUP 1 在用户终端连接(正常或非正常)结束时发出, 通常是在终端的控制进程结束时, 通知同一session内的各个作业, 这时它们与控制终端不再关联。 登录Linux时，系统会分配给登录用户一个终端(Session)。在这个终端运行的所有程序，包括前台进程组和后台进程组，一般都属于这个Session。当用户退出Linux登录时，前台进程组和后台有对终端输出的进程将会收到SIGHUP信号。这个信号的默认操作为终止进程，因此前台进程组和后台有终端输出的进程就会中止。对于与终端脱离关系的守护进程，这个信号用于通知它重新读取配置文件。 SIGINT 2 程序终止(interrupt)信号, 在用户键入INTR字符(通常是Ctrl C)时发出。 SIGQUIT 3 和SIGINT类似, 但由QUIT字符(通常是Ctrl /)来控制. 进程在因收到SIGQUIT退出时会产生core文件, 在此意义上类似于一个程序错误信号。 SIGFPE 8 在发生致命的算术运算错误时发出. 不仅包括浮点运算错误, 还包括溢出及除数为0等其它所有的算术的错误。 SIGKILL 9 用来立即结束程序的运行. 本信号不能被阻塞, 处理和忽略。 SIGALRM 14 时钟定时信号, 计算的是实际时间或时钟时间. alarm函数使用该信号。 SIGTERM 15 程序结束(terminate)信号, 与SIGKILL不同的是该信号可以被阻塞和处理. 通常用来要求程序自己正常退出. shell命令kill缺省产生这个信号。 捕捉信号在终端一个 shel l程序的执行过程中，按下 Ctrl + C 键正常程序将立即终止，并返回命令提示符。可能并不总是可取的。比如有可能最终产生临时文件，不会被清理。 Ctrl + C —&gt; SIGINIT(2) Ctrl+ Z —&gt; SIGCONT(18) 使用 trap 命令可以捕捉信号并执行引号（但双引均可）中的命令串或函数 12# trap 'commands或functions' signal-listtrap 'echo -e "\n\nQuit....\n\a";exit 3' SIGINT; 恢复信号的默认操作 12trap signal-listtrap : signal-list 忽略信号 1trap " " signal-list 注意事项 对信号SIGSEGV(11)不能捕捉，因为shell本身需要捕捉（该信号去进行内存的转储） 在脚本中可以捕捉信号，但无法捕捉KILL(9)和TERM(15) 在trap中可以定义对信号0的处理(实际上没有此信号)，shell程序在其终止(如执行exit语句)时发出该信号 在捕捉到signal-list中指定的信号并执行完相应的命令之后， 如果这些命令没有将shell程序终止的话，shell程序将继续执行收到信号时所执行的命令后面的命令，这样将很容易导致shell程序无法终止。 通常需要忽略的四个信号HUP(1), INT(2), QUIT(3), TSTP(24) 123trap "" 1 2 3 24 # 或 trap "" HUP INT QUIT TSTP 使其恢复默认值 123trap ：1 2 3 24 # 或trap HUP INT QUIT TSTP]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的数组]]></title>
    <url>%2F2015%2F08%2F21%2F172135-shell%E7%9A%84%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[什么是数组 存储多个元素的连续的内存空间。数组只有一个名字，索引号从0开始。 关联数组的索引号可以自定义，bash4及以后版本支持关联数组。 Bash 支持一维数组（不支持多维数组），并且没有限定数组的大小。 获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于0。 如何定义一个数组用括号表示数组，数组元素用 “空格” 符号分割开 使用 declare -a ips 定义一个名为 ips 的索引数组 123456789[user1@study ~]$ declare -a ips # 一般可以省略这条语句，直接使用下面的方法定义即可[user1@study ~]$ ips=(10.0.0.0/8 172.16.0.0/12 192.168.0.0/16)[user1@study ~]$ echo $&#123;ips[0]&#125;10.0.0.0/8[user1@study ~]$ echo $&#123;ips[1]&#125;172.16.0.0/12[user1@study ~]$ echo $&#123;ips[2]&#125;192.168.0.0/16[user1@study ~]$ 使用 declare -A IPS 定义一个名为 IPS 的关联数组 123456789[user1@study ~]$ declare -A IPS[user1@study ~]$ IPS=([ip1]='10.0.0.0/8' [ip2]='172.16.0.0/12' [ip3]='192.168.0.0/16')[user1@study ~]$ echo $&#123;IPS[ip1]&#125;10.0.0.0/8[user1@study ~]$ echo $&#123;IPS[ip2]&#125;172.16.0.0/12[user1@study ~]$ echo $&#123;IPS[ip3]&#125;192.168.0.0/16[user1@study ~]$ 元素赋值单个元素赋值，直接通过 数组名[下标] 就可以对其进行引用赋值，如果下标不存在，自动添加新一个数组元素 1234567[user1@study ~]$ ips=(1.2.3.4 9.9.9.9) # 全部元素赋值[user1@study ~]$ ips[0]='100.64.0.0/10' # 单个元素赋值[user1@study ~]$ ips[2]='8.8.8.8' [user1@study ~]$ ips[9]='8.8.8.8'[user1@study ~]$ echo $&#123;ips[0]&#125; $&#123;ips[1]&#125; $&#123;ips[2]&#125; $&#123;ips[9]&#125; 100.64.0.0/10 9.9.9.9 8.8.8.8 8.8.8.8[user1@study ~]$ 特定元素赋值 1234[user1@study ~]$ abc=([0]='123' [1]='456')[user1@study ~]$ echo $&#123;abc[0]&#125; $&#123;abc[1]&#125;123 456[user1@study ~]$ 使用命令替换赋值 1234[user1@study ~]$ abc=( $(seq 10) )[user1@study ~]$ echo $&#123;abc[3]&#125;4[user1@study ~]$ 交互式赋值，直接在提示符中写，写后回车即可 12345678910[user1@study ~]$ read -a array_nameTom Jerry [user1@study ~]$ echo $&#123;array_name[0]&#125;Tom[user1@study ~]$ echo $&#123;array_name[1]&#125;Jerry[user1@study ~]$ read -a array_name &lt;&lt;&lt; "Tom Jerry yes no" # 和上面的方法完全一样[user1@study ~]$ echo $&#123;array_name[2]&#125; yes[user1@study ~]$ 关联数组赋值，直接给定下标名 123456[user1@study ~]$ declare -A world[user1@study ~]$ world[us]="america"[user1@study ~]$ world[uk]="United kingdom"[user1@study ~]$ echo $&#123;world[us]&#125;america[user1@study ~]$ 元素值引用引用时只给数组名，表示引用为下标为 0 的元素 123456[user1@study ~]$ read -a array_name &lt;&lt;&lt; "Tom Jerry yes no"[user1@study ~]$ echo $&#123;array_name&#125;Tom[user1@study ~]$ echo $&#123;array_name[3]&#125;no[user1@study ~]$ 使用 ${arrar_name[@]} 或 ${array_name[*]} 可以获取数组中的所有元素，区别是 * 是作为一个整体字符串，而 @ 是把每个位置变量都分别作为独立的字符串 1234567891011121314151617181920[user1@study ~]$ array_name=( $(seq 10) )[user1@study ~]$ echo $&#123;array_name[*]&#125; 1 2 3 4 5 6 7 8 9 10[user1@study ~]$ echo $&#123;array_name[@]&#125; 1 2 3 4 5 6 7 8 9 10[user1@study ~]$ [user1@study ~]$ for i in "$&#123;array_name[*]&#125;";do echo $&#123;i&#125;;done1 2 3 4 5 6 7 8 9 10[user1@study ~]$ for i in "$&#123;array_name[@]&#125;";do echo $&#123;i&#125;;done 12345678910[user1@study ~]$ 数组长度引用取得数组元素的个数 123length=$&#123;#array_name[@]&#125;# 或者length=$&#123;#array_name[*]&#125; 取得数组第一个元素的长度 1lengthn=$&#123;#array_name&#125; 取得数组单个元素的长度 1lengthn=$&#123;#array_name[n]&#125; 元素值提取12345678910[user1@study ~]$ a=(net.nf_conntrack_max=====131072 net.ipv4.ip_forward===1 c====5)[user1@study ~]$ echo $&#123;a[1]#*=&#125; # 删掉数组 a 中第 2 个元素中第一个=及其左边的字符串==1[user1@study ~]$ echo $&#123;a[1]##*=&#125; # 删掉数组 a 中第 2 个元素中最后一个=及其左边的字符串1[user1@study ~]$ echo $&#123;a[1]%=*&#125; # 删掉数组 a 中第 2 个元素中最后一个=及其右边的字符串net.ipv4.ip_forward==[user1@study ~]$ echo $&#123;a[1]%%=*&#125; # 删掉数组 a 中第 2 个元素中第一个=及其右边的字符串net.ipv4.ip_forward[user1@study ~]$ 获取元素下标1234567891011121314[user1@study ~]$ array=(a b c d e f g)[user1@study ~]$ echo $&#123;array[0]&#125; # 数组的第一个元素a[user1@study ~]$ echo $&#123;!array[@]&#125; # 数组所有的下标0 1 2 3 4 5 6[user1@study ~]$ for i in $&#123;!array[@]&#125;;do echo $&#123;array[i]&#125; ;done # 在数组里的所有元素abcdefg[user1@study ~]$ 删除元素直接通过：unset 数组[下标] 可以清除相应的元素；不带下标，清除整个数据 123456789101112[user1@study ~]$ a=( $(seq 10) )[user1@study ~]$ echo $&#123;a[2]&#125;3[user1@study ~]$ unset a[2][user1@study ~]$ echo $&#123;a[2]&#125; [user1@study ~]$ echo $&#123;a[*]&#125;1 2 4 5 6 7 8 9 10[user1@study ~]$ unset a[user1@study ~]$ echo $&#123;a[*]&#125;[user1@study ~]$ 元素切片使用 ${array_name[@]:offset:number} 的格式来实现数组中元素的切片， 其中 offset 指的是要跳过元素的个数， number 指的是要取出元素的个数，省略 number 时，表示取偏移量之后的所有元素 对数组切片后返回的是字符串，中间用空格分开，因此如果切片后的结果加上 ()，将得到切片数组 1234567891011[user1@study ~]$ a=(1 2 3 4 5)[user1@study ~]$ echo $&#123;a[@]:0:3&#125;1 2 3[user1@study ~]$ echo $&#123;a[@]:1:4&#125; 2 3 4 5[user1@study ~]$ c=($&#123;a[@]:1:4&#125;)[user1@study ~]$ echo $&#123;#c[@]&#125;4[user1@study ~]$ echo $&#123;c[*]&#125; 2 3 4 5[user1@study ~]$ 元素值替换使用 ${array_name[@或*]/searchstr/replacestr} 的格式可以实现元素值的查找替换，其中 searchstr 指的是要查找的字符串， replacestr 指的是要替换成什么样的字符串 123456789101112[user1@study ~]$ a=(1 2 3 4 5)[user1@study ~]$ echo $&#123;a[@]/3/100&#125;1 2 100 4 5[user1@study ~]$ echo $&#123;a[@]&#125;1 2 3 4 5[user1@study ~]$ a=($&#123;a[@]/3/100&#125;)[user1@study ~]$ echo $&#123;a[@]&#125;1 2 100 4 5[user1@study ~]$ A=(100 101 102 103 104);B=".txt"[user1@study ~]$ echo $&#123;A[@]/%/$B&#125;100.txt 101.txt 102.txt 103.txt 104.txt[user1@study ~]$ 元素值替换操作不会改变原先数组的内容，如果需要修改则需要重新定义数据。 应用示例设置内核参数 12345678910111213141516171819202122232425262728293031#!/bin/bashargs_of_kernel=(net.ipv4.ip_forward=1 net.ipv4.route.max_size=131072 net.nf_conntrack_max=131072 net.netfilter.nf_conntrack_tcp_timeout_established=1800 net.netfilter.nf_conntrack_tcp_timeout_time_wait=30 net.netfilter.nf_conntrack_tcp_timeout_syn_sent=40 net.ipv4.conf.default.rp_filter=0 net.ipv4.conf.all.rp_filter=0 net.ipv4.conf.default.accept_source_route=0 net.ipv4.conf.all.arp_ignore=1 net.ipv4.conf.all.arp_announce=2)config_of_kernel='/etc/sysctl.conf'cp $&#123;config_of_kernel&#125;&#123;,.bak&#125;for i in $&#123;!args_of_kernel[@]&#125;;do if /bin/egrep -q $&#123;args_of_kernel[$i]%%=*&#125; $config_of_kernel;then /bin/sed -ri "s/(^$&#123;args_of_kernel[$i]%%=*&#125; = ).*/\1$&#123;args_of_kernel[$i]##*=&#125;/" $config_of_kernel else if [ $i -eq 0 ] ;then fgrep -qs forwarding $&#123;kernel_cnf&#125; || echo -e '\n# Controls IP packet forwarding' &gt;&gt; $config_of_kernel line_n=`/bin/gawk '/forwarding/&#123;print NR&#125;' $config_of_kernel` else line_n=`/bin/gawk '/'"$&#123;args_of_kernel[$((i-1))]%%=*&#125;"'/&#123;print NR&#125;' $config_of_kernel` fi /bin/sed -ri "$&#123;line_n&#125;a$&#123;args_of_kernel[$i]%%=*&#125; = $&#123;args_of_kernel[$i]##*=&#125;" $config_of_kernel fidoneunset i line_n config_of_kernel args_of_kernel]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的函数]]></title>
    <url>%2F2015%2F08%2F18%2F092143-shell%E7%9A%84%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[函数函数可将一个复杂功能划分成若干模块，让程序结构更加清晰，代码重复利用率更高。 在 shell 中必须先定义函数，然后使用，而且不能独立运行，需要调用执行。函数可出现在任何位置，在代码执行时，都会被自动替换为函数代码。函数命名不应该为命令名，否则会发生冲突。 函数的定义方式定义方式一 1234function function_name &#123; list of commands [ return value ]&#125; 定义方式二 1234function_name () &#123; list of commands [ return value ]&#125; 函数的生命周期每次被调用时创建，返回时终止。在 RedHat 系列的系统中的 /etc/init.d/functions 文件中有很多系统原生的函数，可以用来参考学习。 调用函数调用函数时直接写函数名即可调用该函数。 1234567891011121314151617181920212223242526272829303132[user1@study ~]$ cat test.sh #!/bin/bashchoice()&#123; read -p "Do you want to continue? [yes/no] " yourchoice case "$&#123;yourchoice&#125;" in y|Y|[yY][eE]|[yY][eE][sS]) echo "OK, you can continue" ;; n|N|[nN][oO]) echo "NO" ;; *) echo "Usage: &#123; yes | no &#125;" exit 5 ;; esac&#125;choice[user1@study ~]$ bash test.sh Do you want to continue? [yes/no] yesOK, you can continue[user1@study ~]$ bash test.sh Do you want to continue? [yes/no] nNO[user1@study ~]$ bash test.shDo you want to continue? [yes/no] test Usage: &#123; yes | no &#125;[user1@study ~]$ 函数的返回值 函数的返回值，可以使用 return 语句；如果不加，则将最后一条命令运行结果作为返回值。 Shell 函数返回值只能是整数，一般用来表示函数执行成功与否，0表示成功，其他值表示失败。 如果 return 其他数据，比如一个字符串，往往会得到错误提示：“numeric argument required” 函数中参数的传递在函数体中当中，可以使用 $1，$2，....$n、$@、$#、$* 等引用传递给函数的位置变量；在调用函数时，在函数名后面以空白符分隔给定参数列表即可 1234567891011121314151617181920212223242526272829303132333435363738[user1@study ~]$ cat test.sh #!/bin/bashaction=$1# 传递给脚本的第一个参数me=$(basename $0)servicectl()&#123; case "$1" in # 这里的 $1 是针对当前函数来说的，不是脚本的 $1 start) echo "$&#123;me&#125; $&#123;action&#125;" ;; stop) echo "$&#123;me&#125; $&#123;action&#125;" ;; reload) echo "$&#123;me&#125; $&#123;action&#125;" ;; restart) echo "$&#123;me&#125; $&#123;action&#125;" ;; *) echo "Usage: $&#123;me&#125; &#123; start | stop | reload | restart &#125;" ;; esac&#125;servicectl $&#123;action&#125;# 通过 action 变量将传递给脚本的第一个参数再传递给函数[user1@study ~]$ bash test.sh Usage: test.sh &#123; start | stop | reload | restart &#125;[user1@study ~]$ bash test.sh starttest.sh start[user1@study ~]$ bash test.sh restarttest.sh restart[user1@study ~]$ 局部变量及作用域使用 local VARIABLE=VALUE 的方式来定义一个局部变量，并且 local 关键字可以省略。局部变量的作用域是当前函数，不能被函数体外面的语句调用，在函数结束时被自动销毁。 123456789101112131415161718[user1@study ~]$ cat test.sh #!/bin/bashname="Jerry"afunc()&#123; local name="Tom" echo $&#123;name&#125;&#125;echo $&#123;name&#125;afunc[user1@study ~]$ bash test.sh JerryTom[user1@study ~]$ 递归函数能够调用自身的函数成为递归函数。经典的 fork 炸弹 1.()&#123;.|.&amp;&#125;;. 说明 12345678910. () # 定义一个名叫 . 的函数，无可选参数&#123;# 函数体开始.|.&amp;# 递归调用函数本身，然后利用管道再次调函数本身并将其放到后台执行&#125;;# 函数体结束.# 调用函数]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的状态返回值]]></title>
    <url>%2F2015%2F08%2F15%2F194139-shell%E7%9A%84%E7%8A%B6%E6%80%81%E8%BF%94%E5%9B%9E%E5%80%BC%2F</url>
    <content type="text"><![CDATA[在 shell 中，每个命令都会返回一个状态返回值。成功的命令返回 0，而不成功的命令返回非零值。非零值通常都被解释成一个错误码。 在 shell 中$? 是一个特殊变量，它所引用的值就是上一条命令的执行状态返回值。 在 shell 的函数执行后，$? 返回的是函数执行的最后一条命令的状态返回值 在 shell 脚本执行之后，$? 返回的是脚本执行的最后一条命令的状态返回值 在脚本中，exit n 命令将会把 n 退出状态码传递给父 shell 并结束整个脚本。n 必须是十进制数, 范围是0 - 255。以下是常见的状态码及意义 0 运行成功 2 权限拒绝 1~125 表示运行失败，脚本命令、系统命令错误或参数传递错误 126 找到命令了，但是无法执行 127 要运行的命令不存在 128 命令被系统强制结束 12345678910111213141516171819202122232425262728[user1@study ~]$ cat exitstatus.sh#! /bin/bashecho -e "Successful execution"echo -e "====================="echo "hello world"# Exit status returns 0, because the above command is a success.echo "Exit status" $? echo -e "Incorrect usage"echo -e "====================="ls --option# Incorrect usage, so exit status will be 2.echo "Exit status" $? echo -e "Command Not found"echo -e "====================="bashscript# Exit status returns 127, because bashscript command not foundecho "Exit status" $? echo -e "Command is not an executable"echo -e "============================="&gt; execution.shls -l execution.sh./execution.sh# Exit status returns 126, because its not an executable.echo "Exit status" $? 执行上面的 exitstatus.sh 查看各种退出状态 1234567891011121314151617181920[user1@study ~]$ bash exitstatus.shSuccessful execution=====================hello worldExit status 0Incorrect usage=====================ls: unrecognized option '--option'Try 'ls --help' for more information.Exit status 2Command Not found=====================exitstatus.sh: line 17: bashscript: command not foundExit status 127Command is not an executable=============================-rw-rw-r-- 1 user1 user1 0 Jul 15 23:33 execution.shexitstatus.sh: line 24: ./execution.sh: Permission deniedExit status 126[user1@study ~]$]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的循环结构及其流程控制]]></title>
    <url>%2F2015%2F08%2F12%2F130111-shell%E7%9A%84%E5%BE%AA%E7%8E%AF%E7%BB%93%E6%9E%84%E5%8F%8A%E5%85%B6%E6%B5%81%E7%A8%8B%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[while(当型)循环结构 标准用法，当 condition 条件满足时执行循环体，否则退出循环 12345while [[ condition ]] ; do # statements1 # statements2 # ...........done 死循环,当触发某条件时退出循环 1234while : ; do # statements1 # statements2 &amp;&amp; breakdone 将文件内容作为标准输入，遍历每一行进行循环体内的所有操作 12345while read col1 col2 ; do # statements1 # statements2 # ...........done &lt; /path/to/filename 将进程替换的内容作为标准输入，遍历每一行进行循环体内的所有操作 12345while read col1 col2 ; do # statements1 # statements2 # ...........done &lt; &lt;(command) until(直到型)循环结构 直到 condition 条件满足时退出循环，否则继续执行循环体 12345until [[ condition ]] ; do # statements1 # statements2 # ...........done for循环结构foreach型循环结构 123456for variable in WordList ; do # statements1 # statements2 # ...........done# in WordList 可省略，省略时相当于 in "$@" C语言型的循环结构 12345for (( exp1 ; exp2 ; exp3 )) ; do # statements1 # statements2 # ...........done 示例一 12345#!/bin/bashfor ((i=1;i&lt;=100;i++));do ((sum=sum+i))doneecho $sum 示例二 12345for i in &#123;1..5&#125; ; do # statements1 # statements2 # …………..done 示例三 12345for i in $(seq 5) ; do # statements1 # statements2 # …………..done 示例四 12345for i in 1 2 3 4 5 ; do # statements1 # statements2 # …………..done 循环控制break 用于打断，跳出当前的整个循环 12345678910111213141516171819[user1@study ~]$ cat test.sh#!/bin/bashfor i in Tom 1 2 3 4 Jerry 5 6 7 8;do if [[ "$&#123;i&#125;" == "Jerry" ]];then break echo 'test' else echo $&#123;i&#125; fidone[user1@study ~]$ bash test.sh Tom1234[user1@study ~]$ continue 会跳过本次循环，忽略剩余代码，进入循环的下一次迭代 1234567891011121314151617181920212223[user1@study ~]$ cat test.sh #!/bin/bashfor i in Tom 1 2 3 4 Jerry 5 6 7 8;do if [[ "$&#123;i&#125;" == "Jerry" ]];then continue echo 'test' else echo $&#123;i&#125; fidone[user1@study ~]$ bash test.sh Tom12345678[user1@study ~]$ : 后面的同一行的语句不做任何操作，可以理解为将语句做了注释，需要注意 : 属于语句，而 # 只是注释符 123456789101112131415161718192021222324[user1@study ~]$ cat test.sh #!/bin/bashfor i in Tom 1 2 3 4 Jerry 5 6 7 8;do if [[ "$&#123;i&#125;" == "Jerry" ]];then : echo "yes" echo 'test' else echo $&#123;i&#125; fidone[user1@study ~]$ bash test.sh Tom1234test5678[user1@study ~]$ 在命令行执行 exit 会退出当前的 shell 终端 12[user1@study ~]$ exitlogout 在脚本中不管在什么地方，执行语句遇到 exit 就会结束整个脚本 123456789101112131415161718192021[user1@study ~]$ cat test.sh #!/bin/bashfor i in Tom 1 2 3 4 Jerry 5 6 7 8;do if [[ "$&#123;i&#125;" == "6" ]];then exit echo 'test' else echo $&#123;i&#125; fidone[user1@study ~]$ bash test.shTom1234Jerry5[user1@study ~]$]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的选择语句分支]]></title>
    <url>%2F2015%2F08%2F09%2F190119-shell%E7%9A%84%E9%80%89%E6%8B%A9%E8%AF%AD%E5%8F%A5%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[面向过程的语句结构： 顺序结构：逐条运行 选择结构：两个或以上的,满足条件时只会执行其中一个满足条件的分支 循环结构：某循环体需要执行多次 If语句分支if单分支12345if [[ condition1 ]] ; then # statements1 # statements2 # ...........fi 12345if ([[ condition1 ]] ) then # statements1 # statements2 # ...........fi if双分支1234567if [[ condition1 ]] ; then # statements1 # statements2else # statements3 # ..........fi if多分支12345678if [[ condition1 ]] ; then # statements1 # statements2elif [[ condition2 ]] ; then # statements3elif [[ condition3 ]] ; then # statements4fi 1234567891011if [[ condition1 ]] ; then # statements1 # statements2elif [[ condition2 ]] ; then # statements3elif [[ condition3 ]] ; then # statements4else # statements5 # ..........fi select语句分支select 表达式是 bash 的一种扩展应用，擅长于交互式场合。用户可以从一组不同的值中进行选择 语法格式 12345select varname in "string1" "string2" ; do # statements1 # statements2 # .....done 示例 123456#!/bin/bashecho "What is your favourite OS?"select var in "Linux" "Gnu Hurd" "Free BSD" "Other" ; do break ;doneecho "You have selected $var" 运行结果 1234567What is your favourite OS?1) Linux2) Gnu Hurd3) Free BSD4) Other#? 1You have selected Linux case语句分支语法格式 123456789101112case word in pattern1) # statements1 ;; pattern2) # statements2 ;; # .......... patternN) # statementsN ;;esac case支持的globbing 1234* # 任意长度的任意字符 ? # 任意单个字符[] # 指定范围内的单个字符 a|b # a或者b]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的条件测试语句和运算符]]></title>
    <url>%2F2015%2F08%2F06%2F212103-shell%E7%9A%84%E6%9D%A1%E4%BB%B6%E6%B5%8B%E8%AF%95%E8%AF%AD%E5%8F%A5%E5%92%8C%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[条件测试语句 语法格式 格式1 test expression 格式2 [ expression ] 格式3 [[ expression ]] [ 是一条命令，它与 test 是等价的。在其中的表达式应是它的命令行参数，所以字符串比较操作符 &gt; 与 &lt; 必须转义，否则就变成 重定向向操作符了 12345 [user1@study ~]$ [ 3 \&gt; 2 ] &amp;&amp; echo yes || echo noyes[user1@study ~]$ [ 1 \&gt; 2 ] &amp;&amp; echo yes || echo no no[user1@study ~]$ [[]] 是是扩展的 test 命令，用 [[]] 测试结构比用 [] 更能防止脚本里的许多逻辑错误。&amp;&amp; 、||、 &lt;、&gt; 操作符能够正常存在于 [[ ]] 中，但不能在 [] 中出现。 1234567891011[user1@study ~]$ [[ "2" = "2" &amp;&amp; "3" = "3" ]] &amp;&amp; echo yes || echo noyes[user1@study ~]$ [[ "2" = "2" &amp;&amp; "3" = "5" ]] &amp;&amp; echo yes || echo no no[user1@study ~]$ [ "2" = "2" &amp;&amp; "3" = "5" ] &amp;&amp; echo yes || echo no -bash: [: missing `]'no[user1@study ~]$ [user1@study ~]$ [[ 3 &gt; 2 ]] &amp;&amp; echo yes || echo noyes[user1@study ~]$ 在 [[]] 中可以使用通配符进行模式匹配 12345[user1@study ~]$ [[ abc123 = abc* ]] &amp;&amp; echo yes || echo noyes[user1@study ~]$ [[ ac123 = abc* ]] &amp;&amp; echo yes || echo no no[user1@study ~]$ 在 [[]] 中使用 =~ 时支持 shell 的正则表达式 12345[user1@study ~]$ [[ '12345' =~ [0-9]&#123;5&#125; ]] &amp;&amp; echo yes || echo noyes[user1@study ~]$ [[ '123afsa' =~ [0-9]&#123;5&#125; ]] &amp;&amp; echo yes || echo no no[user1@study ~]$ 需要注意，不管是 [[]] 还是 [] ，最里面的中括号旁边都必须保留一个空格，否则是语法错误 1234567891011[user1@study ~]$ [3=3] &amp;&amp; echo yes || echo no-bash: [3=3]: command not foundno[user1@study ~]$ [[3=3]] &amp;&amp; echo yes || echo no-bash: [[3=3]]: command not foundno[user1@study ~]$ [[ 3=3 ]] &amp;&amp; echo yes || echo noyes[user1@study ~]$ [ 3=3 ] &amp;&amp; echo yes || echo no yes[user1@study ~]$ 算术运算符 运算符 说明 + 加法 `expr $a + $b` - 减法 `expr $a - $b` * 乘法 `expr $a * $b` / 除法 `expr $a / $b` % 取余 `expr $a % $b` = 赋值 a=$b 将变量b的值赋给 a == 相等。用于比较两个整数，相同则返回 true [ $a == $b ] 返回 false。 != 不等。用于比较两个整数，不同则返回 true [ $a != $b ] 返回 true。 算术运算要对整数进行关系运算可以下面几种方式实现 let 算术运算表达式 12345678[user1@study ~]$ a=1; b=2 [user1@study ~]$ let c=$&#123;a&#125;+$&#123;b&#125;; echo $c3[user1@study ~]$ let c+=1; echo $c4[user1@study ~]$ let c=c+b; echo $c # 等同于 ((c=c+b))，但后者效率更高6[user1@study ~]$ $[算术运算表达式] 12345[user1@study ~]$ a=1; b=2[user1@study ~]$ c=$[$a+$b][user1@study ~]$ echo $c3[user1@study ~]$ $((算术运算表达式)) 12345[user1@study ~]$ a=1; b=2[user1@study ~]$ c=$(($a+$b))[user1@study ~]$ echo $c3[user1@study ~]$ expr 算术运算表达式，要注意 expr 的表达式中各操作符及运算符之间要有空格，且要使用命令替换 12345[user1@study ~]$ a=1; b=2[user1@study ~]$ c=$(expr $a + $b)[user1@study ~]$ echo $c3[user1@study ~]$ 也可以使用 shell 的算术运算符 (()) 进行计算，事实上 (()) 比 let、expr 会更高效，最建议使用这种方式 12345[user1@study ~]$ a=1; b=2 [user1@study ~]$ (( sum=a+b ))[user1@study ~]$ echo $&#123;sum&#125;3[user1@study ~]$ 关系运算符关系运算符只支持整数，不支持字符串，除非字符串的值是整数 运算符 说明 举例 -eq 测试两个整数是否相等，相等返回 true [ $a -eq $b ] -ne 测试两个整数是否相等，不相等返回 true [ $a -ne $b ] -gt 测试左边的整数是否大于右边的，如果是，则返回 true [ $a -gt $b ] -lt 测试左边的整数是否小于右边的，如果是，则返回 true [ $a -lt $b ] -ge 测试左边的整数是否大等于右边的，如果是，则返回 true [ $a -ge $b ] -le 测试左边的数是否小于等于右边的，如果是，则返回 true [ $a -le $b ] 逻辑运算符 运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true [ ! 0 -ne 0 ] 返回true -o 或运算，有一个表达式为 true 则返回 true [ $a -lt 20 -o $b -gt 100 ] -a 与运算，两个表达式都为 true 才返回 true [ $a -lt 20 -a $b -gt 100 ] [ expression1 ] &amp;&amp; [ expression2 ] 等价于 [ expression1 -a expression2 ] 12345[user1@study ~]$ [ "abc" = "abc" -a "bcd" = "efg" ] &amp;&amp; echo yes || echo nono[user1@study ~]$ [ "abc" = "abc" ] &amp;&amp; [ "bcd" = "efg" ] &amp;&amp; echo yes || echo no no[user1@study ~]$ 字符串运算符 运算符 说明 举例 &gt; 测试前面字符串的ASCII码比后面的大 [[ “abc” &gt; “ABC” ]] &lt; 测试前面字符串的ASCII码比后面的小 [[ “abc” &lt; “ABC” ]] = 检测两个字符串是否相等，也可使用== [ “$a” = “$b” ] != 检测两个字符串是否相等，不相等返回 true [ “$a” != “$b” ] =~ 左侧的字符串是否能被右侧的正则表达式模式匹配 “$char” =~ pattern -z 检测字符串长度是否为0，为0返回 true [ -z “$a” ] 或 test -z “$a” -n 检测字符串长度是否为0，不为0返回 true [ -n “$a” ] 或 test -n “$a” str 检测字符串是否不为空，不为空返回 true [ “$a” ] 或 test “$a” 从 Bash 3.2 版本开始，正则表达式和globbing表达式都不能用引号包裹。若表达式里有空格，则可以把它存储到一个变量里： 12a="a b+"[[ "a bbb" =~ $a ]] # true (regex比较) 做个练习，比较一下不同的运算符及其作用 1234567a="abc123"[ "$a" == abc* ] # false (字面比较)[ "$a" == "abc*" ] # false (字面比较)[[ "$a" == abc* ]] # true (globbing比较)[[ "$a" == "abc*" ]] # false (字面比较)[[ "$a" =~ [abc]+[123]+ ]] # true (regex比较)[[ "$a" =~ "abc*" ]] # false (字面比较) 文件测试运算符 运算符 说明 举例 -a file 测试文件（包括目录）是否存在；同-e；-a处于弃用状态 [ -a $file ] -b file 测试文件是否是块设备文件 [ -b $file ] -c file 测试文件是否是字符设备文件； [ -b $file ] -d file 测试文件是否是目录； [ -d $file ] -e file 测试文件（包括目录）是否存在； [ -e $file ] -f file 测试文件是否是普通文件（既不是目录，也不是设备文件）； [ -f $file ] -g file 测试文件是否设置了 SGID 位； [ -g $file ] -G file 文件的group-id是否与你的相同 [ -G $file ] -h file 测试文件是否是符号链接文件；同-L； [ -h /bin/awk ] -k file 测试文件是否设置了粘着位(Sticky Bit)； [ -k $file ] -L file 测试文件是否是符号链接文件；同-h； [ -h /bin/awk ] -N file 测试文件从文件上一次被读取到现在为止，是否被修改过 [ -N $file ] -O file 测试文件的owner是否为当前用户 [ -O $file] -p file 测试文件是否是管道文件； [ -p $file ] -r file 测试文件是否可读； [ -r $file ] -s file 测试文件是否存在且不为空（文件大小是否大于0）。 [ -s $file ] -u file 测试文件是否设置了 SUID 位； [ -u $file ] -w file 测试文件是否可写； [ -w $file ] -x file 测试文件是否可执行； [ -x $file ] f1 -nt f2 测试文件f1是否比文件f2新 f1 -ot f2 测试文件f1是否比文件f2旧 f1 -ef f2 测试文件f1和文件f2是否是相同文件的硬链接]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell命令间的逻辑关系]]></title>
    <url>%2F2015%2F08%2F03%2F212127-shell%E5%91%BD%E4%BB%A4%E9%97%B4%E7%9A%84%E9%80%BB%E8%BE%91%E5%85%B3%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[无逻辑关系 用 ; 间隔的各命令按顺序依次执行 1COMMAND1;COMMAND2;COMMAND3... 逻辑关系 逻辑与： &amp;&amp; 第一个条件为假时，第二条件不用再判断，最终结果已确定； 第一个条件为真时，第二条件必须得判断 &amp;&amp; 前面的命令执行成功则执行 &amp;&amp; 后面的命令 逻辑或：|| 第一个条件为真时，第二条件不用再判断，最终结果已确定； 第一个条件为假时，第二条件必须得判断 || 前面的命令执行不成功则执行 || 后面的命令 ! 对条件的结果取反 从优先级上讲，; 优先级最低，|| 和 &amp;&amp; 具有相同的优先级。在同等优先级上，按从左到右的结合原则执行命令。使用 ( ) 可以组合命令行中的命令，改变执行顺序 123456789! id user6 &amp;&amp; useradd user6id user6 || useradd user6# 如果用户user6不存在，就添加用户user6id user1 &amp;&amp; echo "user1 exists." || useradd user1# 如果用户存在，就显示用户已存在；否则，就添加此用户! id user1 &amp;&amp; useradd user1 || echo "user1 exists."# 如果用户不存在，就添加；否则，显示其已经存在! id user1 &amp;&amp; useradd user1 &amp;&amp; echo "user1" | passwd --stdin user1 || echo "user1 exists."#如果用户不存在，添加并且给密码；否则，显示其已经存在]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell登录提示符与登录提示信息]]></title>
    <url>%2F2015%2F07%2F30%2F214135-shell%E7%99%BB%E5%BD%95%E6%8F%90%E7%A4%BA%E7%AC%A6%E4%B8%8E%E7%99%BB%E5%BD%95%E6%8F%90%E7%A4%BA%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[登录提示符常用参数及含义 在 /etc/bashrc 文件中会设定 PS1 变量，这个变量设置的就是登录之后的提示符信息 12[root@localhost ~]$ echo $PS1[\u@\h \W]\$ 不同的参数代表的含义不同 \d ：代表日期，格式为 weekday month date，例如：”Mon Aug 1” \H ：完整的主机名称 \h ：仅取主机名中的第一个名字 \t ：显示时间为24小时格式 HH:MM;SS \T ：显示时间为12小时格式 \A ：显示时间为24小时格式 HH:MM \u ：当前用户的账号名称 \v ：BASH 的版本信息 \w ：完整的工作目录名称 \W ：利用 basename 取得工作目录名称，只显示最后一个目录名 \# ：下达的第几个命令 \$ ：提示字符，如果是root用户，提示符为 # ，普通用户则为 $ 所以 shell 默认的命令行提示信息的格式 PS1=&#39;[\u@\h \W]\$ &#39; 的意思就是： 1[当前用户的账号名@主机名的第一个名字 工作目录的最后一层目录名]# 颜色参数 在 PS1 中还可以设置字符的颜色，其格式为 \[\e[F;Bm\]........\[\e[0m\]，其中 \[\e[ 作为颜色设定的开始。F 为字体颜色，编号范围是 30-37，B 为背景颜色，编号范围是 40-47，而 \[\e[0m\] 作为颜色设定的结束。 下面是颜色对照表： F B 颜色 30 40 黑色 31 41 红色 32 42 绿色 33 43 黄色 34 44 蓝色 35 45 紫红色 36 46 青蓝色色 37 47 白色 个性化配置命令提示符 在 linux 上终端命令行默认全部为白色，会经常导致命令与输出内容难以分辨，于是我们可以通过自定义 PS1 环境变量来解决这个问题。 一行显示日期和时间，一行显示标准的提示符 123456789[user1@study ~]$ export PS1='\D&#123;%c&#125; \w\n[\u@\H]\$ 'Wed 15 Jul 2015 08:22:15 PM CST ~[user1@study]$ echo Tom TomWed 15 Jul 2015 08:22:19 PM CST ~[user1@study]$ echo Jerry JerryWed 15 Jul 2015 08:22:21 PM CST ~[user1@study]$ 显示当前时间 1234[user1@study ~]$ export PS1="\u@\h [\$(date +%k:%M:%S)]&gt; "user1@study [20:21:24]&gt; echo "yes"yesuser1@study [20:21:29]&gt; 为了能永久生效，一般在 /etc/profile.d/ 下自定义一个专门设置 PS1 的脚本并对其添加可执行权限。上面的格式只是设置了多行提示符，并没有对颜色和自己进行设置。 123[root@study ~]# cat /etc/profile.d/my-PS1.shPS1='\[\e[1;36m\][\u@\H \W]\$\[\e[0m\] '[root@study ~]# 参考链接： https://www.thegeekstuff.com/2008/09/bash-shell-ps1-10-examples-to-make-your-linux-prompt-like-angelina-jolie/ 登录提示信息登录前提示信息每次登录系统时都会有提示信息，这个登录提示信息是针对本地终端 tty{1-6} 的，而并非类SSH登录。 本地终端提示信息默认在文件 /etc/issue 中 12345[user1@study ~]$ cat /etc/issue\SKernel \r on an \m[user1@study ~]$ 文件中使用了转义符，下面做一个简要的说明 123456789\d：显示当前系统日期\s：显示操作系统名称\l：显示登录的终端号，这个比较常用\m：显示硬件体系结构，如x86\n：显示主机名\o：显示域名\r：显示内核版本号\t：显示当前系统时间\u：显示当前登录用户的序列号 远程终端提示信息默认在文件 /etc/issue.net 中，如: 1234[user1@study ~]$ cat /etc/issue.net \SKernel \r on an \m[user1@study ~]$ 在 SSH 服务中默认并没有开启显示信息，要想在 SSH 登录时显示这些内容，可以在服务配置文件 /etc/ssh/sshd_config 文件中，把 参数Banner none 改为 Banner /etc/issue.net，然后重启 sshd 服务重新登录就会看到显示信息。但是 Kernel \r on an \m 这行字符原样显示并没有进行转义，原因是远程信息提示不支持转义符的使用，一般就是用来写一些警告信息。 登陆后提示信息使用环境变量配置文件来输出会比较易于定制，因为都是用 shell 来做的 12345678910111213141516171819202122[user1@study ~]$ cat ~/.bash_profile# .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then . ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/.local/bin:$HOME/binexport PATH# Look at themhname=`hostname`echo "Welcome on $hname."echo -e "Kernel Details: " `uname -smr`echo -e "`bash --version`"echo -ne "Uptime: "; uptimeecho -ne "Server time : "; date 重新登录后就会出现提示信息 12345678910111213[root@study ~]# su - user1Last login: Wed Jul 15 19:43:13 CST 2015 on pts/3Welcome on study.Kernel Details: Linux 3.10.0-862.el7.x86_64 x86_64GNU bash, version 4.2.46(2)-release (x86_64-redhat-linux-gnu)Copyright (C) 2011 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software; you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Uptime: 20:17:08 up 6:49, 9 users, load average: 0.00, 0.01, 0.05Server time : Wed Jul 15 20:17:08 CST 2015[user1@study ~]$ 生产环境的服务器最好做到什么信息都不要提示，以免带来安全问题。如果一定要写，建议写在 /etc/motd 文件中，并且最好写一些警告信息。默认这个文件是空的，将提示信息写入即可。 以下是几个供娱乐使用的提示信息模板 1234567891011121314151617181920212223242526[user1@study ~]$ cat /etc/motd _oo8oo_ o8888888o 88" . "88 (| -_- |) 0\ = /0 ___/'==='\___ .' \\| |// '. / \\||| : |||// \ / _||||| -:- |||||_ \ | | \\\ - /// | | | \_| ''\---/'' |_/ | \ .-\__ '-' __/-. / ___'. .' /--.--\ '. .'___ ."" '&lt; '.___\_&lt;|&gt;_/___.' &gt;' "". | | : `- \`.:`\ _ /`:.`/ -` : | | \ \ `-. \_ __\ /__ _/ .-` / / =====`-.____`.___ \_____/ ___.`____.-`===== `=---=` ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ God bless Never crash[user1@study ~]$ 12345678910111213141516171819202122//////////////////////////////////////////////////////////////////// // _ooOoo_ // // o8888888o // // 88" . "88 // // (| ^_^ |) // // O\ = /O // // ____/`---'\____ // // .' \\| |// `. // // / \\||| : |||// \ // // / _||||| -:- |||||- \ // // | | \\\ - /// | | // // | \_| ''\---/'' | | // // \ .-\__ `-` ___/-. / // // ___`. .' /--.--\ `. . ___ // // ."" '&lt; `.___\_&lt;|&gt;_/___.' &gt;'"". // // | | : `- \`.;`\ _ /`;.`/ - ` : | | // // \ \ `-. \_ __\ /__ _/ .-` / / // // ========`-.____`-.___\_____/___.-`____.-'======== // // `=---=' // // ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ // // 佛祖保佑 永无BUG 永不修改 // //////////////////////////////////////////////////////////////////// 1234567891011/*** * 佛曰: * 写字楼里写字间，写字间里程序员； * 程序人员写程序，又拿程序换酒钱。 * 酒醒只在网上坐，酒醉还来网下眠； * 酒醉酒醒日复日，网上网下年复年。 * 但愿老死电脑间，不愿鞠躬老板前； * 奔驰宝马贵者趣，公交自行程序员。 * 别人笑我忒疯癫，我笑自己命太贱； * 不见满街漂亮妹，哪个归得程序员？ */ 12345678910111213141516171819202122/*** * _ooOoo_ * o8888888o * 88" . "88 * (| -_- |) * O\ = /O * ___/`---'\____ * . ' \\| |// `. * / \\||| : |||// \ * / _||||| -:- |||||- \ * | | \\\ - /// | | * | \_| ''\---/'' | | * \ .-\__ `-` ___/-. / * ___`. .' /--.--\ `. . __ * ."" '&lt; `.___\_&lt;|&gt;_/___.' &gt;'"". * | | : `- \`.;`\ _ /`;.`/ - ` : | | * \ \ `-. \_ __\ /__ _/ .-` / / * ======`-.____`-.___\_____/___.-`____.-'====== * `=---=' * ............................................. * 佛曰：bug泛滥，我已瘫痪！ */ 12345678910111213141516171819//// .::::.// .::::::::.// :::::::::::// ..:::::::::::'// '::::::::::::'// .::::::::::// '::::::::::::::..// ..::::::::::::.// ``::::::::::::::::// ::::``:::::::::' .:::.// ::::' ':::::' .::::::::.// .::::' :::: .:::::::'::::.// .:::' ::::: .:::::::::' ':::::.// .::' :::::.:::::::::' ':::::.// .::' ::::::::::::::' ``::::.// ...::: ::::::::::::' ``::.// ```` ':. ':::::::::' ::::..// '.:::::' ':'````.. 12345678910111213141516** * ┌───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┐ * │Esc│ │ F1│ F2│ F3│ F4│ │ F5│ F6│ F7│ F8│ │ F9│F10│F11│F12│ │P/S│S L│P/B│ ┌┐ ┌┐ ┌┐ * └───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┘ └┘ └┘ └┘ * ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───────┐ ┌───┬───┬───┐ ┌───┬───┬───┬───┐ * │~ `│! 1│@ 2│# 3│$ 4│% 5│^ 6│&amp; 7│* 8│( 9│) 0│_ -│+ =│ BacSp │ │Ins│Hom│PUp│ │N L│ / │ * │ - │ * ├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─────┤ ├───┼───┼───┤ ├───┼───┼───┼───┤ * │ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │&#123; [│&#125; ]│ | \ │ │Del│End│PDn│ │ 7 │ 8 │ 9 │ │ * ├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤ └───┴───┴───┘ ├───┼───┼───┤ + │ * │ Caps │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│" '│ Enter │ │ 4 │ 5 │ 6 │ │ * ├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────────┤ ┌───┐ ├───┼───┼───┼───┤ * │ Shift │ Z │ X │ C │ V │ B │ N │ M │&lt; ,│&gt; .│? /│ Shift │ │ ↑ │ │ 1 │ 2 │ 3 │ │ * ├─────┬──┴─┬─┴──┬┴───┴───┴───┴───┴───┴──┬┴───┼───┴┬────┬────┤ ┌───┼───┼───┐ ├───┴───┼───┤ E││ * │ Ctrl│ │Alt │ Space │ Alt│ │ │Ctrl│ │ ← │ ↓ │ → │ │ 0 │ . │←─┘│ * └─────┴────┴────┴───────────────────────┴────┴────┴────┴────┘ └───┴───┴───┘ └───────┴───┴───┘ * 123456789101112/*** * * █████▒█ ██ ▄████▄ ██ ▄█▀ ██████╗ ██╗ ██╗ ██████╗ * ▓██ ▒ ██ ▓██▒▒██▀ ▀█ ██▄█▒ ██╔══██╗██║ ██║██╔════╝ * ▒████ ░▓██ ▒██░▒▓█ ▄ ▓███▄░ ██████╔╝██║ ██║██║ ███╗ * ░▓█▒ ░▓▓█ ░██░▒▓▓▄ ▄██▒▓██ █▄ ██╔══██╗██║ ██║██║ ██║ * ░▒█░ ▒▒█████▓ ▒ ▓███▀ ░▒██▒ █▄ ██████╔╝╚██████╔╝╚██████╔╝ * ▒ ░ ░▒▓▒ ▒ ▒ ░ ░▒ ▒ ░▒ ▒▒ ▓▒ ╚═════╝ ╚═════╝ ╚═════╝ * ░ ░░▒░ ░ ░ ░ ▒ ░ ░▒ ▒░ * ░ ░ ░░░ ░ ░ ░ ░ ░░ ░ * ░ ░ ░ ░ ░ */ 123456789101112131415161718192021222324/*** * ┌─┐ ┌─┐ * ┌──┘ ┴───────┘ ┴──┐ * │ │ * │ ─── │ * │ ─┬┘ └┬─ │ * │ │ * │ ─┴─ │ * │ │ * └───┐ ┌───┘ * │ │ * │ │ * │ │ * │ └──────────────┐ * │ │ * │ ├─┐ * │ ┌─┘ * │ │ * └─┐ ┐ ┌───────┬──┐ ┌──┘ * │ ─┤ ─┤ │ ─┤ ─┤ * └──┴──┘ └──┴──┘ * 神兽保佑 * 代码无BUG! */ 1234567891011121314151617181920/*** * ___====-_ _-====___ * _--^^^#####// \\#####^^^--_ * _-^##########// ( ) \\##########^-_ * -############// |\^^/| \\############- * _/############// (@::@) \\############\_ * /#############(( \\// ))#############\ * -###############\\ (oo) //###############- * -#################\\ / VV \ //#################- * -###################\\/ \//###################- * _#/|##########/\######( /\ )######/\##########|\#_ * |/ |#/\#/\#/\/ \#/\##\ | | /##/\#/ \/\#/\#/\#| \| * ` |/ V V ` V \#\| | | |/#/ V ' V V \| ' * ` ` ` ` / | | | | \ ' ' ' ' * ( | | | | ) * __\ | | | | /__ * (vvv(VVV)(VVV)vvv) * 神兽保佑 * 代码无BUG! */ 123456789101112131415161718192021222324/*** * * * __----~~~~~~~~~~~------___ * . . ~~//====...... __--~ ~~ * -. \_|// |||\\ ~~~~~~::::... /~ * ___-==_ _-~o~ \/ ||| \\ _/~~- * __---~~~.==~||\=_ -_--~/_-~|- |\\ \\ _/~ * _-~~ .=~ | \\-_ '-~7 /- / || \ / * .~ .~ | \\ -_ / /- / || \ / * / ____ / | \\ ~-_/ /|- _/ .|| \ / * |~~ ~~|--~~~~--_ \ ~==-/ | \~--===~~ .\ * ' ~-| /| |-~\~~ __--~~ * |-~~-_/ | | ~\_ _-~ /\ * / \ \__ \/~ \__ * _--~ _/ | .-~~____--~-/ ~~==. * ((-&gt;/~ '.|||' -_| ~~-/ , . _|| * -_ ~\ ~~---l__i__i__i--~~_/ * _-~-__ ~) \--______________--~~ * //.-~~~-~_--~- |-------~~~~~~~~ * //.-~~~--\ * 神兽保佑 * 代码无BUG! */ 123456789101112131415/*** _ * _._ _..._ .-', _.._(`)) * '-. ` ' /-._.-' ',/ * ) \ '. * / _ _ | \ * | a a / | * \ .-. ; * '-('' ).-' ,' ; * '-; | .' * \ \ / * | 7 .__ _.-\ \ * | | | ``/ /` / * /,_| | /,_/ / * /,_/ '`-' */ 123456789101112131415161718192021222324/*** ************************************************************** * * * .=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-. * * | ______ | * * | .-" "-. | * * | / \ | * * | _ | | _ | * * | ( \ |, .-. .-. ,| / ) | * * | &gt; "=._ | )(__/ \__)( | _.=" &lt; | * * | (_/"=._"=._ |/ /\ \| _.="_.="\_) | * * | "=._"(_ ^^ _)"_.=" | * * | "=\__|IIIIII|__/=" | * * | _.="| \IIIIII/ |"=._ | * * | _ _.="_.="\ /"=._"=._ _ | * * | ( \_.="_.=" `--------` "=._"=._/ ) | * * | &gt; _.=" "=._ &lt; | * * | (_/ \_) | * * | | * * '-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=' * * * * LASCIATE OGNI SPERANZA, VOI CH'ENTRATE * ************************************************************** */ 123456789101112131415161718192021222324252627282930313233/*** * ,s555SB@@&amp; * :9H####@@@@@Xi * 1@@@@@@@@@@@@@@8 * ,8@@@@@@@@@B@@@@@@8 * :B@@@@X3hi8Bs;B@@@@@Ah, * ,8i r@@@B: 1S ,M@@@@@@#8; * 1AB35.i: X@@8 . SGhr ,A@@@@@@@@S * 1@h31MX8 18Hhh3i .i3r ,A@@@@@@@@@5 * ;@&amp;i,58r5 rGSS: :B@@@@@@@@@@A * 1#i . 9i hX. .: .5@@@@@@@@@@@1 * sG1, ,G53s. 9#Xi;hS5 3B@@@@@@@B1 * .h8h.,A@@@MXSs, #@H1: 3ssSSX@1 * s ,@@@@@@@@@@@@Xhi, r#@@X1s9M8 .GA981 * ,. rS8H#@@@@@@@@@@#HG51;. .h31i;9@r .8@@@@BS;i; * .19AXXXAB@@@@@@@@@@@@@@#MHXG893hrX#XGGXM@@@@@@@@@@MS * s@@MM@@@hsX#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@&amp;, * :GB@#3G@@Brs ,1GM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@B, * .hM@@@#@@#MX 51 r;iSGAM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@8 * :3B@@@@@@@@@@@&amp;9@h :Gs .;sSXH@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: * s&amp;HA#@@@@@@@@@@@@@@M89A;.8S. ,r3@@@@@@@@@@@@@@@@@@@@@@@@@@@r * ,13B@@@@@@@@@@@@@@@@@@@5 5B3 ;. ;@@@@@@@@@@@@@@@@@@@@@@@@@@@i * 5#@@#&amp;@@@@@@@@@@@@@@@@@@9 .39: ;@@@@@@@@@@@@@@@@@@@@@@@@@@@; * 9@@@X:MM@@@@@@@@@@@@@@@#; ;31. H@@@@@@@@@@@@@@@@@@@@@@@@@@: * SH#@B9.rM@@@@@@@@@@@@@B :. 3@@@@@@@@@@@@@@@@@@@@@@@@@@5 * ,:. 9@@@@@@@@@@@#HB5 .M@@@@@@@@@@@@@@@@@@@@@@@@@B * ,ssirhSM@&amp;1;i19911i,. s@@@@@@@@@@@@@@@@@@@@@@@@@@S * ,,,rHAri1h1rh&amp;@#353Sh: 8@@@@@@@@@@@@@@@@@@@@@@@@@#: * .A3hH@#5S553&amp;@@#h i:i9S #@@@@@@@@@@@@@@@@@@@@@@@@@A. * * * 又看源码，看你妹妹呀！ */ 12345678910111213141516171819202122232425/*** *_______________#########_______________________ *______________############_____________________ *______________#############____________________ *_____________##__###########___________________ *____________###__######_#####__________________ *____________###_#######___####_________________ *___________###__##########_####________________ *__________####__###########_####_______________ *________#####___###########__#####_____________ *_______######___###_########___#####___________ *_______#####___###___########___######_________ *______######___###__###########___######_______ *_____######___####_##############__######______ *____#######__#####################_#######_____ *____#######__##############################____ *___#######__######_#################_#######___ *___#######__######_######_#########___######___ *___#######____##__######___######_____######___ *___#######________######____#####_____#####____ *____######________#####_____#####_____####_____ *_____#####________####______#####_____###______ *______#####______;###________###______#________ *________##_______####________####______________ */ 1234567891011121314151617181920212223242526272829/*** * http://www.freebuf.com/ * _.._ ,------------. * ,' `. ( We want you! ) * / __) __` \ `-,----------' * ( (`-`(-') ) _.-' * /) \ = / ( * /' |--' . \ * ( ,---| `-.)__` * )( `-.,--' _`-. * '/,' ( Uu", * (_ , `/,-' ) * `.__, : `-'/ /`--' * | `--' | * ` `-._ / * \ ( * /\ . \. freebuf * / |` \ ,-\ * / \| .) / \ * ( ,'|\ ,' : * | \,`.`--"/ &#125; * `,' \ |,' / * / "-._ `-/ | * "-. "-.,'| ; * / _/["---'""] * : / |"- ' * ' | / * ` | */ 123456789101112131415/*** * http://www.flvcd.com/ * .--, .--, * ( ( \.---./ ) ) * '.__/o o\__.' * &#123;= ^ =&#125; * &gt; - &lt; * / \ * // \\ * //| . |\\ * "'\ /'"_.-~^`'-. * \ _ /--' ` * ___)( )(___ * (((__) (__))) 高山仰止,景行行止.虽不能至,心向往之。 */ 参考链接：http://www.asciiworld.com]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的模式与环境变量的配置文件]]></title>
    <url>%2F2015%2F07%2F27%2F210135-shell%E7%9A%84%E6%A8%A1%E5%BC%8F%E4%B8%8E%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[四种模式登录式Shell（login shell）取得 bash 时需要完整的登入流程，就称为 login shell 正常通过某终端登录的 shell，当系统启动时或开启一个新的终端登录系统时，系统通过调用 /bin/login 程序处理登录并在一个 shell 中显示命令行提示符，这个 shell 就是 login shell；该 shell 程序可以是 bash 也可以是 sh 或 csh，具体使用哪种 shell 可以在 /etc/passwd 中设置（/bin/login 程序读取该文件决定使用哪种 Shell）。 使用命令 su - USERNAME 或 su -l USERNAME 进行用户切换，这种切换方式是完全切换到了另一个的用户环境，也是 login shell 非登录式Shell（non-login shell）以 X window 登入Linux后，再以X的图形化界面启动命令终端，此时的命令终端并不需要再次输入用户名和密码，所以此时 bash 的环境就称为 non-login shell 自动执行的 shell 脚本也是 non-login shell 使用命令 su USERNAME 进行用户切换，这种切换方式不会切换使用用户的环境，也属于 non-login shell Interactive shell and non-interactive shellinteractive shell 即交互式 shell，会有一个输入提示符，并且它的标准输入、输出和错误输出都会显示在控制台上。所以一般来说只要是需要用户交互的，即一个命令一个命令的输入的 shell 都是 interactive shell。 non-interactive shell，即非交互式 shell，无需用户交互。通常来说如 bash script.sh 此类执行脚本的命令就会启动一个 non-interactive shell，它不需要与用户进行交互，执行完后它便会退出创建的 shell。 打印 shell 内置的特殊变量 $-，就能知道当前的 shell 是不是交互式的。一旦输出的结果中包含了 i 就说明当前的 shell 是 interactive shell ，也就是交互式 shell。 123[user1@study ~]$ echo $-himBH[user1@study ~]$ 典型的启动方式及其shell模式1）登陆机器后的第一个Shell：属于 login + interactive 2）新启动一个 Shell 进程，如运行bash：属于 non-login + interactive 3）执行脚本，如 bash script.sh：属于 non-login + non-interactive 4）运行头部有如 #!/usr/bin/env bash 的可执行文件，如 ./executable：属于 non-login + non-interactive 5）通过ssh登陆到远程主机：属于 login + interactive 6）远程执行脚本，如 ssh user@remote script.sh：属于 non-login + non-interactive 7）远程执行脚本，同时请求控制台，如 ssh user@remote -t &#39;echo $PWD&#39;：属于 non-login + interactive 8）在图形化界面中打开终端：属于 non-login + interactive Bash 环境变量的配置文件全局配置：针对所有用户生效的，它的配置文件有 /etc/profile 和 /etc/profile.d/*.sh 以及 /etc/bashrc 个人配置：仅对当前用户生效，每个用户家目录都有两个环境变量配置文件 ~/.bash_profile 和 ~/.bashrc 文件的读取顺序登录式shell 1）登陆2）执行 /etc/profile3）/etc/profile 调用并执行 /etc/profile.d/*.sh4） 执行 ~/.bash_profile ==&gt;5） ~/.bash_profile 调用并执行 ~/.bashrc6） ~/.bashrc 调用并执行 /etc/bashrc命令提示符 非登录式shell ~/.bashrc ==&gt; /etc/bashrc ==&gt; /etc/profile.d/*.sh Bash 环境变量配置文件作用profile 类的文件用来设定系统环境环境和启动程序，用于登录的设置；bashrc 类的文件用于设定本地变量，定义命令别名 /etc/profile 它是系统整体的配置文件，该配置文件里包含很多重要的变量信息，每个用户登陆取得 bash 后一定会读取这个配置文件。如果你想要设定环境变量对所有用户起作用，就要在这个地方设置。大概内容如下: (1) USER 变量设置。 (2) LOGNAME 变量设置。 (3) MAIL 变量设置。 (4) PATH 变量设置。 (5) HOSTNAME 变量设置。 (6) HISTSIZE 变量设置1000。 (7) 然后使用export把以上所有变量声明成环境变量。 (8) 管理员和普通用户的umask设置。 (9) 调用并执行 /etc/profile.d/*.sh 文件。 /etc/profile.d/*.sh 在这个目录下一般用户可以自定义一些脚本，系统默认也有一些脚本，如 /etc/profile.d/lang.sh 这个脚本，其中最重要的就是这个脚本调用了 /etc/locale.conf 和 $HOME/.i18n 这两个文件，而这个文件中定义的就是系统的默认语言 123[user1@study ~]$ cat /etc/locale.conf LANG="en_US.UTF-8"[user1@study ~]$ ~/.bash_profile 这个文件文件会先检查 ~/.bashrc 是否存在，然后会执行 export PATH 定义 PATH 这个环境变量。 12345678910111213[user1@study ~]$ cat ~/.bash_profile # .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then . ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/.local/bin:$HOME/binexport PATH ~/.bashrc 这个文件中会先检查 /etc//.bashrc 是否存在，然后调用并执行。~/.bashrc 主要是用来定义别名使用的，如果你要定义别名就可以放在这个文件中 /etc/bashrc 这个文件定义了 PS1 变量，可以用来设定登录提示符等信息；设定本地变量，添加定义命令别名。并且特别针对非登录的 shell 重新设定了一些变量，如 PATH，PS1 等。 注意: 按照文件的启动顺序，基本上定义的所有变量都会生效，但是后面启动的文件中定义的变量会覆盖前面文件中定义的相同名称的变量。所以要想更好地设定一些变量和别名，就需要知道这些文件的作用域以及非登录式 shell 和登录式 shell 各自应用哪些文件 其他变量配置文件 ~/.bash_logout 用户登出时使用的配置文件，默认这个文件是空的，如果你想在退出系统时做什么操作就可以在这个文件中定义，如果说退出登录时可以执行命令“history -c”清空历史命令。 ~/.bash_history 这个文件是用来记录用户操作的历史命令的，默认HISTSIZE=1000定义在/etc/profile文件中，你可以把这个变量值改的大一点都行。但是注意这个文件中定义的历史命令跟你用history命令查看的可能不尽相同。因为文件中的都是磁盘上，而history查看的在内存中。 ~/.viminfo 用环境变量来定义vim使用时的一些状态，比如是否显示行数、高亮等。 ~/.vimrc vim的用户配置，全局配置文件为/etc/vimrc ~/.mysql_history 安装MySQL之后就会生成这个文件，跟.bash_history作用基本相同，不同的是.mysql_history是用来记录SQL语句的。 将配置文件立即生效使用 source 或 . 都可以使环境变量配置文件立即生效，也可用于在编写脚本时加载脚本定义的配置文件 12source /PATH/TO/PROFILE. /PATH/TO/PROFILE]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell中对变量的操作]]></title>
    <url>%2F2015%2F07%2F24%2F094139-shell%E4%B8%AD%E5%AF%B9%E5%8F%98%E9%87%8F%E7%9A%84%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[声明变量声明变量通常使用 declare 命令来操作 123456$ declare [OPTIONS] VARIABLES-i # 整型-a # 数值-x # 环境变量-r # 只读变量，不能撤销，不能修改，相当于readonly-f # 声明函数 不使用 declare ，直接使用等号也没有任何问题 12declare -i A=20b=30 变量赋值变量赋值的时候，等号两边不能有空格，如果值里面包括空格必须用引号，variable=&quot;hello world&quot; 12345var_name =VALUE # 这里的变量为本地变量declare -i var_name=VALUE # 定义为整型declare -x var_name=VALUE # 定义为环境变量declare -r var_name=VALUE 或 readonly var_name=VALUE# 只读变量只有进程结果后才会撤销，若定义在环境配置文件中则需要手动清除 变量引用变量的引用实际就是将变量名替换为变量所指向的数据。 12345[user1@study ~]$ a=123;echo $a123[user1@study ~]$ b=456;echo $&#123;b&#125;456[user1@study ~]$ 变量撤销使用 $ 可以对变量进行引用，在撤销变量的时候不需要 $ 直接使用变量名即可 123456[user1@study ~]$ a='Tom';b='Jerry';echo $a and $bTom and Jerry[user1@study ~]$ unset a b[user1@study ~]$ echo $a and $band[user1@study ~]$ 变量间接引用当一个变量所指向的数据是另外一个变量的名字时，可以间接性的引用那个变量所对应的数据。通常使用 ${!var_name} 的方式来实现 123456[user1@study ~]$ message=hello[user1@study ~]$ hello=goodbye[user1@study ~]$ echo $message hello[user1@study ~]$ echo $&#123;!message&#125;goodbye 使用转义符 \ 对 $ 转义而后交给 eval 命令也能实现变量的间接引用 1234567[user1@study ~]$ message=hello;hello=goodbye[user1@study ~]$ echo $message hello[user1@study ~]$ eval x=\$$message[user1@study ~]$ echo $&#123;x&#125;goodbye[user1@study ~]$ 变量的查看123456set # 显示(设置)所有 shell 变量（包括环境变量及本地变量）env # 显示(设置)当 前shell 的环境变量printenv # 同 envexport # 显示(设置)导出成当前 shell 环境变量的变量。declare -x # 同 export declare -r # 显示只读变量 示例 12345678910[user1@study ~]$ name='Tom';echo $&#123;name&#125; # shell 本地变量设定及其引用Tom[user1@study ~]$ env | grep name # 当前 shell 的环境变量不存在[user1@study ~]$ set | grep name # 本地变量存在name=Tom[user1@study ~]$ export | grep name # 导出成当前 shell 的环境变量也不存在[user1@study ~]$ export name # 使用 export 导出为当前shell的环境变量[user1@study ~]$ env | grep namename=Tom[user1@study ~]$ 从变量提取字符串假设定义了变量 strings 1234[user1@study ~]$ strings=hello.10.10.10.10.test.world[user1@study ~]$ echo $&#123;strings&#125; hello.10.10.10.10.test.world[user1@study ~]$ ${strings#*10} 删除掉第一个 10 和它左边的字符串 123[user1@study ~]$ echo $&#123;strings#*10&#125;.10.10.10.test.world[user1@study ~]$ ${strings##*10} 删除掉最后一个 10 和它左边的字符串 123[user1@study ~]$ echo $&#123;strings##*10&#125;.test.world[user1@study ~]$ ${strings%10*} 删除掉最后一个 10 和它右边的字符串 123[user1@study ~]$ echo $&#123;strings%10*&#125; hello.10.10.10.[user1@study ~]$ ${strings%%10*} 删除掉第一个 10 和它右边的字符串 123[user1@study ~]$ echo $&#123;strings%%10*&#125;hello.[user1@study ~]$ 看上去有些绕，为了便于记忆，可以用键盘上的 $ 做个分隔。键盘上 # 位于 $ 的左边，所以提取字符串的时候向左删除，% 位于 $ 的右边，所以提取字符串的时候向右删除。 这里用到的 * 只是一个通配符，有的时候可以不要。单一符号最小匹配，两个符号最大匹配，匹配到的内容删掉。 基于字符串切片从变量指向的字符串中按照指定长度切取数据 ${var:offset:length} offset：要跳过字节的个数； length：取出字节的长度，如果省略则取偏移量后所有元素 ${var: -length} 操作示例 123456789101112[user1@study ~]$ mypath="/etc/sysconfig/network-scripts/"[user1@study ~]$ echo $&#123;mypath:5&#125; # 提取最左边的 5 个字节右边的内容sysconfig/network-scripts/[user1@study ~]$ echo $&#123;mypath:10&#125; # 提取第 10 个字节右边的内容nfig/network-scripts/[user1@study ~]$ echo $&#123;mypath:4:10&#125; # 提取第 4 个字节右边的 10 个字节长度的内容/sysconfig[user1@study ~]$ echo $&#123;mypath: -10&#125; # 取出字符串最后10个字节，- 前面需要有空格k-scripts/[user1@study ~]$ echo $&#123;#mypath&#125; # 取出字符长度31[user1@study ~]$ 大小写切换${a^^} 把 $a 中所有小写字母替换为大写 123[user1@study ~]$ a='Tom and Jerry';echo $&#123;a^^&#125;TOM AND JERRY[user1@study ~]$ ${a,,} 把$a` 中所有大写字母替换为小写 123[user1@study ~]$ a='Tom and Jerry';echo $&#123;a,,&#125;tom and jerry[user1@study ~]$ 变量展开12345678$&#123;a=hehe&#125; # 若 $a 未设定，则用 hehe 作传回值，同时将 $a 赋值为 hehe (空及非空时不作处理)$&#123;a:=hehe&#125; # 若 $a 未设定或为空，则使用hehe作传回值，同时将 $a 赋值为hehe (非空时不作处理)$&#123;a-hehe&#125; # 若 $a 未设定，则使用 hehe 作传回值(空及非空时不作处理)$&#123;a:-hehe&#125; # 若 $a 未设定或为空，则使用hehe 作传回值(非空时不作处理)$&#123;a+hehe&#125; # 若 $a 设为空或非空，则使用hehe作传回值(未设定时不作处理)$&#123;a:+hehe&#125; # 若 $a 为非空，则使用 hehe 作传回值(未设定及空时不作处理)$&#123;a?hehe&#125; # 若 $a 未设定，则将 hehe 输出至STDERR(空及非空时不作处理)$&#123;a:?hehe&#125; # 若 $a 未设定或为空，则将 hehe 输出至 STDERR(非空时不作处理) 以上的理解在于，要分清楚 unset 与 null 及 non-null 这三种赋值状态。 其中 :与 null 有关，如果不带 : 则 null 不受影响；如果带了 : 则连 null 也受影响。 字符串的替换(globbing)1234$&#123;a/hehe/haha&#125; # 将变量 a 中第一个 hehe 提换为 haha$&#123;a//hehe/haha&#125; # 将变量 a 中全部 hehe 提换为 haha $&#123;string/#substring/replace&#125; # 若 $strting 最前面匹配substring，就用replace来替换substring$&#123;string/%substring/replace&#125; # 若 $strting 最后面匹配substring，就用replace来替换substring 字符串的删除(globbing)1234$&#123;a/hehe&#125; # 查找 $a 中首次匹配到的字符串hehe,并删除之$&#123;a//hehe&#125; # 查找 $a 中所有匹配到的字符串hehe,并删除之$&#123;a/#hehe&#125; # 查找 $a 中首部匹配到的字符串hehe,并删除之$&#123;a/%hehe&#125; # 查找 $a 中尾部到的字符串hehe,并删除之]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell的变量和分类]]></title>
    <url>%2F2015%2F07%2F21%2F152123-shell%E7%9A%84%E5%8F%98%E9%87%8F%E5%92%8C%E5%88%86%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[什么是变量变量，就是一个容器用来存储数据也是一段内存空间（内存是编制的存储单元）；通过变量赋值在变量中存储数据，然后可以通过变量名访问到的存储信息的内存空间地址。 变量是脚本语言的核心，shell 脚本又是无类型的，所以要使用变量就需要引用。 数据类型数据类型是指用来事先定义数据的存储格式和存储长度，参与的运算。 数据类型的重要性：有一种系统攻击叫缓冲区溢出，如声明一个数据类型为整型并申请 1 字节空间。当在这个变量中存储 256 时，这个整型数据时就会产生溢出，因为 1 字节是 8 个位存储单元的存储范围是 0-255。而 256 就存储不了也就会产生溢出占用其他进程空间，解决缓冲溢出最简单的方法就是当用户存储一个数据时先检查数据是否可以存储下。 对于解释型语言来说，它的数据类型都是弱类型的。不管变量中的数据有没有类型都可以，因为解释器能理解，而且由解释器在另外一个层次给予避免。 对于编译型语言来说，一旦数据类型出了问题只能靠程序自身来解决，它没有额外的一层保护机制，编译器也可以在编译时检查明显错误，但是对于后期用户输入进来的数据就无法检查了，所以但凡编译型语言都是强类型编译必须事先严格定义变量中的数据类型。 常用的数据类型有字符型，数值型，时间日期型，布尔型等等。 Bash 对变量的机制 所有变量都看作为字符型 它不支持浮点型数据，如果想要支持则需借助外部机制才能实现 变量无需事先声明，也就是说变量赋值和变量声明是同时进行的 Tips： 变量引用机制：把变量名出现的位置，直接替换为其所指向的内存空间中的数据 变量的命名规范 不能以数字开头，只能包含数字、字母、下划线，且变量名中不能出现空格 不能使用下划线以外的标点符号 不能使用程序语言的保留字（if else while 等），保留关键字可以尝试 help if 这种方式查看 变量名最好做到见名知义 Tips： 命名规则针对的是自定义变量 变量分类本地变量本地变量作用域只对当前 shell 进程生效，对子 shell、其他 shell 进程无效。Bash 默认变量都是本地变量。 12345678# 定义本地变量set VAR_NAME=value# set一般都可以省略，如下VAR_NAME=VALUE# 引用变量,其中&#123;&#125;一般可省略，直接echo $VAR_NAME;echo $&#123;VAR_NAME&#125; 局部变量局部变量作用域对当前代码段有效，在一个脚本的函数中的变量跟函数外的变量名同名，就可以把函数内的变量定义为局部变量，这样就不会跟其他变量冲突。 12345678910111213141516[user1@study ~]$ cat test.sh#!/bin/bashname='Tom'func()&#123; # 定义局部变量 local name='Jerry' echo $&#123;name&#125;&#125;func[user1@study ~]$ bash test.sh Jerry[user1@study ~]$ 环境变量环境变量用来定义每一个用户的操作环境，变量作用域只对当前用户 shell 进程及其子 shell 生效，并且机器重启变量失效。如我们常用的 PATH 变量就是一个环境变量，不管机器有没有重启，PATH 变量重来没有失效过，这是因为针对环境变量有特定的环境变量配置文件，每一次用户登录就会加载此配置文件，同理在此文件中的变量就会生效。 定义环境变量123456789# 定义环境变量，定义不存在的变量为环境变量;export VAR_NAME=value# 或如下方式declare -x VAR_NAME=VALUE# 或如下方式VARNAME=VALUE ; export VARNAME# 定义环境变量,定义已存在的变量为环境变量；$ export VAR_NAME 查看当前系统环境变量12345set # 显示(设置)所有shell变量（包括环境变量及本地变量）env # 显示(设置)当前shell的环境变量printenv # 同envexport # 显示(设置)导出成当前shell环境变量的变量。declare -x # 同export 常见的系统环境变量 变量名称 含义 SHELL 当前用户用的是哪种Shell BASH bash的路径 BASH_VERSION bash的版本号 LANG 字符集，是和语言相关的环境变量，使用多种语言的用户可以修改此环境变量 HOSTNAME 主机的名称，许多应用程序如果要用到主机名的话，通常是从这个环境变量中来取得的 HOSTTYPE 主机架构类型，用来识别系统硬件 MACHTYPE 平台类型，系统平台依赖的编译平台 OSTYPE 系统类型 LOGNAME 当前用户的登录名 USER 当前的用户 UID 当前的用户的ID号 EUID 有效用户的ID号 HOME 当前用户的家目录 PWD 当前目录 OLDPWD 上次使用的目录 PATH 包含一系列由冒号分隔开的目录，系统从这些目录里寻找可执行文件。若输入的可执行文件不在这些目录中，系统就无法执行它（除非输入绝对路径） LDPATH 包含一系列用冒号隔开的目录，动态链接器将在这些目录里查找库文件 MANPATH 包含一系列用冒号隔开的目录，命令man会在这些目录里搜索man页面，在/etc/man.config或/etc/man_db.conf中定义 INFODIR 包含一系列用冒号隔开的目录，命令info将在这些目录里搜索info页面 PAGER 包含浏览文件内容的程序的路径（例如less或者more） EDITOR 包含修改文件内容的程序（文件编辑器）的路径（比如nano或者vi） KDEDIRS 包含一系列用冒号隔开的目录，里面放的是KDE相关的资料 MAIL 当前用户的邮件存放目录 HISTSIZE 保存历史命令记录的条数 PS1 命令提示符，对于root用户是#，对于普通用户是$ PS2 是附属提示符，默认是“&gt;”。可以通过修改此环境变量来修改当前的命令符 PS3 第三提示符，用于select命令中 PS4 第四提示符，当使用-X选项调用脚本时，显示的提示符，默认为+号 举个例子，PS2 我们已经知道它是附属提示符，默认是“&gt;”。我们改成其他的来试试。 123456[user1@practice ~]$ export PS2='........'[user1@practice ~]$ if true;then........echo "$&#123;USER&#125;";........fiuser1[user1@practice ~]$ 位置变量传递给脚本或函数的位置参数就是位置变量，引用方式为 $1，$2，…$9，${10}，${11}…${n}，位置变量都是只读的。 1234567891011121314[user1@study ~]$ cat test.sh #!/bin/bashecho "1: $&#123;1&#125;"echo "2: $&#123;2&#125;"echo "3: $&#123;3&#125;"echo "4: $&#123;4&#125;"[user1@study ~]$ bash test.sh Tom Jerry yes no1: Tom2: Jerry3: yes4: no[user1@study ~]$ shift 用来把脚本或函数的位置变量列表向左移动指定的位数(n)，如果 shift 后没有参数，则将位置变量向左移动一位。一旦移位发生，被移出列表的位置变量将被永远删除。 123456789101112131415161718192021[user1@study ~]$ cat test.sh #!/bin/bashecho "$1"shift# 移除第一个位置参数，并把后面的第二个位置参数放到第一个位置，以此类推echo "$1"shift 5# 从当前的位置参数开始，移除 5 个并将之后的位置参数顶替上来echo "arg1: $&#123;1&#125;"echo "arg2: $&#123;2&#125;"echo "arg3: $&#123;3&#125;"[user1@study ~]$ bash test.sh 1 2 3 4 5 6 7 8 9 1012arg1: 7arg2: 8arg3: 9[user1@study ~]$ 特殊变量在 shell 中，会对一些参数做特殊处理，而这些参数只能被引用不能被赋值 $0 代表当前脚本文件的文件名 12345678[user1@study ~]$ cat test.sh #!/bin/bashecho "Usage : $&#123;0&#125; &#123; start | stop &#125;"[user1@study ~]$ bash test.sh Usage : test.sh &#123; start | stop &#125;[user1@study ~]$ $$ 取得当前 shell 脚本或终端的进程 ID 1234567[user1@study ~]$ ps -ef | grep bashroot 1211 1209 0 13:28 pts/0 00:00:00 -bashuser1 1315 1314 0 14:42 pts/0 00:00:00 -bashuser1 1417 1315 0 16:04 pts/0 00:00:00 grep --color=auto bash[user1@study ~]$ echo $$1315[user1@study ~]$ $! 取得上一条在后台执行命令的进程ID 12345678[user1@study ~]$ sleep 50s &amp;[1] 1419[user1@study ~]$ echo $!1419[user1@study ~]$ ps -ef | grep sleepuser1 1419 1315 0 16:07 pts/0 00:00:00 sleep 50suser1 1421 1315 0 16:07 pts/0 00:00:00 grep --color=auto sleep[user1@study ~]$ $# 取得位置参数的个数 12345678910111213[user1@study ~]$ cat test.sh #!/bin/bashecho "total: $#"[user1@study ~]$ [user1@study ~]$ bash test.sh total: 0[user1@study ~]$ bash test.sh Tom Jerry yes nototal: 4[user1@study ~]$ bash test.sh Tom Jerry yes total: 3[user1@study ~]$ 1$&#123;!#&#125; 取得位置参数中的最后一个参数，将 $# 的值赋值给一个变量而后使用 ! 也可以达到同样的效果 1234567891011121314151617181920[user1@study ~]$ cat test.sh #!/bin/bashecho "total: $#"echo "First: $1"echo "Last: $&#123;!#&#125;"x=$#echo "Last: $&#123;!x&#125;"[user1@study ~]$ bash test.shtotal: 0First: Last: test.shLast: test.sh[user1@study ~]$ bash test.sh 1 2 3 4 5total: 5First: 1Last: 5Last: 5[user1@study ~]$ $* 和 $@ 都指的是所有的位置变量，区别是 $* 是作为一个整体字符串，而 $@ 是把每个位置变量都分别作为独立的字符串 1234567891011121314151617181920212223242526272829[user1@study ~]$ cat test.sh #!/bin/bashecho "total: $#"echo '$*'echo '-----------------------'for i in "$*";do echo $&#123;i&#125;;doneecho '-----------------------'echo '$@'echo '***********************'for i in "$@";do echo $&#123;i&#125;;doneecho '***********************'[user1@study ~]$ bash test.sh Tom Jerry yes nototal: 4$*-----------------------Tom Jerry yes no-----------------------$@***********************TomJerryyesno***********************[user1@study ~]$ $- 指的是当前 shell 进程使用了哪些选项，与 set 命令的功能有些类似，要注意不是 shell 脚本的位置参数，而是针对进程级别的设置的选项 123[user1@study ~]$ echo $-himBH[user1@study ~]$ $_ 取得上一个命令或脚本的最后一个参数 12345678910[user1@study ~]$ cat test.sh #!/bin/bashecho &#123;1..5&#125;echo $_[user1@study ~]$ bash test.sh 1 2 3 4 55[user1@study ~]$ $? 指的是上一个命令或脚本的执行状态返回值，执行正常则其值为 0，否则为非 0 数字 1234567[user1@study ~]$ echo '123abc' | grep 123 &amp;&gt;/dev/null[user1@study ~]$ echo $?0[user1@study ~]$ echo '123abc' | grep '456' &amp;&gt;/dev/null[user1@study ~]$ echo $?1[user1@study ~]$]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之 Here Documents 与 Here Strings]]></title>
    <url>%2F2015%2F07%2F20%2F194143-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8BHereDocuments%E4%B8%8EHereStrings%2F</url>
    <content type="text"><![CDATA[Here DocumentsHere Documents 作为重定向的一种方式，指的是 shell 从源文件的当前位置开始读取输出，直到遇到只包含一个单词的文本行时结束。在该过程中读到的所有文本行都将作为某一个命令的标准输入而使用。 Here Documents 的使用形式： 123command &lt;&lt;[-] limit_string msg_bodylimit_string 对于 cat 命令在使用 Here Documents 时默认的标准输入是从键盘的输入读进来的，默认的输出是屏幕 1234567891011[user1@study ~]$ cat &lt;&lt; EOF&gt; 1234&gt; 431&gt; 321&gt; eof&gt; EOF1234431321eof[user1@study ~]$ 在行尾使用转义符 \ 其实是对换行符 \n 进行了转义，意思是此处不进行换行 123456[user1@study ~]$ cat &lt;&lt; EOF&gt; abc\&gt; def&gt; EOFabcdef[user1@study ~]$ 如果用 &lt;&lt; 而不是 &lt;&lt;-，则最后面的 limit_string 必须位于行首，否则如果 Here Documents 用在函数内部，则会报语法错误； 123456789101112131415161718[user1@study ~]$ cat test.sh #!/bin/bashfunc1()&#123; cat &lt;&lt; EOF a b c EOF&#125;func1[user1@study ~]$ [user1@study ~]$ bash test.sh test.sh: line 12: warning: here-document at line 4 delimited by end-of-file (wanted `EOF')test.sh: line 13: syntax error: unexpected end of file[user1@study ~]$ 将后面的 EOF放到行首，再次执行虽然没有报错，但是发现前面带了函数中用来缩进的的 Tab 制表符 123456789101112131415161718[user1@study ~]$ cat test.sh #!/bin/bashfunc1()&#123; cat &lt;&lt; EOF a b cEOF&#125;func1[user1@study ~]$ bash test.sh a b c[user1@study ~]$ 如果重定向操作符是 &lt;&lt;-, 则 msg_body 和 limit_string 行中的所有开头的 Tab 制表字符都将被忽略（但空格不会被忽略）。这样源代码中的 Here Documents 就可以按照优雅的读入方式进行对齐。 123456789101112131415161718[user1@study ~]$ cat test.sh #!/bin/bashfunc1()&#123; cat &lt;&lt;- EOF a b cEOF&#125;func1[user1@study ~]$ bash test.sh abc[user1@study ~]$ 用在函数外面，第一个 limit_string 后面的所有内容均会被当做 Here Documents 的内容。 123456789101112131415161718192021[user1@study ~]$ cat test.sh #!/bin/bashfunc1()&#123; echo hello&#125;func1cat &lt;&lt;- EOFabcEOF[user1@study ~]$ bash test.sh helloabc[user1@study ~]$ 如果用双引号 &quot;&quot; 或单引号 &#39;&#39; 将 limit_string 引起来或用转义符 \ 将其转义，则 Here Documents 中的文本将不被扩展，即参数替换被禁用。请注意，下面的例子对 cat 的标准输出做了覆盖重定向，读入的内容会覆盖到指定的文件而不会再是默认输出到屏幕 123456789101112131415161718192021222324[user1@study ~]$ cat test.sh #!/bin/bash# create a shell scriptcat &gt; hello.sh &lt;&lt;- 'EOF'#!/bin/bashtoday="$(date +'%F %T')"echo $&#123;today&#125;EOF[user1@study ~]$ bash test.sh [user1@study ~]$ cat hello.sh #!/bin/bashtoday="$(date +'%F %T')"echo $&#123;today&#125;[user1@study ~]$ bash hello.sh 2015-07-14 22:10:27[user1@study ~]$ 如果不使用引号或者转义符，则 Here Documents 中的所有文本都将进行常规的参数扩展、命令替换、表达式计算。 12345678910111213141516171819202122232425[user1@study ~]$ cat test.sh #!/bin/bash# create a shell script# 注意这里的 EOF 没有使用引号或转义符 \cat &gt; hello.sh &lt;&lt;- EOF#!/bin/bashtoday="$(date +'%F %T')"echo $&#123;today&#125;EOF[user1@study ~]$ bash test.sh [user1@study ~]$ cat hello.sh #!/bin/bashtoday="2015-07-14 22:11:55"echo [user1@study ~]$ bash hello.sh [user1@study ~]$ 还可以使用 Here Documents 的方式将很多个内容赋值给一个变量 12345678910[user1@study ~]$ a=$(cat &lt;&lt; EOF&gt; 10.0.0.0/8&gt; 100.64.0.0/10&gt; 172.16.0.0/12&gt; 192.168.0.0/16&gt; EOF&gt; )[user1@study ~]$ echo $a10.0.0.0/8 100.64.0.0/10 172.16.0.0/12 192.168.0.0/16[user1@study ~]$ 要提一句的是，: 在 shell 中的意思就是不做任何处理，类似于 Python 中的 pass 语句 12345678910[user1@study ~]$ cat test.sh #!/bin/bashif [ 1 -eq 1 ];then :else echo "no"fi[user1@study ~]$ bash test.sh [user1@study ~]$ 如果不想使用 # 对代码块进行多行注释，可以使用 Here Documents 配合 : 来处理 12345678910111213141516[user1@study ~]$ cat test.sh #!/bin/bash:&lt;&lt;EOFif [ 1 -eq 1 ];then :else echo "no"fiEOFecho '12345'[user1@study ~]$ bash test.sh 12345[user1@study ~]$ 连接数据库，并执行 SQL 语句通常都是在键盘输入到命令行操作的 123456789101112131415161718192021[root@study ~]# mysql -u rootWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 3Server version: 5.5.60-MariaDB MariaDB ServerCopyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; use mysqlReading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMariaDB [mysql]&gt; select * from user;# 内容省略6 rows in set (0.00 sec)MariaDB [mysql]&gt; exitBye[root@study ~]# 有了 Here Documents 就可以在 shell 脚本中用到了。另外类似于这种用法在脚本中使用 fdisk 命令配合 Here Documents 就能自动完成分区操作，此处不再详述。 123456789[root@study ~]# cat test.sh #!/bin/bashmysql -u root &lt;&lt; EOFuse mysql;select * from user;exitEOF[root@study ~]# bash test.sh Here StringsHere Strings 也叫 Here word，指的是从字符中读入数据作为标准输入。 使用格式 1command &lt;&lt;&lt; word 这里的 word 建议最好使用引号括起来，因为有空格的情况会出现错误 12345678[user1@study ~]$ grep yes &lt;&lt;&lt; 'yess'yess[user1@study ~]$ grep -o -i yes &lt;&lt;&lt; 'fyessYes'yesYes[user1@study ~]$ grep -o -i yes &lt;&lt;&lt; fye ssYesgrep: ssYes: No such file or directory[user1@study ~]$ 并不是必须是纯字符才能作为输入，使用有输出的命令替换也是可以的 123[user1@study ~]$ grep -i 'world' &lt;&lt;&lt; "$(cat file.txt)"Hello world ! Wed May 1 15:00:10 CST 2019[user1@study ~]$]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之命令行编辑]]></title>
    <url>%2F2015%2F07%2F19%2F172147-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%BC%96%E8%BE%91%2F</url>
    <content type="text"><![CDATA[说是命令行编辑，其实说白了就是一堆快捷键，实现了 shell 命令行上字符串的剪切拷贝等多种功能。 先来看看常用到的快捷键： Ctrl + a 光标跳转到命令行行首 Ctrl + e 光标跳转到命令行行尾 Ctrl + l 清屏，等同于 clear 命令 Ctrl + u 剪切光标至命令行行首的内容 Ctrl + k 剪切光标至命令行行尾的内容 Ctrl + w 剪切光标到左边最近的一个空格间的内容，即剪切光标前一个单词 Esc + d 剪切光标到右边最近的一个空格间的内容，即剪切光标后一个单词 Ctrl + y 粘贴上一个剪切操作的内容 Ctrl + b 向左移动光标，等同于 ← Ctrl + f 向右移动光标，等同于 → Ctrl + j 相当于回车键，回车执行命令 Ctrl + x + x 光标在命令行中最后两次出现的位置间互相切换 Esc + b 移动到当前单词的词首处，等同于 xterm 终端下的 Ctrl+← Esc + f 移动到当前单词的词尾处，等同于 xterm 终端下的 Ctrl+→ Esc + t 交换光标前的最后两个单词 Esc + u 将当前单词转换为大写 Esc + l 将当前单词转换为小写 Esc + c 将当前字母转换为大写 Esc + . 调用命令历史中上一条命令的最后一个参数，反复敲 Esc + . 将则会倒序切换历史命令的最后一个参数 对于 MacOS 用户来说本身就可以使用自带的 terminal 来 ssh 远程连接 Linux 服务器，但是对于服务器维护数量比较多的情况还需要借助其他工具。 在 Windows 平台上用的最多的远程连接软件应该是这三个：Putty、SecureCRT、XShell。 为什么要说这个呢？是因为快捷键跟这些软件设置的（Emulation）仿真终端类型是有关系的，可能在某些终端下有些快捷键就会失效。在 SecureCRT 中我设置的仿真终端类型是 Linux。 勤加练习这些快捷键的使用，命令行将会快步如飞。]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之输入输出重定向]]></title>
    <url>%2F2015%2F07%2F18%2F214147-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8B%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E9%87%8D%E5%AE%9A%E5%90%91%2F</url>
    <content type="text"><![CDATA[输入输出重定向输入重定向指的是将原来从标准输入读取数据的位置重新定向为从其他位置读取数据，输出重定向指的是把原来要输出到标准输出的内容，重新定向输出到指定的其他位置。 输入输出重定向通常与文件描述符 FD 有关，shell 的 FD 通常为10个，即 0～9，最常用的有 3 个，即 0（stdin）、1（stdout）、2（stderr）。 重定向操作符命令从键盘的输入读入数据是很常见的的。 123[user1@study ~]$ read -p 'Input something: ' line ; echo "Your input : $&#123;line&#125;"Input something: Tom is 15 years old.Your input : Tom is 15 years old. 用 &lt; 来改变读进的数据位置(stdin)，使之从指定的位置读进。0 是 &lt; 的默认值，因此 &lt; 与 0&lt; 是一样的。 1234[user1@study ~]$ read -p 'Input something: ' line &lt; file[user1@study ~]$ echo "Your input : $&#123;line&#125;"Your input : Good good study, day day up![user1@study ~]$ 用 &gt; 来改变送出位置，使之输出到指定的位置。1 是 &gt; 的默认值，因此 &gt; 与 1&gt; 是一样的。如果指定的文件不存在则自动创建这个文件并以覆盖方式写入数据，如果文件存在将会把命令的输出覆盖掉文件内容。所以 &gt; 也叫覆盖重定向。 1234567891011 [user1@study ~]$ date +"Today: %F %T"Today: 2015-07-13 21:44:25[user1@study ~]$ ls today.txtls: cannot access today.txt: No such file or directory[user1@study ~]$ date +"Today: %F %T" &gt; today.txt[user1@study ~]$ cat today.txtToday: 2015-07-13 21:44:31[user1@study ~]$ echo Good &gt; today.txt[user1@study ~]$ cat today.txt Good[user1@study ~]$ 用 &gt;&gt; 来改变送出位置，使之输出到指定的位置。1 是 &gt;&gt; 的默认值，因此 &gt;&gt; 与 1&gt;&gt; 是一样的。如果指定的文件不存在则自动创建这个文件并以追加的方式写入数据，如果文件存在将会把命令的输出追加到文件中。所以 &gt;&gt; 也叫追加重定向。 1234567 [user1@study ~]$ cat file.txt Hello world ![user1@study ~]$ echo $(date) &gt;&gt; file.txt [user1@study ~]$ cat file.txt Hello world !Tue Jul 14 15:00:10 CST 2015[user1@study ~]$ 如果想要对标准错误输出进行重定向，需要使用其文件描述符 2 配合重定向操作符 &gt; 和 &gt;&gt; 来使用，即 2&gt; 和 2&gt;&gt; 。这在记录日志或者在调试的时候显得十分有用。 12345678[user1@study ~]$ ls abc 2&gt; log1.txt[user1@study ~]$ cat log1.txt ls: cannot access abc: No such file or directory[user1@study ~]$ cat bcd 2&gt;&gt; log1.txt [user1@study ~]$ cat log1.txtls: cannot access abc: No such file or directorycat: bcd: No such file or directory[user1@study ~]$ 但是要注意文件描述符和重定向操作符必须紧挨着，不能有空格，否则将无法完成重定向。 1234[user1@study ~]$ cat bcd 2 &gt;&gt; log1.txt cat: bcd: No such file or directorycat: 2: No such file or directory[user1@study ~]$ 用 2&gt;&amp;1 将会把标准错误输出重定向到标准输出。 12345[user1@study ~]$ head 123.txt &gt;&gt; log1.txt 2&gt;&amp;1 [user1@study ~]$ cat log1.txt ls: cannot access abc: No such file or directorycat: bcd: No such file or directoryhead: cannot open ‘123.txt’ for reading: No such file or directory 你可以理解为不管是正确输出还是错误输出，都并到一个数据流来处理。 12345678[user1@study ~]$ echo '123' &gt; 123.txt[user1@study ~]$ head 123.txt &gt;&gt; log1.txt 2&gt;&amp;1 [user1@study ~]$ cat log1.txt ls: cannot access abc: No such file or directorycat: bcd: No such file or directoryhead: cannot open ‘123.txt’ for reading: No such file or directory123[user1@study ~]$ 用 &amp;&gt; 将会把标准错误输出已覆盖的方式重定向一个文件或设备，用起来基本上和 command &gt; filename 2&gt;&amp;1 效果是一样的 123456789[user1@study ~]$ cat log1.txt [user1@study ~]$ [user1@study ~]$ echo 'yes' &amp;&gt; log1.txt [user1@study ~]$ cat log1.txt yes[user1@study ~]$ eco &amp;&gt; log1.txt [user1@study ~]$ cat log1.txt -bash: eco: command not found[user1@study ~]$ 重定向时还可以对标准输出和标准错误输出分别指定各自的输出位置。 1234567 [user1@study ~]$ eco 'yes' &gt; info.log 2&gt; err.log [user1@study ~]$ cat err.log -bash: eco: command not found[user1@study ~]$ echo 'yes' &gt; info.log 2&gt; err.log [user1@study ~]$ cat info.log yes[user1@study ~]$ 在输入输出重定向中，stdout 与 stderr 的管道会先准备好，才会从 stdin 读进数据。因此不管命令输出是错误还是正确，在覆盖重定时文件时都会先被清空。 123456789101112[user1@study ~]$ cat fileGood good study, day day up![user1@study ~]$ date +"%F %T"2015-07-13 21:54:12[user1@study ~]$ date +%F %T date: extra operand ‘%T’Try 'date --help' for more information.[user1@study ~]$ date +%F %T &gt; filedate: extra operand ‘%T’Try 'date --help' for more information.[user1@study ~]$ cat file[user1@study ~]$ /dev/null/dev/null 称为空设备，是一个特殊的设备文件，它会丢弃一切写入其中的数据。/dev/null 常被程序员称为位桶(bit bucket)或者黑洞(black hole)。空设备通常被用于丢弃不需要的输出流，或作为用于输入流的空文件。当你读它的时候，它会提供无限的空字符。 123[user1@study ~]$ ls *.txt &amp;&gt; /dev/null[user1@study ~]$ ls *.txt &gt; /dev/null 2&gt;&amp;1[user1@study ~]$ 在很多时候我们并期望看到命令的输出，只关心执行正确与否。此时可以做输出重定向，并且重定向到 /dev/null 即可 1234[user1@study ~]$ echo $(date) | grep 2015 &amp;&gt;/dev/null[user1@study ~]$ echo $?0[user1@study ~]$ 写在后面有时候需要清空文件的内容而不是删除文件本身。 1234567[user1@study ~]$ cat test.log run-parts(/etc/cron.daily)[1404]: finished logrotaterun-parts(/etc/cron.daily)[1392]: starting man-db.cronrun-parts(/etc/cron.daily)[1415]: finished man-db.cron[user1@study ~]$ &gt; test.log [user1@study ~]$ cat test.log[user1@study ~]$ 这个功能看似没什么复杂的，但在实际工作过程中经常会因为粗心在追加重定向时漏写了一个 &gt;，直接将文件覆盖了， 结果酿成了悲剧。 如何才能禁止覆盖一个已经存在的文件呢？Linux 中有一个内置的 shell 命令 set，结合它的选项 -C 就能实现这个功能。 1234[user1@study ~]$ set -C[user1@study ~]$ &gt; 123.txt -bash: 123.txt: cannot overwrite existing file[user1@study ~]$ 如果百分之百确定要覆盖，可以使用 set +C 关闭这个功能等到操作完成之后再开启。 123 [user1@study ~]$ set +C[user1@study ~]$ echo '456' &gt; 123.txt [user1@study ~]$ set -C 或者使用 &gt;| 在重定向时强进行制覆盖 12345[user1@study ~]$ set -C [user1@study ~]$ echo '456' &gt;| 123.txt [user1@study ~]$ echo '456' &gt; 123.txt -bash: 123.txt: cannot overwrite existing file[user1@study ~]$ 实际上 set -o noclobber 等同于 set -C，set +o noclobber 等同于 set +C 123456[user1@study ~]$ set -o noclobber[user1@study ~]$ echo '567' &gt; 123.txt -bash: 123.txt: cannot overwrite existing file[user1@study ~]$ set +o noclobber[user1@study ~]$ echo '567' &gt; 123.txt [user1@study ~]$]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之管道pipe]]></title>
    <url>%2F2015%2F07%2F15%2F192127-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8B%E7%AE%A1%E9%81%93pipe%2F</url>
    <content type="text"><![CDATA[管道是 Unix 中最古老的进程之间的通信形式。把数据流从一个进程连接到另一个进程就叫做 “管道”。 管道的操作符是 |，仅能处理经由前面一个命令传出的正确输出信息，即标准输出（standard output） 的信息，而对于错误的输出信息，即标准错误输出（stdandard error） 信息没有直接处理能力。而后将标准输出传递给下一个命令，作为下一个命令的标准输入（standard input）。 如上图所示 command1 的正确输出作为 command2 的输入，然后 comand2 的正确输出作为 comand3 的输入 ，comand3 的输出直接显示在屏幕 下面是一个比较简单的例子 123456789[user1@study ~]$ ls | grep filefilefile2.txtfile3.txtfile.bakfile.txt[user1@study ~]$ ls | grep file | grep [0-9]file2.txtfile3.txt 管道右边的命令，必须能够接收标准输入流命令才行，否则无法正常进行 1234[user1@study ~]$ ls | touchtouch: missing file operandTry 'touch --help' for more information.[user1@study ~]$ 管道只处理前一个命令的标准输出，不处理标准错误输出 123[user1@study ~]$ ls file_abc | grep 'No such file or directory'ls: cannot access file_abc: No such file or directory[user1@study ~]$ 如果既想处理前一个命令的标准输出，又想要处理标准错误输出该怎么办呢？这时可以用 |&amp; 来解决，它实际上是对 2&gt;&amp;1 | 的缩写 1234567[user1@study ~]$ ls abcfile | grep -i -o -w 'no' ls: cannot access abcfile: No such file or directory[user1@study ~]$ ls abcfile |&amp; grep -i -o -w 'no'No[user1@study ~]$ ls abcfile 2&gt;&amp;1 | grep -i -o -w 'no' No[user1@study ~]$ 管道和重定向的区别 管道： 左边的命令应该有标准输出 | 右边的命令应该接受标准输入 管道两边必须是 shell 命令，触发了两个子进程，两边命令都各自触发了一个子进程 重定向： 左边的命令应该有标准输出 &gt; 右边只能是文件 左边的命令需要接受标准输入 &lt; 右边需要能产生标准输出进程或文件 重定向是在一个进程内执行的]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之标准输入输出和文件描述符]]></title>
    <url>%2F2015%2F07%2F13%2F192131-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8B%E6%A0%87%E5%87%86%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E5%92%8C%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[标准输入(stdin)标准输入（standard input）指的是输入给要执行命令的数据，通常是键盘的输入，或者是文件中的数据。命令程序要求以读(read)的方式来传输数据。 123456[user1@study ~]$ read -p 'Please input a number: ' user_number; echo "Your number is $&#123;user_number&#125;"Please input a number: 1234Your number is 1234[user1@study ~]$ cat file.txt Hello world ![user1@study ~]$ 并不是所有的命令都要求有输入，例如 ls 或 df 在执行时不需要任何输入 123456789101112[user1@study ~]$ ls file2.txt file3.txt file.bak file.txt nginx1.log nginx2.log nginx3.log nginx4.log nginx5.log[user1@study ~]$ df Filesystem 1K-blocks Used Available Use% Mounted on/dev/sda3 18707456 1534712 17172744 9% /devtmpfs 921652 0 921652 0% /devtmpfs 932640 0 932640 0% /dev/shmtmpfs 932640 9560 923080 2% /runtmpfs 932640 0 932640 0% /sys/fs/cgroup/dev/sda1 201380 114428 86952 57% /boottmpfs 186532 0 186532 0% /run/user/0[user1@study ~]$ 标准输入的文件描述符为 0 123[user1@study ~]$ ls -l /dev/stdin lrwxrwxrwx 1 root root 15 Jul 14 2015 /dev/stdin -&gt; /proc/self/fd/0[user1@study ~]$ 标准输出(stdout)标准输出（standard output）指的是所执行的命令所输出数据，默认输出到屏幕。命令要求以写(write)操作来传输数据。 123[user1@study ~]$ echo 'Hello world'Hello world[user1@study ~]$ 并不是所有的命令都要求输出。如 mv 或 touch 程序在成功完成时不会输出任何东西 123[user1@study ~]$ touch test.txt[user1@study ~]$ mv test.txt&#123;,.bak&#125;[user1@study ~]$ 标准输出的文件描述符为 1 123[user1@study ~]$ ll /dev/stdout lrwxrwxrwx 1 root root 15 Jul 14 2015 /dev/stdout -&gt; /proc/self/fd/1[user1@study ~]$ 标准错误输出(stderr)标准错误输出是另外一种输出流，用于输出执行命令的错误消息。它独立于标准输出，并且可以分别被重导。默认的输出位置也是屏幕 123456[user1@study ~]$ date +'%F %T'2015-07-13 20:31:26[user1@study ~]$ date +%F %Tdate: extra operand ‘%T’Try 'date --help' for more information.[user1@study ~]$ 即便是标准输出被重导也是会输出到屏幕，最典型的例子就是管道，一个管道中的命令的输出被重导到下一个命令，但错误消息仍然直接输出到屏幕 123456[user1@study ~]$ date +'%F %T' | grep 20152015-07-13 20:33:53[user1@study ~]$ date +%F %T | grep 2015 date: extra operand ‘%T’Try 'date --help' for more information.[user1@study ~]$ 标准错误输出的文件描述子为 2 123[user1@study ~]$ ls -l /dev/stderr lrwxrwxrwx 1 root root 15 Jul 14 2015 /dev/stderr -&gt; /proc/self/fd/2[user1@study ~]$ 文件描述符上面提到了三个文件描述符，在 Linux 系统启动后，会默认打开这三个文件描述符，分别是：0（标准输入 stdin），1（标准输出 stdout），2（标准错误输出 stderr）。 究竟什么是文件描述符呢？我们可以理解为 linux 跟踪打开文件而分配的一个数字，这个数字有点类似 C 语言操作文件时候的句柄，通过句柄就可以实现文件的读写操作。 打开文件后新增文件绑定描述符可以依次增加。每条 shell 命令执行，都会继承父进程的文件描述符。因此所有运行的 shell 命令默认都会有这三个文件描述符。 命令执行前会事先准备好所有输入输出，默认分别绑定（stdin，stdout，stderr)，如果这个时候出现错误，命令将终止，不会执行。 对于任何一条 shell 命令执行，它会是这样一个过程：]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之文件名通配globbing]]></title>
    <url>%2F2015%2F07%2F12%2F214127-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8B%E6%96%87%E4%BB%B6%E5%90%8D%E9%80%9A%E9%85%8Dglobbing%2F</url>
    <content type="text"><![CDATA[文件名通配属于 Bash 的一大特性，通配符只会出现在命令的参数中。当参数中出现了通配符时，shell 将会把他当做路径或文件名去文件系统做匹配，如果符合要求的匹配存在则进行替换，否则这个通配符就只是当做普通字符传递给命令，然后交给命令处理。 常见的文件名通配符 字符 含义 * 任意长度的任意字符 ？ 任意单个字符 ~ 当前用户的家目录 ~user1 用户user1的家目录 ~- 上一个工作目录 ~+ 当前工作目录 [] 列表中的任意单个字符 [^] 列表中的所有字符以外的字符 [0-9] 任意单个数字 [a-z] 小写字母 [A-Z] 大写字母 [0-9a-Z] 大小写字母及数字 [:lower:] 任意小写字母 [:upper:] 任意大写字母 [:alpha:] 任意大小写字母 [:alnum:] 任意数字或字母 [:space:] 空格 [:punct:] 标点符号 [:digit:] 任意单个数字，同 [0-9] 示例 123456789[user1@study ~]$ lsfile2.txt file3.txt file.bak nginx1.log nginx2.log nginx3.log nginx4.log nginx5.log[user1@study ~]$ ls *.txtfile2.txt file3.txt[user1@study ~]$ ls nginx*nginx1.log nginx2.log nginx3.log nginx4.log nginx5.log[user1@study ~]$ ls nginx[1-3]*nginx1.log nginx2.log nginx3.log[user1@study ~]$ 注意： 通配符看起来和正则表达式十分相似，但是这两个是完全不同的，不能相互混淆。 参考： https://www.w3resource.com/linux-system-administration/file-globbing.php]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之命令替换和命令行展开]]></title>
    <url>%2F2015%2F07%2F09%2F214135-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8B%E5%91%BD%E4%BB%A4%E6%9B%BF%E6%8D%A2%E5%92%8C%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B1%95%E5%BC%80%2F</url>
    <content type="text"><![CDATA[命令替换命令替换，就是把某个子命令替换为其执行结果的过程。命令替换符有两种 : 1$(command) 或 `command` 在一些命令中如果出现命令替换符，Kernel 会首先执行子命令，然后在执行外部命令 12345[user1@study ~]$ echo "$(date +'%F %T') [ INFO ] log something"2015-07-09 22:48:32 [ INFO ] log something[user1@study ~]$ echo "`date +'%F %T'` [ INFO ] log something" 2015-07-09 22:48:48 [ INFO ] log something[user1@study ~]$ 这两种没有什么区别，但是从直观性上看，更建议使用 $(command)，不容易使人对符号混淆 命令行展开命令行展开会将 {} 花括号中的内容用类似于数学中的因式分解进行展开 123[user1@study ~]$ echo aa&#123;1,2,3&#125;X&#123;a,b&#125; aa1Xa aa1Xb aa2Xa aa2Xb aa3Xa aa3Xb[user1@study ~]$ 备份一个文件时显得十分有用 123456[user1@study ~]$ lsfile[user1@study ~]$ cp file&#123;,.bak&#125;[user1@study ~]$ lsfile file.bak[user1@study ~]$ 还可以利用这个特性一次性创建多个文件 123456[user1@study ~]$ lsfile file.bak[user1@study ~]$ touch file&#123;1,2,3&#125;.txt[user1@study ~]$ lsfile file1.txt file2.txt file3.txt file.bak[user1@study ~]$ 在 {} 花括号中使用数字区间，默认的步进长度为 1，还可以手动指定 12345[user1@study ~]$ echo &#123;1..20&#125;1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20[user1@study ~]$ echo &#123;1..20..2&#125;1 3 5 7 9 11 13 15 17 19[user1@study ~]$]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之命令别名alias]]></title>
    <url>%2F2015%2F07%2F06%2F210143-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8B%E5%91%BD%E4%BB%A4%E5%88%AB%E5%90%8Dalias%2F</url>
    <content type="text"><![CDATA[对于 Linux 的运维人员来说，免不了经常敲一大堆命令，有些命令很长或者选项要经常被用到，重复性的输入很长的命令或选项显得效率十分低下，这时候我们使用命令别名来代替复杂的命令就非常有用了。 如何设置一个别名我们可以在命令行使用如下格式定义一个别名 1alias CMDALIAS='COMMAND [options] [arguments]' alias 是一个 shell 内置命令 CMDALIAS 是用户为命令设置的自定义别名，可以当做命令来执行 COMMAND [options] [arguments] 被别名的命令，即实际要执行的命令及其要用到的选项 每次当输入 CMDALIAS 时，Bash 将会把这个别名替换成实际的命令和相应的选项。 并且这里要注意的是，在 = 等号两边不应该有空格，如果被别名的命令由多个选项或者子命令组成，需要使用引号将其括起来。 在命令行中定义的别名仅在当前 shell 生命周期中有效，作用域仅为当前 shell 进程。也就是说在退出当前 shell 之前别名都是生效的，一旦退出就不会再生效了。因此我们可以在 ~/.bash_profile、~/.bashrc 这两个文件中使用同样的格式来定义命令别名，一旦定义之后，在下次登录以及以后登录都会永久生效。 如何查看所有的命令别名直接执行 alias 命令，不加任何参数即可 12345678910[user1@study ~]$ alias alias egrep='egrep --color=auto'alias fgrep='fgrep --color=auto'alias grep='grep --color=auto'alias l.='ls -d .* --color=auto'alias ll='ls -l --color=auto'alias ls='ls --color=auto'alias vi='vim'alias which='alias | /usr/bin/which --tty-only --read-alias --show-dot --show-tilde'[user1@study ~]$ 临时禁用命令别名，使用原命令本身我们对 cat 命令做一个别名，让它自动加上 -n 选项以显示行号 123456 [user1@study ~]$ alias cat='cat -n'[user1@study ~]$ cat file 1 Bash is an sh-compatible command language interpreter that executes commands read from the standard input or from a file. 2 Bash also incorporates useful features from the Korn and C shells (ksh and csh). 3 Bash can be configured to be POSIX-conformant by default.[user1@study ~]$ 如果只是临时不想使用这个功能，可以试试下面几种方法 使用 \ 1234[user1@study ~]$ \cat fileBash is an sh-compatible command language interpreter that executes commands read from the standard input or from a file. Bash also incorporates useful features from the Korn and C shells (ksh and csh).Bash can be configured to be POSIX-conformant by default. 使用单引号 &#39;&#39; 1[user1@study ~]$ 'cat' file 使用双引号 &quot;&quot; 1[user1@study ~]$ "cat" file 使用绝对路径 /path/to/command 1[user1@study ~]$ /bin/cat file 使用 shell 的内置命令 command 1[user1@study ~]$ command cat file 如何移除别名unalias 是一个 shell 内置的用来去除别名的命令，下面是命令的使用格式： 1unalias CMDALIAS 移除一个别名 1234[user1@study ~]$ unalias cls[user1@study ~]$ cls-bash: cls: command not found[user1@study ~]$ 移除所有别名 1234[user1@study ~]$ unalias -a[user1@study ~]$ cls-bash: cls: command not found[user1@study ~]$ 如果在 ~/.bash_profile、~/.bashrc 这两个文件中定义了命令别名，想要删除的话使用上述命令行的方式只能在当前 shell 生命周期内有效，下次登录后命令别名依然还在。想要永久移除就需要修改文件并删除。 常用的命令别名范例使用 vim 打开最近被修改的文件 12# Open last modified file in vimalias Vim="vim $(ls -t | head -1)" 在当前路径下查找文件大小排列前五名的文件 12# Find top 5 big filesalias findbig="find . -type f -exec ls -s &#123;&#125; \; | sort -n -r | head -5" 过滤出 bash 相关的进程 12# Grep for a bash processalias psg="ps -aux ¦ grep [b]ash" 清空当前 shell 的命令历史，并清屏 12# To clear all the history and screenalias hcl='history -c; clear' 清屏并列出文件 12# Clear the screen and list filealias cls='clear;ls' 解压缩文件老是忘记参数？ 1alias untar='tar -zxvf ' 在历史命令过滤关键字 1alias histgrep="history | grep" 下载命令 wget 断点续传 1alias wget='wget -c ' 快速切换到上层目录 12alias ..='cd ..'alias ....='cd ../../' 为新用户生成 15 位的随机密码 1alias getpass="openssl rand -base64 15" 使用 python3 的模块在当前路径下启动一个 web 服务器 12345# start web server with python2alias www2='python -m SimpleHTTPServer 8000'# start web server with python3alias www3='python3 -m http.server 8000' 对下载的文件测试校验和 1alias sha='shasum -a 256 ' 常用的别名函数在 shell 中命令别名会在函数后被查找到，因此解析速度较慢。虽然命令别名更容易理解，但对于几乎所有的用途， shell 的函数都比别名更受欢迎。 定义的函数也可以像别名一样来使用，为了使用更方便，直接在 ~/.bash_profile 或 ~/.bashrc 文件中添加自定义的函数就可以从下次登录开始永久生效 创建一个目录并进入该目录里 1mkcd()&#123; mkdir -p "$1"; cd "$1";&#125; 备份文件 1bak()&#123; cp "$1"&#123;,.bak&#125;;&#125; 计算并进行比较文件的 md5 值，用法 md5chk 文件名 校验值1md5chk()&#123; md5sum "$1" | grep "$2";&#125;]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之命令行的5个标准补全]]></title>
    <url>%2F2015%2F07%2F03%2F112147-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8B%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%9A%845%E4%B8%AA%E6%A0%87%E5%87%86%E8%A1%A5%E5%85%A8%2F</url>
    <content type="text"><![CDATA[在 Linux 系统中，默认情况下 Bash 就提供了下面这几个可以供用户在命令行使用的标准补全： 变量名补全 用户名补全 可执行命令补全 文件名和目录补全 主机名补全 变量名补全在终端输入 $ 后，敲两次 Tab 键就会列出所有可用的 shell 变量 123456789101112131415161718[root@study ~]# echo $[Tab][Tab]$_ $COLUMNS $LESSOPEN $PS4$BASH $COMP_WORDBREAKS $LINENO $PWD$BASH_ALIASES $DIRSTACK $LINES $RANDOM$BASH_ARGC $EUID $LOGNAME $SECONDS$BASH_ARGV $GROUPS $LS_COLORS $SHELL$BASH_CMDS $HISTCMD $MACHTYPE $SHELLOPTS$BASH_COMMAND $HISTCONTROL $MAIL $SHLVL$BASH_LINENO $HISTFILE $MAILCHECK $SSH_CLIENT$BASHOPTS $HISTFILESIZE $OPTERR $SSH_CONNECTION$BASHPID $HISTSIZE $OPTIND $SSH_TTY$BASH_SOURCE $HOME $OSTYPE $TERM$BASH_SUBSHELL $HOSTNAME $PATH $UID$BASH_VERSINFO $HOSTTYPE $PIPESTATUS $USER$BASH_VERSION $ID $PPID $XDG_RUNTIME_DIR$COBBLER_SERVER $IFS $PS1 $XDG_SESSION_ID$colors $LANG $PS2 [root@study ~]# 用户名补全当在波浪符 ~ 后按下两次 Tab 键，Bash 就会自动开始用户名的补全 12345678[root@study ~]# cd ~~adm/ ~games/ ~polkitd/ ~systemd-network/~bin/ ~halt/ ~postfix/ ~tcpdump/~chrony/ ~lp/ ~root/ ~tss~daemon/ ~mail/ ~shutdown/ ~user1/~dbus/ ~nobody/ ~sshd/ ~ftp ~operator/ ~sync/ [root@study ~]# 需要注意的是，这里的用户名补全并不是在用户的家目录 (home) 下获得用户名，与此相反它是从 /etc/passwd 中列出所有可用的用户名。 所以对于一些非登陆用户(没有家目录)，使用 cd 命令切换会是失败的 12345[root@study sbin]# cd ~ftp -bash: cd: /var/ftp: No such file or directory[root@study sbin]# grep ftp /etc/passwdftp:x:14:50:FTP User:/var/ftp:/sbin/nologin[root@study sbin]# 可执行命令的路径补全当你想要执行一个命令的时候，如果这个命令具有可执行权限，那么如果只能找到一个匹配项，按两次 Tab 就会直接自动完成补全 1234[root@study ~]# ll /usr/bin/systemctl -rwxr-xr-x. 1 root root 717688 Apr 11 2018 /usr/bin/systemctl[root@study ~]# /usr/bin/systemc[Tab][Tab][root@study ~]# /usr/bin/systemctl 如果找到多个匹配项，按两次 Tab 就会列出匹配的所有可用命令 1234567891011121314[root@study ~]# /usr/bin/system[Tab][Tab]systemctl systemd-inhibitsystemd-analyze systemd-loginctlsystemd-ask-password systemd-machine-id-setupsystemd-cat systemd-notifysystemd-cgls systemd-nspawnsystemd-cgtop systemd-pathsystemd-coredumpctl systemd-runsystemd-delta systemd-stdio-bridgesystemd-detect-virt systemd-sysv-convertsystemd-escape systemd-tmpfilessystemd-firstboot systemd-tty-ask-password-agentsystemd-hwdb [root@study ~]# 一般情况下我们不会使用绝对路径来执行命令，而是上来就直接执行命令。为什么能直接执行这个命了呢？在 Bash 中，提供了 PATH 环境变量，在他指定的每个路径下会搜索并尝试补全以我们给出的字符串开头的可执行文件（命令） 1[root@study ~]# cat ~/.bash_profile 和当前用户相关的配置文件就是 ~/.bash_profile 123456789101112# .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then . ~/.bashrcfi# User specific environment and startup programsPATH=$PATH:$HOME/binexport PATH 如果我们想要在命令行补全中添加自己指定的路径下的命令，就可以在原有的基础上以 : 作为分隔符添加自己的路径 12345# User specific environment and startup programsPATH=$PATH:$HOME/bin:/opt/bin/export PATH 文件名和目录补全这是对在命令行的第二个位置和后续位置出现的文件名和目录名的补全。与上面的示例不同，它不检查任何权限，在给出的起始路径下只显示所有可用的文件和目录，并试图补全 123456[root@study ~]# lsdir1 dir2 dir3 file1 file2 file3 hello.sh[root@study ~]# cat file[Tab][Tab]file1 file2 file3 [root@study ~]# cat h[Tab][Tab][root@study ~]# cat hello.sh 除此之外，如果要显示的文件太多，这可能会让人感到非常懵逼，它将给出警告消息而不是在屏幕上显示所有可用的文件 12[root@study ~]# ls /etc/[Tab][Tab]Display all 185 possibilities? (y or n) 主机名补全如果在 ssh 连接一个远程主机时，想要获得要连接的主机名，请在 @ 后按两次 Tab 键，如下所示： 12345[root@study ~]# ssh root@[Tab][Tab]@::1 @localhost6@localhost @localhost6.localdomain6@localhost4 @localhost.localdomain@localhost4.localdomain4 在任何可以为主机名提供 @ 的命令中，都可以使用这个主机名补全功能。例如，可以将其与 scp 命令一起使用 12345[root@study ~]# scp file1 root@[Tab][Tab]@::1 @localhost6@localhost @localhost6.localdomain6@localhost4 @localhost.localdomain@localhost4.localdomain4 用 echo 也是可以的 12345[root@study ~]# echo @[Tab][Tab]@::1 @localhost6@localhost @localhost6.localdomain6@localhost4 @localhost.localdomain@localhost4.localdomain4 参考：https://www.thegeekstuff.com/2013/11/bash-standard-completion/]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash的基本特性之命令历史history与神奇的叹号]]></title>
    <url>%2F2015%2F07%2F01%2F102110-Bash%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%89%B9%E6%80%A7%E4%B9%8B%E5%91%BD%E4%BB%A4%E5%8E%86%E5%8F%B2history%E4%B8%8E%E7%A5%9E%E5%A5%87%E7%9A%84%E5%8F%B9%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[history 命令用于显示历史记录和执行过的命令。命令历史被保存在内存中的，当退出 shell 时会自动保存到历史命令文件 ~/.bash_history ，当登录 shell 时则从中读取以前的命令 常用选项 history n 列出最近执行过的n条命令 history -c 清除所有历史命令、 histoty -w 将缓冲区命令写入历史命令文件 ~/.bash_history history -d 5 删除历史记录中序号为 5 的命令 配置定义在内存中仅能够存储 1000 条历史命令，该数量是由环境变量 HISTSIZE 进行控制。这个值可以在 /etc/profile 进行修改，修改成功后在下次登录时即可生效 12HISTSIZE=1000# 注意等号两边不要有空格 默认情况下 history 不显示命令的执行时间，但是系统已经记录。同样，可以在 /etc/profile 进行修改，修改成功后在下次登录时即可生效 123export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL # 在这一行下面添加如下两行HISTTIMEFORMAT="%F %T | "export HISTTIMEFORMAT 这里需要说明一下，%F %T 等同于 %Y-%m-%d %H:%M:%S，和 date 命令的用法一致，表示的是年月日、时分秒，而 | 竖线加个空格没有其他特殊意义，只是为了作为分隔符，能够更清晰地区分不同的多条命令 注意事项： 当同一用户同时登录多个 bash 时，只有最后一个退出的会写入 bash_history，其他的会被覆盖 神奇的叹号 “!”执行上一条命令使用键盘 ↑ 可以很快再执行一次上一条命令，与之效果相同的是两个叹号， !! 代表了上一条命令，例如： 123456[user1@study ~]$ which head/bin/head[user1@study ~]$ !! # 再次执行上一条命令which head/bin/head[user1@study ~]$ 再比如，想操作一个文件但是漏掉了操作命令，可以这样来补救： 12345678[user1@study ~]$ /etc/issue-bash: /etc/issue: Permission denied[user1@study ~]$ cat !!cat /etc/issue\SKernel \r on an \m[user1@study ~]$ 按我们平常的操作习惯还是喜欢再次从头敲一次命令，但是当文件路径比较长的时候用上面的方法会显得更高效 调用上条命令的参数在什么场景下可能会用到这个功能呢？有一条很长很长的命令，包含了很多参数，类似于源码包编译安装的命令，敲错了一个字母或者多了一个选项，使用退格键删除觉得又慢又很麻烦，用下面的方法会显得十分高效 调用上条命令最后一个参数在命令行使用 !$ 可以很方便地引用上一条命令的最后一个参数，如下 123456789101112[Test@CentOS6~]$ sudo ifconfig 192.168.127.127 eth1eth1: Unknown hostifconfig: `--help gives usage information.[user1@study ~]$ sudo ifconfig !$ 192.168.127.127sudo ifconfig eth1 192.168.127.127[user1@study ~]$ [user1@study ~]$ ls /etc/redhat-release/etc/redhat-release[user1@study ~]$ ls -al !$ls -al /etc/redhat-releaselrwxrwxrwx. 1 root root 14 Jul 2 2015 /etc/redhat-release -&gt; centos-release[user1@study ~]$ 另外，和 !$ 有着相同功能的还有一个快捷键：Esc + . 执行一次 Esc + .，跟 !$ 功能一样 重复执行 Esc + . 则会倒序切换历史命令的最后一个参数 调用上条命令但剔除最后一个参数有时候命令行会从别处粘贴一个字符串来操作，但是由于失误多复制了一部分并且执行时出错，此时 !:- 就派上用场了： 1234567[user1@study ~]$ ip route show match 192.168.127.127 devCommand line is not complete. Try option "help"[user1@study ~]$ !:-ip route show match 192.168.127.127default via 192.168.127.2 dev eth0 192.168.127.0/24 dev eth0 proto kernel scope link src 192.168.127.159 [user1@study ~]$ 调用上条命令第一个参数如果想引用上一条命令的第一个参数，使用 !^ 或 !:1 即可： 12345678910111213141516171819[user1@study ~]$ cp /etc/sysconfig/network-scripts/ifcfg-eth0 /tmp/[user1@study ~]$ cat !:^cat /etc/sysconfig/network-scripts/ifcfg-eth0# Generated by parse-kickstartDEVICE="eth0"IPV6INIT="yes"BOOTPROTO="none"UUID="fec3a443-a913-4a91-afbe-8c3e8b859230"ONBOOT="yes"IPADDR=192.168.127.159NETMASK=255.255.255.0PREFIX=24BROADCAST=192.168.127.255NETWORK=192.168.127.0GATEWAY=192.168.127.2[user1@study ~]$ wc -l !:1wc -l /etc/sysconfig/network-scripts/ifcfg-eth012 /etc/sysconfig/network-scripts/ifcfg-eth0[user1@study ~]$ 调用上条命令所有参数如果一条操作命令后面有很多选项和参数，但是我们把命令敲错了，这时候该怎么办呢？此时我们再重新敲对操作命令，将上一条命令的所有参数引用下来即可： 123456[user1@study ~]$ ips route add 192.168.127.128/32 dev 192.168.127.127 dev eth1 -bash: ips: command not found[user1@study ~]$ ip !*ip route add 192.168.127.128/32 dev 192.168.127.127 dev eth1RTNETLINK answers: Operation not permitted[user1@study ~]$ 第一条命令执行失败是因为命令敲错，第二条命令执行失败是因为当前用户是普通用户，权限不允许 调用上条命令中指定的参数如果只想用上条命令中某个参数呢，则按照 ![命令名]:[参数号] 的规则即可，并且命令名可以省略。例如 123456[user1@study ~]$ sudo ip route add 114.114.114.114 via 192.168.127.2 dev eth0 [user1@study ~]$ ip route show match !:4ip route show match 114.114.114.114default via 192.168.127.2 dev eth0 114.114.114.114 via 192.168.127.2 dev eth0 [user1@study ~]$ 对于 sudo 命令来说 114.114.114.114 是他是它的第4个参数 调用上条以关键字开头的命令 !string 执行命令历史中最近一个以指定字符串(string)开头的命令 1234[user1@study ~]$ !wcwc -l /etc/sysconfig/network-scripts/ifcfg-eth012 /etc/sysconfig/network-scripts/ifcfg-eth0[user1@study ~]$ 替换上条命令的参数如果上一条命令很长，而且有个参数不小心敲错了该怎么办？使用 ^no^yes 就可以将上条命令中错误的参数 no 改成 yes 并再次执行一次。比如： 12345[user1@study ~]$ grp -i 163 /etc/yum.repos.d/CentOS-Base.repo-bash: grp: command not found[user1@study ~]$ ^grp^grepgrep -i 163 /etc/yum.repos.d/CentOS-Base.repo[user1@study ~]$ 但是这种方法只能替换上条命令中第一次被匹配到的参数： 123456[user1@study ~]$ ip route show match 192.168.10.10default via 192.168.127.2 dev eth0 [user1@study ~]$ ^10^123ip route show match 192.168.123.10default via 192.168.127.2 dev eth0 [user1@study ~]$ 如果想把上条命令中所有匹配到的参数全部替换可以这样做： 123456[user1@study ~]$ ip route show match 192.168.10.10 default via 192.168.127.2 dev eth0 [user1@study ~]$ !!:gs/10/123ip route show match 192.168.123.123default via 192.168.127.2 dev eth0 [user1@study ~]$ 对上条以关键字开头的命令也是可以做替换的，例如将上一条 scp 命令中的所有 10 替换为 123 1!scp:gs/10/123 逻辑非删除除了 cfg 结尾以外的所有文件： 1rm !(*.cfg) 其他 !n 执行历史命令中第n条命令 !-n 执行历史命令中倒数第n条命令 !?str? 最近一条包含str的命令 ↑ 或 Ctrl + p 引用上一条命令 ↓ 或 Ctrl + n 引用下一条命令 Ctrl + r 按下 Ctrl + r ，然后输入关键字搜索历史命令，按 Enter 执行命令]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell中使用echo命令输出信息及带颜色的文本]]></title>
    <url>%2F2015%2F06%2F28%2F154139-shell%E4%B8%AD%E4%BD%BF%E7%94%A8echo%E5%91%BD%E4%BB%A4%E8%BE%93%E5%87%BA%E4%BF%A1%E6%81%AF%E5%8F%8A%E5%B8%A6%E9%A2%9C%E8%89%B2%E7%9A%84%E6%96%87%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[echoshell 中有个内置的命令 echo 用来输出信息，在默认情况下输出位置是屏幕。 123[user1@study ~]$ echo "Hello World"Hello World[user1@study ~]$ 此外 echo 命令还可以改变样式，以输出不同颜色的文本，但是必须有 -e 选项(开启 echo 中的转义)。 格式如下 12echo -e "\033[字背景颜色；文字颜色m 字符串\033[0m" echo -e "\033[1;36;41m Something here \033[0m" \代表转义 033 代表键盘的Control键 1代表字体行为(高亮，闪烁，下划线等)； 36代表字体的颜色 41的位置代表背景色 注： 字背景颜色和文字颜色之间是英文的分号’;’ 文字颜色后面有个m 字符串前后可以没有空格，如果有的话，输出也是同样有空格 文字和背景颜色搭配字体颜色范围是 30~37 12345678echo -e "\033[30m 黑色字 \033[0m"echo -e "\033[31m 红色字 \033[0m"echo -e "\033[32m 绿色字 \033[0m"echo -e "\033[33m 黄色字 \033[0m"echo -e "\033[34m 蓝色字 \033[0m"echo -e "\033[35m 紫色字 \033[0m"echo -e "\033[36m 天蓝字 \033[0m"echo -e "\033[37m 白色字 \033[0m" 字体背景颜色范围是 40~47 12345678echo -e "\033[40;37m 黑底白字 \033[0m" echo -e "\033[41;37m 红底白字 \033[0m" echo -e "\033[42;37m 绿底白字 \033[0m" echo -e "\033[43;37m 黄底白字 \033[0m" echo -e "\033[44;37m 蓝底白字 \033[0m" echo -e "\033[45;37m 紫底白字 \033[0m" echo -e "\033[46;37m 天蓝底白字 \033[0m" echo -e "\033[47;30m 白底黑字 \033[0m" 不同的控制选项决定了字体输出的属性 1234567891011121314151617181920\033[0m # 关闭所有属性 \033[1m # 设置高亮度 \033[4m # 下划线 \033[5m # 闪烁 \033[7m # 反显 \033[8m # 消隐 \033[30m — \33[37m # 设置前景色 \033[40m — \33[47m # 设置背景色 \033[60A # 光标上移60行 \033[60B # 光标下移60行 \033[60C # 光标右移60行 \033[60G # 光标右移60行\033[60D # 光标左移60行 \033[y;xH # 设置光标位置 \033[2J # 清屏 \033[K # 清除从光标到行尾的内容 \033[s # 保存光标位置 \033[u # 恢复光标位置 \033[?25l # 隐藏光标 \033[?25h # 显示光标 一些需要注意的地方 前景颜色各数字是对应背景颜色减去10 结束非常规字符序列的 m 要紧跟前面的数字，不能有空格 命令也可以写 成echo -e &quot;^[[44;37;5m ME \033[0m COOL&quot;，其中的 ^[ 需要先按 Ctrl + V 键 ,然后再按 ESC 键生成 参考在 RedHat 系统的 /etc/sysconfig/init 文件中有事先设置好的输出方式 1234567891011121314151617# color =&gt; new RH6.0 bootup# verbose =&gt; old-style bootup# anything else =&gt; new style bootup without ANSI colors or positioningBOOTUP=color# column to start "[ OK ]" label in RES_COL=60# terminal sequence to move to that column. You could change this# to something like "tput hpa $&#123;RES_COL&#125;" if your terminal supports itMOVE_TO_COL="echo -en \\033[$&#123;RES_COL&#125;G"# terminal sequence to set color to a 'success' color (currently: green)SETCOLOR_SUCCESS="echo -en \\033[0;32m"# terminal sequence to set color to a 'failure' color (currently: red)SETCOLOR_FAILURE="echo -en \\033[0;31m"# terminal sequence to set color to a 'warning' color (currently: yellow)SETCOLOR_WARNING="echo -en \\033[0;33m"# terminal sequence to reset to the default color.SETCOLOR_NORMAL="echo -en \\033[0;39m" 一个不错的网站 Colors and formatting (ANSI/VT100 Control sequences)]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shell中使用read命令接收键盘输入]]></title>
    <url>%2F2015%2F06%2F27%2F214131-shell%E4%B8%AD%E4%BD%BF%E7%94%A8read%E5%91%BD%E4%BB%A4%E6%8E%A5%E6%94%B6%E9%94%AE%E7%9B%98%E8%BE%93%E5%85%A5%2F</url>
    <content type="text"><![CDATA[read 命令从标准输入中读取一行，并把输入行的每个字段的值指定给 shell 变量 用法格式 123read [-ers] [-a array] [-d delim] [-i text] [-n nchars] [-N nchars] [-p prompt] [-t timeout] [-u fd] [name ...]# 或read [ -p ][ -r ][ -s ][ -u[ n ] ] [ VariableName?Prompt ][ VariableName ... ] 命令参数 123456789-a 后跟一个变量，该变量会被认为是个数组，然后给其赋值，默认是以空格为分割符。-d 后面跟一个标志符，其实只有其后的第一个字符有用，作为结束的标志。-p 后面跟提示信息，即在输入前打印提示信息。-e 在输入的时候可以时候命令补全功能。-n 后跟一个数字，定义输入文本的长度。-r 屏蔽，如果没有该选项，则作为一个转义字符，有的话就是个正常的字符。-s 安静模式，在输入字符时不再屏幕上显示，例如login时输入密码。-t 后面跟秒数，定义输入字符的等待时间。-u 后面跟fd，从文件描述符中读入，该文件描述符可以是exec新开启的。 使用示例 1234567891011121314#!/bin/bash read -t 30 -p "Please input your name: " name # 提示“请输入姓名”并等待30秒，把用户的输入保存入变量name中 echo "Name is $name" read -s -t 30 -p "Please enter your age: " age # 年龄是隐私，所以我们用“-s”选项隐藏输入 echo -e "\n" echo "Age is $age" read -n 1 -t 30 -p "Please select your gender[M/F]: " gender # 使用“-n 1”选项只接收一个输入字符就会执行（都不用输入回车） echo -e "\n" echo "Sex is $gender"]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识Shell]]></title>
    <url>%2F2015%2F06%2F26%2F111410-%E8%AE%A4%E8%AF%86Shell%2F</url>
    <content type="text"><![CDATA[什么是 ShellShell 也可称为“壳”，充当人与内核（硬件）的翻译官，用户将一些命令 “告诉” Shell，它就会调用相应的程序服务执行工作。因此 Shell 的最简单的定义就是—命令解释器(Command Interpreter) Shell 将使用者的命令翻译给核心处理，同时将核心处理结果翻译给使用者。每次完成系统登入(login)，就会取得一个互动模式的 shell ，也称为 login shell 或 primary shell。 如果从进程(process)角度看，我们在 shell 所下达的命令，均是 shell 所产生的子进程，这种现象可称为 fork 如果是执行脚本(shell script)的话，脚本中的命令则是由另外一个非互动模式的子 shell (sub shell)来执行的。也就是 primary shell 产生 sub shell 的进程，sub shell 再产生 script 中所有命令的进程。 kernel 与 shell 是不同的两套软件，而且都是可以被替换的，不同的操作系统使用不同的 kernel，在同一个 kernel 之上也可使用不同的 shell 在 linux 的预设系统中，通常都可以找到好几种不同的 shell ，且通常会被列于 /etc/shells 当中。不同的 shell 有着不同的功能，且也彼此各异、或说”大同小异”。 常见 Shell 分类主要分为两大主流：sh 和 csh。 sh 分为 burne shell (sh) 和 burne again shell (bash)。大部分的 Linux 系统的预设 shell 都是 bash 这是因为它是自由软件，并且功能强大 csh 分为 c shell (csh)、tc shell (tcsh)、korn shell (ksh) Shell 和其他语言的差别严格意义上讲，Shell 不属于编程语言，Shell 脚本是由命令的堆砌而成。Shell 的优势在于处理操作系统底层的业务，一键安装、报警脚本，常规的业务应用，并且开发简单高效。 其他语言类似 php、 Python 是严格意义上的编程语言，优势在于开发运维工具，web界面的管理工具等 Shell 脚本基本格式123#!/bin/bash# This is a shell-scriptecho "Hello world!" 第 1 行很重要，它给 shell 一个很重要的线索，告诉它用什么程序来解释这个脚本，在这个列子中用的是 /bin/bash。其他脚本语言例如 perl、awk、python 等都是采用这种机制。 第 2 行是注释，在 # 符号后面的东西，bash 都视而不见给忽略掉。 第 3 行就是 shell 脚本要执行要解释的指令了。 第 1 行和第 2 行都是 # 号开头，区别在于第 1 行的 # 号后面接着一个 ! 号，这个就是脚本解释程序的声明指令，由调用这个脚本的 shell 来检测。它仅在脚本程序的第一行有效 执行 Shell 脚本的方式 用法 123$ bash [OPTIONS] firsh.sh-n：测试脚本是否有语法错误-x：显示脚本执行的详细过程 示例 123# 直接执行脚本文件或在当前路径下执行，脚本需要有执行权限;$ /etc/rc.d/init.d/network$ ./firsh.sh]]></content>
      <tags>
        <tag>BashShell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下软件包的管理]]></title>
    <url>%2F2015%2F05%2F28%2F112123-Linux%E4%B8%8B%E8%BD%AF%E4%BB%B6%E5%8C%85%E7%9A%84%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[RPM什么是rpmRPM是RedHat Package Manager（RedHat软件包管理工具）。它工作于R e d Hat Linux以及其它Linux系统，成为了Linux中公认的软件包管理标准。红帽子软件公司鼓励其他厂商来了解R PM并在自己的产品中使用它。R PM的发布基于GPL协议。随着R PM在各种发行版本的广泛使用，如今R PM的全称是R PM Pack ageManage r。 rpm包管理的用途1、可以安装、删除、升级和管理软件；当然也支持在线安装和升级软件；2、通过RPM包管理能知道软件包包含哪些文件，也能知道系统中的某个文件属于哪个软件包；3、可以在查询系统中的软件包是否安装以及其版本；4、作为开发者可以把自己的程序打包为RPM 包发布；5、软件包签名GPG和MD5的导入、验证和签名发布6、依赖性的检查，查看是否有软件包由于不兼容而扰乱了系统； RPM 包的命名方式以 httpd-2.2.15-39.el6.centos.x86_64.rpm 为例， httpd 表示软件名 2.2.15 表示主版本号，次版本号，发行版本号分别是2，2，15 39.el6.centos 表示 RPM 包的修订号和 OS 信息 x86_64 表示此软件包适用的平台，常见的有i386，i586，x86_64 等 RPM包管理命令的使用安装1rpm &#123;-i|--install&#125; [install-options] PACKAGE_FILE1.. 安装时可以使用 -h 以#的个数显示安装进度，一个#表示2%的进度，使用 -v 显示详细安装信息 --test 可以用于测试安装是否能够成功，而不实际安装 在安装过程中，可能遇到软件包的依赖问题，而需要先安装其他软件包，--nodeps 忽略依赖强制安装，但是这样安装的软件包通常也会因为依赖缺失而无法正常工作 如果需要重新安装并覆盖原有的文件，可以使用 --replacepkgs 选项 使用 --force 可以进行强制覆盖安装，它等同于--replacepkgs, --replacefiles, 和 --oldpackage 12rpm -ivh /media/cdrom/CentOS/elinks-0.11.1-5.1.el5.i386.rpmrpm -ivh http://centos.candishosting.com.cn/5/os/i386/CentOS/elinks-0.11.1-5.1.el5.i386.rpm 升级或安装 如果不知道一个软件包是否已经安装，并希望如果已经安装那么升级次软件包，使用 -U 选项。 1rpm &#123;-U|--upgrade&#125; [install-options] PACKAGE_FILE ... 如果仅仅希望升级软件包，使用 -F 选项 1rpm &#123;-F|--freshen&#125; [install-options] PACKAGE_FILE ... 升级软件包和安装软件包一样，可以使用 --test、--nodeps、--force 等选项。 1234567# 安装并升级 zsh 软件包[root@localhost rpm]# rpm -ivh zsh-4.3.10-7.el6.x86_64.rpmPreparing... ########################################### [100%]1:zsh ########################################### [100%][root@localhost rpm]# rpm -Uvh zsh-4.3.10-9.el6.x86_64.rpmPreparing... ########################################### [100%]1:zsh ########################################### [100%] 如果想要将软件包降级到旧版本，使用 –oldpackage 选项 123[root@localhost rpm]# rpm -Uvh --oldpackage zsh-4.3.10-7.el6.x86_64.rpmPreparing... ########################################### [100%]1:zsh ########################################### [100%] 在升级软件包时，原来软件包的配置文件可能已经被修改，升级时，新版本的文件不会将老版本的配置文件覆盖，而是将新版本的配置文件加上 .rpmnew 后缀后保存。 注意：内核也是软件包，但是不建议直接对内核进行升级。多版本内核可以并存，因此建议执行安装操作 卸载1rpm &#123;-e|--erase&#125; [--allmatches] [--nodeps] [--test] PACKAGE_NAME ... 通常使用 rpm -e PACKAGE_ANEM 即可简单卸载一个软件包 使用 --nodeps 忽略依赖关系--test 测试卸载。--allmatches 表示如果一个程序包同时安装多个版本，则次选项一次全部卸载之 如果卸载正常，不会输出任何信息。 注意：如果程序包的配置文件安装后曾被修改，卸载时，此文件通常不会被删除，而是被重命名为 .rpmsave 后缀后留存。 查询 查询使用 -q 选项，可以检查安装的所有包，还可以查看某包的详细信息。 1rpm &#123;-q|--query&#125; [select-options] [query-options] 1234567891011121314151617181920212223242526272829303132333435363738rpm -q zsh# 查询某包是否已经安装rpm -qa# 查询安装的所有包 rpm -qp nmap-5.51-4.el6.x86_64# 查询未安装包信息# 查询未安装包的信息指定的是 RPM 包的文件名而不是某个包的软件名。rpm -qi bash# 查询安装包包的简要说明信息rpm -ql zsh# 查询软件包安装的文件列表rpm -qf /etc/ssh/sshd_config# 查询某文件是哪个包安装生成的rpm -qc openssh-server# 查看软件包安装后生成的所有配置文件rpm -qd nmap# 查看软件包安装后生成的所有说明文件和帮助文件rpm -q --changelog nmap# 查看软件包制作时随版本变化的 changelog 信息rpm -q --requires nmap# 查看软件包所需的依赖rpm -q --scripts zsh# 查看软件包安装或卸载时执行的脚本# 脚本分四类# preinstall 安装前脚本# postinstall 安装后脚本# preuninstall 卸载前脚本# postuninstall 卸载后脚本 检验查询软件包安装之后的文件是否发生了改变 1rpm &#123;-V|--verify&#125; [select-options] [verify-options] 检验时使用了多个位表示文件的多个属性是否发生了变化： S 文件大小M 文件权限5 文件摘要信息（通常是 MD5 码）D 设备文件的主/次设备号L 软链接变化U 属主G 属组T 文件的 mtimeP caPabilities 程序包的合法性验证 在软件包制作时，为了防止软件包被人修改植入后门，制作者可以使用自己私钥对软件包进行数字签名，安装者就可以使用公钥验证软件包的合法性。同时还可以使用摘要算法提取软件包的摘要信息用于验证软件包的完整性。 通常，RHEL 系的安装光盘中包含有用于验证其软件包合法性的公钥文件。 导入公钥 1rpm --import /path/to/RPM-GPG-KEY-FILE 验证合法性 1rpm &#123;-K|--checksig&#125; PACKAGE_FILE RPM 管理器的数据库每次安装 rpm 包时，rpm 系统会将一些元信息存储在它的数据库中，使用 rpm -q 命令查询软件包的相关信息时将会查询这些数据库，数据库文件位于 /var/lib/rpm 目录中。如果 RPM 的数据库损坏，将会导致一些 RPM 数据丢失，一些功能将无法正常使用。 重建数据库如果 RPM 的数据库损坏，首先可以尝试重建它，如果无法重建，那么需要重新初始化数据库。 1rpm --rebuilddb 表示重建数据库 这个命令会从已安装的软件包提取信息重建数据库，它从 /var/lib/rpm/Packages 这个文件中提取信息，其他所有的数据库文件都可以由这个文件重建。如果 RPM 的数据库是完好的，这个命令不会重建，而是对数据库中未使用的条目进行空间回收。 1rpm --initdb 创建一个新的 RPM 数据 如果已经没有其他别的办法了，–initdb 会创建一个新的空的 RPM 数据库。由于新建的数据库是空的，不要万不得已不要使用这个命令。 yum为什么使用yumLinux系统维护中令管理员很头疼的就是软件包之间的依赖性了，往往是你要安装A软件，但是编译的时候告诉你X软件安装之前需要B软件，而当你安装Y软件的时候，又告诉你需要Z库了，好不容易安装好Z库，发现版本还有问题等。由于历史原因，R PM软件包管理系统对软件之间的依存关系没有内部定义，造成安装RPM软件时经常出现令人无法理解的软件依赖问题。其实开源社区早就对这个问题尝试进行解决了，不同的发行版推出了各自的工具，比如Yellow Dog的YUM（Yellowdog Updater, Modified），De bian的APT(Advance d Pack aging Tool)等。开发这些工具的目的都是为了要解决安装RPM时的依赖性问题，而不是额外再建立一套安装模式。 什么是yum yum（全称为 Yellow dog Updater, Modified）是一个在Fedora和RedHat以及SUSE中的Shell前端软件包管理器。 基於RPM包管理，能够从指定的服务器自动下载RPM包并且安装，可以自动处理依赖性关系，并且一次安装所有依赖的软体包，无须繁琐地一次次下载、安装。 YUM基于RPM包管理工具，能够从指定的源（服务器，本地目录等）自动下载目标RPM包并且安装，可以自动处理依赖性关系并进行下载、安装，无须繁琐地手动下载、安装每一个需要的依赖包。 yum的特点 自动解决包的倚赖性问题能更方便的添加/删除/更新R PM包 便于管理大量系统的更新问题 可以同时配置多个资源库(Re pository) 简洁的配置文件(/etc/yum .conf) 保持与RPM数据库的一致性 有一个比较详细的log，可以查看何时升级安装了什么软件包等 使用方便 yum客户端 配置文件：指定各可用的yum仓库 缓存元数据：yum会到各可用yum仓库获取元数据，并缓存至本地 分析元数据：根据具体的操作请求完成元数据分析，可能包括依赖关系、文件列表等信息 执行具体操作 客户端配置文件指定对服务器配置文件 ftp ftp://server/path/to/repo http http://server/path/to/repo nfs nfs://servr/nfs_path file file:///path/to/path 仓库配置 要使用yum管理应用程序，首先得配置其可用的yum仓库，保存在配置文件中。 配置文件格式：由两段组成。 /etc/yum.conf： [main]，主配置段 /etc/yum.repo.d/*.repo： [repo]，仓库配置段 配置repo 123456789[repositoryid]name=Some name for this repositorybaseurl=url://server1/path/to/repository/url://server2/path/to/repository/url://server3/path/to/repository/mirrorlist=url://path/to/mirrorlist/repository/enabled=0/1gpgcheck=0/1gpgkey=A URL pointing to the ASCII-armoured GPG key file for the repository 12345678910repositoryid # 指定一个仓库name # 指定易读的仓库名称baseurl # 指定本仓库的URL，可以是如下的几种类型# http # 指定远程HTTP协议的源 ftp # 指定远程FTP协议的源 file # 本地镜像或NFS挂装文件系统enabled # 指定是否使用本仓库，默认值为1，即可用gpgcheck # 指定是否检查软件包的GPG签名gpgkey # 公钥地址，可以是本地，也可以是服务器端路径cost # 定义此仓库开销，默认为1000 常用命令 安装 1234yum install # 全部安装yum install package1 # 安装指定的安装包package1，手动禁止检查来源及完整性：--nogpgcheckyum reinstall package1 # 重新安装指定的安装包package1yum groupinsall group1 # 安装程序组group1 更新和升级 123456yum check-update # 检查可升级的包yum update # 全部更新yum update package1 # 更新指定程序包package1，要升级到指定版本要带版本号如nmap-5.51yum upgrade package1 # 升级指定程序包package1yum groupupdate group1 # 升级程序组group1yum downgrade package1 # 降级指定程序包package1 查找和显示 1234567891011yum info package1 # 显示安装包信息package1yum list # [all|installed（已安装过的）|available(可用)];显示所有已经安装和可以安装的程序包yum list package1 # 显示指定程序包安装情况package1yum info # 显示包的详细信息yum grouplist # 列出所有的包组yum groupinfo group1 # 显示程序组group1信息yum search string # 根据关键字string查找安装包yum deplist package1 # 查看程序package1依赖情况yum whatprovides /etc/shadow # 查看/etc/shadow是由哪个包提供的yum provides /etc/shadow # 查看/etc/shadow是由哪个包提供的yum history # 查看yum的命令历史 删除和卸载 12yum remove|erase package1 # 移除|卸载程序包package1，依赖的包也会被卸载yum groupremove group1 # 删除程序组group1 清除缓存 1234yum clean packages # 清除缓存目录/var/cache/yum 下的软件包yum clean headers # 清除缓存目录/var/cache/yum 下的 headersyum clean oldheaders # 清除缓存目录/var/cache/yum 下旧的 headersyum clean;yum clean all # = yum clean packages; yum clean oldheaders) yum配置文件中可用的宏 $releasever：程序的版本 对Yum而言指的是redhat-relrase版本。 只替换为主版本号，如Redhat6.5 则替换为6 $arch:系统架构 $basharch:系统基本架构，如i686，i586等的基本架构为i386 $YUM0-9:在系统定义的环境变量，可以在yum中使用 CentOS的镜像站点镜像站点的第一级目录是发行版本号，如 3、4、5 等 搜狐开源镜像站：http://mirrors.sohu.com/ 网易开源镜像站：http://mirrors.163.com/ 北京理工大学： http://mirror.bit.edu.cn (IPv4 only) http://mirror.bit6.edu.cn (IPv6 only) 清华大学： http://mirrors.tuna.tsinghua.edu.cn/ (IPv4+IPv6) http://mirrors.6.tuna.tsinghua.edu.cn/ (IPv6 only) http://mirrors.4.tuna.tsinghua.edu.cn/ (IPv4 only) 天津大学：http://mirror.tju.edu.cn/ 中国科学技术大学： http://mirrors.ustc.edu.cn/ (IPv4+IPv6) http://mirrors4.ustc.edu.cn/ http://mirrors6.ustc.edu.cn/ 源码包linux源码包与RPM包的区别 安装之前 源码包是开源的，比RPM包安装更自由，但是它安装更慢，更容易报错 RPM包是经过编译的，不能看到源代码，但是它安装更快，报错更容易解决，只有依赖性问题 安装之后 RPM包不需要指定安装位置，它会安装到系统默认位置 源码包是人为手工设置 源码包编译安装基本步骤 注意：源码包编译安装前提是准备开发环境(编译环境) 若系统为Centos 5，开发包组为”Development Tools“和”DeveLopment Libraries“ 若系统为centos 6，常用的开发包为”Development tools“和”Server Platform Development” 拿到源代码，并解压 tar -xf package-version.tar.{gz|bz2|xz}注意：展开后的目录通常为package-version 切换至源码目录中 cd package-version 执行configure脚本 ./configure 编译 make 安装 make install 头文件输出给系统、创建库文件链接、二进制可执行文件环境变量、导出man文件 configure脚本的通用功能(需要定义的配置) 指定安装路径 --prefix=前缀，用于指定安装路径 --sysconfdir=/etc/package_name 指定启动/禁用的特性 --enable-feature --disable-fecture 指定所依赖功能、程序或文件 --with-function：启用某功能 --without-function： 禁用某功能 不同的程序，其configure不尽相同，应获取帮助信息 1./configure --help]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中netstat命令的使用]]></title>
    <url>%2F2015%2F05%2F27%2F134115-Linux%E4%B8%ADnetstat%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Netstat 是一款命令行工具，可用于列出系统上所有的网络套接字连接情况，包括 tcp, udp 以及 unix 套接字，另外它还能列出处于监听状态（即等待接入请求）的套接字 常见参数 -a, --all 列出所有连接，netstat 默认不显示 LISTEN 相关 -t, --tcp 只列出 TCP 的连接 -u, --udp 只列出 UDP 的连接 -n, --numeric 禁用对域名、主机名、端口名的反向解析，能显示数字的全部转化成数字 -l, --listening 仅列出有在 Listen (监听) 的服务状态，不要使用 -a 选项，否则会列出所有连接，而不仅仅是监听端口 -p, --program 获取进程名、进程ID -r, --route , 显示路由信息，路由表 -e, --extend 显示扩展信息，例如 uid 等 -s, --statistics 按各个协议进行统计 (重要) -c, --continuous 每隔一个固定时间，执行该netstat命令 常用示例列出所有端口，不显示域名、主机名、端口名 12netstat -ant # 列出所有 tcp 端口netstat -anu # 列出所有 udp 端口: 列出所有处于监听状态的 Sockets 1234netstat -l # 只显示监听端口netstat -lt # 只列出所有监听 tcp 端口 netstat -lu # 只列出所有监听 udp 端口 netstat -lx # 只列出所有监听 UNIX 端口 显示每个协议的统计信息 123netstat -s # 显示所有协议的统计信息netstat -st # 显示 tcp 协议的统计信息netstat -su # 显示 udp 协议的统计信息 显示 PID 和进程名称 1234567891011[root@study ~]$ netstat -tunlpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 24172/sshd tcp 0 0 127.0.0.1:25 0.0.0.0:* LISTEN 1406/master tcp6 0 0 :::22 :::* LISTEN 24172/sshd tcp6 0 0 ::1:25 :::* LISTEN 1406/master udp 0 0 127.0.0.1:323 0.0.0.0:* 509/chronyd udp 0 0 0.0.0.0:68 0.0.0.0:* 607/dhclient udp6 0 0 ::1:323 :::* 509/chronyd [root@study ~]# 不显示域名、主机名、端口名 123456netstat -an# 如果只是不想让这三个名称中的一个被显示，使用以下命令netstat -a --numeric-portsnetstat -a --numeric-hostsnetstat -a --numeric-users 持续输出 netstat 信息 1netstat -antp -c 2 # netstat 将每隔一秒输出网络信息 显示核心路由信息 1netstat -rn 显示网络接口列表 123456789[user1@study ~]$ netstat -iKernel Interface tableIface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flgeth0 1500 21443 0 0 0 11674 0 0 0 BMRUeth1 1500 69 0 0 0 0 0 0 0 BMRUeth2 1500 69 0 0 0 0 0 0 0 BMRUeth3 1500 69 0 0 0 0 0 0 0 BMRUlo 65536 0 0 0 0 0 0 0 0 LRU[user1@study ~]$]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux中date命令的使用]]></title>
    <url>%2F2015%2F05%2F26%2F150103-Linux%E4%B8%ADdate%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[date print or set the system date and time，打印或设置系统日期和时间 Rtc：real time clock，硬件时间 Ntp：Network time Protocol，网络时间协议 常用选项12345678910111213141516-d, --date=STRING 显示由 STRING 指定的时间, 而不是当前时间 -f, --file=DATEFILE 显示 DATEFILE 中每一行指定的时间, 如同将 DATEFILE 中的每行作为 --date 的参数一样 -r, --reference=FILE 显示 FILE 的最后修改时间 -R, --rfc-822 根据 RFC-822 指定格式输出日期 -s, --set=STRING 根据 STRING 设置时间 -u, --utc, --universal 显示或设置全球时间(格林威治时间) --help 显示本帮助文件并退出 --version 显示版本信息并退出 输出格式的控制格式 FORMAT 控制着输出格式. 仅当选项指定为全球时间时本格式才有效 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172 %% 文本的 % %a 当前区域的星期几的简写 (Sun~Sat) %A 当前区域的星期几的全称 (不同长度) (Sunday~Saturday) %b 当前区域的月份的简写 (Jan~Dec) %B 当前区域的月份的全称(变长) (January~December) %c 当前区域的日期和时间 (Sat Nov 04 12:02:33 EST 1989) %d (月份中的)几号(用两位表示) (01~31) %D 日期(按照 月/日期/年 格式显示) (mm/dd/yy) %e (月份中的)几号(去零表示) ( 1~31) %F 完整日期，同 %Y-%m-%d %h 同 %b %H 小时(按 24 小时制显示，用两位表示) (00~23) %I 小时(按 12 小时制显示，用两位表示) (01~12) %j (一年中的)第几天(用三位表示) (001~366) %k 小时(按 24 小时制显示，去零显示) ( 0~23) %l 小时(按 12 小时制显示，去零表示) ( 1~12) %m 月份(用两位表示) (01~12) %M 分钟数(用两位表示) (00~59) %N %N输出的是当前时间的纳秒部分 %n 换行 %p 当前时间是上午 AM 还是下午 PM %r 时间,按 12 小时制显示 (hh:mm:ss [A/P]M) %s 从 1970年1月1日0点0分0秒到现在历经的秒数 (GNU扩充) %S 秒数(用两位表示)(00~60) %t 水平方向的 tab 制表符 %T 时间,按 24 小时制显示(hh:mm:ss) %U (一年中的)第几个星期，以星期天作为一周的开始(用两位表示) (00~53) %V (一年中的)第几个星期，以星期一作为一周的开始(用两位表示) (01~52) %w 用数字表示星期几 (0~6); 0 代表星期天 %W (一年中的)第几个星期，以星期一作为一周的开始(用两位表示) (00~53) %x 按照 (mm/dd/yy) 格式显示当前日期 %X 按照 (%H:%M:%S) 格式显示当前时间 %y 年的后两位数字 (00~99) %Y 年(用 4 位表示) (1970~~~) %z 按照 RFC-822 中指定的数字时区显示(如, -0500) (为非标准扩充) %Z 时区(例如, EDT (美国东部时区)), 如果不能决定是哪个时区则为空 默认情况下,用 0 填充数据的空缺部分. GNU 的 date 命令能分辨在%和数字指示之间的以下修改. - (连接号) 不进行填充 _ (下划线) 用空格进行填充 常见用法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152date -s '20161105'# Sat Nov 5 00:00:00 HKT 2016 日期设置成20061010，这样会把具体时间设置成空00:00:00 date -s '16:20:00'# Sat Nov 5 16:20:00 HKT 2016 只设置时间，不更改日期 date -s '2016-11-05 16:14:29'date -s '20161105 16:14:29'# Sat Nov 5 16:14:29 HKT 2016 设置日期和时间 date -d "20161105" +%s # 1478275200 时间转时间戳 date -d '1970-01-01 UTC 1478275200 seconds'date -d @1478275200# Sat Nov 5 00:00:00 HKT 2016 时间戳转时间 date +%F\ %T# 2016-11-05 16:35:11 获取当前日期和时间 date +%Y%m%d%H%M%S# 20161105163652 获取将当前日期为字串 date +%Y%m%d# 20161105 获取当前日期格式为yyyymmdd date +%Y%m%d -d "1 day ago" date +%Y%m%d --date="+1 day" 获取前一天的日期格式为yyyymmdd date -d '3days ago -1 hour' +"%Y-%m-%d %H"date -d '-3 day -1 hour' +"%F %T" 3天前再向后1小时 date +%Y%m%d --date="-1 day" 显示后一天的日期date +%Y%m%d --date="-1 month" 显示上一月的日期date +%Y%m%d --date="+1 month" 显示下一月的日期date +%Y%m%d --date="-1 year" 显示前一年的日期date +%Y%m%d --date="+1 year" 显示下一年的日期]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下命令路径搜索]]></title>
    <url>%2F2015%2F05%2F14%2F150123-Linux%E4%B8%8B%E5%91%BD%E4%BB%A4%E8%B7%AF%E5%BE%84%E6%90%9C%E7%B4%A2%2F</url>
    <content type="text"><![CDATA[which概述用于查找并显示给定命令的绝对路径，环境变量PATH中保存了查找命令时需要遍历的目录。which指令会在环境变量$PATH设置的目录里查找符合条件的文件。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 语法1Usage: which [options] [--] programname [...] 选项1234-n &lt;文件名长度&gt;：制定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名-p &lt;文件名长度&gt;：与-n参数相同，但此处的&lt;文件名长度&gt;包含了文件的路径-w：指定输出时栏位的宽度-V：显示版本信息 示例1234567891011[user1@practice ~]$ which lsalias ls='ls --color=tty' /bin/ls[user1@practice ~]$ which awk/bin/awk[user1@practice ~]$ which grepalias grep='grep --color' /usr/bin/grep[user1@practice ~]$ which test/usr/bin/test[user1@practice ~]$ dirname概述去除文件名中的非目录部分，仅显示与目录有关的内容。dirname命令读取指定路径名保留最后一个/及其前面的字符，删除其他部分，并写结果到标准输出。如果最后一个/后无字符，dirname 命令使用倒数第二个/，并忽略其后的所有字符。 语法12Usage: dirname NAME or: dirname OPTION 选项12--help：显示帮助--version：显示版本号 示例1234567891011[user1@practice ~]$ dirname ///[user1@practice ~]$ dirname /usr/local/bin//usr/local[user1@practice ~]$ dirname /usr/local/bin/usr/local[user1@practice ~]$ dirname /usr/bin/sort/usr/bin[user1@practice ~]$ dirname test.[user1@practice ~]$ basename概述用于打印目录或者文件的基本名称。 语法12Usage: basename NAME [SUFFIX] or: basename OPTION 选项12--help：显示帮助--version：显示版本号 示例12345678910111213[user1@practice ~]$ basename ///[user1@practice ~]$ basename /usr/local/bin/bin[user1@practice ~]$ basename /usr/local/binbin[user1@practice ~]$ basename /usr/bin/sortsort[user1@practice ~]$ basename testtest[user1@practice ~]$ basename /usr/bin/sort rtso[user1@practice ~]$ readlink概述输出符号链接值或者权威文件名，主要用来 找出符号链接所指向的位置 语法1readlink [OPTION]... FILE 选项123-f, --canonicalize：递归跟随给出文件名的所有符号链接以标准化，除最后一个外所有组件必须存在。简单地说，就是一直跟随符号链接，直到非符号链接的文件位置，限制是最后必须存在一个非符号链接的文件--help：显示帮助--version：显示版本号 示例123456789[user1@practice ~]$ readlink awk [user1@practice ~]$ readlink -f awk /home/user1/awk[user1@practice ~]$ readlink -f /usr/bin/awk /bin/gawk# awk其实是一个符号链接文件，指向的是/bin/gawk[user1@practice ~]$ readlink -f /bin/gawk/bin/gawk[user1@practice ~]$ type概述用来显示指定命令的类型，判断给出的指令是内部指令还是外部指令 命令类型 alias：别名。 keyword：关键字，Shell保留字 function：函数，Shell函数 builtin：内建命令，Shell内建命令 file：文件，磁盘文件，外部命令 unfound：没有找到 语法1type: usage: type [-afptP] name [name ...] 选项 -a：打印name的所有可能情况，例如 1234[user1@practice ~]$ type -a lsls is aliased to `ls --color=tty&apos;ls is /bin/ls[user1@practice ~]$ -f：不会去查找function -t：打印alias，keyword，function，built-in，file这5种类型 -p：如果type -t name输出file，那么会打印name所在路径 -P：不管type -t name是不是输出file，都会去搜索name所在路径，比如type -P ls，尽管type -t ls打印的是alias(因为alias的优先级高于file)，但是仍然会搜索出ls所在的路径/bin/ls 如果type不加任何选项，直接加1个或者多个name，那么会依次打印这些name的类型。只有所有name的类型都能成功打印，type才返回成功，否则，只要任何一个name类型无法打印，那么就返回失败 示例123456789101112[user1@practice ~]$ type -t echobuiltin[user1@practice ~]$ type -p echo[user1@practice ~]$ type -P echo/bin/echo[user1@practice ~]$ type -t awkfile[user1@practice ~]$ type -p awk/bin/awk[user1@practice ~]$ type -P awk/bin/awk[user1@practice ~]$]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下如何获取命令的帮助]]></title>
    <url>%2F2015%2F05%2F13%2F210127-Linux%E4%B8%8B%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E7%9A%84%E5%B8%AE%E5%8A%A9%2F</url>
    <content type="text"><![CDATA[获得命令的帮助 内建命令 12help command command -h 外部命令 123command --helpman commandinfo command 命令手册 manual whatis 查看命令的章节 1whatis command 章节分类 Standard commands 标准命令（/bin，/usr/bin，/usr/local/bin） System calls 系统调用 Library functions 库函数 Special devices 特殊设备 File formats 文件格式（配置文件的语法格式） Games and toys 游戏和娱乐 Miscellaneous 杂项 Administrative Commands 管理员命令（/sbin，/usr/sbin，/usr/local/sbin） 其他（Linux特定的） 用来存放内核例行程序的文档 man 查看使用手册 &gt; 符号标识 &lt;&gt; 必选项 [] 可选项 .... 可出现多次 | 多选一 {} 分组，无特殊意义 标题说明 NAME 命令名称及功能简要说明 SYNOPSIS：用法说明，包括可用的选项 DESCRIPTION：命令功能的详尽说明，可能包括每一个选项的意义 OPTIONS：说明每一个选项的意义 FILES：此命令相关的配置文件 BUGS：漏洞或缺陷 EXAMPLES：使用示例 SEE ALSO：另外参照 界面操作 ‘空格’ 键 向后翻一屏 b 向前翻一屏 Enter、j、↓ 向后翻一行 k、↑ 向前翻一行 /keyword 向后查询，再按 n 查询下一个，N 上一个 ?keyword 向前查询，n 下一个，N 上一个 q 退出man帮助 info文档 界面操作 ?：显示info的常用快捷键。 N：显示（相对于本节点的）下一节点的文档内容 P：显示（相对于本节点的）前一节点的文档内容 U：进入当前命令所在的主题。 M：敲M键后输入命令的名称就可以查看该命令的帮助文档 G：敲G键后输入主题名称，进入该主题 L：回到上一个访问的页面 SPACE：向前滚动一页 BackSpace 或 Del ：向后滚动一页 Q：退出 info 使用man中文手册下载中文手册包 man-pages 下载链接 https://manpages-zh.googlecode.com/files/manpages-zh-1.5.1.tar.gz Github：https://github.com/manpages-zh 配置安装 1234567891011# 查看系统支持的字符集locale -a # 设置语言环境为中文 export LANG=zh_CN.utf8# 编译安装tar -zxvf manpages-zh-1.5.1.tar.gzcd manpages-zh-1.5.1./configure --disable-zhtwmake &amp;&amp; make install 测试 12345678# 查看man中文手册是否加入到man路径里面man --path# 列出所有和passwd相关的帮助手册man 5 -a --path passwd# 查看man手册是否变成中文man find]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux的whereis命令]]></title>
    <url>%2F2015%2F05%2F05%2F150131-Linux%E7%9A%84whereis%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[whereis 可以查找指定命令的二进制文件、源文件和帮助文件。 被找到的文件在显示时，会去掉主路径名，然后再去掉文件的（单个）尾部扩展名 (如: .cc)，来源于源代码控制的 s. 前缀也会被去掉。接下来，whereis 会尝试在标准的 Linux 位置里寻找具体程序，也会在由 $PATH 和 $MANPATH 指定的路径中寻找。 1whereis [options] [-BMS directory... -f] name... 命令寻找二进制文件所在位置 12345[root@study ~]# whereis whereiswhereis: /usr/bin/whereis /usr/share/man/man1/whereis.1.gz[root@study ~]# whereis lsls: /usr/bin/ls /usr/share/man/man1/ls.1.gz[root@study ~]# 使用 -b 选项在搜索时规定只搜索二进制文件 12345678[root@study ~]# whereis -b lsls: /usr/bin/ls[root@study ~]# whereis -b whereiswhereis: /usr/bin/whereis[root@study ~]# whereis -b ls whereisls: /usr/bin/lswhereis: /usr/bin/whereis[root@study ~]# 使用 -m 选项在搜索时规定只搜索帮助页面文件 12345678[root@study ~]# whereis -m lsls: /usr/share/man/man1/ls.1.gz[root@study ~]# whereis -m whereiswhereis: /usr/share/man/man1/whereis.1.gz[root@study ~]# whereis -m ls whereisls: /usr/share/man/man1/ls.1.gzwhereis: /usr/share/man/man1/whereis.1.gz[root@study ~]# 使用 -s 选项在搜索时规定只搜索源代码文件 1234[root@study ~]# whereis -s lsls:[root@study ~]# [root@study ~]# whereis -s whereiswhereis:[root@study ~]# 使用 -u 选项找到一个有异常条目的命令。对于 whereis 命令来说，如果一个命令对每个显式的请求类型都不止一项，则该命令被视为异常。例如，没有可用文档的命令，或者对应文档分散在各处的命令都可以算作异常命令。 当使用 -u 这一选项，whereis 就会显示那些有异常条目的命令。 在当前目录中，寻找没有对应文档或有多个文档的命令 1whereis -m -u * 使用 -l 选项查看 whereis 的搜索路径 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566[root@study ~]# whereis -lbin: /usr/binbin: /usr/sbinbin: /usr/libbin: /usr/lib64bin: /etcbin: /usr/etcbin: /usr/gamesbin: /usr/local/binbin: /usr/local/sbinbin: /usr/local/etcbin: /usr/local/libbin: /usr/local/gamesbin: /usr/includebin: /usr/localbin: /usr/libexecbin: /usr/shareman: /usr/share/man/man1man: /usr/share/man/man5man: /usr/share/man/man7man: /usr/share/man/man8man: /usr/share/man/man0pman: /usr/share/man/man1pman: /usr/share/man/man1xman: /usr/share/man/man2man: /usr/share/man/man2xman: /usr/share/man/man3man: /usr/share/man/man3pman: /usr/share/man/man3xman: /usr/share/man/man4man: /usr/share/man/man4xman: /usr/share/man/man5xman: /usr/share/man/man6man: /usr/share/man/man6xman: /usr/share/man/man7xman: /usr/share/man/man8xman: /usr/share/man/man9man: /usr/share/man/man9xman: /usr/share/man/mannman: /usr/share/man/frman: /usr/share/man/jaman: /usr/share/man/koman: /usr/share/man/plman: /usr/share/man/ruman: /usr/share/man/skman: /usr/share/man/csman: /usr/share/man/daman: /usr/share/man/deman: /usr/share/man/human: /usr/share/man/idman: /usr/share/man/itman: /usr/share/man/pt_BRman: /usr/share/man/svman: /usr/share/man/trman: /usr/share/man/zh_CNman: /usr/share/man/zh_TWman: /usr/share/man/ptman: /usr/share/man/esman: /usr/share/man/hrman: /usr/share/man/pt_PTman: /usr/share/man/roman: /usr/share/man/zhman: /usr/share/man/nlsrc: /usr/src/debugsrc: /usr/src/kernels[root@study ~]#]]></content>
      <tags>
        <tag>Command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统目录结构]]></title>
    <url>%2F2015%2F05%2F04%2F192107-Linux%E7%B3%BB%E7%BB%9F%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[. ：当前目录，也可以用 ./ 表示； .. ：上一级目录，也可以用 ../ 表示； ~ ： 用户自己的宿主目录； / ：根目录 Linux文件系统树形结构的最顶端，称为 Linux 文件系统的 root，它是 Linux 文件系统的入口。所有的目录、文件、设备都在 / 之下，它是 Linux 文件系统最顶层的唯一的目录; 一般建议在根目录下面只有目录，不直接存放文件； 根目录是 linux 系统启动时系统第一个载入的分区，所以启动过程中用到的文件应该都放在这个分区中，其中 /etc、/bin、/dev、/lib、/sbin 这 5 个子目录都应该要与根目录连在一起，不可独立成为某个分区； /bin：含了引导启动所需的命令或普通用户可能用的命令(可能在引导启动后)。这些命令都是二进制文件的可执行程序(bin是binary的简称)，多是系统中重要的系统文件 /sbin：类似 /bin ，也用于存储二进制文件。因为其中的大部分文件多是系统管理员使用的基本的系统程序，所以虽然普通用户必要且允许时可以使用，但一般不给普通用户使用，多数管理命令默认只有管理员可以使用 /etc ：存放着各种系统的管理和配置文件 /root：超级用户 root 的家目录 /lib：根文件系统上的程序所需的共享库，存放了根文件系统程序运行所需的共享文件。 这些文件包含了可被许多程序共享的代码，以避免每个程序都包含有相同的子程序的副本，故可以使得可执行文件变得更小，节省空间。 /lib/modules ：包含系统核心可加载各种模块，尤其是那些在恢复损坏的系统时重新引导系统所需的模块(例如网络和文件系统驱动)。 /boot：目录存放引导加载器(bootstrap loader)使用的文件，包括开机启动加载程序的核心文件；(如kernel和grub) /mnt ：临时挂载用的设备挂载点；(如磁盘分区，网络共享) /media：移动存储设备默认挂载点；(如光盘) /opt：额外所安装的应用程序目录,有些软件包我们可以将它安装在该目录中；(一般为空，某些应用软件安装需要这个目录) /tmp：临时文件存放区域，默认被设置了粘滞位，存放程序在运行时产生的信息和数据 /dev：设备文件目录，即设备驱动程序，用户通过这些文件访问外部设备。比如，用户可 以通过访问/dev/mouse来访问鼠标的输入，就像访问其他文件一样，设备文件分为 2 种类型：字符设备文件和块设备文件 /dev/console：系统控制台，也就是直接和系统连接的监视器； /dev/hd：IDE设备文件 /dev/sd：sata、usb、scsi等设备文件 /dev/fd：软驱设备文件 /dev/tty：虚拟控制台设备文件 /dev/pty：提供远程虚拟控制台设备文件 /dev/null：数据”黑洞”，所有写入该设备的信息都将消失，如当想要将屏幕上的输出信息隐藏起来时，只要将输出信息输入到 /dev/null 中即可； /home：默认存放用户的宿主目录(除了 root 用户) /home/~/.bashrc：提供 bash 环境中所需使用的别名； /home/~/.bash_profile：提供 bash 环境所需的变量； 一般先执行 .bashrc 后，才会再执行 .bash_profile； /home/~/.bash_history：用户历史命令文件，记录用户曾经输入过的所有命令；(默认为1000条，可以通过 HISTSIZE 变量更改) /home/~/.bash_logout：当用户注销的同时，系统会自动执行 .bash_logout 文件，如果管理员需要记录用户注销的一些额外记录、动作或其他信息，就可以利用这个机制去完成； /lost+found：当系统在运行时，有时会无法避免宕机、断电或不正常重启动，在这样的情况下，当系统重新启动时，发现某些文件写入未完成或其他问题产生，一般会使用 fsck 进行文件修复，而这些被修复或救回的文件，就会被放在这个目录下，只要是一个文件系统，系统就会自动在该文件系统所在的目录下建立 lost+found 目录 /sys：虚拟文件系统，被建立在内存中，是在2.6版的kernel之后才被加入到正式的文件系统中，以分类的方式将系统的信息存放在这个目录中，以方便linux用户通过不同的分类找出系统相关的信息； /proc：虚拟文件系统，此目录是 kernel 加载后，在内存里面建立的一个虚拟目录，有专属的文件系统，主要提供系统一些实时的信息，此目录下不能建立和删除文件；(某些文件可以修改)；/proc 主要作用可以整理为： 整理系统内部的信息； 存放主机硬件信息； 调整系统执行时的参数； 检查及修改网络和主机的参数； 检查及调整系统的内存和性能； /proc下常用的信息文件有： /proc/cpuinfo：cpu的硬件信息，如类型、厂家、型号和性能等 /proc/devices：记录所有在 /dev 目录中相关的设备文件分类方式 /proc/filesystems：当前运行内核所配置的文件系统 /proc/interrupts：可以查看每一个IRQ的编号对应到哪一个硬件设备 /proc/loadavg：系统”平均负载”，3个数据指出系统当前的工作负载 /proc/dma：当前正在使用的DMA通道 /proc/ioports：将目前系统上所有可看到的硬件对应到内存位置的分配表的详细信息呈现出来 /proc/kcore：系统上可以检测到的物理内存，主机内存多大，这个文件就有多大 /proc/kmsg：在系统尚未进入操作系统阶段，把加载 kernel 和 initrd 的信息先记录到该文件中，后续会将日志信息写入/var/log/message文件中 /proc/meminfo：记录系统的内存信息 /proc/modules：与lsmod命令查看到的模块信息完全一致 /proc/mtrr：负责内存配置的机制 /proc/iomem：主要用于储存配置后所有内存储存的明细信息 /proc/partitions：这个文件可以实时呈现系统目前看到的分区 /proc/数字目录：数字目录很多，它们代表所有目前正在系统中运行的所有程序 /proc/bus：有关该主机上现有总线的所有信息，如输入设备、PCI接口、PCMCIA扩展卡及USB接口信息 /proc/net：存放的都是一些网络相关的虚拟配置文件，都是ASCII文件，可以查看(与ifconfig、arp、netstat等有关) /proc/scsi：保存系统上所有的scsi设备信息(包括sata和usb设备的信息) /proc/sys ：存放系统核心所使用的一些变量，根据不同性质的文件而存放在不同的子目录中，可以通过/etc/sysctl.conf文件设置和更改其默认值；变量时实时的变更，有很多设置很象是开关，设置后马上生效； /proc/tty：存放有关目前可用的正在使用的tty设备的信息 /proc/self：存放到查看/proc的程序的进程目录的符号连接，当2个进程查看proc时，这将会是不同的连接；主要便于程序得到它自己的进程目录； /proc/stat：系统的不同状态信息； /proc/uptime：系统启动的时间长度； /proc/version：系统核心版本； /usr：安装除操作系统本身外的一些应用程序或组件，一般可以认为linux系统上安装的应用程序默认都安装在此目录中 /usr/bin：一般用户有机会使用到的程序，或者该软件默认就是要让所有用户使用才会放在该目录中 /usr/sbin：一些系统有可能会用到的系统命令，与 /sbin 比起来，都是一些较次要的文件； /usr/etc：自行安装或非系统主要的配置文件目录； /usr/games：只要是电脑游戏相关的软件，就都安装到这个目录； /usr/include：存放的文件都是一些系统中用户所会使用到的C语言header文件，保存的都是”.h”的文件； /usr/lib：存放一些函数库、执行文件及连接文件，特别的是，存放在这里面的文件都是不希望直接被用户或shell脚本所使用的文件，在/usr/lib中有非常多的子目录，每一个软件都有其各自所需的函数库； /usr/libexec：这个目录下的文件及文件夹应该都可以放置在/usr/lib下； /usr/local：linux系统中安装的共享软件程序最好的方式是安装在 /usr/local 下，按照linux标准目录结构，新建立的软件都应该放在/usr/local下； /usr/local/bin：存放软件执行文件的目录； /usr/local/sbin：同样存放软件执行文件的目录，但此目录专门针对系统所使用的文件； /usr/local/lib：软件相关的函数库； /usr/local/share：当文件性质不好归属时就会放在此，man手册就放在这个目录下； /usr/local/src：所安装软件的源代码放置在此； /usr/share：此目录都是一些共享信息，最常被用到的就是 /usr/share/man 这个目录，/usr/share 里的信息时跨平台的； /usr/share/doc：放置一些系统帮助文件的地方； /usr/share/man：manpage的文件存放目录，也是使用man查看手册页时查询的路径； /usr/src：主要储存内核源代码的文件； /usr/X11R6：存放一些X windows系统的相关文件； /var：动态文件或数据存放目录，默认日志文件都存放在这个目录下，一般建议把此目录单独划分一个分区； /var/empty：默认是sshd程序用到的这个目录，当建立ssh连接，ssh服务器必须使用该目录下的sshd子目录 /var/ftp：ftp服务器软件一般默认会将匿名登陆的用户的宿主目录； /var/lib：该目录下存放很多与应用程序名称同名的子目录，每个子目录下都是应用执行的状态信息； /var/lock：每个服务一开始都会在这个目录下产生一个该服务的空文件，主要是避免服务启动冲突； /var/log：常用目录，专门用来存放所有日志文件的目录，里面存放很多系统、软件、用户等相关的日志信息；里面有一些文件是比较常用的； lastlog：记录用户最后一次登录的信息，使用lastlog命令读取； message：记录系统的几乎所有信息，主要包括启动信息，syslogd服务记录的信息等； wtmp：记录所有用户登陆及注销的信息，使用last命令读取； secure：记录登录系统访问数据的文件，如ssh pop3 telnet ftp等都会记录在此文件中 btmp：记录失败的用户登录 boot.log：记录开机或一些服务启动时所显示的启动和关闭信息 /var/log/maillog 或 /var/log/mail/*：记录邮件访问或往来的用户信息 cron： 记录 crontab 例行性服务的内容 dmesg：开机引导日志信息 sudolog：纪录使用sudo发出的命令 /var/run：此目录中的大部分文件都记载目前系统正在执行程序的PID值，每一个文件都是以个独立的PID记录；此目录下存放一个特殊文件utmp，此文件记录目前谁在使用系统，必须使用utmpdump命令才能看到其中的内容； /var/spool：里面主要都是一些临时存放，随时会被用户所调用的数据；打印机、邮件、代理服务器等假脱机目录存放在该目录下； /var/tmp：专门为了一些应用程序在安装或执行时，需要在重启后使用的某些文件时，能将该文件暂时存放在这个目录中，完成后再行删除；]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2015%2F03%2F01%2F162610-Hello%20World%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
